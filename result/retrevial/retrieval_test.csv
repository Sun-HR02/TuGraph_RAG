Q,K1,K2,K3
在添加边时，如果指定的值不包含在value_dict中将如何处理？,"page_content='业务开发指南

边类型操作

边类型添加字段

>该操作会同步变更所有该类型边的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于边类型`edge1`，一次添加了两个字段: `field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是`0`.
```
CALL db.alterLabelAddFields('edge', 'edge1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型添加字段'}","page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/relationship/{euid}
```  
与 Nodes 功能类似，Relationships 提供边（edge）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。每一条边都可以由一个唯一 ID（euid）来标识。这个 ID 可以从在插入边时获得，或者在 [列出所有边](#%E5%88%97%E5%87%BA%E6%89%80%E6%9C%89%E8%BE%B9) 操作中得到。  
#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| fields | 数据列名 | 列表 |
| edge | 边数据 | 列表 |  
其中 edge 是一个数据列表，其中每个元素都是一条边，其定义如下：  
| 域名        | 说明     | 类型                                                   |
| ----------- | -------- | ------------------------------------------------------ |
| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}"
在使用LIMIT子句时，如果查询数据库中前两个人的名字，返回的名字是什么？,"page_content='ISO GQL

2.Clauses

2.8.LIMIT

`LIMIT`限制结果行数。  
#### 使用LIMIT  
```
MATCH (n:Person)
RETURN n.name LIMIT 2;
```  
返回结果
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.8.LIMIT'}","page_content='Cypher API

2.Clauses

2.6.LIMIT

- ✓ Return a subset of the records  
```
MATCH (n:person)
RETURN n.name
LIMIT 3
```  
- ❏ Using an expression with LIMIT to return a subset of the records  
```
MATCH (n:person)
RETURN n.name
LIMIT toInteger(3 * rand())+ 1
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.6.LIMIT'}","page_content='Cypher API

2.Clauses

2.5.SKIP

- ✓ Skip first three records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 3
```  
- ✓ Return middle two records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 1
LIMIT 2
```  
- ❏ Using an expression with SKIP to return a subset of the records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP toInteger(3*rand())+ 1
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.5.SKIP'}"
如何查询数据库中现有角色及其相关信息？,"page_content='部署高可用模式

9.查看服务器状态

备份组的当前状态可以在 TuGraph 可视化工具、REST API 以及 Cypher 查询中获取。  
在 TuGraph 可视化工具中，可以在 DBInfo 部分中找到备份组中的服务器及其角色列表。  
使用 REST API 时，可以使用`GET /info/peers` 请求获取信息。  
在 Cypher 中，使用`CALL dbms.listServers()`语句来查询当前备份组的状态信息。' metadata={'Header 1': '部署高可用模式', 'Header 2': '9.查看服务器状态'}","page_content='可视化操作手册

2.操作指南

2.5.控制台

`控制台`提供可视化的的账户管理和数据库信息查看功能，它为用户提供了全面的账户和角色管理功能，包括账户的增删改查以及禁用，角色的增删改查以及禁用。此外，它也为用户提供了便捷的数据库信息查看功能，让用户可以轻松地查看图数据库的基础信息和配置信息。其中，基础信息主要包括版本号、运行时间、CPP编译版本号等，而数据库配置信息则包括端口号、系统功能参数配置等。  
#### 2.5.1.账户管理  
##### 2.5.1.1.账户管理  
###### a.添加账户  
在`账户管理`界面点击`添加`按钮创建新的账户，用户需要输入账户名称、账户描述、账户密码以及相关角色。  
![账户管理-添加账户按钮](../../../images/browser/account-add-button.png)  
- 账户名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 相关角色：新建账户时必须要选择一个角色，在账户添加成功后，系统会自动生成一个与账户名称一样的角色。  
![账户管理-添加账户](../../../images/browser/account-add.png)  
###### b.编辑账户  
在`账户管理`界面点击`添加`按钮创建新的账户，用户可以编辑账户描述、账户密码以及相关角色。  
![账户管理-编辑账户](../../../images/browser/account-edit.png)  
###### c.禁用账户  
在`账户管理`界面点击`禁用`按钮禁止对应的账户登录和访问，点击`启用`按钮开启对应的账户登录和访问权限。  
![账户管理-禁用](../../../images/browser/account-disable.png)
![账户管理-启用](../../../images/browser/account-enable.png)  
###### d.删除账户  
在`账户管理`界面点击`删除`按钮删除对应的账户。  
![账户管理-删除](../../../images/browser/account-delete.png)  
##### 2.5.1.2.角色管理  
###### a.添加角色  
在`角色管理`界面点击`添加`按钮创建新的角色，用户需要输入角色名称、角色描述以及图权限。  
![角色管理-添加角色按钮](../../../images/browser/role-add-button.png)  
- 角色名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图权限：browser支持全部、读、写和无共四类图权限配置。
- 全部：对应图的读和写权限，包含编辑图模型权限（schema）。
- 读写：对应图的写权限，不包含编辑图模型权限（schema）。
- 只读：对应图的读权限。
- 无：无法访问和操作对应图。
- 角色冲突：当两个角色对同一个图有不同图权限，同时对一个账户授权了这两个角色，该账户对该图的图权限为两个角色的并集。  
![角色管理-添加角色](../../../images/browser/role-add.png)  
###### b.编辑角色  
在`角色管理`界面点击`编辑`按钮编辑已有角色，用户可以编辑角色描述以及图权限。  
![角色管理-编辑角色](../../../images/browser/role-edit.png)  
###### c.禁用角色  
在`角色管理`界面点击`禁用`按钮禁止对应的角色，点击`启用`按钮开启对应的角色。禁用角色后，对应角色图访问权限失效。  
- 禁用角色：禁用之后，对应角色图访问权限失效。
- 当一个用户拥有两个角色对同一个图有操作权限时，当禁用其中一个角色时，另一个角色权限同样有效。  
![角色管理-禁用](../../../images/browser/role-disable.png)
![角色管理-启用](../../../images/browser/role-enable.png)  
###### d.删除角色  
在`角色管理`界面点击`删除`按钮删除对应的角色。  
![角色管理-删除](../../../images/browser/role-delete.png)  
#### 2.5.2.数据库信息  
##### 2.5.2.1.基础信息  
`基础信息`获取当前系统运行的状态，并展示关键信息。  
![数据库信息-基础信息](../../../images/browser/db_basic.png)  
|参数    |含义    |
|-------|--------|
|TuGraph版本号|当前TuGraph的版本号，x.x.x|
|运行时间|TuGraph服务启动到现' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.5.控制台'}","page_content='Use Graph

Example

```sql
-- Set current using graph.
USE GRAPH modern;

INSERT INTO tbl_result
SELECT
a.id,
b.id,
c.id,
c.kind,
d.id,
d.type
FROM (
MATCH (a) -> (b) where b.id > 0 and a.lang is null
MATCH (a) <- (c) where label(c) = 'person'
Let c.kind = 'k' || cast(c.age / 10 as varchar)
MATCH (c) -> (d) where d != b
Let d.type = if (label(d) = 'person', 1, 0)
RETURN a, b, c, d
)
;
```' metadata={'Header 1': 'Use Graph', 'Header 2': 'Example'}"
tugraph可以最多创建多少点边和点边上最多创建多少属性？,"page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='TuGraph图模型说明

2. 图项目、点、边、属性命名规则和建议

2.2 使用限制

|**描述**|**最大个数**|
|-------- |--------- |
|用户数、角色数|65536|
|图项目的个数|4096|
|每个图项目的点和边类型数量之和|4096|
|每个点或边类型的属性数量|1024|  
注：
1、特殊字符和关键字说明：使用特殊字符或非保留关键字时，需要使用反单引号/backquote（``）进行引用；  
示例： ```match (`match`:match) return `match`.id limit 1```  
2、大小写敏感性：TuGraph大小写敏感；  
3、图项目、点/边、属性名称之间可以重复使用，同一点或边下的属性名称不可以重复；  
4、属性名字保留关键字：SRC_ID / DST_ID / SKIP' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '2. 图项目、点、边、属性命名规则和建议', 'Header 3': '2.2 使用限制'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属性不会存在相同的值。
由于底层存储设计，组合索引key需要保存属性的长度，因此，
组合唯一索引k' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}"
我下载了4.3.2镜像，启动成功了，进入容器后没有 setup.sh 脚本是改变目录了吗？,"page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

1. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7:${VERSION}
```  
2. 启动docker  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}","page_content='快速上手

2.安装

2.1.通过docker快速体验

1. 本地安装 docker 环境  
参考 docker 官方文档：https://docs.docker.com/get-started/  
2. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7
```  
3. 启动docker  
启动 TuGraph 服务可以通过两种方式来实现。第一种方式将镜像拉取与服务启动整合在一起，用户只需执行运行容器的操作，即可同时启动 TuGraph 服务。第二种方式则是在创建 TuGraph 容器后，手动进入容器内部以触发服务启动。尽管这种方法初期步骤稍显繁琐，但在如忘记密码的情况下，它提供了更灵活的密码重置选项。  
**方式一**  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
**方式二**  
```shell
docker run -dt -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION} /bin/bash

docker exec -it tugraph_demo bash
lgraph_server -c /usr/local/etc/lgraph.json -d start

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
5. 前端访问  
访问tugraph-db-browser: `http://x.x.x.x:7070`，数据库地址格式为 `bolt://ip:bolt_port`（老版本不用填），默认用户名为 `admin`，密码为 `73@TuGraph`。
首次登录会默认跳转修改密码页面，请尽快修改默认密码避免安全风险。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.1.通过docker快速体验'}","page_content='开始上手(GeaFlow Console运行)

准备工作

1. 下载安装[Docker](https://docs.docker.com/engine/install/)，调整Docker服务资源配置（Dashboard-Settings-Resources）后启动Docker服务：  
![docker_pref](../static/img/docker_pref.png)  
2. 拉取GeaFlow Console镜像  
执行以下命令拉取远程geaflow console镜像:  
x86架构拉取x86镜像：
```shell
docker pull tugraph/geaflow-console:0.1
```  
如果是arm架构，拉取arm镜像：
```shell
docker pull tugraph/geaflow-console-arm:0.1
```  
如果遇到网络问题导致拉取失败，也可以通过下面命令直接构建镜像(构建镜像之前需要先启动docker容器,构建脚本根据机器类型build对应类型的镜像):  
```shell
git clone https://github.com/TuGraph-family/tugraph-analytics.git
cd tugraph-analytics/
bash ./build.sh --all

```  
整个编译过程可能持续一段时间，请耐心等待。镜像编译成功后，通过以下命令查看镜像：
```shell
docker images
```
远程拉取的镜像名称为：**tugraph/geaflow-console:0.1**(x86架构) 或者**tugraph/geaflow-console-arm:0.1**(arm架构)
。本地镜像名称为：**geaflow-console:0.1**，只需选择一种方式构建镜像即可。' metadata={'Header 1': '开始上手(GeaFlow Console运行)', 'Header 2': '准备工作'}"
lgraph_server -d start的方式启动，不是会在pwd路径下生成pid文件吗？这个pid文件有参数能控制路径吗？,"page_content='数据库运行

3.服务操作

3.1.启动服务

TuGraph 需要通过 `lgraph_server -d start` 命令行启动，启动命令示例如下：  
```bash
$ ./lgraph_server -d start -c lgraph.json
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.1.启动服务'}","page_content='数据库运行

2.运行模式

2.2.运行进程守护模式

启动命令：  
```shell
$ ./lgraph_server -d start -c lgraph.json
```  
守护模式的运行输出示例：  
```shell
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '2.运行模式', 'Header 3': '2.2.运行进程守护模式'}","page_content='数据迁移

3. 升级迁移

3.3. 启动新服务

使用如下命令启动新服务
```bash
lgraph_server -c /usr/local/etc/lgraph.json --directory db.export -d start
```' metadata={'Header 1': '数据迁移', 'Header 2': '3. 升级迁移', 'Header 3': '3.3. 启动新服务'}"
如果在使用ARM机器（如M1芯片的Mac）编译TuGraph，应该如何修改cmake命令？,"page_content='从源码编译

2.编译介绍

以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`，如果在arm机器编译（如M1芯片的Mac中，需要加上` -DENABLE_BUILD_ON_AARCH64=ON`）
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build
$ cmake .. -DOURSYSTEM=centos7
$ make
$ make package
```' metadata={'Header 1': '从源码编译', 'Header 2': '2.编译介绍'}","page_content='TuGraph-db

3. 从源代码编译

建议在Linux系统中构建TuGraph，Docker环境是个不错的选择。如果您想设置一个新的环境，请参考[Dockerfile]  
以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build
$ cmake .. -DOURSYSTEM=centos7
$ make
$ make package
```' metadata={'Header 1': 'TuGraph-db', 'Header 2': '3. 从源代码编译'}","page_content='TuGraph Management

使用

TuGraph Management使用Maven进行管理，请运行如下命令启动TuGraph Management  
`mvn spring-boot:run`  
TuGraph Management 使用了sofastack框架，并使用brpc与TuGraph进行通信，sofastack默认端口为`6071`，brpc默认端口为`6091`，如需修改服务端口，请修改`./src/main/resources/application.properties`文件中的对应配置项。' metadata={'Header 1': 'TuGraph Management', 'Header 2': '使用'}"
启动参数中cleanup_dir指定的目录用于执行什么操作？,"page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
EXPO' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}","page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

#### 2.3.1.rest  
样例代码中在test_get_info函数执行之前先启动server，server启动后启动了rest client，进入test_get_info函数后获取server的一些信息，并通过assert判断是否有获取到cpu的信息。  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7073 --rpc_port 9093"",
""cleanup_dir"":[""./testdb""]}
RESTTOPT = {""port"":""7073"", ""user"":""admin"", ""password"":""73@TuGraph""}
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""rest"", [RESTTOPT], indirect=True)
def test_get_info(self, server, rest):
res = rest.get_server_info()
log.info(""res : %s"", res)
assert('cpu' in res)
```  
#### 2.3.2.client  
样例代码中在test_flushdb函数执行之前先执行了数据离线导入逻辑，并启动server后，通过client创建链接，进入test_flushdb函数后，通过查询点的个数判断导入是否成功，导入成功后执行flushDB操作，再次通过assert判断是否能正常清空db  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}

CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}

IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}

@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_flushdb(self, importor, server, client):
ret = client.callCypher(""MATCH (n) RETURN n LIMIT 100"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert len(res) == 21
ret = client.callCypher(""CALL db.flushDB()"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}","page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客户端端口。默认端口为 7687。                                ' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}"
使用什么命令来启动 TuGraph？,"page_content='数据库运行

3.服务操作

3.1.启动服务

TuGraph 需要通过 `lgraph_server -d start` 命令行启动，启动命令示例如下：  
```bash
$ ./lgraph_server -d start -c lgraph.json
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.1.启动服务'}","page_content='TuGraph Management

使用

TuGraph Management使用Maven进行管理，请运行如下命令启动TuGraph Management  
`mvn spring-boot:run`  
TuGraph Management 使用了sofastack框架，并使用brpc与TuGraph进行通信，sofastack默认端口为`6071`，brpc默认端口为`6091`，如需修改服务端口，请修改`./src/main/resources/application.properties`文件中的对应配置项。' metadata={'Header 1': 'TuGraph Management', 'Header 2': '使用'}","page_content='快速上手

2.安装

2.1.通过docker快速体验

1. 本地安装 docker 环境  
参考 docker 官方文档：https://docs.docker.com/get-started/  
2. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7
```  
3. 启动docker  
启动 TuGraph 服务可以通过两种方式来实现。第一种方式将镜像拉取与服务启动整合在一起，用户只需执行运行容器的操作，即可同时启动 TuGraph 服务。第二种方式则是在创建 TuGraph 容器后，手动进入容器内部以触发服务启动。尽管这种方法初期步骤稍显繁琐，但在如忘记密码的情况下，它提供了更灵活的密码重置选项。  
**方式一**  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
**方式二**  
```shell
docker run -dt -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION} /bin/bash

docker exec -it tugraph_demo bash
lgraph_server -c /usr/local/etc/lgraph.json -d start

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
5. 前端访问  
访问tugraph-db-browser: `http://x.x.x.x:7070`，数据库地址格式为 `bolt://ip:bolt_port`（老版本不用填），默认用户名为 `admin`，密码为 `73@TuGraph`。
首次登录会默认跳转修改密码页面，请尽快修改默认密码避免安全风险。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.1.通过docker快速体验'}"
TuGraph团队为了提高解析速度所进行的优化包括了哪些主要手段？,"page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

当 TuGraph 遇见 Antlr4

ISO GQL（ISO/IEC 39075）是一种标准化的图数据库查询语言，蚂蚁集团是其主要贡献者之一。因此，Antlr4 作为一种强大的解析器生成器，成为了蚂蚁图数据库 TuGraph 生成 GQL 解释器的理想选择。Antlr4 能够帮助团队更快、更准确地构建图数据库的查询语言，从而提高产品性能和用户体验。  
然而，当我们从开发场景来到生产场景，超高的并发量带来一个严重问题：Antlr4 C++ target 的并发性能不足以支持所需的超高并发 GQL 请求。经过调研并与 Antlr 开源社区讨论，我们发现\*\*并发性能这个问题普遍存在，并且在过去 5 年中持续困扰着 C++生态的开发者。\*\*我们决定解决这个问题。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '当 TuGraph 遇见 Antlr4'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

TuGraph做了哪些工作

在调研讨论的过程中我们发现，多位开发者在论坛提出其耗时甚至多于 Java target 数倍之多。因此，我们决定从问题和开源代码出发，来定位、解决问题。  
这是一个典型的并发程序优化问题，根据以往的程序优化经验，我们分步推进该问题的解决：  
（1）识别问题  
通过对程序运行时的性能数据进行收集和分析，我们找到了程序运行瓶颈所在，通过调用分析，初步将问题定位为数据竞争导致的并发问题。  
（2）深入阅读 Antlr4 开源代码  
接下来，我们对 Antlr4 的源代码进行仔细的阅读和理解，掌握其内部的结构和核心逻辑，找出了核心的数据结构和关键的调用链路。为我们破解性能难题和分析修改的正确性做好了准备。  
（3）梳理数据竞争链路  
根据上述分析，我们判断问题的症结极大概率是数据竞争造成的。形成数据竞争至少有两个条件：一是线程之间共享内存数据，二是至少存在两个线程去读写某个共享内存。  
进一步地，我们通过分析程序中的并发访问情况，找到了可能引发数据竞争的所有代码段和共享变量（主要为 DFA、ATN 等结构），拼接出了数据竞争的完整链路。  
（4）破解数据竞争问题  
数据竞争问题是多线程程序中常见而又复杂的问题，可以考虑通过破解多种竞争条件来解决。就本文问题来说，也存在多种破解方案选择，如何制定最优的解决方案是一项极具挑战的工作，主要难点有两个：  
（i）保证修改后程序的正确性/稳定性  
（ii）保证方案的有效性（低成本）  
反复推演后，我们选择了提交给社区的优化方案，即通过改变关键数据的 ownership 接触对锁的依赖。针对上述两个难点的分析如下：  
经过源码分析并与开源社区讨论，我们确认关键数据结构的初始化构建是非常耗时的，但可以通过“只调用一次”（`call_once`）手段将成本均摊，而后续的增量构建相对开销较低，并且也可均摊。因此该优化方案的低时间成本是可以保证的。  
关于程序正确性的保证，我们通过双重验证来保证。首先在设计之初我们已经从源代码角度，推断出共享数据仍然是安全的，其次我们也设计了实验对此进行了验证，验证结果与我们的分析一致' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': 'TuGraph做了哪些工作'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

贡献和成果

对Antlr4的优化的效果十分显著，32 线程的并发性能提升超过 18 倍 。考虑到实际生产服务器性能远高于测试机型，实际的性能提升效果将比测试结果更高， 优化后 GQL 解析能力已能完全满足企业业务的需要。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '贡献和成果'}"
当中止一个正在执行的任务时，应该使用哪种HTTP请求方法？,"page_content='RESTful API Legacy

6.Deprecated

6.4.任务管理

TuGraph 提供长任务的跟踪和中止功能。用户可以通过 REST API 来查询当前正在运行的在 Cypher 和存储过程查询，并选择中止正在执行的查询。  
任务管理对应的 URI 格式为  
```
http://{host}:{port}/task/{thread_id}/{task_id}
```  
#### 6.4.1.查询正在执行的任务  
- **URI**: `/task`
- **METHOD**: GET
- **RESPONSE**:  
返回的 JSON 为一个数组，其中每一个元素格式如下：  
| 域名         | 说明                         | 类型   |
| ------------ | ---------------------------- | ------ |
| description  | 任务描述                     | 字符串 |
| time_elapsed | 任务已经执行的时间，单位为秒 | 浮点   |
| task_id      | 任务 ID                      | 字符串 |  
**Example request.**  
```
• GET http://localhost:7070/task
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""description"" : ""[CPP_PLUGIN] scan_graph"",
""time_elapsed"" : 13.987,
""task_id"" : ""3_10""
},
{
""description"" : ""[CYPHER] MATCH(n) return n"",
""time_elapsed"" : 30.887,
""task_id"" : ""2_6""
}
]
}
```  
#### 6.4.2.中止任务  
- **URI**: `/task/{task_id}`
其中 `{task_id}` 是 `GET /task` 返回结果中的 `task_id`。
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• DELETE http://localhost:7070/task/3_10
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.4.任务管理'}","page_content='数据迁移

4. 在线迁移

4.3. 停止原节点

停止原节点服务，后续应用请求直接发给新集群
```bash
lgraph_server -c /usr/local/etc/lgraph_ha.json --directory db.cp --ha_conf 192.168.0.1:9090,192.168.0.2:9090,192.168.0.3:9090 -d stop
```' metadata={'Header 1': '数据迁移', 'Header 2': '4. 在线迁移', 'Header 3': '4.3. 停止原节点'}","page_content='TuGraph-Restful-Server

7.接口

7.8 数据导入请求

用户通过此类请求导入已经上传的数据文件。导入不论成功或失败，都将删除已上传文件。数据导入请求在server中实现为一个异步任务，响应返回并不意味着导入已完成，返回的是任务id，后续可以通过此任务id查询导入进度
#### 7.8.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_data
#### 7.8.2 REQUEST
|  body参数  |          参数说明           |  参数类型  | 是否必填 |
|:--------:|:-----------------------:|:------:|:----:|
| graph |         导入目标子图          |  字符串  |  是   |
| schema |       导入schema描述        | json字符串  |  是   |
| delimiter |           分隔符           |  字符串  |  是   |
| continueOnError |     单行数据出错是否跳过错误并继续     |  boolean  |  否   |
| skipPackages |         跳过的包个数          |  字符串  |  否   |
| taskId |  任务id   |  字符串  |  否   |
| other | 其他参数 |  json字符串  |  否   |  
#### 7.8.3 RESPONSE
|    body参数     |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| taskId | 任务编号 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.8 数据导入请求'}"
AllocVertexSubset函数用来做什么？,"page_content='OlapOnDB API

3. 算法举例

3.1 主函数

主函数输入有三个参数，`TuGraph`数据库参数`db`，从网页端获取的请求`request`，给网页端的返回值`response`，整体流程可以分为一下几步：  
1. 相关参数的获取
2. 快照类的创建
3. PageRank算法主流程
4. 网页端返回值的获取和发送  
```C++
extern ""C"" bool Process(GraphDB & db, const std::string & request, std::string & response) {

// 从网页端请求中获取迭代次数（num_iterations），
int num_iterations = 20;
try {
json input = json::parse(request);
num_iterations = input[""num_iterations""].get<int>();
} catch (std::exception & e) {
throw std::runtime_error(""json parse error"");
return false;
}

// 读事务的创建以及快照类的创建
auto txn = db.CreateReadTxn();
OlapOnDB<Empty> olapondb(
db,
txn,
SNAPSHOT_PARALLEL
);

// 创建pr数组用于存储每个节点的pr值
ParallelVector<double> pr = olapondb.AllocVertexArray<double>();
// pagerank算法主流程，获取每个节点的pagerank值
PageRankCore(olapondb, num_iterations, pr);

auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
/*
函数用途：从所有节点中获取pagerank值最大的节点编号

函数流程描述：该函数对点集合all_vertices中所有为1的位对应的节点vi（又称为活跃点）执行Func A，再将Func A的返回值作为Func B的第二个输入参数，得到局部最大值（因为第一个输入参数为0，因此实际上返回值就是每个节点的pagerank值），最后再将所有线程的返回值汇总，再次 执行Func B得到全局返回值，并存入max_pr_vi变量中
*/
size_t max_pr_vi = olapondb.ProcessVertexActive<size_t>(

//Func A
[&](size_t vi) {
return vi;
},
all_vertices,
0,

//Func B
[&](size_t a, size_t b) {
return pr[a] > pr[b] ? a : b;
}
);

// 网页端返回值的获取和发送
json output;
output[""max_pr_vid""] = olapondb.OriginalVid(max_pr_vi);
output[""max_pr_val""] = pr[max_pr_vi];
response = output.dump();
return true;
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.1 主函数'}","page_content='OlapOnDB API

3. 算法举例

3.2 PageRank算法流程

`pagerank`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关数据结构的初始化
1. 每个节点pagerank值的初始化
1. 每个节点pagerank值的计算，活跃点为所有点（意味着所有点都需要计算pagerank值）
1. 得到每个节点经过`num_iterations`次迭代后的pagerank值  
```C++
void PageRankCore(OlapBase<Empty>& graph, int num_iterations, ParallelVector<double>& curr) {

// 相关数据结构的初始化
auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
auto curr = olapondb.AllocVertexArray<double>();
auto next = olapondb.AllocVertexArray<double>();
size_t num_vertices = olapondb.NumVertices();
double one_over_n = (double)1 / num_vertices;

// 每个节点pagerank值的初始化，和该节点的出度成反比
double delta = graph.ProcessVertexActive<double>(
[&](size_t vi) {
curr[vi] = one_over_n;
if (olapondb.OutDegree(vi) > 0) {
curr[vi] /= olapondb.OutDegree(vi);
}
return one_over_n;
},
all_vertices);

// 总迭代过程
double d = (double)0.85;
for (int ii = 0;ii < num_iterations;ii ++) {
printf(""delta(%d)=%lf\n"", ii, delta);
next.Fill((double)0);

/*
函数用途：计算所有节点的pagerank值

函数流程描述：该函数用于计算所有节点的pagerank值，对all_vertices中所有为1的位对应的节点vi执行Func C，得到本轮迭代中vi的pagerank值，并返回vi节点的pagerank变化值，最终经过函数内部处理汇总所有活跃节点的总变化值并返回，该值被存储在delta变量中
*/
delta = graph.ProcessVertexActive<double>(
// Func C
[&](size_t vi) {
double sum = 0;

// 从邻居中获取当前节点的pagerank值
for (auto & edge : olapondb.InEdges(vi)) {
size_t src = edge.neighbour;
sum += curr[src];
}
next[vi] = sum;

// pagerank值计算核心公式
next[vi] = (1 - d) * one_over_n + d * next[vi];
if (ii == num_iterations - 1) {
return (double)0;
} else {

// 相关中间变量统计
if (olapondb.OutDegree(vi) > 0) {
next[vi] /= olapondb.OutDegree(vi);
return fabs(next[vi] - curr[vi]) * olapondb.OutDegree(vi);
} else {
return fabs(next[vi] - curr[vi]);
}
}
},
all_vertices
);

// 将本轮迭代得到的pagerank值输出作为下一轮迭代的输入
curr.Swap(next);
}
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.2 PageRank算法流程'}","page_content='OlapBase API

7. 图类OlapBase

7.2 点集和边集及其相关操作

- `ParallelVector<VertexData> AllocVertexArray<VertexData>()`：分配一个类型为VertexData的数组，大小为点个数
- `void fill_vertex_array<V>(V * array, V value)`：将数组array中的所有元素赋值为value
- `ParallelBitset AllocVertexSubset()`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `AdjList<EdgeData> OutEdges(size_t vid)`：获取点v的所有出边集合
- `AdjList<EdgeData> InEdges(size_t vid)`：获取点v的所有入边集合
- `void Transpose()`：对有向图进行图反转
- `LoadFromArray(char * edge_array, VertexId input_vertices, EdgeId input_edges,  EdgeDirectionPolicy edge_direction_policy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.2 点集和边集及其相关操作'}"
web端导入10G数据报错,"page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

#### 6.10.1.指定文件内容导入  
- **URI**: `/db/{graph_name}/import/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |
| data | 要导入的文件内容（建议最大在 16MB 左右，最长不超过 17MB） | 字符串 / 数组 / 对象 |
| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""description"": ""{\\""files\\"":[{\\""columns\\"":[\\""SRC_ID\\"",\\""role\\"",\\""DST_ID\\""],\\""format\\"":\\""CSV\\"",\\""label\\"":\\""role\\"",\\""SRC_ID\\"":\\""actor\\"",\\""DST_ID\\"":\\""movie\\""}]}""}"",
""data"": ""1,Role1,2\n3,Role2,4\n"",
""continue_on_error"": true,
""delimiter"": "",""
}
```  
上述 description 的值是如下 json 序列化后的字符串  
```json
{
""files"": [
{
""format"": ""CSV"",
""label"": ""role"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""log"": ""Missing src uid 1\n""
}
```  
由于请求中指定了在出错时继续，该返回信息说明 SRC_ID 为 1 的边没有被导入，而其他信息导入成功。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}","page_content='QA汇总

数据导入QA

读取oracle数据报错

Q：读取oracle数据报错
""error_message"":""Error parsing file memory_file_stream\n\tError occurred at offset 0, exception detail:\n\tjson reading failed, error msg : std::bad_cast\n>Error line....""，如何解决？
A：看起来像在处理数据的时候遇到特使符号导致报错的，建议用相对较小的表以及数据可以尝试测一下' metadata={'Header 1': 'QA汇总', 'Header 2': '数据导入QA', 'Header 3': '读取oracle数据报错'}","page_content='安装指南

一键安装

集群配置

配置GeaFlow作业的运行时集群，推荐使用Kubernates。本地模式下默认为本地的代理地址${your.host.name}:8000，请确保本地已经启动minikube并设置好代理地址。如果设置K8S集群地址，请确保集群地址的连通性正常。
![install_cluster_config](../../static/img/install_cluster_config.png)  
K8S集群模式添加以下配置
```
# 存储限制为10Gi
""kubernetes.resource.storage.limit.size"":""10Gi""
# 服务API配置为K8S服务地址，一般为6443端口
""kubernetes.master.url"":""https://${your.host.name}:6443""
# 在K8S集群找到 /etc/kubernetes/admin.conf 配置文件，从上到下分别配置以下三个字段
""kubernetes.ca.data"":""""
""kubernetes.cert.data"":""""
""kubernetes.cert.key"":""""
```' metadata={'Header 1': '安装指南', 'Header 2': '一键安装', 'Header 3': '集群配置'}"
TuGraph支持的导出格式？,"page_content='TuGraph console client

在线数据导出

lgraph_cli 支持流式读取，导出数据只需要把lgraph_cli的输出重定向到文件中即可，导出格式支持csv和json。' metadata={'Header 1': 'TuGraph console client', 'Header 2': '在线数据导出'}","page_content='功能概览

4.核心功能

4.3.数据导入导出

尽管TuGraph本身支持数据的插入，但批量导入能够大幅提升的效率。导入的功能可以分为空库导入（离线导入）和增量导入，前者指子图是空的时候进行导入，额外的假设能够大幅提升导入的性能，在 TuGraph 中，空库导入和增量导入的吞吐率差了10 倍。在数据导出中，需要考虑导出数据的一致性，即是基于一个快照数据导出的。  
TuGraph 可以通过 命令行工具`lgraph_export` 来对已经存放在TuGraph的图数据进行数据导出，导出格式支持CSV和JSON。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.3.数据导入导出'}","page_content='功能概览

6.生态工具

6.1.TuGraph DataX

![导入导出](../../../images/tugraph-datax.png)  
TuGraph 核心支持 CSV 和 JSON 合适的导入导出，提供空库导入和增量导入的模式。实际中会存在 MySQL、Kafka、Hive 等多数据源导入的需求，TuGraph 通过 DataX 做多数据源的对接。由于关系模型和图模型存在的差异，数据清洗的流程可以使用 SparkSQL 快速处理，TuGraph 本身仅关注 CSV 和 JSON 的简单场景导入可靠性和性能。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.1.TuGraph DataX'}"
TuGraph的调优，除了语句前加EXPLAIN和PROFILE还有没有别的方式,"page_content='TuGraph console client

`lgraph_cli`使用

语句以分号结束，输入`exit`, `quit`或者Ctrl-C退出客户端。  
```powershell
lgraph_cli --ip 127.0.0.1 --port 7687 --graph default --user admin --password 73@TuGraph

Welcome to the TuGraph console client. Commands end with ';'.
Copyright(C) 2018-2023 Ant Group. All rights reserved.
Type 'exit', 'quit' or Ctrl-C to exit.

TuGraph> match(n) return n limit 1;
+-------------------------------------------------------------------------------------------------------------------------------------+
| n                                                                                                                                   |
+-------------------------------------------------------------------------------------------------------------------------------------+
| (:person {id:2,born:1961,poster_image:""https://image.tmdb.org/t/p/w185/mh0lZ1XsT84FayMNiT6Erh91mVu.jpg"",name:""Laurence Fishburne""}) |
+-------------------------------------------------------------------------------------------------------------------------------------+

TuGraph>
```  
语句可以中间换行，多行输入。  
```powershell
TuGraph> match(n)
-> return n
-> limit 1;
+-------------------------------------------------------------------------------------------------------------------------------------+
| n                                                                                                                                   |
+-------------------------------------------------------------------------------------------------------------------------------------+
| (:person {id:2,born:1961,poster_image:""https://image.tmdb.org/t/p/w185/mh0lZ1XsT84FayMNiT6Erh91mVu.jpg"",name:""Laurence Fishburne""}) |
+-------------------------------------------------------------------------------------------------------------------------------------+

TuGraph>
```  
非交互式
```powershell

echo ""match(n) return n limit 1;"" | lgraph_cli --ip 127.0.0.1 --port 7687 --graph default --user admin --password 73@TuGraph
+-----------------------------------------------------------' metadata={'Header 1': 'TuGraph console client', 'Header 2': '`lgraph_cli`使用'}","page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

TuGraph 是一个具备多图能力的强模式属性图数据库。在每一张子图中，每种点和边都需要有预定义的数据格式。数据格式由 Label 决定，每种 Label 都有自己的数据格式。用户可以使用 REST API 添加，删除和查询 Label 及其对应的数据格式。  
Label 操作对应的 URI 格式为  
```
http://{host}:{port}/db/{graph_name}/label/{type}/{label_name}
```  
其中{type}可以是 node 或者 relationship。  
#### 6.6.1.创建Label  
创建 Label 的过程同时也是定义其数据类型的过程。只有创建了 Label 才能在图中插入相应类型的点或者边。  
- **URI**: `/db/{graph_name}/label`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | Label 名 | 字符串 |
| fields | 数据列定义 | 列表 |
| is_vertex | 是否是点 Label | 布尔值 |
| primary | 点的主键属性 | 字符串 |
| edge_constraints | 边的约束 | 列表 |  
`primary` 在 `is_vertex` 为 `true` 的时候设置，这个字段只有点才有, 创建点的时候必须设置。  
`edge_constraints` 在 `is_vertex` 为 `false` 的时候设置，这个字段只有边有。这个字段限制了该边的起点和终点只能是哪些点的组合，比如：`[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]`，限制了该边只能是从 `vertex_label1` 到 `vertex_label2` 和 从 `vertex_label3` 到 `vertex_label4`。如果不想有任何限制，不设置该字段即可。  
其中`fields`为一个数组，其中每个元素定义数据的一列，内容如下：  
| 域名     | 说明                                     | 类型                                                                                                |
| -------- | ---------------------------------------- | --------------------------------------------------------------------------------------------------- |
| name     | 列名                                     | 字符串                                                                                              |
| type     | 列数据类型                               | 字符串，有以下类型： int8, int16, int32, int64, float, double, string, date, datetime, binary, bool |
| optional | 数据是否可以为空（可选，缺省值为 false） | 布尔值                                                                                              |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/label
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""name"":""Actor"",
""fields"": [
{""name"":""uid"", ""type"":""int64"", ""optional"":false},
{""name"":""name"", ""type"":""st' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}","page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}"
RpcSingleClient 构造函数需要哪些参数？,"page_content='RPC API

3.登录

登录请求信息包含以下参数：
- user: 必要参数，用户名
- pass: 必要参数，密码
以C++为例，用户使用构建好的服务存根发送登录请求：
```C++
auto* req = request.mutable_acl_request();
auto* auth = req->mutable_auth_request()->mutable_login();
auth->set_user(user);
auth->set_password(pass);
// send data
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req->set_client_version(server_version);
req->set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), req, &resp, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
token = res.acl_response().auth_response().token();
```
登录响应信息包含以下参数：
- token: 必要参数，登录成功会收到带有签名的令牌，即 Json Web Token，客户端储存该令牌，并且用于以后的每次发送请求。
如果登录失败会收到“Authentication failed”错误。' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}","page_content='RPC API

4.查询

用户可以通过Cypher查询和TuGraph进行绝大多数的交互，Cypher请求信息包含以下参数：
- query: 必要参数，Cypher查询语句
- param_names: 可选参数，参数名
- param_values: 可选参数，参数值
- result_in_json_format: 必要参数，查询结果是否以JSON格式返回
- graph: 可选参数，Cypher语句执行的子图名称
- timeout: 可选参数，Cypher语句执行的超时时间  
以C++为例，用户发送Cypher请求的方式如下所示：
```C++
LGraphResponse res;
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
LGraphRequest req;
req.set_client_version(server_version);
req.set_token(token);
lgraph::CypherRequest* cypher_req = req.mutable_cypher_request();
cypher_req->set_graph(graph);
cypher_req->set_query(query);
cypher_req->set_timeout(timeout);
cypher_req->set_result_in_json_format(true);
LGraphRPCService_Stub stub(channel.get());
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
server_version = std::max(server_version, res.server_version());
CypherResponse cypher_res = res.cypher_response();
```
Cypher请求响应为以下两个参数之一：
- json_result: JSON格式的cypher查询结果
- binary_result: CypherResult格式的cypher查询结果' metadata={'Header 1': 'RPC API', 'Header 2': '4.查询'}","page_content='RPC API

5.存储过程

5.2.调用存储过程

调用存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称
- param: 必要参数，存储过程参数
- result_in_json_format: 可选参数，调用结果是否以JSON格式返回
- in_process: 可选参数，未来支持
- timeout: 可选参数，调用存储过程的超时时间  
以C++为例，用户调用存储过程的方式如下所示：
```C++
LGraphRequest req;
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
lgraph::CallPluginRequest *cpRequest = pluginRequest->mutable_call_plugin_request();
cpRequest->set_name(procedure_name);
cpRequest->set_in_process(in_process);
cpRequest->set_param(param);
cpRequest->set_timeout(procedure_time_out);
cpRequest->set_result_in_json_format(json_format);
LGraphResponse res;
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
if (json_format) {
result = res.mutable_plugin_response()->mutable_call_plugin_response()->json_result();
} else {
result = res.mutable_plugin_response()->mutable_call_plugin_response()->reply();
}
```
调用存储过程的响应为以下两个参数之一：
- reply: ByteString格式的存储过程调用结果
- json_result: JSON格式的存储过程调用结果' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.2.调用存储过程'}"
Cython是如何导入与Olap相关的模块和图数据库模块的？,"page_content='Python Olap API

5. lgraph_db API

见procedures/algo_cython/lgraph_db.pxd与lgraph_db_python.py文件。  
lgraph_db.pxd中接口用法与功能基本与C++接口相同，lgraph_db.pxd中声明的接口都由C++实现，在py文件中必须通过`from cython.cimports.olap_base import *`的方式导入，由Cython编译py文件后才能运行。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API'}","page_content='Python Olap API

4. Olap API

见procedures/algo_cython/olap_base.pxd文件，用法与功能基本与C++接口相同，olap_base.pxd中声明的接口都由C++实现，在py文件中必须通过`from cython.cimports.olap_base import *`的方式导入，由Cython编译py文件后才能运行。' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API'}","page_content='Python Olap API

3. Cython

Cython是一种高效的编程语言，是Python的超集。Cython能将py文件翻译为C/C++代码后编译为Python拓展类，在Python中通过import调用。在TuGraph中，所有的Python plugin都由Cython编译为Python拓展类后使用。  
Cython的Pure Python模式在保证Python语法的同时具有C/C++的性能，TuGraph Python接口均使用Cython实现。  
[Cython 文档](https://cython.readthedocs.io/en/latest/index.html)' metadata={'Header 1': 'Python Olap API', 'Header 2': '3. Cython'}"
在调用db.addEdgeIndex时，'unique'参数和'pair_unique'参数有何不同？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.addEdgeIndex(label_name, field_name, unique, pair_unique)

create an index on some field of one edge label .  
**Parameters:**  
| parameter | parameter type | description               |
| ---------- | -------------- | ------------------------------------- |
| label_name | string     | name of the label             |
| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |
| pair_unique | boolean    | Specifies whether the index is pair_unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.addEdgeIndex('BornIn', 'id', true, false)
```  
**Example output:**  
```
Added index [BornIn:id]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addEdgeIndex(label_name, field_name, unique, pair_unique)'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}"
图数据库相比于关系型数据库有什么优势？,"page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.2. 兼容性

现实中，项目进程通常不断演变，数据的内容甚至数据格式也在不断变化。在关系型数据库中，这意味着表结构的变化或建立多个新表，对源数据的修改非常大。而在图数据库中，仅需添加新的点、边和属性，并将其设置为对应的类型即可。从本质上说，一个表代表一种类型的数据，一个点代表一个特定的数据。这意味着关系型数据库更关注数据类型，而图数据库更关注数据个体及其关联关系。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.2. 兼容性'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.1. 性能

在关联关系处理上，使用关系型数据库不可避免地要使用表的JOIN操作，这会对性能产生较大影响；而图数据库则直接跳转访问类指针，操作关联数据的效率更高，比关系型数据库提高2到4个数量级的性能。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.1. 性能'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.3. 直观性

使用图的方式表达现实世界的关系更直接和自然，在万物互联的时代尤为突出。如果使用关系型数据，先建立实体表，再建立关系表，最后映射数据，需要高度的抽象思维。在图数据上进行分析查询时，可以直观地通过点边连接的拓扑结构找到所需数据，无需任何专业知识。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.3. 直观性'}"
在创建节点的时候，报错：message: Vertex unique index value [xxx] is too long，是属性值太长了吗？,"page_content='业务开发指南

点类型操作

创建点类型

如下json定义了一个点类型，名字是`node1`。
```json
{
""label"": ""node1"",
""primary"": ""id"",
""type"": ""VERTEX"",
""detach_property"": true,
""properties"": [{
""name"": ""id"",
""type"": ""INT32"",
""optional"": false
}, {
""name"": ""name"",
""type"": ""STRING"",
""optional"": false,
""index"": true
}, {
""name"": ""num"",
""type"": ""INT32"",
""optional"": false,
""index"": true,
""unique"": true
}, {
""name"": ""desc"",
""type"": ""STRING"",
""optional"": true
}]
}

```
把上面这个json序列化成字符串，作为参数传入，建议使用驱动的参数化特性，避免自己拼接语句。
```
CALL db.createVertexLabelByJson($json_data)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '点类型操作', 'Header 3': '创建点类型'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.addIndex(label_name, field_name, unique)

create an index on some field of one vertex label .  
**Parameters:**  
| parameter | parameter type | description               |
| ---------- | -------------- | ------------------------------------- |
| label_name | string     | name of the label             |
| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.addIndex('Person', 'id', true)
```  
**Example output:**  
```
Added index [Perosn:id]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addIndex(label_name, field_name, unique)'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属性不会存在相同的值。
由于底层存储设计，组合索引key需要保存属性的长度，因此，
组合唯一索引k' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}"
使用 GET 方法获取具体边属性时，如果边不存在该属性，会返回什么错误代码？,"page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/relationship/{euid}
```  
与 Nodes 功能类似，Relationships 提供边（edge）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。每一条边都可以由一个唯一 ID（euid）来标识。这个 ID 可以从在插入边时获得，或者在 [列出所有边](#%E5%88%97%E5%87%BA%E6%89%80%E6%9C%89%E8%BE%B9) 操作中得到。  
#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| fields | 数据列名 | 列表 |
| edge | 边数据 | 列表 |  
其中 edge 是一个数据列表，其中每个元素都是一条边，其定义如下：  
| 域名        | 说明     | 类型                                                   |
| ----------- | -------- | ------------------------------------------------------ |
| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}","page_content='Sampling API

3. 图采样算子介绍

3.3.Nagetive算子：

采用负采样算法，生成不存在边的子图。
```python
Process(db_: lgraph_db_python.PyGraphDB, olapondb: lgraph_db_python.PyOlapOnDB, feature_num: size_t, num_samples: size_t, NodeInfo: list, EdgeInfo: list)
```
参数列表：
db_: 图数据库实例。
olapondb: 图分析类。
feature_num: size_t类型，feature特征向量的长度。
num_samples: size_t类型，生成不存在边的数量。
NodeInfo: list类型，点属性字典的列表，表示点的元数据信息。
EdgeInfo: list类型，边属性字典的列表，表示边的元数据信息。
返回值： 无。' metadata={'Header 1': 'Sampling API', 'Header 2': '3. 图采样算子介绍', 'Header 3': '3.3.Nagetive算子：'}","page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}"
TuGraph针对不同用户的需求提供了哪些类型的系统环境？,"page_content='环境和版本选择

1. 简介

TuGraph为不同需求的用户提供了差异化的系统环境和部署方式，来满足新手、系统开发者、生产运维人员、研究人员等不同用户的需求。' metadata={'Header 1': '环境和版本选择', 'Header 2': '1. 简介'}","page_content='环境分类

2.依赖系统库

针对三种环境，除去TuGraph的运行包，所需要的系统库如下：
* 编译环境，包括gcc、python、java等编译器，也包含antlr4、pybind11等，具体参见tugraph-db源码目录 ci/images/tugraph-compile-*-Dockerfile。
* 运行环境，主要由存储过程引入，包括gcc、boost、cmake等，具体参见tugraph-db源码目录 ci/images/tugraph-runtime-*-Dockerfile。
* 精简运行环境，无，可以参见tugraph-db源码目录 ci/images/ tugraph-mini-runtime-*-Dockerfile。' metadata={'Header 1': '环境分类', 'Header 2': '2.依赖系统库'}","page_content='环境分类

1.分类

根据环境所承载功能的不同，区分为编译环境，运行环境，以及精简运行环境。
* 编译环境，具备TuGraph编译的所有依赖库，包含运行环境的所有依赖，并且能够编译TuGraph源码，但不包含预编译好的TuGraph可执行文件和库文件，供开发者编译源码使用。
* 运行环境，具备GCC/Java/Python环境，能够运行TuGraph的所有功能，并且能承载全文索引，java client，c++源码上传为plugin，以及python plugin的完整功能，内置TuGraph预编译好的可执行文件和库文件，供客户直接安装使用，无需编译源码。
* 精简运行环境，约等于裸系统加预编译TuGraph，仅能运行TuGraph的基本功能，无C++ plugin编译运行，仅so上传，无全文索引，无python plugin，供快速搭建试用。  
TuGraph编译后，会把所有的依赖库以.a的形式打包在一起，因此原则上运行不需要的其他的依赖库。但TuGraph支持存储过程，即在服务端编译C++代码，因此在环境中依然需要涉及的编译器。' metadata={'Header 1': '环境分类', 'Header 2': '1.分类'}"
TuGraph-DB新增支持的空间数据类型有哪些？,"page_content='空间数据类型在TuGraph-DB中的实现

定义空间数据类型

TuGraph-DB当前已经支持Point、Linestring与Polygon三种类型  
-   • Point：点，创建方式例如POINT(2.0, 2.0, 7203)  
-   • Linestring：折线，创建方式例如LINESTRING(0 2,1 1,2 0)  
-   • Polygon：多边形，创建方式例如POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '定义空间数据类型'}","page_content='空间数据类型在TuGraph-DB中的实现

需求分析

结合上述案例，我们可以分析总结出对空间数据类型的需求:  
-   •支持不同坐标系下（包括地球地理坐标系，平面几何坐标系等）不同空间数据类型（包括Point、LineString,、Polygon）的存储与创建  
-   •支持不同坐标系下的常见空间查询操作, 包括Distance、BoundingBox、Disjoint（判断两个数据是否相交）的查询等  
-   •支持空间数据索引（R-Tree）  
-   •支持常见空间数据格式的导入（ESRI Shapefile data / OpenStreetMap）  
-   •支持空间数据的可视化' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '需求分析'}","page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

OGC(Open Geospatial Consortium) 定义了空间数据的标准表示格式，分别为EWKT(extended well known text)与EWKB(extended well known binary)格式，用于在不同系统和平台之间交换和存储空间数据，现已被广泛采用。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现'}"
在CREATE LABEL命令中，如果要创建一个顶点标签，主要属性名称应该由哪个参数确定？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.createLabel(label_type, label_name, extra, field_spec...)

Create a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| extra      | string     | for edge, it means constraints; for vertex, it means primary property |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.
for edge, `extra` should be a json array string, like this `[[""label1"",""label2""], [""label3"",""label4""]]`, if edge has no constraints, give an empty json array, like this `[]`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createLabel('vertex', 'new_label', 'id', ['id','int32',false], ['name','string', true]);
CALL db.createLabel('edge', 'new_edge', '[[""id1"",""id2""]]', ['id','int32',false], ['name', 'string', true]);
```  
**Example output:**  
```
Vertex label [new_label] successfully added.
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createLabel(label_type, label_name, extra, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createEdgeLabel( label_name, field_spec...)

Create an edge label.  
**Parameters:**  
| parameter  | parameter type | description          |
| ---------- | -------------- | ------------------------ |
| label_name | string     | name of the label    |
| edge_constraints | string | edge constraints |
| field_spec | list       | specification of a field |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`, where optional is specified as true, only for  optional fields.  
`edge_constraints` is a json array string, This parameter limits the combination of starting and ending vertex of the edge, for example: `'[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]'`, which limits the edge direction can only be from `vertex_label1` to `vertex_label2` or from `vertex_label3` to `vertex_label4`. If you don't want to have any constraints, give an empty array string, like this `'[]'`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createEdgeLabel('KNOWS', '[]', 'name', 'int32', true)
```  
**Example output:**  
```
Added type [KNOWS]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createEdgeLabel( label_name, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createVertexLabel(label_name, primary_field, field_spec...)

Create a vertex label.  
**Scope:** whole instance.  
**Parameters:**  
| parameter  | parameter type | description          |
| ---------- | -------------- | ------------------------ |
| label_name | string     | name of  vertex label    |
| primary_field | string  | primary field of vertex label |
| field_spec | list       | specification of a field |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, true]`, where true is specified only for optional fields.  
**Output:** If successful, it returns a success message.  
**Example input:**  
```
CALL db.createVertexLabel('Person', 'id', 'id', 'int64', false, 'name', 'string', true)
```  
**Example output:**  
```
Added label [Person]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createVertexLabel(label_name, primary_field, field_spec...)'}"
在HA模式下，client可以向谁发送导入点边数据请求？,"page_content='Java客户端

2.使用示例

2.14.从文件中导入点边数据

```java
boolean ret = client.importDataFromFile(""./test/data/yago.conf"", "","", true, 16, 0, ""default"", 1000000000);
log.info(""importDataFromFile : "" + ret);
```
```
@param confFile: data file contain format description and data
@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param skipPackages: skip packages number
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromFile(String confFile, String delimiter, boolean continueOnError, int threadNums,
int skipPackages, String graph, double timeout) throws IOException, UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.14.从文件中导入点边数据'}","page_content='Java客户端

2.使用示例

2.12.从字节流中导入点边数据

```java
boolean ret = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000);
log.info(""importDataFromContent : "" + ret);
```
```
@param desc: data format description
@param data: the data to be imported
@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromContent(String desc, String data, String delimiter, boolean continueOnError,
int threadNums, String graph, double timeout) throws UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='Python客户端

3.RPC Client

3.14.从文件中导入点边数据

```python
ret, res = client.importDataFromFile(""./test/data/yago.conf"", "","", true, 16, 0, ""default"", 1000000000)
```
```
importDataFromFile(self: liblgraph_client_python.client, conf_file: str, delimiter: str, continue_on_error: bool, thread_nums: int, skip_packages: int, graph: str, json_format: bool, timeout: float) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.14.从文件中导入点边数据'}"
在只读事务中调用 SetFields 方法会抛出什么异常？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='Procedure API

5.Procedure v2接口

5.1.编写存储过程

用户可以通过使用 lgraph API 来编写 C++ 存储过程。一个简单的 C++ 存储过程举例如下：  
```c++
// peek_some_node_salt.cpp
#include <cstdlib>
#include ""lgraph/lgraph.h""
#include ""lgraph/lgraph_types.h""
#include ""lgraph/lgraph_result.h""

#include ""tools/json.hpp""

using json = nlohmann::json;
using namespace lgraph_api;

extern ""C"" LGAPI bool GetSignature(SigSpec &sig_spec) {
sig_spec.input_list = {
{.name = ""limit"", .index = 0, .type = LGraphType::INTEGER},
};
sig_spec.result_list = {
{.name = ""node"", .index = 0, .type = LGraphType::NODE},
{.name = ""salt"", .index = 1, .type = LGraphType::FLOAT}
};
return true;
}

extern ""C"" LGAPI bool ProcessInTxn(Transaction &txn,
const std::string &request,
Result &response) {
int64_t limit;
try {
json input = json::parse(request);
limit = input[""limit""].get<int64_t>();
} catch (std::exception &e) {
response.ResetHeader({
{""errMsg"", LGraphType::STRING}
});
response.MutableRecord()->Insert(
""errMsg"",
FieldData::String(std::string(""error parsing json: "") + e.what()));
return false;
}

response.ResetHeader({
{""node"", LGraphType::NODE},
{""salt"", LGraphType::FLOAT}
});
for (size_t i = 0; i < limit; i++) {
auto r = response.MutableRecord();
auto vit = txn.GetVertexIterator(i);
r->Insert(""node"", vit);
r->Insert(""salt"", FieldData::Float(20.23*float(i)));
}
return true;
}
```  
从代码中我们可以看到：
- 存储过程定义了一个获取签名的方法`GetSignature`。该方法返回了存储过程的签名，其中包含输入参数名称及其类型，返回参数及其类型。这使得Cypher查询语句在调用存储过程能够利用签名信息校验输入数据以及返回数据是否合理。
- 入口函数是`ProcessInTxn`函数，它的参数有三个，分别为：  
- `txn`: 存储过程所处的事务，通常来说即调用该存储过程的Cypher语句所处事务。
- `request`: 输入数据，其内容为`GetSignature`中定义的输入参数类型及其Cypher查询语句中传入的值经过json序列化后的字符串。e.g. `{num_iteration: 10}`
- `response`: 输出数据，为保证在Cypher语言中能够兼容，用户可以通过往`lgraph_api::Result` 写入存储过程处理后的数据，最后用`lgraph_api::Result::Dump`来序列化成json格式的数据。  
`ProcessInTxn`函数的返回值是一个布尔值。当它返回`true`的时候，表示该请求顺利完成，反之表示这个存储过程在执行过程中发现了错误。  
C++存储过程编写完毕后需要编译成动态链接库。TuGraph 提供了`compile.sh`脚本来帮助用户自动编译存储过程。`compile.sh`脚本只有一个参数，是该存储过程的名称，在上面的例子中就是`custom_pagerank`。编译调用命令行如下：  
```bash
g++ -fno-gnu-unique -fPIC -g --std=c++14 -I/usr/lo' metadata={'Header 1': 'Procedure API', 'Header 2': '5.Procedure v2接口', 'Header 3': '5.1.编写存储过程'}","page_content='Java客户端

2.使用示例

2.8.加载存储过程

```java
boolean result = client.loadProcedure(""./test/procedure/khop.so"", ""CPP"", ""khop"", ""SO"", ""test loadprocedure"", true, ""v1"", ""default"");
log.info(""loadProcedure : "" + result);
```
```
@param sourceFile: the source_file contain procedure code
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param codeType: code type, currently supported PY, SO, CPP, ZIP
@param procedureDescription: procedure description
@param readOnly: procedure is read only or not
@param version: The version of procedure
@param graph: the graph to query.
@return: the result of procedure execution
public boolean loadProcedure(String sourceFile, String procedureType, String procedureName, String codeType,
String procedureDescription, boolean readOnly, String version, String graph) throws Exception
```
本接口支持在单机模式和HA模式下使用。其中，由于加载存储过程是写请求，HA模式下的client只能向leader发送加载存储过程请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.8.加载存储过程'}"
GetVertexIndexIterator函数在liblgraph_python_api.Transaction中用于获取什么类型的迭代器？,"page_content='Python Olap API

5. lgraph_db API

Transaction：

```
GetVertexIndexIterator(
label: std::string,
field: std::string,
key_start: std::string,
key_end: std::string)-> VertexIndexIterator
```
获取索引迭代器。迭代器的field值为 [key_start, key_end]。所以在key_start=key_end=v时，返回指向field值为v的点的迭代器  
lgraph_db_python.py是lgraph_db.pxd中C++类 Galaxy与GraphDB的包装，将C++类包装为Python类，将lgraph_db_python.py编译为Python拓展后，可以直接在Python文件或Python命令行中`import lgraph_db_python`访问lgraph_db_python.PyGraphDB与PyGraphDB.PyGalaxy。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Transaction：'}","page_content='Python Olap API

5. lgraph_db API

VertexIndexIterator

- `GetVid()-> int64_t`: 获取点的vid' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'VertexIndexIterator'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends GraphSnapShot<K, VV, EV> {
/** 获取开始图遍历的点 */
Travers' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
db.importor.dataImportor 函数在导入数据时是否可以指定错误继续执行和线程数？,"page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

#### 6.10.1.指定文件内容导入  
- **URI**: `/db/{graph_name}/import/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |
| data | 要导入的文件内容（建议最大在 16MB 左右，最长不超过 17MB） | 字符串 / 数组 / 对象 |
| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""description"": ""{\\""files\\"":[{\\""columns\\"":[\\""SRC_ID\\"",\\""role\\"",\\""DST_ID\\""],\\""format\\"":\\""CSV\\"",\\""label\\"":\\""role\\"",\\""SRC_ID\\"":\\""actor\\"",\\""DST_ID\\"":\\""movie\\""}]}""}"",
""data"": ""1,Role1,2\n3,Role2,4\n"",
""continue_on_error"": true,
""delimiter"": "",""
}
```  
上述 description 的值是如下 json 序列化后的字符串  
```json
{
""files"": [
{
""format"": ""CSV"",
""label"": ""role"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""log"": ""Missing src uid 1\n""
}
```  
由于请求中指定了在出错时继续，该返回信息说明 SRC_ID 为 1 的边没有被导入，而其他信息导入成功。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}","page_content='Java客户端

2.使用示例

2.12.从字节流中导入点边数据

```java
boolean ret = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000);
log.info(""importDataFromContent : "" + ret);
```
```
@param desc: data format description
@param data: the data to be imported
@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromContent(String desc, String data, String delimiter, boolean continueOnError,
int threadNums, String graph, double timeout) throws UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='Java客户端

2.使用示例

2.14.从文件中导入点边数据

```java
boolean ret = client.importDataFromFile(""./test/data/yago.conf"", "","", true, 16, 0, ""default"", 1000000000);
log.info(""importDataFromFile : "" + ret);
```
```
@param confFile: data file contain format description and data
@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param skipPackages: skip packages number
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromFile(String confFile, String delimiter, boolean continueOnError, int threadNums,
int skipPackages, String graph, double timeout) throws IOException, UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.14.从文件中导入点边数据'}"
在尝试读取一个已完成索引构建的顶点时，应该使用哪个函数？,"page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.2.构建采样器

训练过程中，首先使用GetDB算子从数据库中获取图数据并转换成所需数据结构，具体代码如下：
```python
GetDB.Process(db_: lgraph_db_python.PyGraphDB, olapondb: lgraph_db_python.PyOlapOnDB, feature_num: size_t, NodeInfo: list, EdgeInfo: list)
```
如代码所示，结果存储在NodeInfo和EdgeInfo中。NodeInfo和EdgeInfo是python list结果，其存储的信息结果如下：  
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |  
然后构建采样器
```python
batch_size = 5
count = 2708
sampler = TugraphSample(args)
dataloader = dgl.dataloading.DataLoader(fake_g,
torch.arange(count),
sampler,
batch_size=batch_size,
num_workers=0,
)
```' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.2.构建采样器'}","page_content='业务开发指南

边类型操作

边类型添加索引

>该操作会同步构建索引数据，数据量大的时候，有时间消耗。  
如下例子，对于边类型`edge1`，给字段`field1`添加了一个非唯一索引。
```
CALL db.addEdgeIndex('edge1', 'field1', false, false)
```
如下例子，对于边类型`edge1`，给字段`field2`添加了一个唯一索引。
```
CALL db.addEdgeIndex('edge1', 'field2', true, false)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型添加索引'}","page_content='业务开发指南

点类型操作

点类型添加索引

>该操作会同步构建索引数据，数据量大的时候，有时间消耗。  
如下例子，对于点类型`node1`，给`field1`字段添加了一个非唯一索引。
```
CALL db.addIndex('node1', 'field1', false)
```
如下例子，对于点类型`node1`，给`field2`字段添加了一个唯一索引。
```
CALL db.addIndex('node1', 'field2', true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '点类型操作', 'Header 3': '点类型添加索引'}"
在调用函数DeleteGraph时，如果操作未被授权会抛出什么异常？,"page_content='RPC API

5.存储过程

5.3.删除存储过程

删除存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称  
以C++为例，用户删除存储过程的方式如下所示：
```C++
LGraphRequest req;
req.set_is_write_op(true);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
lgraph::DelPluginRequest* dpRequest = pluginRequest->mutable_del_plugin_request();
dpRequest->set_name(procedure_name);
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
删除存储过程的响应不包含参数，如果删除失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.3.删除存储过程'}","page_content='Java客户端

2.使用示例

2.10.删除存储过程

```java
String result = client.deleteProcedure(""CPP"", ""sortstr"", ""default"");
log.info(""loadProcedure : "" + result);
```
```
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param graph: the graph to query.
@return: the result of procedure execution
public boolean deleteProcedure(String procedureType, String procedureName, String graph) throws Exception
```
本接口支持在单机模式和HA模式下使用。其中，由于删除存储过程是写请求，HA模式下的client只能向leader发送删除存储过程请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.10.删除存储过程'}","page_content='Cypher API

5.附录2. 内置procedures列表

* dbms.graph.deleteGraph(graph_name)

delete a subgraph in this graph database .  
| parameter  | parameter type | description              |
| ---------- | -------------- | ------------------------------------ |
| graph_name | string     | the name of subgraph to been deleted |  
**Output:**  
if successful , it will return true.  
**Example input:**  
```
CALL dbms.graph.deleteGraph('graph1')
```  
**Example output:**  
| success |
| ------- |
| true    |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* dbms.graph.deleteGraph(graph_name)'}"
在初始化每个节点的pagerank值时，当节点的出度大于0，pagerank值是如何计算的？,"page_content='OlapOnDB API

3. 算法举例

3.2 PageRank算法流程

`pagerank`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关数据结构的初始化
1. 每个节点pagerank值的初始化
1. 每个节点pagerank值的计算，活跃点为所有点（意味着所有点都需要计算pagerank值）
1. 得到每个节点经过`num_iterations`次迭代后的pagerank值  
```C++
void PageRankCore(OlapBase<Empty>& graph, int num_iterations, ParallelVector<double>& curr) {

// 相关数据结构的初始化
auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
auto curr = olapondb.AllocVertexArray<double>();
auto next = olapondb.AllocVertexArray<double>();
size_t num_vertices = olapondb.NumVertices();
double one_over_n = (double)1 / num_vertices;

// 每个节点pagerank值的初始化，和该节点的出度成反比
double delta = graph.ProcessVertexActive<double>(
[&](size_t vi) {
curr[vi] = one_over_n;
if (olapondb.OutDegree(vi) > 0) {
curr[vi] /= olapondb.OutDegree(vi);
}
return one_over_n;
},
all_vertices);

// 总迭代过程
double d = (double)0.85;
for (int ii = 0;ii < num_iterations;ii ++) {
printf(""delta(%d)=%lf\n"", ii, delta);
next.Fill((double)0);

/*
函数用途：计算所有节点的pagerank值

函数流程描述：该函数用于计算所有节点的pagerank值，对all_vertices中所有为1的位对应的节点vi执行Func C，得到本轮迭代中vi的pagerank值，并返回vi节点的pagerank变化值，最终经过函数内部处理汇总所有活跃节点的总变化值并返回，该值被存储在delta变量中
*/
delta = graph.ProcessVertexActive<double>(
// Func C
[&](size_t vi) {
double sum = 0;

// 从邻居中获取当前节点的pagerank值
for (auto & edge : olapondb.InEdges(vi)) {
size_t src = edge.neighbour;
sum += curr[src];
}
next[vi] = sum;

// pagerank值计算核心公式
next[vi] = (1 - d) * one_over_n + d * next[vi];
if (ii == num_iterations - 1) {
return (double)0;
} else {

// 相关中间变量统计
if (olapondb.OutDegree(vi) > 0) {
next[vi] /= olapondb.OutDegree(vi);
return fabs(next[vi] - curr[vi]) * olapondb.OutDegree(vi);
} else {
return fabs(next[vi] - curr[vi]);
}
}
},
all_vertices
);

// 将本轮迭代得到的pagerank值输出作为下一轮迭代的输入
curr.Swap(next);
}
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.2 PageRank算法流程'}","page_content='内置算法

基础算法包

网页排序

网页排序程序实现了常用的Pagerank算法。该算法根据图中边和边权值计算所有点的重要性排名，PageRank值越高，表示该点在图中的重要性越高。计算时以点数量的倒数为各点初始Rank值，然后将点的Rank值按照出边平均传递到相邻点，重复该传递过程直到满足给定的收敛阈值或达到给定迭代轮数。每轮传递结束后，所有点的Rank值会有一定的的比例随机传递到任意点上。算法内容请参考 [https://en.wikipedia.org/wiki/PageRank](https://en.wikipedia.org/wiki/PageRank ""pagerank wiki"")。' metadata={'Header 1': '内置算法', 'Header 2': '基础算法包', 'Header 3': '网页排序'}","page_content='内置算法

扩展算法包

个性化网页排序

个性化网页排序程序实现了Personalized PageRank算法。该算法根据给定的源点，基于该源点个性化计算所有点对于源点的重要性排名。Rank值越高，表示该点对于源点越重要。与PageRank不同的是，初始化时源点Rank值为1，其余点Rank值为0；并且每轮传递结束后，Rank值会有一定的比例随即传递回源点。算法内容请参考 [https://cs.stanford.edu/people/plofgren/Fast-PPR_KDD_Talk.pdf](https://cs.stanford.edu/people/plofgren/Fast-PPR_KDD_Talk.pdf)。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': '个性化网页排序'}"
TuGraph 支持哪些数据导出格式？,"page_content='TuGraph console client

在线数据导出

lgraph_cli 支持流式读取，导出数据只需要把lgraph_cli的输出重定向到文件中即可，导出格式支持csv和json。' metadata={'Header 1': 'TuGraph console client', 'Header 2': '在线数据导出'}","page_content='功能概览

6.生态工具

6.1.TuGraph DataX

![导入导出](../../../images/tugraph-datax.png)  
TuGraph 核心支持 CSV 和 JSON 合适的导入导出，提供空库导入和增量导入的模式。实际中会存在 MySQL、Kafka、Hive 等多数据源导入的需求，TuGraph 通过 DataX 做多数据源的对接。由于关系模型和图模型存在的差异，数据清洗的流程可以使用 SparkSQL 快速处理，TuGraph 本身仅关注 CSV 和 JSON 的简单场景导入可靠性和性能。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.1.TuGraph DataX'}","page_content='功能概览

4.核心功能

4.3.数据导入导出

尽管TuGraph本身支持数据的插入，但批量导入能够大幅提升的效率。导入的功能可以分为空库导入（离线导入）和增量导入，前者指子图是空的时候进行导入，额外的假设能够大幅提升导入的性能，在 TuGraph 中，空库导入和增量导入的吞吐率差了10 倍。在数据导出中，需要考虑导出数据的一致性，即是基于一个快照数据导出的。  
TuGraph 可以通过 命令行工具`lgraph_export` 来对已经存放在TuGraph的图数据进行数据导出，导出格式支持CSV和JSON。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.3.数据导入导出'}"
"启动TuGraph的时候报这个错误：0x00007f7e5f272900 FATAL include/fma-common/binary_buffer.h:289] CHECK(gpos_ + size <= ppos_)      failedreading beyond the array: required size=4, actual size=2","page_content='TuGraph Management

使用

TuGraph Management使用Maven进行管理，请运行如下命令启动TuGraph Management  
`mvn spring-boot:run`  
TuGraph Management 使用了sofastack框架，并使用brpc与TuGraph进行通信，sofastack默认端口为`6071`，brpc默认端口为`6091`，如需修改服务端口，请修改`./src/main/resources/application.properties`文件中的对应配置项。' metadata={'Header 1': 'TuGraph Management', 'Header 2': '使用'}","page_content='Docker部署

2.现有Docker Image

2.4. M1芯片支持

在 M1 芯片的机器上运行 amd64 容器可能造成未知错误。TuGraph提供 arm64 的镜像供 M1 机器使用。
包含compile和runtime两种镜像。  
在`tugraph-runtime-centos7:3.6.0`与`tugraph-compile-centos7:1.2.7`及之后，`tugraph-runtime-centos7`与`tugraph-compile-centos7`提供linux/amd64和linux/arm64/v8两种架构的镜像，可以在 M1 机器上通过docker pull获取arm64架构镜像。' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.4. M1芯片支持'}","page_content='运维监控

2.部署方案

2.2.第二步

启动TuGraph Monitor工具，启动命令如下：  
```shell
./lgraph_monitor --server_host 127.0.0.1:9091 -u admin -p your_password \
--monitor_host 127.0.0.1:9999  --sampling_interval_ms 1000
```  
参数含义如下  
```shell
Available command line options:
--server_host       Host on which the tugraph rpc server runs.
Default=127.0.0.1:9091.
-u, --user          DB username.
-p, --password      DB password.
--monitor_host      Host on which the monitor restful server runs.
Default=127.0.0.1:9999.
--sampling_interval_ms
sampling interval in millisecond. Default=1.5e2.
-h, --help          Print this help message. Default=0.
```' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.2.第二步'}"
如果在FrontierTraversal中开启了TRAVERSAL_PARALLEL标志，事务必须是怎样的？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bo' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.1. Snapshot

C++ OLAP API 中的 Snapshot 模版类用于表示抽取出来的静态子图，其中 EdgeData 用来表示该子图上每条边所用权值的数据类型（如果边不需要权值，使用 Empty 作为 EdgeData 即可）。  
抽取的子图通过 Snapshot 类的构造函数来描述：  
```c
Snapshot::Snapshot(
GraphDB & db,
Transaction & txn,
size_t flags = 0,
std::function<bool(VertexIterator &)> vertex_filter = nullptr,
std::function<bool(OutEdgeIterator &, EdgeData &)> out_edge_filter = nullptr
);
```  
其中，db 为数据库句柄，txn 为事务句柄，flags 为生成时使用的选项，可选值包括以下的组合：SNAPSHOT_PARALLEL 表示导出时使用多个线程进行并行；SNAPSHOT_UNDIRECTED 表示需要将导出的图变为无向图。
vertex_filter 是面向点的用户自定义过滤函数，返回值为 true 表示该点需要被包含到待抽取的子图中，反之则表示需要被排除。
out_edge_filter 是面向边的用户自定义过滤函数，返回值为 true 表示该边需要被包含到待抽取的子图中，反之则表示需要被排除。
当过滤函数为缺省值时，则表示需要将所有点/边都包含进来。  
Snapshot 类提供的其它方法请参考详细的 C++ API 文档（olap_on_db.h）。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.1. Snapshot'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends GraphSnapShot<K, VV, EV> {
/** 获取开始图遍历的点 */
Travers' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
使用 CSV 文件导入数据时，文件中的栏位与配置文件中的 columns 如何对应？,"page_content='数据导入

3.配置文件

3.2.配置文件示例

```json
{
""schema"": [
{
""label"": ""actor"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""aid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" }
],
""primary"": ""aid""
},
{
""label"": ""movie"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""mid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" },
{ ""name"": ""year"", ""type"": ""INT16"" },
{ ""name"": ""rate"", ""type"": ""FLOAT"", ""optional"": true }
],
""primary"": ""mid"",
""detach_property"": false
},
{
""label"": ""play_in"",
""type"": ""EDGE"",
""properties"": [{ ""name"": ""role"", ""type"": ""STRING"", ""optional"": true }],
""constraints"": [[""actor"", ""movie""]]
}
],
""files"": [
{
""path"": ""actors.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""actor"",
""columns"": [""aid"", ""name""]
},
{
""path"": ""movies.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""movie"",
""columns"": [""mid"", ""name"", ""year"", ""rate""]
},
{
""path"": ""roles.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""play_in"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
对于上述配置文件，定义了三个 label：两个点类型`actor`和`movie`，一个边类型`role`。每个 label 都描述了：label 的名字、类型（点还是边）、属性字段有哪些以及每个字段的类型。对于点，另外定义了 primary 字段是哪个；对于边，另外定义了 constraints 字段，用来限制边的起点和终点只能是哪些组合。  
还描述了三个数据文件，两个点的数据文件`actors.csv`和`movies.csv`，一个边的数据文件`roles.csv`。每个部分都描述了：文件的路径（path）、数据类型（format）、信息头占开头几行（header）、是哪个 label 的数据（label）、文件中每行数据中的每个列对应的字段是哪个。  
对于上述配置文件，import 工具在执行的过程中会先在 TuGraph 中创建`actor`、`movie`、`role`这三个 label，然后再执行三个文件的数据导入。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.2.配置文件示例'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='数据导入

4.离线全量导入

离线模式只能在离线状态的服务器使用。离线导入会创建一张新图，因此更适合新安装的 TuGraph 服务器上的第一次数据导入。
要在离线模式下使用`lgraph_import`工具，可以指定`lgraph_import --online false`选项。要了解可用的命令行选项，请使用`lgraph_import --online false --help`：  
```shell
$ ./lgraph_import --online false -help
Available command line options:
--log               Log file to use, empty means stderr. Default="""".
-v, --verbose       Verbose level to use, higher means more verbose.
Default=1.
...
-h, --help          Print this help message. Default=0.
```  
命令行参数：  
- **-c, --config_file** `config_file`: 导入配置文件名，其格式要求见下述。
- **--log** `log_dir`: 日志目录。默认为空字符串，此时将日志信息输出到控制台。
- **--verbose** `0/1/2`: 日志等级，等级越高输出信息越详细。默认为 1。
- **-i, --continue_on_error** `true/false`: 在碰到错误时跳过错误并继续，默认为 false，碰到错误立即退出。
- **-d, --dir** `{diretory}`: 数据库目录，导入工具会将数据写到这个目录。默认为`./db`。
- **--delimiter** `{delimiter}`: 数据文件分隔符。只在数据源是 CSV 格式时使用，默认为`"",""`。
- **-u, --username** `{user}`: 数据库用户名。需要是管理员用户才能执行离线导入。
- **-p, --password** `{password}`: 指定的数据库用户的密码
- **--overwrite** `true/false`: 是否覆盖数据。设为 true 时，如果数据目录已经存在，则覆盖数据。默认为`false`。
- **-g, --graph** `{graph_name}`: 指定需要导入的图种类。
- **-h, --help**: 输出帮助信息。' metadata={'Header 1': '数据导入', 'Header 2': '4.离线全量导入'}"
在创建一个顶点标签时，需要指定哪些参数？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.createEdgeLabel( label_name, field_spec...)

Create an edge label.  
**Parameters:**  
| parameter  | parameter type | description          |
| ---------- | -------------- | ------------------------ |
| label_name | string     | name of the label    |
| edge_constraints | string | edge constraints |
| field_spec | list       | specification of a field |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`, where optional is specified as true, only for  optional fields.  
`edge_constraints` is a json array string, This parameter limits the combination of starting and ending vertex of the edge, for example: `'[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]'`, which limits the edge direction can only be from `vertex_label1` to `vertex_label2` or from `vertex_label3` to `vertex_label4`. If you don't want to have any constraints, give an empty array string, like this `'[]'`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createEdgeLabel('KNOWS', '[]', 'name', 'int32', true)
```  
**Example output:**  
```
Added type [KNOWS]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createEdgeLabel( label_name, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createLabel(label_type, label_name, extra, field_spec...)

Create a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| extra      | string     | for edge, it means constraints; for vertex, it means primary property |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.
for edge, `extra` should be a json array string, like this `[[""label1"",""label2""], [""label3"",""label4""]]`, if edge has no constraints, give an empty json array, like this `[]`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createLabel('vertex', 'new_label', 'id', ['id','int32',false], ['name','string', true]);
CALL db.createLabel('edge', 'new_edge', '[[""id1"",""id2""]]', ['id','int32',false], ['name', 'string', true]);
```  
**Example output:**  
```
Vertex label [new_label] successfully added.
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createLabel(label_type, label_name, extra, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.addEdgeIndex(label_name, field_name, unique, pair_unique)

create an index on some field of one edge label .  
**Parameters:**  
| parameter | parameter type | description               |
| ---------- | -------------- | ------------------------------------- |
| label_name | string     | name of the label             |
| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |
| pair_unique | boolean    | Specifies whether the index is pair_unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.addEdgeIndex('BornIn', 'id', true, false)
```  
**Example output:**  
```
Added index [BornIn:id]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addEdgeIndex(label_name, field_name, unique, pair_unique)'}"
TuGraph Browser 的默认端口号是什么？,"page_content='可视化操作手册

2.操作指南

2.1.访问

当用户完成图数据库的安装后，可以通过浏览器访问Browser。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7070。  
- 例如：127.0.0.1:7070。
- 推荐使用Chrome。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.1.访问'}","page_content='可视化操作手册（旧版）

操作详情

1.连接数据库

当用户完成图数据库的安装后，可以通过浏览器进行访问，TuGraph Browser 工具。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7090。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '1.连接数据库'}","page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

1. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7:${VERSION}
```  
2. 启动docker  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}"
在配置中，用于计算图表中显示的值的方法是什么？,"page_content='Cypher API

5.附录2. 内置procedures列表

* dbms.config.list()

get config of this graph database.  
**Output:**  
a list of {configuration}.  
**Example input:**  
```
CALL dbms.config.list()
```  
**Example output:**  
| name      | value   |
|-----------| ---------|
| bind_host | 0.0.0.0 |
| durable   | true    |
| ...       |  ...    |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* dbms.config.list()'}","page_content='数据导入

3.配置文件

`lgraph_import`工具通过指定的配置文件进行环境配置。配置文件描述输入文件的路径、它们所代表的点/边以及点/边的格式。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件'}","page_content='内置算法

扩展算法包

直径估计

直径估计程序实现了Dimension Estimation算法。该算法会计算图中最长的最短路径长度，用来表征图的直径大小。算法内容请参考[http://mathworld.wolfram.com/GraphDiameter.html](http://mathworld.wolfram.com/GraphDiameter.html ""graph diameter"")。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': '直径估计'}"
TuGraph是由哪个团队开发的？,"page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。  
蚂蚁集团 2015 年开始自主研发分布式图数据库、流式图计算等图相关技术，2016 年发布自研分布式图数据库，并应用于支付宝。至今 TuGraph 已应用于蚂蚁内部 150 多个场景，包括在线支付的实时链路，以支付宝风险识别能力提升近 10 倍、风险审理分析效率提升 90%的成绩，验证了其高可靠性。  
LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，TuGraph 在功能完整性、吞吐率、响应速度等层面全球领先。  
目前，蚂蚁集团已形成了一套以图数据库为底座、同时包含流式图计算，离线图学习的大规模图计算系统。  
蚂蚁集团图数据库负责人洪春涛表示，图技术是未来大数据、人工智能和高性能计算产业发展的关键所在，它很有可能会成为下一代的数据底座。蚂蚁集团愿意通过开源持续输出核心技术优势，推动图数据库更广泛的应用生态，携手行业抢占技术高地，不断探索技术的可能性。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}"
图学习系统是解决什么问题的？,"page_content='名词解释

2.图产品

> __图计算系统__：一般包括图数据库、图分析系统、图学习系统，有时也特指图分析系统。  
> __图数据库__：侧重于对图数据的增删改查、事务性操作等，如TuGraph DB、Neo4j、JanusGraph等。  
> __图分析系统__：解决图分析问题，可以细分为流水图分析、离线图分析，如TuGraph Analytics、GraphX等。  
> __图学习系统__：解决图学习问题，比如TuGraph Learn、DGL等。' metadata={'Header 1': '名词解释', 'Header 2': '2.图产品'}","page_content='TuGraph在图计算系统建设中的作用

TuGraph 技术优势

蚂蚁自己开发了一套图计算系统 TuGraph，既能解决图数据的存储问题，也能解决流式计算、离线计算和图学习的问题。目前，超过 100 个业务线和 300 多个场景都在使用这套系统。这套系统在 2021 年获得了世界互联网大会领先科技成果奖。  
在 TuGraph 中，性能是一个重要的因素，因为图数据集的体积很大，如果性能不佳就会浪费机器资源，导致许多情况下无法完成任务。比如，希望业务的查询能在几十毫秒内返回结果，但是如果做的性能不好，几秒钟才能返回结果，就无法作为在线查询使用。因此，我们是非常对性能是很重视的，其中在 LDBC-SNB 标准测试中（类似于数据库领域性能标准测试 TPC-C），TuGraph 仍然是世界纪录的保持者。  
TuGraph 的整个图存储是建立在完美哈希的基础上的，这是我们与其他图系统的一个重要区别。目前，大多数图系统使用的是基于数的存储，但数的问题在于永远存在一个 LogN 的查找操作。然而，在图中可以看到，不同的顶点之间实际上是无序的，不需要有顺序，所以顶点这个级别实际上是基于哈希的，理论上，顶点的读取是最优的。  
此外，TuGraph 还参与了许多标准的定制，整个系统在尽量往标准化的方向去做。  
除了为内部提供服务，我们还向外提供服务，主要是因为，作为一个系统，如果只为有限的客户提供服务，就很容易构建成一个专有系统。我们希望这是一个标准化、开放的系统，所以我们也在对外提供图计算系统的产品和服务。目前，我们也有很多外部客户，包括金融、工业、互联网以及政企领域。  
开源开放，共建发展  
整个图计算系统目前仍处于较早期的阶段，我们认为还有很多工作要做，包括提升应用性、性能和降低成本。所有的系统都会有这些问题。但是，如果希望普及，我们认为最重要的是有健康的生态，来推动图计算系统的发展，需要有更多的用户和更多的场景使用这个系统。  
所有的计算机系统都需要去有一个更开放、更大的生态才能促进发展。蚂蚁有一句话叫做“成熟一个、开放一个”，一个系统成熟以后，我们就会试着开放出去，让更多的人去用。今年 9 月，我们已经在 GitHub 上开源了 TuGraph 中的单机版图数据库，以及一个离线图分析引擎 TuGraph Compute。分布式图数据库和流式图计算现在已经包含在我们的商业化版本中，包括一站式图研发平台。我们计划在未来迭代更多更丰富的系统功能，希望能做得更好。' metadata={'Header 1': 'TuGraph在图计算系统建设中的作用', 'Header 2': 'TuGraph 技术优势'}","page_content='TuGraph在图计算系统建设中的作用

图计算系统建设中的问题与挑战

在建立蚂蚁图计算系统的过程中，我们遇到了各种各样的问题。为了解决这些问题，我们与学术界和许多研究界的同事一起合作，并发表了许多相关的学术论文，包括 EuroSys 等。然而，我们在建立系统的过程中发现，目前的图计算仍处于较早期的阶段，因此许多标准尚未成形。这对我们来说是一个棘手的问题。例如，在关系型数据库中，查询语言基本上就是 SQL，但在图数据库中，仅查询语言就有许多种，包括 Gremlin、G-SQL 等等。这导致了市场的碎片化，人们学习和使用的成本也很高。  
在建立图计算系统的过程中，我们也遇到了许多挑战。为了分担较大的通信量，需要将图数据分布到多台机器上，但这会导致边的信息在不同机器之间传递，造成大量的通信。此外，单次查询所涉及的数据量也比较大，例如五跳查询涉及的点数就已达到 10 的五次方，图中还存在一些非常大的点。同时，用户对图计算系统的需求也十分多样，既有快速查询的需求，也有对复杂算法（如社区发现）的需求，单一系统很难满足这些不同的需求。' metadata={'Header 1': 'TuGraph在图计算系统建设中的作用', 'Header 2': '图计算系统建设中的问题与挑战'}"
VertexIterator GetVertexByUniqueCompositeIndex函数需要哪些参数？,"page_content='Python Olap API

5. lgraph_db API

Transaction：

```
GetVertexIndexIterator(
label: std::string,
field: std::string,
key_start: std::string,
key_end: std::string)-> VertexIndexIterator
```
获取索引迭代器。迭代器的field值为 [key_start, key_end]。所以在key_start=key_end=v时，返回指向field值为v的点的迭代器  
lgraph_db_python.py是lgraph_db.pxd中C++类 Galaxy与GraphDB的包装，将C++类包装为Python类，将lgraph_db_python.py编译为Python拓展后，可以直接在Python文件或Python命令行中`import lgraph_db_python`访问lgraph_db_python.PyGraphDB与PyGraphDB.PyGalaxy。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Transaction：'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.addIndex(label_name, field_name, unique)

create an index on some field of one vertex label .  
**Parameters:**  
| parameter | parameter type | description               |
| ---------- | -------------- | ------------------------------------- |
| label_name | string     | name of the label             |
| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.addIndex('Person', 'id', true)
```  
**Example output:**  
```
Added index [Perosn:id]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addIndex(label_name, field_name, unique)'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bo' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}"
rpc port怎么配置？,"page_content='数据库运行

4.服务配置

4.2.服务器配置文件

TuGraph 的配置文件以 JSON 格式存储。建议将大多数配置存储在配置文件中，并且仅在需要时使用命令行选项临时修改某些配置参数。
一个典型的配置文件如下：  
```json
{
""directory"" : ""/var/lib/lgraph/data"",
""host"" : ""0.0.0.0"",
""port"" : 7070,
""rpc_port"" : 9090,
""enable_rpc"" : true,
""bolt_port"": 7687,
""enable_ha"" : false,
""verbose"" : 1,
""log_dir"" : ""/var/log/lgraph_log"",
""disable_auth"" : false,
""ssl_auth"" : false,
""server_key"" : ""/usr/local/etc/lgraph/server-key.pem"",
""server_cert"" : ""/usr/local/etc/lgraph/server-cert.pem"",
""web"" : ""/usr/local/share/lgraph/browser-resource""
}
```' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.2.服务器配置文件'}","page_content='部署高可用模式

2.准备工作

要启用高可用模式，用户需要：  
- 三台及以上的 TuGraph 服务器实例。  
- 在启动 lgraph_server 时打开高可用模式，可以使用配置文件或者命令行将`enable_ha`选项设置为`true`。  
- 设置正确的`rpc_port`，可通过配置文件或者命令行设置。' metadata={'Header 1': '部署高可用模式', 'Header 2': '2.准备工作'}","page_content='部署高可用模式

5.横向扩展其他服务器

启动初始备份组后，如果想对备份组进行横向扩展，要将新服务器添加到备份组，
应使用`--ha_conf HOST：PORT`选项，其中`HOST`可以是该备份组中已有的任何服务器的 IP 地址，
而`PORT`是其 RPC 端口。例如：  
```bash
./lgraph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090
```  
此命令将启动一台高可用模式的 TuGraph 服务器，并尝试将其添加到包含服务器`172.22.224.15:9090`的备份组中。
请注意，加入备份组需要服务器将其数据与备份组的`leader`服务器同步，此过程可能需要相当长的时间，具体取决于数据的大小。' metadata={'Header 1': '部署高可用模式', 'Header 2': '5.横向扩展其他服务器'}"
图数据库在处理关联关系时相比关系型数据库有什么优势？,"page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.1. 性能

在关联关系处理上，使用关系型数据库不可避免地要使用表的JOIN操作，这会对性能产生较大影响；而图数据库则直接跳转访问类指针，操作关联数据的效率更高，比关系型数据库提高2到4个数量级的性能。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.1. 性能'}","page_content='什么是图数据库

3. 图数据库与关系型数据库对比

| 分类         | 模型   | 优势                                   | 劣势                                     | 举例           |
| ------------ | ------ | -------------------------------------- | ---------------------------------------- | -------------- |
| 关系型数据库 | 表结构 | 数据高度结构化，一致性强，软件成熟度高 | 面向多跳的关联关系查询低效或不支持       | MySQL、Oracle  |
| 图数据库     | 图结构 | 针对关联关系的建模建模和操作效率非常高 | 高度结构化的数据处理能力不及关系型数据库 | Neo4j、TuGraph |  
总之，面对海量数据的存储和处理问题，传统的关系数据库已经无法满足大部分的日常数据存储需求。图数据库技术可以将关系信息存储为实体，灵活拓展数据模型。由于提供了对关联数据最直接的表达方式和图模型对异构数据的天然包容性，图数据库技术必将成为未来最热点的技术之一，为企业提供存储和分析大规模图数据的有力支持。' metadata={'Header 1': '什么是图数据库', 'Header 2': '3. 图数据库与关系型数据库对比'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.2. 兼容性

现实中，项目进程通常不断演变，数据的内容甚至数据格式也在不断变化。在关系型数据库中，这意味着表结构的变化或建立多个新表，对源数据的修改非常大。而在图数据库中，仅需添加新的点、边和属性，并将其设置为对应的类型即可。从本质上说，一个表代表一种类型的数据，一个点代表一个特定的数据。这意味着关系型数据库更关注数据类型，而图数据库更关注数据个体及其关联关系。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.2. 兼容性'}"
使用TuGraph Browser时，默认的登录密码是什么？,"page_content='可视化操作手册

2.操作指南

2.2.登录

![login](../../../images/browser/login.png)  
- 浏览器成功访问Browser后，首先进入的是登录页面（如上图所示），用户需要填写账号和密码进行登录。
- 数据库地址格式为：ip:bolt_port。
- 默认账号：admin。
- 默认密码：73@TuGraph。
- 用户首次登录后，会跳转至修改密码页面，密码修改成功后，使用新密码重新登录即可使用。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.2.登录'}","page_content='可视化操作手册（旧版）

操作详情

2.登录数据库

![alt 登录](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/1.tugraph-browser-lpgin.png)  
- 页面打开成功会，首先进图的是登录页面，用户需要填写账号和密码进行登录。
- 默认账号：admin
- 默认密码：73@TuGraph
- 建议用户登录后，及时修改初始化的密码' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '2.登录数据库'}","page_content='RESTful API Legacy

3.登录

3.1.登录

用户通过用户名和密码发送登录请求。登录成功会收到带有签名的令牌(Json Web Token)和判断是否为默认密码的布尔型变量，客户端储存该令牌，并且用于以后的每次发送请求。如果登录失败会收到“Authentication failed”错误。  
- **URI**: `/login`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| jwt | 令牌 | 字符串 |
| default_password | 是否为默认密码 | 布尔值 |  
**Example request.**  
```
• POST http://localhost:7070/login
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""user"":""admin"",
""password"":""73@TuGraph""
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""jwt"": ""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek"",
""default_password"": true
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '3.登录', 'Header 3': '3.1.登录'}"
SetFields函数的第一个版本中，field_value_strings参数的数据类型是什么？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

Adds specified fields to the label.  
**Parameters:**  
| parameter    | parameter type | description           |
| ---------------- | -------------- | ------------------------- |
| label_type       | string     | either 'vertex' or 'edge' |
| label_name       | string     | name of the label     |
| field_value_spec | list       | specification of a field  |  
in which each `field_value_spec` is a list of string in the form of `[field_name, field_type, field_value, optional]`, where: `field_value` is the default value of the field.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelAddFields(
'vertex',
'new_label',
['birth_date', DATE, '', true],
['img', BLOB, '', true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}","page_content='业务开发指南

点类型操作

点类型添加字段

>该操作会同步变更所有该类型点的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于点类型`node1`，一次添加了两个字段：`field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是0.
```
CALL db.alterLabelAddFields('vertex', 'node1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '点类型操作', 'Header 3': '点类型添加字段'}","page_content='业务开发指南

边类型操作

边类型添加字段

>该操作会同步变更所有该类型边的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于边类型`edge1`，一次添加了两个字段: `field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是`0`.
```
CALL db.alterLabelAddFields('edge', 'edge1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型添加字段'}"
DB和tuGraph Analytics是独立运行吗？,"page_content='数据库运行

1.前置条件

TuGraph 运行的前置条件为 TuGraph 正确安装，参考[安装流程](1.environment.md)。  
TuGraph 运行需要保证库文件 liblgraph.so 的文件位置在环境变量 LD_LIBRARY_PATH。  
运行 TuGraph 进程的用户不需要超级权限，但需要对配置文件（一般为lgraph.json）及文件中涉及的文件有读权限，并且对数据文件夹、日志文件夹等有写权限。' metadata={'Header 1': '数据库运行', 'Header 2': '1.前置条件'}","page_content='数据库运行

2.运行模式

TuGraph 可以作为前台普通进程启动，也可以作为后台守护进程启动。
当作为普通进程运行时，TuGraph 可以直接将日志打印到终端，这在调试服务器配置时非常方便。但是，由于前台进程在终端退出后被终止，因此用户须确保在 TuGraph 服务器处于运行状态时，终端保持打开状态。另一方面，在守护进程模式下，即使启动它的终端退出，TuGraph 服务器也可以继续运行。因此，在长时间运行的服务器下推荐以守护进程模式启动 TuGraph 服务器。' metadata={'Header 1': '数据库运行', 'Header 2': '2.运行模式'}","page_content='文档地图

主要仓库

> TuGraph-DB 仓库: [https://github.com/TuGraph-family/tugraph-db](https://github.com/TuGraph-family/tugraph-db)  
> 可视化界面: [https://github.com/TuGraph-family/tugraph-db-browser](https://github.com/TuGraph-family/tugraph-db-browser)  
> 基于twitter数据的简单测试方法: [https://github.com/TuGraph-family/gdbms-microbenchmark](https://github.com/TuGraph-family/gdbms-microbenchmark)  
> 基于标准LDBC-SNB的测试方法: [https://github.com/TuGraph-family/tugraph-snb-interactive](https://github.com/TuGraph-family/tugraph-snb-interactive)  
> TuGraph-Analytics 仓库: [https://github.com/TuGraph-family/tugraph-analytics](https://github.com/TuGraph-family/tugraph-analytics)' metadata={'Header 1': '文档地图', 'Header 2': '主要仓库'}"
RpcClient 构造函数需要什么参数用于用户登录？,"page_content='RPC API

3.登录

登录请求信息包含以下参数：
- user: 必要参数，用户名
- pass: 必要参数，密码
以C++为例，用户使用构建好的服务存根发送登录请求：
```C++
auto* req = request.mutable_acl_request();
auto* auth = req->mutable_auth_request()->mutable_login();
auth->set_user(user);
auth->set_password(pass);
// send data
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req->set_client_version(server_version);
req->set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), req, &resp, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
token = res.acl_response().auth_response().token();
```
登录响应信息包含以下参数：
- token: 必要参数，登录成功会收到带有签名的令牌，即 Json Web Token，客户端储存该令牌，并且用于以后的每次发送请求。
如果登录失败会收到“Authentication failed”错误。' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}","page_content='Java客户端

2.使用示例

2.1.实例化client对象

添加maven依赖  
```xml
<dependency>
<groupId>com.antgroup.tugraph</groupId>
<artifactId>tugraph-db-java-rpc-client</artifactId>
<version>1.4.1</version>
</dependency>
```  
引入依赖
```java
import com.antgroup.tugraph.TuGraphDbRpcClient;
```  
#### 2.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
```java
TuGraphDbRpcClient client = new TuGraphDbRpcClient(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(String url, String user, String pass)
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```  
#### 2.1.2.实例化HA集群直连连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化。
```java
TuGraphDbRpcClient client = new TuGraphDbRpcClient(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(String url, String user, String pass)
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 2.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化
```java
List<String> urls = new ArrayList<>();
urls.add(""189.33.97.23:9091"");
urls.add(""189.33.97.24:9091"");
urls.add(""189.33.97.25:9091"");
TuGraphDbRpcClient client = new TuGraphDbRpcClient(urls, ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(List<String> urls, String user, String password)
@param urls: tugraph host list
@param user: login user name
@param password: login password
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.1.实例化client对象'}","page_content='RPC API

2.请求

2.2.请求类型

TuGraph支持10种RPC请求，其中每种请求的功能如下表所示：  
| 请求              | 功能         |
|-----------------|------------|
| GraphApiRequest | 点边索引操作请求   |
| CypherRequest   | cypher请求   |
| PluginRequest   | 存储过程请求     |
| HARequest       | 高可用模式请求    |
| ImportRequest   | 数据导入请求     |
| GraphRequest    | 子图操作请求     |
| AclRequest      | 权限管理请求     |
| ConfigRequest   | 配置管理请求     |
| RestoreRequest  | 备份请求       |
| SchemaRequest   | schema管理请求 |  
用户发送请求时，需要传入以下参数：
- client_version: 可选参数，HA模式下可通过对比`client_version`和`server_version`防止响应过时的请求
- token: 必要参数，客户端登陆之后获得token，每次请求传入token以校验用户身份
- is_write_op: 可选参数，标志请求是否是写请求
- user: 可选参数，HA模式下主从之间同步请求时设置user，不需验证token  
服务处理完RPC请求之后发回响应，响应消息中除了包含每个请求的单独响应信息之外，还包含以下参数：
- error_code: 必要参数，标志请求处理状态
- redirect: 可选参数，HA模式下向follower发送写请求时处理失败，设置redirect为请求转发地址，即leader地址
- error: 可选参数，请求错误信息
- server_version: 可选参数，HA模式的请求响应中设置`server_version`以避免client读取数据时发生反向时间旅行问题  
:warning:  **除CypherRequest、PluginRequest、HARequest和AclRequest外，其余RPC接口将逐步废弃，其功能统一至CypherRequest接口。**' metadata={'Header 1': 'RPC API', 'Header 2': '2.请求', 'Header 3': '2.2.请求类型'}"
如何使用lgraph_cypher工具在命令行中以单命令模式提交一条Cypher查询并保存结果？,"page_content='命令行工具

1.单命令模式

在单命令模式下，`lgraph_cypher`可用于提交单个 Cypher 查询并将结果直接打印到终端，打印结果也可以容易地重定向写入指定文件。当用户需要从服务器获取大量结果并将其保存在文件中时，这非常便利。
在此模式下，`lgraph_cypher`工具具有以下选项：' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式'}","page_content='命令行工具

1.单命令模式

1.2.命令示例:

**cypher 命令文件查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -f /home/usr/cypher.json
```  
**cypher 命令单句查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -s ""MATCH (n) RETURN n""
```' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式', 'Header 3': '1.2.命令示例:'}","page_content='命令行工具

2.交互模式

2.3.cypher 查询命令:

在交互模式下，用户也可直接输入单句 cypher 命令进行查询，以""`;`""结束。输入命令不区分大小写。例子如下：  
```
login success
>MATCH (n) RETURN n, n.name;
+---+---+-------------+
|   | n |n.name       |
+---+---+-------------+
| 0 | 0 |david        |
| 1 | 1 |Ann          |
| 2 | 2 |first movie  |
| 3 | 3 |Andres       |
+---+---+-------------+
time spent: 0.000520706176758
size of query: 4
>
```  
`lgraph_cypher`输入命令时支持多行输入，用户可使用`ENTER`键将长查询语句分多行输入。多行输入情况下命令行开头会从`>`变为`=>`，然后用户可以继续输入查询的其余部分。  
例子如下：  
```
login success
>MATCH (n)
=>WHERE n.uid='M11'
=>RETURN n, n.name;
```' metadata={'Header 1': '命令行工具', 'Header 2': '2.交互模式', 'Header 3': '2.3.cypher 查询命令:'}"
数据和日志目录的持久化位置在哪里？,"page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

1. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7:${VERSION}
```  
2. 启动docker  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}","page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客户端端口。默认端口为 7687。                                ' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='快速上手

2.安装

2.1.通过docker快速体验

1. 本地安装 docker 环境  
参考 docker 官方文档：https://docs.docker.com/get-started/  
2. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7
```  
3. 启动docker  
启动 TuGraph 服务可以通过两种方式来实现。第一种方式将镜像拉取与服务启动整合在一起，用户只需执行运行容器的操作，即可同时启动 TuGraph 服务。第二种方式则是在创建 TuGraph 容器后，手动进入容器内部以触发服务启动。尽管这种方法初期步骤稍显繁琐，但在如忘记密码的情况下，它提供了更灵活的密码重置选项。  
**方式一**  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
**方式二**  
```shell
docker run -dt -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION} /bin/bash

docker exec -it tugraph_demo bash
lgraph_server -c /usr/local/etc/lgraph.json -d start

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
5. 前端访问  
访问tugraph-db-browser: `http://x.x.x.x:7070`，数据库地址格式为 `bolt://ip:bolt_port`（老版本不用填），默认用户名为 `admin`，密码为 `73@TuGraph`。
首次登录会默认跳转修改密码页面，请尽快修改默认密码避免安全风险。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.1.通过docker快速体验'}"
TuGraph 的 Traversal API 当中对于遍历的起始点设置有哪三种方式？,"page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends GraphSnapShot<K, VV, EV> {
/** 获取开始图遍历的点 */
Travers' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bo' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='OLAP API

1. TuGraph 图分析引擎介绍

TuGraph的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助TuGraph的 C++ / Python 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如PageRank、LPA、WCC等迭代式图算法，最后根据运行结果做出相应的对策。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph图计算系统社区版内置6个算法，商业版内置了25种算法，用户几乎不需要自己实现具体的图计算过程。其详细介绍可参考algorithms.md。  
根据数据来源及实现不同，可分为Procedure、Embed和Standalone三种运行方式，均继承于OlapBase API，OlapBase API接口文档可参考olapbase-api.md。  
其中Procedure和Embed的数据来源是图数据库中预加载的db数据，可以分别编译生成tugraph-web加载使用的.so文件和后台终端使用的embed文件，输入的图数据均通过db的加载形式，其接口文档可参考olapondb-api.md。
Standalone用于编译生成standalone文件，区别于前者，该文件的输入图数据通过txt、二进制、ODPS文件的形式加载，其接口文档可参考olapondisk-api.md。' metadata={'Header 1': 'OLAP API', 'Header 2': '1. TuGraph 图分析引擎介绍'}"
方法 `SetField` 的目的是什么？,"page_content='RESTful API Legacy

6.Deprecated

6.9.索引

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/index/{label}/{field}
```  
提供索引操作，接受 GET/POST 请求。  
#### 6.9.1.创建索引  
该操作会启动一个创建索引的后台任务，用户可以通过列出该 Label 相关的所有索引来检查新建索引的状态。  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: POST
- **REQUEST**:  
| 域名    | 说明     | 类型                                  |
|-------|--------|-------------------------------------|
| label | Label 名 | 字符串                                 |
| field | 域名     | 字符串                                 |
| type  | 索引类型   | int类型，0表示非唯一索引，1表示全局唯一索引，2表示两点间唯一索引 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"": ""Person"",
""field"": ""birthyear"",
""is_unique"" : false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.9.2.列出所有索引  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""field"": ""name"",
""label"": ""City"",
""is_unique"": false
},
{
""field"": ""title"",
""label"": ""Film"",
""is_unique"": false
},
{
""field"": ""name"",
""label"": ""Person"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
#### 6.9.3.列出所有与某个 Label 相关的索引  
- **URI**: `/db/{graph_name}/index/{label}`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index/Person
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""label"": ""Person"",
""field"": ""name"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
#### 6.9.4.删除索引  
- **URI**: `/db/{graph_name}/ind' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.9.索引'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='OLAP API

3. Embed 编译与运行

C++:

```C++
#include <iostream>
#include ""lgraph/lgraph.h""
#include ""lgraph/olap_base.h""
using namespace std;

extern ""C"" bool Process(lgraph_api::GraphDB &db, const std::string &request, std::string &response);

int main(int argc, char **argv) {
// db_path表示预加载图数据存放的路径
std::string db_path = ""../fb_db/"";
if (argc > 1)
db_path = argv[1];
lgraph_api::Galaxy g(db_path);
g.SetCurrentUser(""admin"", ""73@TuGraph"");
// 指定图数据的名称
lgraph_api::GraphDB db = g.OpenGraph(""fb_db"");
std::string resp;
// 以json形式输入算法参数
bool r = Process(db, ""{\""root_id\"":\""0\"", \""label\"":\""node\"",\""field\"":\""id\""}"", resp);
cout << r << endl;
cout << resp << endl;
return 0;
}
```
保存后在tugraph-db/procedures 目录下执行`bash make_embed.sh bfs`即可在tugraph-db/procedures/algo_cpp 目录下得到bfs_procedure文件。  
在tugraph-db/procedures 文件夹下执行`./algo_cpp/bfs_procedure` 即可得到返回结果：  
```json
{
""core_cost"":0.025603055953979492,
""found_vertices"":3829,
""num_edges"":88234,
""num_vertices"":4039,
""output_cost"":9.059906005859375e-06,
""prepare_cost"":0.056738853454589844,
""total_cost"":0.0823509693145752
}
```  
参数解释同上。' metadata={'Header 1': 'OLAP API', 'Header 2': '3. Embed 编译与运行', 'Header 3': 'C++:'}"
TuGraph-DB图数据库是由哪个团队开发的？,"page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}","page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。  
蚂蚁集团 2015 年开始自主研发分布式图数据库、流式图计算等图相关技术，2016 年发布自研分布式图数据库，并应用于支付宝。至今 TuGraph 已应用于蚂蚁内部 150 多个场景，包括在线支付的实时链路，以支付宝风险识别能力提升近 10 倍、风险审理分析效率提升 90%的成绩，验证了其高可靠性。  
LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，TuGraph 在功能完整性、吞吐率、响应速度等层面全球领先。  
目前，蚂蚁集团已形成了一套以图数据库为底座、同时包含流式图计算，离线图学习的大规模图计算系统。  
蚂蚁集团图数据库负责人洪春涛表示，图技术是未来大数据、人工智能和高性能计算产业发展的关键所在，它很有可能会成为下一代的数据底座。蚂蚁集团愿意通过开源持续输出核心技术优势，推动图数据库更广泛的应用生态，携手行业抢占技术高地，不断探索技术的可能性。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}"
TuGraph 的精简运行环境需要哪些系统库？,"page_content='环境分类

2.依赖系统库

针对三种环境，除去TuGraph的运行包，所需要的系统库如下：
* 编译环境，包括gcc、python、java等编译器，也包含antlr4、pybind11等，具体参见tugraph-db源码目录 ci/images/tugraph-compile-*-Dockerfile。
* 运行环境，主要由存储过程引入，包括gcc、boost、cmake等，具体参见tugraph-db源码目录 ci/images/tugraph-runtime-*-Dockerfile。
* 精简运行环境，无，可以参见tugraph-db源码目录 ci/images/ tugraph-mini-runtime-*-Dockerfile。' metadata={'Header 1': '环境分类', 'Header 2': '2.依赖系统库'}","page_content='环境分类

1.分类

根据环境所承载功能的不同，区分为编译环境，运行环境，以及精简运行环境。
* 编译环境，具备TuGraph编译的所有依赖库，包含运行环境的所有依赖，并且能够编译TuGraph源码，但不包含预编译好的TuGraph可执行文件和库文件，供开发者编译源码使用。
* 运行环境，具备GCC/Java/Python环境，能够运行TuGraph的所有功能，并且能承载全文索引，java client，c++源码上传为plugin，以及python plugin的完整功能，内置TuGraph预编译好的可执行文件和库文件，供客户直接安装使用，无需编译源码。
* 精简运行环境，约等于裸系统加预编译TuGraph，仅能运行TuGraph的基本功能，无C++ plugin编译运行，仅so上传，无全文索引，无python plugin，供快速搭建试用。  
TuGraph编译后，会把所有的依赖库以.a的形式打包在一起，因此原则上运行不需要的其他的依赖库。但TuGraph支持存储过程，即在服务端编译C++代码，因此在环境中依然需要涉及的编译器。' metadata={'Header 1': '环境分类', 'Header 2': '1.分类'}","page_content='环境和版本选择

2. 环境能力选择

用户可以根据实际使用场景，来选择不同的环境。编译环境的能力最完备，所需的第三方软件也越多。与其相对应的，精简运行环境几乎不需要安装任何依赖库，能运行TuGraph除存储过程外的基础功能。  
| 环境     | 用途             | 备注        |
|--------|----------------|-----------|
| 编译环境   | 从源码编译TuGraph   | 适用于开发人员   |
| 运行环境   | 运行TuGraph安装包   | 适用于大部分用户  |
| 精简运行环境 | 运行精简TuGraph安装包 | 对系运行统依赖较小 |  
不同环境的具体介绍参见 [链接](../5.installation&running/2.environment-mode.md)。' metadata={'Header 1': '环境和版本选择', 'Header 2': '2. 环境能力选择'}"
函数 SetFrontier(std::function<bool(VertexIterator&)> root_vertex_filter) 是如何利用参数 root_vertex_filter 的？,"page_content='Traversal API

2. 接口说明

2.1. Snapshot

C++ OLAP API 中的 Snapshot 模版类用于表示抽取出来的静态子图，其中 EdgeData 用来表示该子图上每条边所用权值的数据类型（如果边不需要权值，使用 Empty 作为 EdgeData 即可）。  
抽取的子图通过 Snapshot 类的构造函数来描述：  
```c
Snapshot::Snapshot(
GraphDB & db,
Transaction & txn,
size_t flags = 0,
std::function<bool(VertexIterator &)> vertex_filter = nullptr,
std::function<bool(OutEdgeIterator &, EdgeData &)> out_edge_filter = nullptr
);
```  
其中，db 为数据库句柄，txn 为事务句柄，flags 为生成时使用的选项，可选值包括以下的组合：SNAPSHOT_PARALLEL 表示导出时使用多个线程进行并行；SNAPSHOT_UNDIRECTED 表示需要将导出的图变为无向图。
vertex_filter 是面向点的用户自定义过滤函数，返回值为 true 表示该点需要被包含到待抽取的子图中，反之则表示需要被排除。
out_edge_filter 是面向边的用户自定义过滤函数，返回值为 true 表示该边需要被包含到待抽取的子图中，反之则表示需要被排除。
当过滤函数为缺省值时，则表示需要将所有点/边都包含进来。  
Snapshot 类提供的其它方法请参考详细的 C++ API 文档（olap_on_db.h）。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.1. Snapshot'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bo' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void init(VertexCentricComputeFuncContext<K, VV, EV, M> vertexCentricFuncContext) | 迭代计算初始化接口 | vertexCentricFuncContext：静态图计算的上下文，K表示vertex id的类型，VV表示vertex value类型，EV表示edge value类型，M表示发送消息的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 迭代计算接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：迭代过程中所有发送给当前vertex的消息，其中M表示迭代计算过程中定义的发送消息类型。 |
| void finish() | 迭代计算完成接口 | 无 |  
- 详细接口  
```java
public interface VertexCentricComputeFunction<K, VV, EV, M> extends VertexCentricFunction<K, VV,
EV, M> {

void init(VertexCentricComputeFuncContext<K, VV, EV, M> vertexCentricFuncContext);

void compute(K vertex, Iterator<M> messageIterator);

void finish();

interface VertexCentricComputeFuncContext<K, VV, EV, M> extends VertexCentricFuncContext<K, VV,
EV, M> {
/** 设置vertex value */
void setNewVertexValue(VV value);

}

}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}"
rpm包中包含新版前端页面资源吗？,"page_content='数据库运行

3.服务操作

3.4.新旧前端切换

进入容器，可以通过修改配置文件""/usr/local/etc/lgraph.json""中的""web""参数来选择使用老版本或新版本的前端。对于老版本，可以将""web""的值设为""/usr/local/share/lgraph/resource""；对于新版本，可以将""web""的值设为""/usr/local/share/lgraph/browser-resource""。完成配置文件的修改后，请执行命令 `docker restart tugraph` 以使更改生效。需要注意的是，新版本是默认选项。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.4.新旧前端切换'}","page_content='快速上手

2.安装

2.2.新旧前端说明

进入容器，可以通过修改配置文件""/usr/local/etc/lgraph.json""中的""web""参数来选择使用老版本或新版本的前端。对于老版本，可以将""web""的值设为""/usr/local/share/lgraph/resource""；对于新版本，可以将""web""的值设为""/usr/local/share/lgraph/browser-resource""。完成配置文件的修改后，请执行命令 `docker restart tugraph` 以使更改生效。需要注意的是，新版本是默认选项。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.2.新旧前端说明'}","page_content='本地包部署

3. CentOS 下的安装方法

用于在 CentOS 上安装的 TuGraph 的.rpm 安装包，其中包含了 TuGraph 可执行文件以及编写嵌入式程序和存储过程所需的头文件和相关库文件。  
使用已经下载完成的`tugraph_x.y.z.rpm 安装包在终端下安装，只需要运行以下命令：  
```shell
$ rpm -ivh tugraph-x.y.z.rpm
```  
用户也可以通过指定`--prefix`选项指定安装目录。' metadata={'Header 1': '本地包部署', 'Header 2': '3. CentOS 下的安装方法'}"
请问一下镜像 tugraph-runtime-centos7启动大概需要多少资源,"page_content='快速上手

2.安装

2.1.通过docker快速体验

1. 本地安装 docker 环境  
参考 docker 官方文档：https://docs.docker.com/get-started/  
2. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7
```  
3. 启动docker  
启动 TuGraph 服务可以通过两种方式来实现。第一种方式将镜像拉取与服务启动整合在一起，用户只需执行运行容器的操作，即可同时启动 TuGraph 服务。第二种方式则是在创建 TuGraph 容器后，手动进入容器内部以触发服务启动。尽管这种方法初期步骤稍显繁琐，但在如忘记密码的情况下，它提供了更灵活的密码重置选项。  
**方式一**  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
**方式二**  
```shell
docker run -dt -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION} /bin/bash

docker exec -it tugraph_demo bash
lgraph_server -c /usr/local/etc/lgraph.json -d start

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
5. 前端访问  
访问tugraph-db-browser: `http://x.x.x.x:7070`，数据库地址格式为 `bolt://ip:bolt_port`（老版本不用填），默认用户名为 `admin`，密码为 `73@TuGraph`。
首次登录会默认跳转修改密码页面，请尽快修改默认密码避免安全风险。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.1.通过docker快速体验'}","page_content='部署高可用模式

8.docker部署高可用集群

8.1.安装镜像

使用如下命令下载TuGraph的编译docker镜像环境
```shell
docker pull tugraph/tugraph-compile-centos7
```
然后拉取TuGraph源码并编译安装' metadata={'Header 1': '部署高可用模式', 'Header 2': '8.docker部署高可用集群', 'Header 3': '8.1.安装镜像'}","page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

1. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7:${VERSION}
```  
2. 启动docker  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}"
当创建组合索引时，需要提供哪些参数？,"page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属性不会存在相同的值。
由于底层存储设计，组合索引key需要保存属性的长度，因此，
组合唯一索引k' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.addEdgeIndex(label_name, field_name, unique, pair_unique)

create an index on some field of one edge label .  
**Parameters:**  
| parameter | parameter type | description               |
| ---------- | -------------- | ------------------------------------- |
| label_name | string     | name of the label             |
| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |
| pair_unique | boolean    | Specifies whether the index is pair_unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.addEdgeIndex('BornIn', 'id', true, false)
```  
**Example output:**  
```
Added index [BornIn:id]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addEdgeIndex(label_name, field_name, unique, pair_unique)'}","page_content='Vector index

创建向量索引

如下json定义了一个点类型，名字是`person`, 里面有个字段是`embedding`，类型是`FLOAT_VECTOR`，用来存储向量数据。
目前向量数据只能在点上创建。  
```json
{
""label"": ""person"",
""primary"": ""id"",
""type"": ""VERTEX"",
""properties"": [{
""name"": ""id"",
""type"": ""INT32"",
""optional"": false
}, {
""name"": ""age"",
""type"": ""INT32"",
""optional"": false
}, {
""name"": ""embedding"",
""type"": ""FLOAT_VECTOR"",
""optional"": false
}]
}

```
把上面这个json序列化成字符串，作为参数传入，建议使用驱动的参数化特性，避免自己拼接语句。
```
CALL db.createVertexLabelByJson($json_data)
```
给`embedding`字段添加向量索引，第三个参数是个map，里面可以设置一些向量索引的配置参数，如下，`dimension`设置向量维度是4
```
CALL db.addVertexVectorIndex('person','embedding', {dimension: 4});
```  
再定义一个边，用来测试，如下json定义了一个边类型，名字是`like`。
```json
{
""label"": ""like"",
""type"": ""EDGE"",
""constraints"": [
[""person"", ""person""]
],
""properties"": []
}
```
把上面这个json序列化成字符串，作为参数传入。
```
CALL db.createEdgeLabelByJson($json_data)
```  
写入几条测试数据
```
CREATE (n1:person {id:1, age:10, embedding: [1.0,1.0,1.0,1.0]})
CREATE (n2:person {id:2, age:20, embedding: [2.0,2.0,2.0,2.0]})
CREATE (n3:person {id:3, age:30, embedding: [3.0,3.0,3.0,3.0]})
CREATE (n1)-[r:like]->(n2),
(n2)-[r:like]->(n3),
(n3)-[r:like]->(n1);
```' metadata={'Header 1': 'Vector index', 'Header 2': '创建向量索引'}"
函数 `SetField` 抛出的异常之一是什么？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

`图项目`提供可视化的图项目管理和图数据研发功能，它为用户提供了一系列便捷的图数据可视化操作，包括图项目的创建、修改、删除等管理操作，以及图数据的查询、点边统计等操作。此外，它也支持图模型的管理，使用户可以更加方便地进行图数据的管理和维护。  
#### 2.4.1.图项目管理  
在`图项目`界面，可以看到当前图数据库中的图项目。  
![图项目-首页](../../../images/browser/graphmanagement-homepage.png)  
##### 2.4.1.1.新建图项目  
在`图项目`界面，点击`新建图项目`按钮创建一个新的图项目。  
![图项目-新建图项目按钮](../../../images/browser/graphmanagement-creategraph.png)  
新建图项目需要通过`选择模板`和`填写配置`两个页面完成图项目的创建。  
- __选择模板__：产品提供空模板和demo模板两类模板。
- 空模板：全新的图项目，用户需要自己创建图模型和导入图数据，一般用于正式项目开发。
- demo模板：产品内置的demo数据，图项目创建成功后，系统会自动创建demo图模型并导入demo图数据，一般用于试用和学习。  
![图项目-选择模板](../../../images/browser/graphmanagement-selecttemplate.png)  
- __填写配置__：用户需要填写图项目基本信息，并点击`创建`按钮创建图项目。
- 图名称：新建图项目的名称，同时作为该图项目的唯一主键。支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图描述：新建图项目的描述，可用于详细说明该项目的背景和目标。
- 高级配置-最大存储空间：设置图项目最大可占用的存储空间，实际并不会提前占用物理存储空间，实际数据量达到最大存储空间阈值后不可再写入数据。  
![图项目-填写配置](../../../images/browser/graphmanagement-configure.png)  
创建成功后，可在`图项目`页面的图项目选项卡中查看。  
##### 2.4.1.2.编辑图项目  
在`图项目`界面，点击图项目选项卡中的`编辑`按钮（笔形图标），编辑对应图项目的基础信息。  
![图项目-编辑图项目按钮](../../../images/browser/graphmanagement-editgraph-button.png)  
编辑图项目功能可以修改`图描述`和`最大存储空间`。  
![图项目-编辑图项目](../../../images/browser/graphmanagement-editgraph.png)  
##### 2.4.1.3.删除图项目  
在`图项目`界面，点击图项目选项卡中的`删除`按钮（垃圾桶图标），删除对应的图项目。  
![图项目-删除图项目按钮](../../../images/browser/graphmanagement-deletegraph-button.png)  
_需要注意：图项目删除后无法恢复_。  
##### 2.4.1.4.点边统计  
在`图项目`界面，点击图项目选项卡中的`点边统计`按钮（刷新图标），统计对应图项目当前时间节点的点边数量。  
![图项目-点边统计按钮](../../../images/browser/graphmanagement-statistics-button.png)  
统计结果将展示在图项目选项卡上，已经统计过点边数据的图项目再次统计需要点击`刷新`按钮。  
![图项目-点边统计](../../../images/browser/graphmanagement-statistics.png)  
![图项目-刷新点边统计按钮](../../../images/browser/graphmanagement-statistics-refresh-button.png)  
##### 2.4.1.5.存储过程  
在`图项目`界面，点击图项目选项卡中的`存储过程`按钮（卡片最右侧图标），跳转到操作存储过程的图页面。  
![图项目-存储过程按钮](../../../images/browser/graphmanagement-procedure-button.png)  
在`存储过程`页面，可以新建存储过程，新建时需要填写""存储过程名称""、""存储过程类型""、""存储过程描述""，然后选择""版本""和""执行时是否修改数据库""  
![图项目-存储过程](../../../images/browser/graphmanagement-procedure.png)  
更多存储过程的相关操作可见 [存储过程]' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
EXPO' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}"
TuGraphClient是什么？,"page_content='TuGraph Java Client

特性

- Java中的RPC客户端
- OGM，即对象图映射，支持将图中的实体和关系映射到Java对象，从而加速Java开发过程。' metadata={'Header 1': 'TuGraph Java Client', 'Header 2': '特性'}","page_content='Python客户端

1. 概述

Python的TuGraph Client有两种，一种是RESTful的Client，使用HTTP方法向server发送请求，另一种是RPC的Client，使用RPC方法调用server远程服务，两者各有优劣。
RESTful client的使用方式简单，在项目的src/client/python/TuGraphClient目录下可以找到Client的源码文件，直接安装到用户环境中即可使用，但是支持的功能较少，
性能也不高。RPC Client既支持单机的server，也支持高可用集群和负载均衡，接口较多，功能强大。但是使用方式较为复杂，需要用户自己编译TuGraph项目得到liblgraph_client_python.so，
或者使用runtime镜像时直接在/usr/local/lib64目录下找到该依赖库，将其引入python项目即可正常使用。接下来将详细介绍这两种Client的使用方式。' metadata={'Header 1': 'Python客户端', 'Header 2': '1. 概述'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}"
TuGraph 支持哪些类型的硬件平台？,"page_content='环境准备

1.硬件环境

1.1. CPU

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的硬件平台，测试认证过的硬件平台包括 Intel、AMD、Kunpeng、Hygon、飞腾等。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.1. CPU'}","page_content='快速上手

1.简介

1.1.支持的平台

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的的平台。' metadata={'Header 1': '快速上手', 'Header 2': '1.简介', 'Header 3': '1.1.支持的平台'}","page_content='环境准备

2.软件环境

2.1. 操作系统

TuGraph 能够兼容主流操作系统，包括Ubuntu、CentOS、SUSE、银河麒麟、 中标麒麟、UOS等，均通过测试认证。  
其中最稳定使用的系统版本是 Ubuntu 18.04、CentOS 7、CentOS 8。' metadata={'Header 1': '环境准备', 'Header 2': '2.软件环境', 'Header 3': '2.1. 操作系统'}"
"我想问一下字节流导入点边数据的api：boolean ret = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000);前两个参数的格式，是不是和执行导入脚本一样","page_content='Python客户端

3.RPC Client

3.12.从字节流中导入点边数据

```python
ret, res = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000)
```
```
importDataFromContent(self: liblgraph_client_python.client, desc: str, data: str, delimiter: str, continue_on_error: bool, thread_nums: int, graph: str, json_format: bool, timeout: float) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.12.从字节流中导入点边数据'}","page_content='Java客户端

2.使用示例

2.12.从字节流中导入点边数据

```java
boolean ret = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000);
log.info(""importDataFromContent : "" + ret);
```
```
@param desc: data format description
@param data: the data to be imported
@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromContent(String desc, String data, String delimiter, boolean continueOnError,
int threadNums, String graph, double timeout) throws UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='C++客户端

2.使用示例

2.12.从字节流中导入点边数据

```C++
std::string str;
ret = client.ImportDataFromContent(str, sImportContent[""person_desc""], sImportContent[""person""],"","");
```
```
bool ImportDataFromContent(std::string& result, const std::string& desc,
const std::string& data, const std::string& delimiter,
bool continue_on_error = false, int thread_nums = 8,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0);
@param [out] result              The result.
@param [in]  desc                data format description.
@param [in]  data                the data to be imported.
@param [in]  delimiter           data separator.
@param [in]  continue_on_error   (Optional) whether to continue when importing data fails.
@param [in]  thread_nums         (Optional) maximum number of threads.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  timeout             (Optional) Maximum execution time, overruns will be
interrupted.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}"
什么标签和属性用于表示OGM中类的映射为一个边类型？,"page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

0 映射原理

TuGraph-OGM 将 JAVA 对象映射为图的对象，类映射为点，类的属性映射为图中的属性，类中的方法映射为操作 TuGraph 的查询语句。  
以电影场景为例，对演员、电影、导演之间的关系进行数据化，就形成了非常典型的图数据。举一个简单的示例，演员Alice在1990年和2019年分别出演了两部电影《Jokes》和《Speed》，其中《Jokes》的导演是Frank Darabont。  
以图的思维来看，演员、导演、电影可以被映射为三种不同的节点，而出演、执导可以被映射为两种边，映射结果如上图所示，将数据存入图数据库后，相关的开发人员就可以使用各类图查询语言对数据进行查询。  
但对非图数据库相关的开发人员来说，这个例子中的演员、导演、电影作为实体，同样可以映射为类中的对象，而与实体相关联的对象可以通过集合存储，这是大多数开发人员熟悉的领域。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '0 映射原理'}","page_content='TuGraph-OGM

1.简介

> TuGraph-OGM 项目在其他仓库开源。  
TuGraph-OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。同时 TuGraph-OGM 兼容 Neo4j-OGM，Neo4j 生态用户可以无缝迁移到 TuGraph 数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '1.简介'}","page_content='TuGraph-OGM

简介

TuGraph-OGM(Object Graph Mapping), 源自 `Neo4j-OGM` 项目，TuGraph-OGM
支持将JAVA对象（POJO）映射到TuGraph中，JAVA中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此JAVA开发人员可以在熟悉的生态中轻松地使用TuGraph数据库。同时TuGraph-OGM兼容Neo4j-OGM，Neo4j生态用户可以无缝迁移到TuGraph数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '简介'}"
如果在对 DateTime 对象使用 operator+= 或 operator-= 运算时发生溢出，会如何处理？,"page_content='C++客户端

2.使用示例

2.6.调用存储过程

```C++
std::string str;
bool ret = client.CallProcedure(str, ""CPP"", ""test_plugin1"", ""bcefg"");
```
```
bool CallProcedure(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& param,
double procedure_time_out = 0.0, bool in_process = false,
const std::string& graph = ""default"", bool json_format = true,
const std::string& url = """");
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  url                 (Optional) Node address of calling procedure.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}","page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

#### 6.10.1.指定文件内容导入  
- **URI**: `/db/{graph_name}/import/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |
| data | 要导入的文件内容（建议最大在 16MB 左右，最长不超过 17MB） | 字符串 / 数组 / 对象 |
| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""description"": ""{\\""files\\"":[{\\""columns\\"":[\\""SRC_ID\\"",\\""role\\"",\\""DST_ID\\""],\\""format\\"":\\""CSV\\"",\\""label\\"":\\""role\\"",\\""SRC_ID\\"":\\""actor\\"",\\""DST_ID\\"":\\""movie\\""}]}""}"",
""data"": ""1,Role1,2\n3,Role2,4\n"",
""continue_on_error"": true,
""delimiter"": "",""
}
```  
上述 description 的值是如下 json 序列化后的字符串  
```json
{
""files"": [
{
""format"": ""CSV"",
""label"": ""role"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""log"": ""Missing src uid 1\n""
}
```  
由于请求中指定了在出错时继续，该返回信息说明 SRC_ID 为 1 的边没有被导入，而其他信息导入成功。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}","page_content='C++客户端

2.使用示例

2.7.向leader调用存储过程

```C++
std::string str;
bool ret = client.CallProcedureToLeader(str, ""CPP"", ""test_plugin1"", ""bcefg"");
```
```
bool CallProcedureToLeader(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& param,
double procedure_time_out = 0.0, bool in_process = false,
const std::string& graph = ""default"", bool json_format = true);
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@returns True if it succeeds, false if it fails.
```
本接口支持在HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.7.向leader调用存储过程'}"
AlterEdgeLabelAddFields函数成功执行的条件是什么？,"page_content='业务开发指南

边类型操作

边类型添加字段

>该操作会同步变更所有该类型边的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于边类型`edge1`，一次添加了两个字段: `field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是`0`.
```
CALL db.alterLabelAddFields('edge', 'edge1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型添加字段'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

Adds specified fields to the label.  
**Parameters:**  
| parameter    | parameter type | description           |
| ---------------- | -------------- | ------------------------- |
| label_type       | string     | either 'vertex' or 'edge' |
| label_name       | string     | name of the label     |
| field_value_spec | list       | specification of a field  |  
in which each `field_value_spec` is a list of string in the form of `[field_name, field_type, field_value, optional]`, where: `field_value` is the default value of the field.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelAddFields(
'vertex',
'new_label',
['birth_date', DATE, '', true],
['img', BLOB, '', true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}","page_content='业务开发指南

点类型操作

点类型添加字段

>该操作会同步变更所有该类型点的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于点类型`node1`，一次添加了两个字段：`field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是0.
```
CALL db.alterLabelAddFields('vertex', 'node1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '点类型操作', 'Header 3': '点类型添加字段'}"
带权图的边权重是什么类型的数值？,"page_content='OlapOnDisk API

2. 算法举例

2.2 配置类MyConfig

MyConfig配置类函数用于提供算法逻辑计算时所需的配置信息，继承于ConfigBase<EdgeData>,其中EdgeDate可根据加载图类型不同选择Empty（无权图）、int（带权图权重为整数）或者double（带权图权重为double）类型。  
MyConfig配置类一般根据算法不同，需要额外配置信息如下：  
1.算法所需参数
2.算法名称
3.配置类内Print函数
其余公用成员继承与ConfigBase，可参考src/olap/olap_config.h查阅。  
```C++
class MyConfig : public ConfigBase<Empty> {
public:

// 算法所需参数初始化
size_t root = 0;
std::string name = std::string(""bfs"");
void AddParameter(fma_common::Configuration & config) {
ConfigBase<Empty>::AddParameter(config);
config.Add(root, ""root"", true)
.Comment(""the root of bfs"");
}
void Print() {
ConfigBase<Empty>::Print();
std::cout << ""  name: "" << name << std::endl;
if (root != size_t(-1)) {
std::cout << ""  root: "" << root << std::endl;
} else {
std::cout << ""  root: UNSET"" << std::endl;
}
}
// 配置文件接受命令行参数，该用例会顺次读取命令行调用算法时的参数，优先使用用户指定数值，若用户并未指定则选择默认参数。
MyConfig(int &argc, char** &argv): ConfigBase<Empty>(argc, argv) {
fma_common::Configuration config;
AddParameter(config);
config.ExitAfterHelp(true);
config.ParseAndFinalize(argc, argv);
Print();
}
};
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.2 配置类MyConfig'}","page_content='OlapOnDB API

4. 其他常用函数功能描述

4.6 获取出边集合

```C++
/*
函数名称：AdjList<EdgeData> OutEdges(size_t vid)
数据结构:
AdjList 可以理解为类型为AdjUnit结构体的数组
AdjUnit 有两个成员变量： 1. size_t neighbour 2. edge_data，其中neighbour表示该出边指向的目标节点编号，如果为有权图，则edge_data数据类型和输入文件中边的权重值相同，否则数据类型为Empty

使用示例：输出节点vid的所有出度邻居
*/
for (auto & edge : olapondb.OutEdges(vid)) {
size_t dst = edge.neighbour;
printf(""src = %lu,dst = %lu\n"",vid,dst);
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.6 获取出边集合'}","page_content='内置算法

扩展算法包

带权重的网页排序

带权重的网页排序算法程序实现了Weighted Pagerank算法。与PageRank算法不同的是，Rank值的传递跟边的权重有关，点的Rank值将按照边权重加权传递到相邻点。算法内容请参考[https://en.wikipedia.org/wiki/PageRank](https://en.wikipedia.org/wiki/PageRank)。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': '带权重的网页排序'}"
RPC 是一种如何工作的通信协议？,"page_content='RPC API

1.简介

TuGraph 提供丰富的 RPC API，以供开发者通过 RPC 请求远程调用 TuGraph 提供的服务。  
RPC（远程过程调用）是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。
相比REST，RPC 面向方法，主要用于函数方法的调用，可以适合更复杂通信需求的场景，且性能更高。
brpc是用c++语言编写的工业级RPC框架，基于brpc，TuGraph 提供了丰富的RPC API，本文档描述
TuGraph 的 RPC API 使用方式。' metadata={'Header 1': 'RPC API', 'Header 2': '1.简介'}","page_content='C++客户端

1.概述

C++ Client 能够使用 RPC 连接lgraph_server，进行数据导入、执行存储过程、调用Cypher等操作。' metadata={'Header 1': 'C++客户端', 'Header 2': '1.概述'}","page_content='RPC API

2.请求

2.1.建立连接

开发者向TuGraph服务发送RPC请求，首先要建立连接。以C++语言为例，开发者创建指定url的通道（channel），
由通道创建指定的服务存根（LGraphRPCService_Stub），后续即可通过存根像调用本地方法一样向远程
服务器发送请求。  
```C++
std::shared_ptr<lgraph_rpc::m_channel_options> options = std::make_shared<lgraph_rpc::m_channel_options>();
options->protocol = ""baidu_std"";
options->connection_type = """";
options->timeout_ms = 60 * 60 * 1000 /*milliseconds*/;
options->max_retry = 3;
std::string load_balancer = """";
std::shared_ptr<lgraph_rpc::m_channel> channel = std::make_shared<lgraph_rpc::m_channel>();
if (channel->Init(url.c_str(), load_balancer, options.get()) != 0)
throw RpcException(""Fail to initialize channel"");
LGraphRPCService_Stub stub(channel.get());
```' metadata={'Header 1': 'RPC API', 'Header 2': '2.请求', 'Header 3': '2.1.建立连接'}"
TuGraph中主键的作用是什么？,"page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='TuGraph-DataX

3. 导入TuGraph

3.2.MySQL数据通过DataX导入TuGraph

我们在 `test` database 下建立如下电影 `movies` 表  
```sql
CREATE TABLE `movies` (
`mid`  varchar(200) NOT NULL,
`name` varchar(100) NOT NULL,
`year` int(11) NOT NULL,
`rate` float(5,2) unsigned NOT NULL,
PRIMARY KEY (`mid`)
);
```  
往表中插入几条数据  
```sql
insert into
test.movies (mid, name, year, rate)
values
('tt0188766', 'King of Comedy', 1999, 7.3),
('tt0286112', 'Shaolin Soccer', 2001, 7.3),
('tt4701660', 'The Mermaid',   2016,  6.3);
```  
建立一个 DataX 的 job 配置文件  
`job_mysql_to_tugraph.json`  
**配置字段方式**  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"": 1
}
},
""content"": [
{
""reader"": {
""name"": ""mysqlreader"",
""parameter"": {
""username"": ""root"",
""password"": ""root"",
""column"": [""mid"", ""name"", ""year"", ""rate""],
""splitPk"": ""mid"",
""connection"": [
{
""table"": [""movies""],
""jdbcUrl"": [""jdbc:mysql://127.0.0.1:3306/test?useSSL=false""]
}
]
}
},
""writer"": {
""name"": ""tugraphwriter"",
""parameter"": {
""url"": ""bolt://127.0.0.1:27687"",
""username"": ""admin"",
""password"": ""73@TuGraph"",
""graphName"": ""default"",
""labelType"": ""VERTEX"",
""labelName"": ""movie"",
""batchNum"": 1000,
""properties"": [""mid"", ""name"", ""year"", ""rate""]
}
}
}
]
}
}
```  
**写简单 sql 方式**  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"": 1
}
},
""content"": [
{
""reader"": {
""name"": ""mysqlreader"",
""parameter"": {
""username"": ""root"",
""password"": ""root"",
""connection"": [
{
""querySql"": [
""select mid, name, year, rate from test.movies where year > 2000;""
],
""jdbcUrl"": [""jdbc:mysql://127.0.0.1:3306/test?useSSL=false""]
}
]
}
},
""writer"": {
""name"": ""tugraphwriter"",
""parameter"": {
""url"": ""bolt://127.0.0.1:27687"",
""username"": ""admin"",
""password"": ""73@TuGraph"",
""graphName"": ""default"",
""labelType"": ""VERTEX"",
""labelName"": ""movie"",
""batchNum"": 1000,
""properties"": [""mid"", ""name"", ""year"", ""rate""]
}
}
}
]
}
}
```  
`./lgraph_server -c lgraph_standalone.json -d 'run'` 启动 TuGraph 后执行如下命令：  
```shell
python3 datax/bin/datax.py  job_mysql_to_tugraph.json
```' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '3. 导入TuGraph', 'Header 3': '3.2.MySQL数据通过DataX导入TuGraph'}","page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}"
RpcException是什么类型的异常？,"page_content='RPC API

2.请求

2.1.建立连接

开发者向TuGraph服务发送RPC请求，首先要建立连接。以C++语言为例，开发者创建指定url的通道（channel），
由通道创建指定的服务存根（LGraphRPCService_Stub），后续即可通过存根像调用本地方法一样向远程
服务器发送请求。  
```C++
std::shared_ptr<lgraph_rpc::m_channel_options> options = std::make_shared<lgraph_rpc::m_channel_options>();
options->protocol = ""baidu_std"";
options->connection_type = """";
options->timeout_ms = 60 * 60 * 1000 /*milliseconds*/;
options->max_retry = 3;
std::string load_balancer = """";
std::shared_ptr<lgraph_rpc::m_channel> channel = std::make_shared<lgraph_rpc::m_channel>();
if (channel->Init(url.c_str(), load_balancer, options.get()) != 0)
throw RpcException(""Fail to initialize channel"");
LGraphRPCService_Stub stub(channel.get());
```' metadata={'Header 1': 'RPC API', 'Header 2': '2.请求', 'Header 3': '2.1.建立连接'}","page_content='RPC API

5.存储过程

5.3.删除存储过程

删除存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称  
以C++为例，用户删除存储过程的方式如下所示：
```C++
LGraphRequest req;
req.set_is_write_op(true);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
lgraph::DelPluginRequest* dpRequest = pluginRequest->mutable_del_plugin_request();
dpRequest->set_name(procedure_name);
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
删除存储过程的响应不包含参数，如果删除失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.3.删除存储过程'}","page_content='RPC API

4.查询

用户可以通过Cypher查询和TuGraph进行绝大多数的交互，Cypher请求信息包含以下参数：
- query: 必要参数，Cypher查询语句
- param_names: 可选参数，参数名
- param_values: 可选参数，参数值
- result_in_json_format: 必要参数，查询结果是否以JSON格式返回
- graph: 可选参数，Cypher语句执行的子图名称
- timeout: 可选参数，Cypher语句执行的超时时间  
以C++为例，用户发送Cypher请求的方式如下所示：
```C++
LGraphResponse res;
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
LGraphRequest req;
req.set_client_version(server_version);
req.set_token(token);
lgraph::CypherRequest* cypher_req = req.mutable_cypher_request();
cypher_req->set_graph(graph);
cypher_req->set_query(query);
cypher_req->set_timeout(timeout);
cypher_req->set_result_in_json_format(true);
LGraphRPCService_Stub stub(channel.get());
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
server_version = std::max(server_version, res.server_version());
CypherResponse cypher_res = res.cypher_response();
```
Cypher请求响应为以下两个参数之一：
- json_result: JSON格式的cypher查询结果
- binary_result: CypherResult格式的cypher查询结果' metadata={'Header 1': 'RPC API', 'Header 2': '4.查询'}"
match语句中是否支持set多个属性,"page_content='QA汇总

Cypher QA

merge语法错误

Q：MERGE语法报错（""BadRequest CypherException: Function not implemented yet: ExtractNodePattern at :166""），查询语句（MERGE (n1:domain {name:'root',id: 'root', tag: 'root'})）
A：现在对于有多个属性的这种Merge语法还没完全支持，可以参考这几种用法：  
1. MERGE (n:Person {name:'Zhugeliang'}) ON CREATE SET n.gender=1,n.birthyear=181 RETURN n.name
2. MERGE (n:Person {name:'Liubei'}) ON MATCH SET n.birthyear=2010 RETURN n.birthyear' metadata={'Header 1': 'QA汇总', 'Header 2': 'Cypher QA', 'Header 3': 'merge语法错误'}","page_content='Cypher API

2.Clauses

2.7.CREATE

- Create nodes  
> **Note**
> TuGraph不支持创建空的nodes，不支持多labels。  
- ☒ Create single node  
```
CREATE (n)
```  
- ☒ Create multiple nodes  
```
CREATE (n), (m)
```  
- ☒ Create a node with a label  
```
CREATE (n:person)
```  
- ☒ Create a node with multiple labels  
```
CREATE (n:Person:Swedish)
```  
- ✓ Create node and add labels and properties  
```
CREATE (n:person {id:2001, name: 'Andres'})
```  
- ✓ Return created node  
```
CREATE (n:person {id:2002, name: 'Andres'})
RETURN n
```  
- Create relationships
- ✓ Create a relationship between two nodes  
```
MATCH (n:person), (m:movie)
WHERE n.name = 'Jada Pinkett Smith' AND m.title = 'The Matrix'
CREATE (n)-[r:write]->(m)
```  
- ✓ Create a relationship and set properties  
```
MATCH (n:person), (m:movie)
WHERE n.name = 'Jada Pinkett Smith' AND m.title = 'The Matrix'
CREATE (n)-[r:acted_in{role: 'Trinity'}]->(m)
```  
- ❏ Create a full path  
```
CREATE p = (andres:person {id: 2005, name:'Andres'})-[:acted_in {role: 'Trinity'}]->
(m:movie {id: 2006})<-[:acted_in {role: 'Trinity'}]-(michael {id: 2006, name:'Michael'})
RETURN p
```  
- Use parameters with CREATE
- ❏ Create node with a parameter for the properties  
```
CREATE (n:Person $props)
RETURN n
```  
- ☒ Create multiple nodes with a parameter for their properties  
```
UNWIND $props AS map
CREATE (n)
SET n = map
```
cannot create vertex without label.' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.7.CREATE'}","page_content='场景：三体

6.查询展示

6.4.设置/更改属性

随着剧情推进，我们逐步了解了""叶文洁""身上的多个标签，那么我们也可以将这些标签更新至“叶文洁”节点上：  
```cypher
MATCH (p:person {name: ""叶文洁""})
SET p.introduce = ""清华大学教授、ETO精神领袖、首位和三体人交流的人""
RETURN p
```' metadata={'Header 1': '场景：三体', 'Header 2': '6.查询展示', 'Header 3': '6.4.设置/更改属性'}"
TuGraph DB关于Antlr4改进了哪些性能方面的内容？,"page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

关于 Antlr4

Antlr4 是一款备受欢迎的开源解析器生成器，能够根据语法规则快速生成自定义解析器。其支持 LL(\*)解析，拥有更强大的错误处理能力和更快的解析速度。不仅如此，Antlr4 还支持 Java、Python、C++、JavaScript、Go 等 10 种目标语言，广泛应用于多种开发语言生态中。简单易用的 API 和文档使得开发人员能够快速上手。无论是编程语言、数据格式、编译器还是解释器等领域，Antlr4 都发挥着重要作用。  
著名的开源项目如 Apache Spark、Eclipse IDE 和 MongoDB 等都选择了 Antlr4。 对于语言工具开发者而言，Antlr4 是不可或缺的工具，能大幅提高开发效率和代码质量。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '关于 Antlr4'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

贡献和成果

对Antlr4的优化的效果十分显著，32 线程的并发性能提升超过 18 倍 。考虑到实际生产服务器性能远高于测试机型，实际的性能提升效果将比测试结果更高， 优化后 GQL 解析能力已能完全满足企业业务的需要。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '贡献和成果'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

当 TuGraph 遇见 Antlr4

ISO GQL（ISO/IEC 39075）是一种标准化的图数据库查询语言，蚂蚁集团是其主要贡献者之一。因此，Antlr4 作为一种强大的解析器生成器，成为了蚂蚁图数据库 TuGraph 生成 GQL 解释器的理想选择。Antlr4 能够帮助团队更快、更准确地构建图数据库的查询语言，从而提高产品性能和用户体验。  
然而，当我们从开发场景来到生产场景，超高的并发量带来一个严重问题：Antlr4 C++ target 的并发性能不足以支持所需的超高并发 GQL 请求。经过调研并与 Antlr 开源社区讨论，我们发现\*\*并发性能这个问题普遍存在，并且在过去 5 年中持续困扰着 C++生态的开发者。\*\*我们决定解决这个问题。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '当 TuGraph 遇见 Antlr4'}"
TuGraph 和 OpenCypher 在处理节点和关系的标签数量上有什么不同？,"page_content='Cypher API

4.附录1. 语法扩充及不同

TuGraph查询语言与OpenCypher的不同点如下：  
- Label数量
- TuGraph: Each node/relationship must have one and only one label. So error occurs when there is no label, and the 1st label will be picked as the label if there are more than one label.
- OpenCypher: One node/relationship may have 0 to many labels.
- Schema.
- TuGraph: TuGraph has strong schema
- OpenCypher: schema-less' metadata={'Header 1': 'Cypher API', 'Header 2': '4.附录1. 语法扩充及不同'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}"
函数DeleteVertexIndex成功执行时返回什么值？,"page_content='Python Olap API

5. lgraph_db API

Transaction：

```
GetVertexIndexIterator(
label: std::string,
field: std::string,
key_start: std::string,
key_end: std::string)-> VertexIndexIterator
```
获取索引迭代器。迭代器的field值为 [key_start, key_end]。所以在key_start=key_end=v时，返回指向field值为v的点的迭代器  
lgraph_db_python.py是lgraph_db.pxd中C++类 Galaxy与GraphDB的包装，将C++类包装为Python类，将lgraph_db_python.py编译为Python拓展后，可以直接在Python文件或Python命令行中`import lgraph_db_python`访问lgraph_db_python.PyGraphDB与PyGraphDB.PyGalaxy。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Transaction：'}","page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/node/{vid}
```  
Nodes 提供节点（Vertex）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。  
#### 6.7.1.列出点数量和label数量  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| num_label | 点 label 数量 | 整数 |
| num_vertex | 点数量 | 整数 |  
_注意 num_vertex 返回的并不是准确的点数量，只是一个估计值。_  
#### 6.7.2.创建一个点  
向数据库中插入一个点。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 点属性 | 字典，其中 key 是列名，value 是相应值。value 必须是与列类型相应的类型，如列为 int32，则 value 只能是整数。 |  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新点 vid。该 ID 可用于后续的点操作中。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""property"" : {
""name"" : ""Passerby A"",
""birthyear"" : 1989
}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
21
}
```  
#### 6.7.3.批量创建点  
TuGraph 允许一次性插入多个点，以减少网络开销。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| fields | 点属性 | 列表 |
| values | 点数据 | 列表 |  
其中 fields 是一个字符串列表，列出一系列列名；values 是一个列表，其中每个元素是一个列表，列表中每个元素是列数据。  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新增加的点的 vid 列表，该列表中每一个 vid 按顺序对应请求中的每一个点。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""fields"" : [""name"", ""birthyear""],
""values"" : [[""alex"", 2000],
[""bob"", 1999]]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
22,
23
]
}
```  
#### 6.7.4.获取点  
- **URI**: `/db/{graph_name}/node/{vertex_id}`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 属性 | 字典，格式为 { {列名 1}:{列值 1},...' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}","page_content='RESTful API Legacy

5.存储过程

5.5.删除存储过程

- **URI**: `/db/{graph_name}/cpp_plugin|python_plugin/{plugin_name}`
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• DELETE http://localhost:7070/db/graph1/cpp_plugin/example_plugin
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程', 'Header 3': '5.5.删除存储过程'}"
现在tugraph-analytics是不支持窗口函数吗？,"page_content='🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！

仅需 5 步，即可呈现 🎊

1. 启动 GeaFlow 流图作业和 Socket 服务

参考 [快速开始](https://github.com/TuGraph-family/tugraph-analytics/blob/master/docs/docs-cn/quick_start.md)  
⚠️ 注意在 `启动SocketServer` 步骤使用下列命令代替  
```bash
bin/socket.sh 9003 GI
```  
输出下列内容时，即表示 Tugraph Analytics 准备好建立连接  
<img width=""610"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/a25ed6ba-4fb9-4db1-9325-ee2f26a4337f"">  
> 如启动服务过程中遇到问题，可见 https://github.com/TuGraph-family/tugraph-analytics/issues/1' metadata={'Header 1': '🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！', 'Header 2': '仅需 5 步，即可呈现 🎊', 'Header 3': '1. 启动 GeaFlow 流图作业和 Socket 服务'}","page_content='🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！

仅需 5 步，即可呈现 🎊

5. 结果展示

Tugraph Analytics 完成环路检测计算任务后，会自动返回检测结果。  
<img width=""324"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/ba343acf-812a-4df5-8da4-ff70e0b2531d"">  
右侧画布中会动态显示出本次环路检测结果信息：  
![Jun-12-2023 19-53-35](https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/f8595322-d477-4702-a52e-4f03092b7219)' metadata={'Header 1': '🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！', 'Header 2': '仅需 5 步，即可呈现 🎊', 'Header 3': '5. 结果展示'}","page_content='🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！

仅需 5 步，即可呈现 🎊

4. 演示

环路检测 Demo 提供了两种方式来进行交互：  
* 方式一 在输入框中输入点边信息
* 方式二 使用内置数据进行演示  
> 两种方式本质都是调用 Tugraph Analytics 进行实时计算，不过方式二省略了手动输入过程。  
这里我们使用内置数据进行快速演示，点击【选项】，选择`添加点`，画布中出现了 7 个点信息；接着选择`添加边`。我们可以在上方对话框中看到添加记录。  
<img width=""332"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/7ca76607-41a1-4afe-9427-cf7599de6889"">  
同样的，Tugraph Analytics 终端也会实时输出操作信息，并自动启动计算任务。  
<img width=""611"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/d8d0d73a-4c07-4ecd-bcac-4633a742933a"">' metadata={'Header 1': '🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！', 'Header 2': '仅需 5 步，即可呈现 🎊', 'Header 3': '4. 演示'}"
当调用CallProcedure函数时，如果设置json_format参数为false，返回的结果格式是什么？,"page_content='C++客户端

2.使用示例

2.7.向leader调用存储过程

```C++
std::string str;
bool ret = client.CallProcedureToLeader(str, ""CPP"", ""test_plugin1"", ""bcefg"");
```
```
bool CallProcedureToLeader(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& param,
double procedure_time_out = 0.0, bool in_process = false,
const std::string& graph = ""default"", bool json_format = true);
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@returns True if it succeeds, false if it fails.
```
本接口支持在HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.7.向leader调用存储过程'}","page_content='Java客户端

2.使用示例

2.6.调用存储过程

```java
String result = client.callProcedure(""CPP"", ""khop"", kHopParamGen(), 1000, false, ""default"");
log.info(""testCallProcedure : "" + result);
```
```
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param param: the execution parameters
@param procedureTimeOut: Maximum execution time, overruns will be interrupted
@param inProcess: Running query or not
@param graph: the graph to query
@param jsonFormat: (Optional) Return format of calling stored procedure
@param url: (Optional) Node address of calling procedure
@return: the result of procedure execution
public String callProcedure(String procedureType, String procedureName, String param, double procedureTimeOut,
boolean inProcess, String graph, String url)
```
本接口支持在单机模式和HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}","page_content='C++客户端

2.使用示例

2.6.调用存储过程

```C++
std::string str;
bool ret = client.CallProcedure(str, ""CPP"", ""test_plugin1"", ""bcefg"");
```
```
bool CallProcedure(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& param,
double procedure_time_out = 0.0, bool in_process = false,
const std::string& graph = ""default"", bool json_format = true,
const std::string& url = """");
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  url                 (Optional) Node address of calling procedure.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}"
在 PathTraversal 类中，通过调用哪个函数来通过传入的过滤器设置初始边界？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bo' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.1. Snapshot

C++ OLAP API 中的 Snapshot 模版类用于表示抽取出来的静态子图，其中 EdgeData 用来表示该子图上每条边所用权值的数据类型（如果边不需要权值，使用 Empty 作为 EdgeData 即可）。  
抽取的子图通过 Snapshot 类的构造函数来描述：  
```c
Snapshot::Snapshot(
GraphDB & db,
Transaction & txn,
size_t flags = 0,
std::function<bool(VertexIterator &)> vertex_filter = nullptr,
std::function<bool(OutEdgeIterator &, EdgeData &)> out_edge_filter = nullptr
);
```  
其中，db 为数据库句柄，txn 为事务句柄，flags 为生成时使用的选项，可选值包括以下的组合：SNAPSHOT_PARALLEL 表示导出时使用多个线程进行并行；SNAPSHOT_UNDIRECTED 表示需要将导出的图变为无向图。
vertex_filter 是面向点的用户自定义过滤函数，返回值为 true 表示该点需要被包含到待抽取的子图中，反之则表示需要被排除。
out_edge_filter 是面向边的用户自定义过滤函数，返回值为 true 表示该边需要被包含到待抽取的子图中，反之则表示需要被排除。
当过滤函数为缺省值时，则表示需要将所有点/边都包含进来。  
Snapshot 类提供的其它方法请参考详细的 C++ API 文档（olap_on_db.h）。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.1. Snapshot'}","page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentric function进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |  
- 详细接口  
```java
public interface VertexCentricTraversalFunction<K, VV, EV, M, R> extends VertexCentricFunction<K, VV
, EV, M> {

void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);
/** 图遍历算法初始化方法 */
void init(ITraversalRequest<K> traversalRequest);
/** 实现图遍历逻辑 */
void compute(K vertexId, Iterator<M> messageIterator);

void finish();

void close();

interface VertexCentricTraversalFuncContext<K, VV, EV, M, R> extends VertexCentricFuncContext<K,
VV, EV, M> {
/** 获取图遍历结果 */
void takeResponse(ITraversalResponse<R> response);
/** 获取开始图遍历的点 */
TraversalVertexQuery<K, VV> vertex();
/** 获取开始图遍历的边 */
TraversalEdgeQuery<K, EV> edges();

void broadcast(IGraphMessage<K, M> message);
}

interface TraversalVertexQuery<K, VV> extends VertexQuery<K, VV> {
/** 获取图遍历中点的迭代器 */
Iterator<K> loadIdIterator();
}

interface TraversalEdgeQuery<K, EV> extends EdgeQuery<K, EV> {
/** 通过指定的点id，获取对应的图遍历起点 */
TraversalEdgeQuery<K, EV> withId(K vertexId);
}
}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}"
GeaBase的主要部署方式需要多长时间？,"page_content='云部署

3.部署流程

3.5.启动TuGraph服务

- 查看服务实例：服务实例创建成功后，部署时间大约需要2分钟。部署完成后，页面上可以看到对应的服务实例，如下图  
![查看实例](../../../images/cloud-deployment-6.png)  
- 点击该服务实例访问TuGraph。进入到对应的服务实例后，可以在页面上获取到web、rpc、ssh共3种使用方式，并且页面上展示了admin用户的密码  
![访问方式](../../../images/cloud-deployment-7.png)  
- 点击web的链接，即可跳转访问已经部署好的TuGraph Web。建议新手先通过TuGraph Web，快速使用demo上手。
- 首先在TuGraph Web的登录页面上，输入默认用户名admin和页面上展示的admin用户的密码进行登录，参考下图
- 登录完成后，选择任意一个带有官方图标的图项目，其中内置了demo数据，开启图数据的探索和发现！  
![登录](../../../images/cloud-deployment-8.png)
![创建demo](../../../images/cloud-deployment-9.png)' metadata={'Header 1': '云部署', 'Header 2': '3.部署流程', 'Header 3': '3.5.启动TuGraph服务'}","page_content='Console平台介绍

部署架构

GeaFlow支持多种异构环境执行，以常见的K8S部署环境为例，GeaFlow物理部署架构如下：  
![deploy_arch](../../static/img/deploy_arch.png)  
在GeaFlow作业的全生命周期过程中，涉及的关键数据流程有：  
* **研发阶段**：Console平台提供了实例下所有的研发资源的管理，用户可以在创建任务前，提前准备所需的研发资源信息，并存储在Catalog。
* **构建阶段**：任务创建完成后，通过发布动作触发构建流水线，用户的JAR包、任务的ZIP包等会上传到RemoteFileStore。
* **提交阶段**：作业提交时，Console会根据作业的参数配置、运行时环境信息，以及远程文件地址等创建KubernetesJobClient，既而会拉起Client Pod，Client会拉起Master Pod，Master会拉起Container Pods和Driver Pod。所有的Pod拉起后，Client会把作业的Pipeline发送给Driver执行，Driver最终通过Cycle调度的Events与Containers交互。所有的Pod启动时都会从RemoteFileStore下载版本JAR包、用户JAR包、作业ZIP包等信息。Driver对DSL代码编译时，也需要通过Console提供的Catalog API操作Schema信息。
* **运行阶段**：作业运行时，各个组件会上报不同的数据和信息。Master会上报作业的心跳汇总信息，Driver会上报作业的Pipeline/Cycle指标以及错误信息，Container会上报作业的Offset、指标定义以及错误信息等。RuntimeMetaStore存储作业的Pipeline/Cycle指标、Offset、心跳汇总、错误等信息。HAMetaStore存储各个运行组件的地址信息。DataStore存储State数据和作业FailOver时所需的元数据信息。MetricStore存储运行时指标信息。
* **监控阶段**：Console会主要查询RuntimeMetaStore和MetricStore存储的信息用于作业的运行时监控。
* **清理阶段**：作业重置/删除时，Console会对作业的RuntimeMeta、HAMeta以及部分Data做清理操作。' metadata={'Header 1': 'Console平台介绍', 'Header 2': '部署架构'}","page_content='开始上手(GeaFlow Console运行)

Docker容器运行GeaFlow作业

下面介绍在docker容器里面运行前面[本地模式运行](quick_start.md)介绍的流图作业。  
1. 启动GeaFlow Console平台服务。  
* 远程镜像启动方式如下：  
**x86架构**
```
docker run -d --name geaflow-console -p 8888:8888 tugraph/geaflow-console:0.1
```  
**arm架构**
```
docker run -d --name geaflow-console -p 8888:8888 tugraph/geaflow-console-arm:0.1
```
通过**uname -a**命令可以查看机器架构类型.  
* 本地镜像启动方式如下：
```
docker run -d --name geaflow-console -p 8888:8888 geaflow-console:0.1
```
**注意**: 远程拉取镜像和本地镜像tag名称不同，启动命令有所区别。  
进入容器等待Java进程启动完成后，访问[localhost:8888](http://localhost:8888)进入GeaFlow Console平台页面。  
```shell
> docker exec -it geaflow-console tailf /tmp/logs/geaflow/app-default.log

# wait the logs below and open url http://localhost:8888
GeaflowApplication:61   - Started GeaflowApplication in 11.437 seconds (JVM running for 13.475)
```  
2. 注册用户  
首位注册用户将默认被设置为管理员，以管理员身份登录，通过一键安装功能开始系统初始化。  
![install_welcome](../static/img/install_welcome.png)  
3. 配置运行时环境  
GeaFlow首次运行需要配置运行时环境相关的配置，包括集群配置、运行时配置、数据存储配置以及文件存储配置。  
3.1 集群配置  
使用默认Container模式，即本地容器运行。  
![install_container](../static/img/install_container.png)  
3.2 运行时配置  
本地运行模式下可以跳过这一步配置，使用系统默认配置，直接点下一步。  
![install_conainer_meta_config.png](../static/img/install_conainer_meta_config.png)
3.3 数据存储配置  
选择图数据存储位置，本地模式下选择LOCAL,填写一个本地目录。默认不需填写，直接点下一步。  
![install_storage_config](../static/img/install_storage_config.png)  
3.4 文件存储配置  
该配置为GeaFlow引擎JAR、用户JAR文件的持久化存储，比如HDFS等。本地运行模式下和数据存储配置相同，选择LOCAL模式，填写一个本地目录。默认不需填写，直接点下一步。  
![install_jar_config](../static/img/install_jar_config.png)
配置完成后点击一键安装按钮，安装成功后，管理员会自动切换到个人租户下的默认实例，并可以直接创建发布图计算任务。  
4. 创建图计算任务  
进入图研发页面，选择左侧图任务Tab栏，点击右上角新增按钮，新建一个DSL作业。  
![create_job](../static/img/create_job.png)
分别填写任务名称、任务描述和DSL内容。其中DSL内容和前面本地运行作业介绍的一样，只需修改DSL,**将tbl_source和tbl_result表的${your.host.ip}替换成本机ip**即可。  
```sql
set geaflow.dsl.window.size = 1;
set geaflow.dsl.ignore.exception = true;

CREATE GRAPH IF NOT EXISTS dy_modern (
Vertex person (
id bigint ID,
name varchar
),
Edge knows (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight dou' metadata={'Header 1': '开始上手(GeaFlow Console运行)', 'Header 2': 'Docker容器运行GeaFlow作业'}"
在图论中，图的基本元素包括哪些？,"page_content='图相关DDL

Create Graph

**Syntax**
一个图至少包含一对点边，点表必须包含一个id字段作为主键，边表必须包含srcId和targetId作为主键，边表还可以有一个时间戳字段标识时间。  
```
CREATE GRAPH <graph name>
(
<graph vertex>
[ { , <graph vertex> } ... ]
, <graph edge>
[ { , <graph edge> } ... ]
) WITH （
storeType = <graph store type>
[ { , <config key> = <config value> } ... ]
);

<graph vertex>  ::=
VERTEX <vertex name>
(
<column name> <data type> ID
[ {, <column name> <data type> } ... ]
)

<graph edge>  ::=
Edge <edge name>
(
<column name> <data type> SOURCE ID
, <column name> <data type> DESTINATION ID
[ , <column name> <data type> TIMESTAMP ]
[ {, <column name> <data type> } ... ]
)

```  
**Example**
```sql
CREATE GRAPH dy_modern (
Vertex person (
id bigint ID,
name varchar,
age int
),
Vertex software (
id bigint ID,
name varchar,
lang varchar
),
Edge knows (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
),
Edge created (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
)
) WITH (
storeType = 'rocksdb',
shardCount = 2
);
```
这个例子创建了一张包含2个点2个边的图，存储类型为rocksdb, 分片数2个。' metadata={'Header 1': '图相关DDL', 'Header 2': 'Create Graph'}","page_content='图算法介绍

5.2 图迭代推理

定义图迭代计算结合推理逻辑如下：  
```
public static class PRVertexCentricComputeFunction implements
IncVertexCentricComputeFunction<Integer, Integer, Integer, Integer> {

private IncGraphComputeContext<Integer, Integer, Integer, Integer> graphContext;
private IncGraphInferContext<String> inferContext;

@Override
public void init(IncGraphComputeContext<Integer, Integer, Integer, Integer> graphContext) {
this.graphContext = graphContext;
this.inferContext = (IncGraphInferContext<String>) graphContext;
}

@Override
public void evolve(Integer vertexId,
TemporaryGraph<Integer, Integer, Integer> temporaryGraph) {
long lastVersionId = 0L;
IVertex<Integer, Integer> vertex = temporaryGraph.getVertex();
HistoricalGraph<Integer, Integer, Integer> historicalGraph = graphContext
.getHistoricalGraph();
if (vertex == null) {
vertex = historicalGraph.getSnapShot(lastVersionId).vertex().get();
}

if (vertex != null) {
List<IEdge<Integer, Integer>> newEs = temporaryGraph.getEdges();
List<IEdge<Integer, Integer>> oldEs = historicalGraph.getSnapShot(lastVersionId)
.edges().getOutEdges();
if (newEs != null) {
for (IEdge<Integer, Integer> edge : newEs) {
graphContext.sendMessage(edge.getTargetId(), vertexId);
}
}
if (oldEs != null) {
for (IEdge<Integer, Integer> edge : oldEs) {
graphContext.sendMessage(edge.getTargetId(), vertexId);
}
}
}

}

@Override
public void compute(Integer vertexId, Iterator<Integer> messageIterator) {
int max = 0;
while (messageIterator.hasNext()) {
int value = messageIterator.next();
max = max > value ? max : value;
}
IVertex<Integer, Integer> vertex = graphContext.getTemporaryGraph().getVertex();
IVertex<Integer, Integer> historyVertex = graphContext.getHistoricalGraph().getSnapShot(0).vertex().get();
if (vertex != null && max < vertex.getValue()) {
max = vertex.getValue();
}
if (historyVertex != null && max < historyVertex.getValue()) {
max = historyVertex.getValue();
}
graphContext.getTemporaryGraph().updateVertexValue(max);
}

@Override
public void finish(Integer vertexId, MutableGraph<Integer, Integer' metadata={'Header 1': '图算法介绍', 'Header 2': '5.2 图迭代推理'}","page_content='图算法介绍

1\. 图算法概述

在计算机科学中，图是一种表示实体（节点或顶点）以及实体之间关系（边）的数据结构。图模型可以天然地描述网络结构，能更清晰地表达复杂的数据关系和依赖，简化关联数据的理解和分析。在不同的场景下，图中点边具备不同的语义信息。比如在资金交易场景下，每个人可以抽象成一个点表示，人与人之间的转账关系可以抽象成一条边表示。通过图数据模型反映出各个实体之间的资金往来关系，让数据的关联分析更加直观和高效。  
在图数据模型上可以执行多种图算法，如社区检测，最短路径匹配，环路检测算法等。通过点边上的迭代计算，探索图模型中各个实体之间的关系。探索过程不依赖于数据的线性结构，从而便于识别隐藏的模式和关联关系。在主流迭代图算法中，节点通过消息传递的方式进行通信。每次迭代，节点可以接收来自它们邻居的消息，处理这些消息，然后决定是否发送新的消息给其他节点。迭代算法中，每个节点有一个状态，每次迭代它们都有可能更新这个状态直至收敛。例如，在PageRank算法中，每个节点的状态是其PageRank值，这个值在迭代过程中会随着邻居的值的更新而更新。  
图迭代算法解决了经典的图计算问题，但随着业务需求的复杂度提升，基于迭代的图算法存在着表达能力不足、自适应性能力差、异质图处理难度大等缺点。近年来随着深度学习的研究和应用的发展，以图神经网络（Graph Neural Networks，GNNs）为代表的一类神经网络算法，被设计用来捕获图中实体（节点）和关系（边）间的复杂模式。图神经网络能够结合节点特征和图的结构来学习节点和边的表示，相比之下，传统的迭代图算法通常不会直接从原始特征中学习，而更多地专注于结构特征。依赖于深度学习的天然优势，GNNs具有更强的表示学习能力，可以自动从数据中学习复杂的模式，这使得 GNNs 能够更好地处理多任务学习和迁移学习等问题。在社交网络分析、知识图谱、生物分子网络、推荐系统以及交通网络等领域，得到广泛应用。' metadata={'Header 1': '图算法介绍', 'Header 2': '1\\. 图算法概述'}"
TuGraph支持哪些编程语言？,"page_content='Procedure API

3.存储过程语言支持

在 TuGraph 中，用户可以动态的加载，更新和删除存储过程。TuGraph 支持 C++ 语言、 Python 语言和 Rust 语言编写存储过程。在性能上 C++ 语言支持的最完整，性能最优。  
注意存储过程是在服务端编译执行的逻辑，和客户端的语言支持无关。' metadata={'Header 1': 'Procedure API', 'Header 2': '3.存储过程语言支持'}","page_content='RPC API

5.存储过程

为满足用户较为复杂的查询/更新逻辑，TuGraph支持 C 语言和 Python 语言编写的存储过程。
用户可以使用RPC请求对存储过程进行增删改查操作。' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程'}","page_content='功能概览

4.核心功能

4.2.存储过程

当用户需要表达的查询/更新逻辑较为复杂（例如 Cypher 无法描述，或是对性能要求较高）时，相比调用多个 REST 请求并在客户端完成整个
处理流程的方式，TuGraph 提供的存储过程（Procedure）是更简洁和高效的选择。  
从 3.5 版本开始，TuGraph 重新设计了新的存储过程编程范式，支持定义标准的签名和结果，支持POG编程。  
TuGraph 支持 POG (Procedres on Graph Query Languages) 编程和 POG 库，其中“Graph Query Languages”包含 Cypher 以及
制定中的 ISO GQL 等图查询语言。POG 库提供在查询语言中对用户定义的存储过程的访问，打破了查询语言和存储过程之间的界限，扩展了查询
语言的使用范围。  
> 这个文档描述了 [新的 Procedure 编程范式以及 POG](../9.olap&procedure/1.procedure/1.procedure.md)。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.2.存储过程'}"
在这段代码中，如何获取存储过程响应的列表？,"page_content='RESTful API Legacy

5.存储过程

5.2.列出所有存储过程

- **URI**: `/db/{graph_name}/cpp_plugin|python_plugin`
- **METHOD**: GET
- **RESPONSE**: 存储过程列表，其中每个元素是一个 plugin 的描述，其格式为：
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | 存储过程名 | 字符串 |
| description | 存储过程描述 | 字符串 |
| read_only | 存储过程是否只读 | 布尔值 |  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/cpp_plugin
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
Output:
{
[
{
""description"":""adds a vertex label to the db"",
""name"":""add_label"",
""read_only"":false
},
{
""description"": ""scans graph and get number of edges"",
""name"": ""scan_graph"",
""read_only"": true
}
]
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程', 'Header 3': '5.2.列出所有存储过程'}","page_content='Procedure API

4.2.如何使用存储过程

4.2.2.列出已加载的存储过程

在服务器运行过程中，用户可以随时获取存储过程列表。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin')
>>> r.status_code
200
>>> r.text
'{""plugins"":[{""description"":""Custom Page Rank Procedure"", ""name"":""age_10"", ""read_only"":true}]}'
```' metadata={'Header 1': 'Procedure API', 'Header 2': '4.2.如何使用存储过程', 'Header 3': '4.2.2.列出已加载的存储过程'}","page_content='RESTful API Legacy

5.存储过程

5.3.获取存储过程的详细信息

- **URI**: `/db/{graph_name}/cpp_plugin|python_plugin/{plugin_name}`
- **METHOD**: GET
- **RESPONSE**: 存储过程信息，包括代码，其格式为：
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | 存储过程名 | 字符串 |
| description | 存储过程描述 | 字符串 |
| read_only | 存储过程是否只读 | 布尔值 |
| code_base64 | 存储过程的代码 | 字符串，使用 base64 编码 |
| code_type | 上传代码的类型，C++类型可选 zip/so/cpp，Python 为 py | 字符串 |  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/cpp_plugin/echo
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
Output:
{
""name"" : ""echo"",
""description"" : ""A test plugin that returns the input"",
""code_base64"" : ""{base64 encoded echo.zip}"",
""read_only"" : true,
""code_type"" : ""zip""
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程', 'Header 3': '5.3.获取存储过程的详细信息'}"
什么是RPC接口？,"page_content='RPC API

1.简介

TuGraph 提供丰富的 RPC API，以供开发者通过 RPC 请求远程调用 TuGraph 提供的服务。  
RPC（远程过程调用）是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。
相比REST，RPC 面向方法，主要用于函数方法的调用，可以适合更复杂通信需求的场景，且性能更高。
brpc是用c++语言编写的工业级RPC框架，基于brpc，TuGraph 提供了丰富的RPC API，本文档描述
TuGraph 的 RPC API 使用方式。' metadata={'Header 1': 'RPC API', 'Header 2': '1.简介'}","page_content='Python客户端

3.RPC Client

Python的TuGraph Rpc Client是使用pybind11包装的CPP Client SDK，下表列出了Python和CPP Client SDK的对应关系。  
| Python Client SDK                                                                                                                                                                                                     | CPP Client SDK                                                                                                                                                                                                                                                                              |
|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| client(self: liblgraph_client_python.client, url: str, user: str, password: str)                                                                                                                                      | RpcClient(const std::string& url, const std::string& user, const std::string& password)                                                                                                                                                                                                     |
| client(self: liblgraph_client_python.client, urls: list, user: str, password: str)                                                                                                                                    | RpcClient(std::vector<std::string>& urls, std::string user, std::string password)                                                                                                                           ' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client'}","page_content='功能概览

4.核心功能

4.6 高可用

高可用是指通过通过集群配置，做到实时多副本数据热备，在部分副本不用时，集群仍然能正常提供服务，TuGraph采用 RAFT 协议的多机热备机制，能够将 RPO 降低到接近 0 的程度。TuGraph 选择在计算层进行数据同步，同步的对象是写操作，通过 RPC 接口快速同步。TuGraph 的高可用集群采用主从模式，只有主节点处理写请求，主从节点均能处理读请求。主节点的写请求处理需要同步到多于二分之一的总节点上，多数节点写成功，该写请求才算完成。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.6 高可用'}"
在文本中，The Matrix参与了哪几种类型的关系？,"page_content='Cypher API

2.Clauses

2.2.MATCH

- Basic node finding  
- ✓ Get all nodes  
```
MATCH (n)
RETURN n
```  
- ✓ Get all nodes with a label  
```
MATCH (movie:movie)
RETURN movie.title
```  
- ✓ Related nodes  
```
MATCH (person {name: 'Laurence Fishburne'})-[]-(movie)
RETURN movie.title
```  
- ✓ Match with labels  
```
MATCH (:person {name: 'Laurence Fishburne'})-[]-(movie:movie)
RETURN movie.title
```  
- Relationship basics  
- ✓ Outgoing relationships  
```
MATCH (:person {name: 'Laurence Fishburne'})-[]->(movie)
RETURN movie.title
```  
- ✓ Directed relationships and variable  
```
MATCH (:person {name: 'Laurence Fishburne'})-[r]->(movie)
RETURN type(r)
```  
- ✓ Match on relationship type  
```
MATCH (matrix:movie {title: 'The Matrix'})<-[:acted_in]-(actor)
RETURN actor.name
```  
- ✓ Match on multiple relationship types  
```
MATCH (matrix {title: 'The Matrix'})<-[:acted_in|:directed]-(person)
RETURN person.name
```  
- ✓ Match on relationship type and use a variable  
```
MATCH (matrix {title: 'The Matrix'})<-[r:acted_in]-(actor)
RETURN r.role
```
- Relationships in depth  
- ❏ Relationship types with uncommon characters  
```
MATCH (n {name: 'Rob Reiner'})-[r:`TYPE WITH SPACE`]->()
RETURN type(r)
```  
- ✓ Multiple relationships  
```
MATCH (laurence {name: 'Laurence Fishburne'})-[:acted_in]->(movie)<-[:directed]-(director)
RETURN movie.title, director.name
```  
- ✓ Variable-length relationships  
```
MATCH (laurence {name: 'Laurence Fishburne'})-[:acted_in*1..3]-(movie:movie)
RETURN movie.title
```  
- ✓ Relationship variable in variable-length relationships  
```
MATCH p = (laurence {name: 'Laurence Fishburne'})-[:acted_in*2]-(co_actor)
RETURN p
```  
- ❏ Match with properties on a variable-length path  
```
MATCH p = (charlie:person)-[* {blocked:false}]-(martin:person)
WHERE charlie.name = 'Charlie Sheen' AND martin.name = 'Martin Sheen'
RETURN p
```  
- ✓ Zero-length paths  
```
MATCH (matrix:movie {title: 'The Matrix'})-[*0..1]-(x)
RETURN x
```  
- ✓ Named paths  
```
MATCH p = (michael {name: 'Micha' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.2.MATCH'}","page_content='Cypher API

2.Clauses

2.7.CREATE

- Create nodes  
> **Note**
> TuGraph不支持创建空的nodes，不支持多labels。  
- ☒ Create single node  
```
CREATE (n)
```  
- ☒ Create multiple nodes  
```
CREATE (n), (m)
```  
- ☒ Create a node with a label  
```
CREATE (n:person)
```  
- ☒ Create a node with multiple labels  
```
CREATE (n:Person:Swedish)
```  
- ✓ Create node and add labels and properties  
```
CREATE (n:person {id:2001, name: 'Andres'})
```  
- ✓ Return created node  
```
CREATE (n:person {id:2002, name: 'Andres'})
RETURN n
```  
- Create relationships
- ✓ Create a relationship between two nodes  
```
MATCH (n:person), (m:movie)
WHERE n.name = 'Jada Pinkett Smith' AND m.title = 'The Matrix'
CREATE (n)-[r:write]->(m)
```  
- ✓ Create a relationship and set properties  
```
MATCH (n:person), (m:movie)
WHERE n.name = 'Jada Pinkett Smith' AND m.title = 'The Matrix'
CREATE (n)-[r:acted_in{role: 'Trinity'}]->(m)
```  
- ❏ Create a full path  
```
CREATE p = (andres:person {id: 2005, name:'Andres'})-[:acted_in {role: 'Trinity'}]->
(m:movie {id: 2006})<-[:acted_in {role: 'Trinity'}]-(michael {id: 2006, name:'Michael'})
RETURN p
```  
- Use parameters with CREATE
- ❏ Create node with a parameter for the properties  
```
CREATE (n:Person $props)
RETURN n
```  
- ☒ Create multiple nodes with a parameter for their properties  
```
UNWIND $props AS map
CREATE (n)
SET n = map
```
cannot create vertex without label.' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.7.CREATE'}","page_content='Cypher API

5.附录2. 内置procedures列表

* algo.shortestPath(startNode, endNode, config)

get one of the shortest paths between two vertexes.  
**Parameters:**  
| parameter | parameter type | description                          |
| --------- | -------------- | ------------------------------------------------------------ |
| startNode | Node       | the source node of paths                     |
| endNode   | Node       | the destination node paths                   |
| config    | MAP        | the filter of shortest paths, the formate as {maxHops:3, relationshipQuery:'HAS_CHILD'} |  
**Output:**  
If successful, it will returns one group result of the shortest path.  
**Example input:**  
```
MATCH (n1 {name:'Hugo Weaving'}),(n2 {title:'The Matrix'})
CALL algo.shortestPath(n1,n2) YIELD nodeCount,totalCost RETURN nodeCount,totalCost
```  
**Example output:**  
| nodeCount | totalCost |
| --------- | --------- |
| 2     | 1     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* algo.shortestPath(startNode, endNode, config)'}"
使用什么命令启动 TuGraph 服务器？,"page_content='数据库运行

3.服务操作

3.1.启动服务

TuGraph 需要通过 `lgraph_server -d start` 命令行启动，启动命令示例如下：  
```bash
$ ./lgraph_server -d start -c lgraph.json
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.1.启动服务'}","page_content='数据库运行

2.运行模式

2.2.运行进程守护模式

启动命令：  
```shell
$ ./lgraph_server -d start -c lgraph.json
```  
守护模式的运行输出示例：  
```shell
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '2.运行模式', 'Header 3': '2.2.运行进程守护模式'}","page_content='数据库运行

2.运行模式

2.1.运行普通进程

`lgraph_server -d run`命令可以将 TuGraph 作为普通进程运行。普通进程依赖命令行终端，因此终端结束时，TuGraph 进程也会自动终止。普通进程模式配合`--log_dir """"`可以将进程日志直接输出到终端，因此更方便调试。注：当不使用`-d run`命令时，将默认运行普通进程。  
lgraph_server的默认路径为：/usr/local/bin/lgraph_server 。  
lgraph.json的默认路径为：/usr/local/etc/lgraph.json 。  
启动命令：  
```shell
$ ./lgraph_server -d run -c lgraph.json --log_dir """"
```
或者：
```shell
$ ./lgraph_server -c lgraph.json --log_dir """"
```  
普通模式的运行输出示例：  
```shell
**********************************************************************
*                  TuGraph Graph Database v4.3.2                     *
*                                                                    *
*    Copyright(C) 2018-2023 Ant Group. All rights reserved.          *
*                                                                    *
**********************************************************************
Server is configured with the following parameters:
Backup log enable:                   0
DB directory:                        /var/lib/lgraph/data
HA enable:                           0
HTTP port:                           7070
HTTP web dir:                        /usr/local/share/lgraph/browser-resource
RPC enable:                          1
RPC port:                            9090
SSL enable:                          0
Whether the token is unlimited:      0
audit log enable:                    0
bind host:                           0.0.0.0
bolt port:                           7687
disable auth:                        0
durable:                             0
log dir:                             """"
log verbose:                         1
number of bolt io threads:           1
optimistic transaction:              0
reset admin password if you forget:  0
subprocess idle limit:               600
thread limit:                        0
[20240730 15:34:27.848783 0x00007f81bb3889c0 INFO  src/server/lgraph_server.h:78] [StateMachine] Builtin services are disabled according to ServerOptions.has_builtin_services
[20240730 15:34:27.849116 0x00007f81bb3889c0 INFO ' metadata={'Header 1': '数据库运行', 'Header 2': '2.运行模式', 'Header 3': '2.1.运行普通进程'}"
如果在添加顶点时存在相同的unique_id，将会发生什么？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.addEdgeIndex(label_name, field_name, unique, pair_unique)

create an index on some field of one edge label .  
**Parameters:**  
| parameter | parameter type | description               |
| ---------- | -------------- | ------------------------------------- |
| label_name | string     | name of the label             |
| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |
| pair_unique | boolean    | Specifies whether the index is pair_unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.addEdgeIndex('BornIn', 'id', true, false)
```  
**Example output:**  
```
Added index [BornIn:id]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addEdgeIndex(label_name, field_name, unique, pair_unique)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.addIndex(label_name, field_name, unique)

create an index on some field of one vertex label .  
**Parameters:**  
| parameter | parameter type | description               |
| ---------- | -------------- | ------------------------------------- |
| label_name | string     | name of the label             |
| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.addIndex('Person', 'id', true)
```  
**Example output:**  
```
Added index [Perosn:id]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addIndex(label_name, field_name, unique)'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/relationship/{euid}
```  
与 Nodes 功能类似，Relationships 提供边（edge）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。每一条边都可以由一个唯一 ID（euid）来标识。这个 ID 可以从在插入边时获得，或者在 [列出所有边](#%E5%88%97%E5%87%BA%E6%89%80%E6%9C%89%E8%BE%B9) 操作中得到。  
#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| fields | 数据列名 | 列表 |
| edge | 边数据 | 列表 |  
其中 edge 是一个数据列表，其中每个元素都是一条边，其定义如下：  
| 域名        | 说明     | 类型                                                   |
| ----------- | -------- | ------------------------------------------------------ |
| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}"
TuGraph 支持哪些硬件架构？,"page_content='环境准备

1.硬件环境

1.1. CPU

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的硬件平台，测试认证过的硬件平台包括 Intel、AMD、Kunpeng、Hygon、飞腾等。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.1. CPU'}","page_content='快速上手

1.简介

1.1.支持的平台

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的的平台。' metadata={'Header 1': '快速上手', 'Header 2': '1.简介', 'Header 3': '1.1.支持的平台'}","page_content='TuGraph与ARM架构

摘要：

- TuGraph适配国产ARM架构处理器，又双叒叕打破了LDBC SNB世界纪录，较之前纪录提升31%，云端机器开销降低了40%，大大提升了资源能效。  
- 验证了TuGraph对于ARM架构的兼容性，成为对X86和ARM架构均完整适配的图数据库，也使得TuGraph继麒麟、鲲鹏、海光等国产操作系统和处理器之后，**实现了对国产软硬件的全面支持，为用户的机器选型提供更多选择**。  
- 我们还测试了数据量大于内存的情况，结果显示，性能只下降了20%左右，显示了TuGraph在大规模数据下的适用性。  
TuGraph图数据库GitHub仓库：https://github.com/tugraph-family/tugraph-db' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '摘要：'}"
TuGraph-OGM项目如何面向TuGraph数据库支持JAVA开发人员进行图对象映射？,"page_content='TuGraph-OGM

1.简介

> TuGraph-OGM 项目在其他仓库开源。  
TuGraph-OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。同时 TuGraph-OGM 兼容 Neo4j-OGM，Neo4j 生态用户可以无缝迁移到 TuGraph 数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '1.简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

0 映射原理

TuGraph-OGM 将 JAVA 对象映射为图的对象，类映射为点，类的属性映射为图中的属性，类中的方法映射为操作 TuGraph 的查询语句。  
以电影场景为例，对演员、电影、导演之间的关系进行数据化，就形成了非常典型的图数据。举一个简单的示例，演员Alice在1990年和2019年分别出演了两部电影《Jokes》和《Speed》，其中《Jokes》的导演是Frank Darabont。  
以图的思维来看，演员、导演、电影可以被映射为三种不同的节点，而出演、执导可以被映射为两种边，映射结果如上图所示，将数据存入图数据库后，相关的开发人员就可以使用各类图查询语言对数据进行查询。  
但对非图数据库相关的开发人员来说，这个例子中的演员、导演、电影作为实体，同样可以映射为类中的对象，而与实体相关联的对象可以通过集合存储，这是大多数开发人员熟悉的领域。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '0 映射原理'}","page_content='TuGraph-OGM

简介

TuGraph-OGM(Object Graph Mapping), 源自 `Neo4j-OGM` 项目，TuGraph-OGM
支持将JAVA对象（POJO）映射到TuGraph中，JAVA中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此JAVA开发人员可以在熟悉的生态中轻松地使用TuGraph数据库。同时TuGraph-OGM兼容Neo4j-OGM，Neo4j生态用户可以无缝迁移到TuGraph数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '简介'}"
OPTIONAL MATCH在GQL中有什么作用？,"page_content='ISO GQL

2.Clauses

2.2.OPTIONAL MATCH

`OPTIONAL MATCH`匹配图模式，如果未命中，则返回`null`。  
#### 查询命中  
```
OPTIONAL MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
#### 查询未命中  
```
OPTIONAL MATCH (n:Person{name:'Redgrave Michael'})
RETURN n.birthyear
```  
返回结果  
```JSON
[{""n.birthyear"":null}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.2.OPTIONAL MATCH'}","page_content='ISO GQL

2.Clauses

2.1.MATCH

`MATCH`子句式是GQL最基础的子句，几乎所有查询都是通过 `MATCH`展开。  
`MATCH`子句用于指定在图中搜索的匹配模式，用来匹配满足一定条件的点或者路径。  
#### 点查询  
##### 查询所有点  
```
MATCH (n)
RETURN n
```  
##### 查询特定标签的点  
```
MATCH (n:Person)
RETURN n
```  
##### 通过属性匹配点  
```
MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
##### 通过过滤条件匹配点  
```
MATCH (n:Person WHERE n.birthyear > 1910)
RETURN n.name LIMIT 2
```  
返回结果
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```  
#### 边查询  
##### 出边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1970)-[e]->(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""BORN_IN"",""m.name"":""London"",""n.name"":""Christopher Nolan""},{""label(e)"":""DIRECTED"",""m.name"":null,""n.name"":""Christopher Nolan""}]
```  
##### 入边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1939)<-[e]-(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""HAS_CHILD"",""m.name"":""Rachel Kempson"",""n.name"":""Corin Redgrave""},{""label(e)"":""HAS_CHILD"",""m.name"":""Michael Redgrave"",""n.name"":""Corin Redgrave""}]
```  
##### 带过滤条件的边匹配  
```
MATCH (n:Person)-[e:BORN_IN WHERE e.weight > 20]->(m)
RETURN n.name, e.weight, m.name
```  
返回结果
```JSON
[{""e.weight"":20.549999237060547,""m.name"":""New York"",""n.name"":""John Williams""},{""e.weight"":20.6200008392334,""m.name"":""New York"",""n.name"":""Lindsay Lohan""}]
```  
#### 路径匹配  
##### 不定跳查询  
```
MATCH (n:Person)-[e]->{2,3}(m:Person)
RETURN m.name LIMIT 2
```  
返回结果
```JSON
[{""m.name"":""Liam Neeson""},{""m.name"":""Natasha Richardson""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.1.MATCH'}","page_content='ISO GQL

2.Clauses

| 类别                | 子句           |
| ------------------- | -------------- |
| Reading clauses     | MATCH          |
|                     | OPTIONAL MATCH |
| Projecting clauses  | RETURN         |
|                     | NEXT           |
| Reading sub-clauses | WHERE          |
|                     | ORDER BY       |
|                     | SKIP           |
|                     | LIMIT          |' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses'}"
loadProcedure方法中，如何通过参数控制存储过程是否为只读？,"page_content='C++客户端

2.使用示例

2.8.加载存储过程

```C++
std::string str;
bool ret = client.LoadProcedure(str, code_sleep, ""PY"", ""python_plugin1"", ""PY"", ""this is a test plugin"", true)
```
```
bool LoadProcedure(std::string& result, const std::string& source_file,
const std::string& procedure_type, const std::string& procedure_name,
const std::string& code_type, const std::string& procedure_description,
bool read_only, const std::string& version = ""v1"",
const std::string& graph = ""default"");
@param [out] result                  The result.
@param [in]  source_file             the source_file contain procedure code.
@param [in]  procedure_type          the procedure type, currently supported CPP and PY.
@param [in]  procedure_name          procedure name.
@param [in]  code_type               code type, currently supported PY, SO, CPP, ZIP.
@param [in]  procedure_description   procedure description.
@param [in]  read_only               procedure is read only or not.
@param [in]  version                 (Optional) the version of procedure.
@param [in]  graph                   (Optional) the graph to query.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，由于加载存储过程是写请求，HA模式下的client只能向leader发送加载存储过程请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.8.加载存储过程'}","page_content='RPC API

5.存储过程

5.1.加载存储过程

加载存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称
- read_only: 必要参数，是否只读
- code: 必要参数，存储过程文件读入生成的ByteString
- desc: 可选参数，存储过程描述
- code_type: 可选参数，存储过程代码类型，PY、SO、CPP、ZIP四者之一  
以C++为例，用户加载存储过程的方式如下所示：
```C++
std::string content;
if (!FieldSpecSerializer::FileReader(source_file, content)) {
std::swap(content, result);
return false;
}
LGraphRequest req;
req.set_is_write_op(true);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
pluginRequest->set_version(version);
lgraph::LoadPluginRequest* loadPluginRequest = pluginRequest->mutable_load_plugin_request();
loadPluginRequest->set_code_type([](const std::string& type) {
std::unordered_map<std::string, lgraph::LoadPluginRequest_CodeType> um{
{""SO"", lgraph::LoadPluginRequest::SO},
{""PY"", lgraph::LoadPluginRequest::PY},
{""ZIP"", lgraph::LoadPluginRequest::ZIP},
{""CPP"", lgraph::LoadPluginRequest::CPP}};
return um[type];
}(code_type));
loadPluginRequest->set_name(procedure_name);
loadPluginRequest->set_desc(procedure_description);
loadPluginRequest->set_read_only(read_only);
loadPluginRequest->set_code(content);
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
加载存储过程的响应不包含参数，如果加载失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.1.加载存储过程'}","page_content='Java客户端

2.使用示例

2.8.加载存储过程

```java
boolean result = client.loadProcedure(""./test/procedure/khop.so"", ""CPP"", ""khop"", ""SO"", ""test loadprocedure"", true, ""v1"", ""default"");
log.info(""loadProcedure : "" + result);
```
```
@param sourceFile: the source_file contain procedure code
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param codeType: code type, currently supported PY, SO, CPP, ZIP
@param procedureDescription: procedure description
@param readOnly: procedure is read only or not
@param version: The version of procedure
@param graph: the graph to query.
@return: the result of procedure execution
public boolean loadProcedure(String sourceFile, String procedureType, String procedureName, String codeType,
String procedureDescription, boolean readOnly, String version, String graph) throws Exception
```
本接口支持在单机模式和HA模式下使用。其中，由于加载存储过程是写请求，HA模式下的client只能向leader发送加载存储过程请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.8.加载存储过程'}"
在RPC调用中，如果回应的错误码不是成功，则抛出的异常类型是什么？,"page_content='RPC API

5.存储过程

5.3.删除存储过程

删除存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称  
以C++为例，用户删除存储过程的方式如下所示：
```C++
LGraphRequest req;
req.set_is_write_op(true);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
lgraph::DelPluginRequest* dpRequest = pluginRequest->mutable_del_plugin_request();
dpRequest->set_name(procedure_name);
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
删除存储过程的响应不包含参数，如果删除失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.3.删除存储过程'}","page_content='RPC API

3.登录

登录请求信息包含以下参数：
- user: 必要参数，用户名
- pass: 必要参数，密码
以C++为例，用户使用构建好的服务存根发送登录请求：
```C++
auto* req = request.mutable_acl_request();
auto* auth = req->mutable_auth_request()->mutable_login();
auth->set_user(user);
auth->set_password(pass);
// send data
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req->set_client_version(server_version);
req->set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), req, &resp, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
token = res.acl_response().auth_response().token();
```
登录响应信息包含以下参数：
- token: 必要参数，登录成功会收到带有签名的令牌，即 Json Web Token，客户端储存该令牌，并且用于以后的每次发送请求。
如果登录失败会收到“Authentication failed”错误。' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}","page_content='RPC API

4.查询

用户可以通过Cypher查询和TuGraph进行绝大多数的交互，Cypher请求信息包含以下参数：
- query: 必要参数，Cypher查询语句
- param_names: 可选参数，参数名
- param_values: 可选参数，参数值
- result_in_json_format: 必要参数，查询结果是否以JSON格式返回
- graph: 可选参数，Cypher语句执行的子图名称
- timeout: 可选参数，Cypher语句执行的超时时间  
以C++为例，用户发送Cypher请求的方式如下所示：
```C++
LGraphResponse res;
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
LGraphRequest req;
req.set_client_version(server_version);
req.set_token(token);
lgraph::CypherRequest* cypher_req = req.mutable_cypher_request();
cypher_req->set_graph(graph);
cypher_req->set_query(query);
cypher_req->set_timeout(timeout);
cypher_req->set_result_in_json_format(true);
LGraphRPCService_Stub stub(channel.get());
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
server_version = std::max(server_version, res.server_version());
CypherResponse cypher_res = res.cypher_response();
```
Cypher请求响应为以下两个参数之一：
- json_result: JSON格式的cypher查询结果
- binary_result: CypherResult格式的cypher查询结果' metadata={'Header 1': 'RPC API', 'Header 2': '4.查询'}"
Transform操作中的swap_id函数是用来做什么的？,"page_content='Python Olap API

4. Olap API

点数组类ParallelVector

- `ParallelVector[T](size_t capacity)` 构建ParallelVector，capacity为点数组的初始容量大小
- `operator[](i: size_t)-> T`：下标为i的数据
- `begin()-> cython.pointer(T)`：ParallelVector的起始指针
- `end()-> cython.pointer(T)`：ParallelVector的结束指针。begin和end的用法类似于vector容器的begin和end指针，可以使用这两个指针对数组进行顺序访问
- `Back()-> T`：ParallelVector最后一个数据
- `Data()-> cython.pointer(T)`：表示数组本身数据
- `Destroy()-> cython.void`：清空ParallelVector数组内数据并删除数组
- `Size()-> size_t`：表示ParallelVector中的数据个数
- `Resize(size: size_t)-> cython.void`：更改ParallelVector为size大小，该size应大于等于更改前的大小且小于capacity
- `Clear()-> cython.void`：清空ParallelVector内数据
- `ReAlloc(capacity: size_t)-> cython.void`：给ParallelVector分配新的容量大小，若数组有数据则将数据迁移至新内存
- `Fill(elem: T)-> cython.void`：为ParallelVector的全部数据赋值为elem
- `Append(elem: T, atomic: cython.bint = true)-> cython.void`：向ParallelVector结尾添加一个数据
- `Swap(other: ParallelVector[T])-> cython.void`：和其他的ParallelVector交换数据
- `Copy()-> ParallelVector[T]`：复制当前的ParallelVector数据存至Copy数组中' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '点数组类ParallelVector'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends GraphSnapShot<K, VV, EV> {
/** 获取开始图遍历的点 */
Travers' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void init(IncGraphComputeContext<K, VV, EV, M> incGraphContext) | 图计算初始化接口 | incGraphContext： 增量动态图计算的上下文，K表示vertex id的类型，VV表示vertex value类型，EV表示edge value类型，M表示发送消息的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮迭代对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 迭代计算接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 迭代计算完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型 |  
- 详细接口  
```java
public interface IncVertexCentricFunction<K, VV, EV, M> extends Function {

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncGraphContext<K, VV, EV, M> {
/** 获取job id */
long getJobId();

/** 获取当前迭代 id */
long getIterationId();

/** 获取运行时上下文 */
RuntimeContext getRuntimeContext();

/** 获取可变图 */
MutableGraph<K, VV, EV> getMutableGraph();

/** 获取增量图 */
TemporaryGraph<K, VV, EV> getTemporaryGraph();

/** 获取图存储上的历史图 */
HistoricalGraph<K, VV, EV> getHistoricalGraph();

/** 给指定vertex发送消息 */
void sendMessage(K vertexId, M message);

/** 给当前vertex邻居节点发送消息 */
void sendMessageToNeighbors(M message);

}

interface TemporaryGraph<K, VV, EV> {
/** 从增量图中获取vertex */
IVertex<K, VV> getVertex();

/** 从增量图中获取edges */
List<IEdge<K, EV>> getEdges();

/** 更新vertex value */
void updateVertexValue(VV value);

}

interface HistoricalGraph<K, VV, EV> {
/** 获取图数据最新版本id */
Long getLatestVersionId();

/** 获取图数据所有版本 */
List<Long> getAllVersionIds();

/** 获取图数据所有vertex */
Map<Long, IVertex<K, VV>> getAllVertex();

/** 获取图数据指定版本的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions);

/** 获取图数据指定版本并满足过滤条件的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(L' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
在影视场景Demo中，如何通过Cypher语言查询影片'Forrest Gump'的所有演员以及他们扮演的角色？,"page_content='场景：影视

2.查询示例

2.2.示例二

查询影片 'Forrest Gump' 的所有演员，列出演员在影片中扮演的角色。  
```
MATCH (m:movie {title: 'Forrest Gump'})<-[r:acted_in]-(a:person) RETURN a.name,r.role
```' metadata={'Header 1': '场景：影视', 'Header 2': '2.查询示例', 'Header 3': '2.2.示例二'}","page_content='场景：影视

2.查询示例

2.1.示例一

查询影片 'Forrest Gump' 的所有演员，返回影片和演员构成的子图。  
```
MATCH (m:movie {title: 'Forrest Gump'})<-[:acted_in]-(a:person) RETURN a, m
```' metadata={'Header 1': '场景：影视', 'Header 2': '2.查询示例', 'Header 3': '2.1.示例一'}","page_content='场景：影视

2.查询示例

2.7.示例七

通过查询给'Forrest Gump'打高分的人也喜欢哪些影片，给喜欢'Forrest Gump'的用户推荐类似的影片。  
```
MATCH (m:movie {title:'Forrest Gump'})<-[r:rate]-(u:user)-[r2:rate]->(m2:movie) WHERE r.stars>3 AND r2.stars>3 RETURN m, u,m2
```' metadata={'Header 1': '场景：影视', 'Header 2': '2.查询示例', 'Header 3': '2.7.示例七'}"
TuGraph-DB图数据库社区版内置了多少种基础算法？,"page_content='内置算法

简介

TuGraph目前包含以下6个基础算法28种扩展算法，共34个图算法：' metadata={'Header 1': '内置算法', 'Header 2': '简介'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。  
<table><tbody><tr><td>算法类型</td><td>中文算法名</td><td>英文算法名</td><td>程序名</td></tr><tr><td rowspan=""5"">路径查询</td><td>广度优先搜索</td><td>Breadth-First Search</td><td>bfs</td></tr><tr><td>单源最短路径</td><td>Single-Source Shortest Path</td><td>sssp</td></tr><tr><td>全对最短路径</td><td>All-Pair Shortest Path</td><td>apsp</td></tr><tr><td>多源最短路径</td><td>Multiple-source Shortest Paths</td><td>mssp</td></tr><tr><td>两点间最短路径</td><td>Single-Pair Shortest Path</td><td>spsp</td></tr><tr><td rowspan=""9"">重要性分析</td><td>网页排序</td><td>Pagerank</td><td>pagerank</td></tr><tr><td>介数中心度</td><td>Betweenness Centrality</td><td>bc</td></tr><tr><td>置信度传播</td><td>Belief Propagation</td><td>bp</td></tr><tr><td>距离中心度</td><td>Closeness Centrality</td><td>clce</td></tr><tr><td>个性化网页排序</td><td>Personalized PageRank</td><td>ppr</td></tr><tr><td>带权重的网页排序</td><td>Weighted Pagerank Algorithm</td><td>wpagerank</td></tr><tr><td>信任指数排名</td><td>Trustrank</td><td>trustrank</td></tr><tr><td>sybil检测算法</td><td>Sybil Rank</td><td>sybilrank</td></tr><tr><td>超链接主题搜索</td><td>Hyperlink-Induced Topic Search</td><td>hits</td></tr><tr><td rowspan=""4"">关联性分析</td><td>平均集聚系数</td><td>Local Clustering Coefficient</td><td>lcc</td></tr><tr><td>共同邻居</td><td>Common Neighborhood</td><td>cn</td></tr><tr><td>度数关联度</td><td>Degree Correlation</td><td>dc</td></tr><tr><td>杰卡德系数</td><td>Jaccard Index</td><td>ji</td></tr><tr><td rowspan=""5"">图结构</td><td>直径估计</td><td>Dimension Estimation</td><td>de</td></tr><tr>' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}","page_content='OLAP API

1. TuGraph 图分析引擎介绍

TuGraph的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助TuGraph的 C++ / Python 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如PageRank、LPA、WCC等迭代式图算法，最后根据运行结果做出相应的对策。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph图计算系统社区版内置6个算法，商业版内置了25种算法，用户几乎不需要自己实现具体的图计算过程。其详细介绍可参考algorithms.md。  
根据数据来源及实现不同，可分为Procedure、Embed和Standalone三种运行方式，均继承于OlapBase API，OlapBase API接口文档可参考olapbase-api.md。  
其中Procedure和Embed的数据来源是图数据库中预加载的db数据，可以分别编译生成tugraph-web加载使用的.so文件和后台终端使用的embed文件，输入的图数据均通过db的加载形式，其接口文档可参考olapondb-api.md。
Standalone用于编译生成standalone文件，区别于前者，该文件的输入图数据通过txt、二进制、ODPS文件的形式加载，其接口文档可参考olapondisk-api.md。' metadata={'Header 1': 'OLAP API', 'Header 2': '1. TuGraph 图分析引擎介绍'}"
TuGraph-DB支持的三种空间数据类型是什么？,"page_content='空间数据类型在TuGraph-DB中的实现

定义空间数据类型

TuGraph-DB当前已经支持Point、Linestring与Polygon三种类型  
-   • Point：点，创建方式例如POINT(2.0, 2.0, 7203)  
-   • Linestring：折线，创建方式例如LINESTRING(0 2,1 1,2 0)  
-   • Polygon：多边形，创建方式例如POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '定义空间数据类型'}","page_content='地理空间数据类型使用示例

3. 数据类型

目前在TuGraph中，我们已经支持了Point, Linestring与Polygon三种类型:  
- Point：点    point(2.0, 2.0, 7203)
- Linestring：折线 LINESTRING(0 2,1 1,2 0)
- Polygon：多边形  POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型，创建图模型和插入数据示例如下：  
**创建标记美食位置的点模型**  
```
CALL db.createVertexLabel('food', 'id', 'id', int64, false, 'name', string, true,'pointTest',point,true)
```  
![image.png](../../../images/spatail/createVertexLabel.png)  
**插入标记美食点的数据**  
```
CREATE (n:food {id:10001, name: 'aco Bell',pointTest:point(3.0,4.0,7203)}) RETURN n
```  
![image.png](../../../images/spatail/createFoodData.png)  
**创建具有折线属性的点模型**  
```
CALL db.createVertexLabel('lineTest', 'id', 'id', int64, false, 'name', string, true,'linestringTest',linestring,true)
```  
![image.png](../../../images/spatail/createVertexLabel_lineTest.png)  
**插入具有折线属性的点数据**  
```
CREATE (n:lineTest {id:102, name: 'Tom',linestringTest:linestringwkt('LINESTRING(0 2,1 1,2 0)', 7203)}) RETURN n
```  
![image.png](../../../images/spatail/createLineTestData.png)  
**创建具有多边型属性的点模型**  
```
CALL db.createVertexLabel('polygonTest', 'id', 'id', int64, false, 'name', string, true,'polygonTest',polygon,true)
```  
![image.png](../../../images/spatail/createVertexLabel_PolygonTest.png)  
**插入具有多边型属性的点数据**  
```
CREATE (n:polygonTest {id:103, name: 'polygonTest',polygonTest:polygonwkt('POLYGON((0 0,0 7,4 2,2 0,0 0))', 7203)}) RETURN n
```' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '3. 数据类型'}","page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

实现思路

在TuGraph-DB的实现，基于boost geometry库的基础上进行封装，用EWKB格式存储数据，其中Point类型为定长存储50，其余皆为变长存储。我们支持了Point, Linestring与Polygon三种类型，同时支持了WGS84, CARTESIAN两种坐标系，数据类型与坐标系均可根据需要拓展。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现', 'Header 3': '实现思路'}"
产品是否支持麒麟操作系统？只有企业版支持么？,"page_content='QA汇总

安装部署QA

麒麟操作系统支持

Q：产品是否支持麒麟操作系统？只有企业版支持么？
A：开源和企业版都支持' metadata={'Header 1': 'QA汇总', 'Header 2': '安装部署QA', 'Header 3': '麒麟操作系统支持'}","page_content='TuGraph与ARM架构

摘要：

- TuGraph适配国产ARM架构处理器，又双叒叕打破了LDBC SNB世界纪录，较之前纪录提升31%，云端机器开销降低了40%，大大提升了资源能效。  
- 验证了TuGraph对于ARM架构的兼容性，成为对X86和ARM架构均完整适配的图数据库，也使得TuGraph继麒麟、鲲鹏、海光等国产操作系统和处理器之后，**实现了对国产软硬件的全面支持，为用户的机器选型提供更多选择**。  
- 我们还测试了数据量大于内存的情况，结果显示，性能只下降了20%左右，显示了TuGraph在大规模数据下的适用性。  
TuGraph图数据库GitHub仓库：https://github.com/tugraph-family/tugraph-db' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '摘要：'}","page_content='环境准备

2.软件环境

2.1. 操作系统

TuGraph 能够兼容主流操作系统，包括Ubuntu、CentOS、SUSE、银河麒麟、 中标麒麟、UOS等，均通过测试认证。  
其中最稳定使用的系统版本是 Ubuntu 18.04、CentOS 7、CentOS 8。' metadata={'Header 1': '环境准备', 'Header 2': '2.软件环境', 'Header 3': '2.1. 操作系统'}"
TuGraph-DB中存储Point类型数据的格式是什么？,"page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

实现思路

在TuGraph-DB的实现，基于boost geometry库的基础上进行封装，用EWKB格式存储数据，其中Point类型为定长存储50，其余皆为变长存储。我们支持了Point, Linestring与Polygon三种类型，同时支持了WGS84, CARTESIAN两种坐标系，数据类型与坐标系均可根据需要拓展。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现', 'Header 3': '实现思路'}","page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

EWKB

EWKB格式数据如下  
-   •第0-1位: 表示编码方式 00表示大端法，01表示小端法  
-   •第2 - 5位: 空间数据类型  
-   •0100: point  
-   •0200: linestring  
-   •0300: polygon  
-   •第6 - 9位: 数据维度  
-   •0020: 二维  
-   •0030: 三维  
-   •第10 - 17位: 坐标系的EPSG编码  
-   •第18 - n位: double类型的坐标对的16进制表示  
**注:**对于POINT类型，其EWKB格式为定长存储，固定长度为50，而对于其他类型，则为不定长。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现', 'Header 3': 'EWKB'}","page_content='空间数据类型在TuGraph-DB中的实现

定义空间数据类型

TuGraph-DB当前已经支持Point、Linestring与Polygon三种类型  
-   • Point：点，创建方式例如POINT(2.0, 2.0, 7203)  
-   • Linestring：折线，创建方式例如LINESTRING(0 2,1 1,2 0)  
-   • Polygon：多边形，创建方式例如POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '定义空间数据类型'}"
TuGraph嵌入模式的API允许用户执行哪些操作？,"page_content='Procedure API

1.简介

当用户需要表达的查询/更新逻辑较为复杂（例如 Cypher 无法描述，或是对性能要求较高）时，相比调用多个请求并在客户端完成整个处理流程的方式，TuGraph 提供的存储过程是更简洁和高效的选择。  
与传统数据库类似，TuGraph 的存储过程运行在服务器端，用户通过将处理逻辑（即多个操作）封装到一个过程单次调用，并且可以在实现时通过并行处理的方式（例如使用相关的 C++ OLAP 接口以及基于其实现的内置算法）进一步提升性能。  
存储过程中有一类特殊的API来进行数据的并行操作，我们叫 Traversal API，见[文档](2.traversal.md)。' metadata={'Header 1': 'Procedure API', 'Header 2': '1.简介'}","page_content='RPC API

5.存储过程

为满足用户较为复杂的查询/更新逻辑，TuGraph支持 C 语言和 Python 语言编写的存储过程。
用户可以使用RPC请求对存储过程进行增删改查操作。' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程'}","page_content='OlapBase API

3. 原子操作

TuGraph使用了多线程技术进行批处理操作，在这种情况下可能会出现访存冲突现象。为了保证并行计算时修改操作的正确性，TuGraph实现了原子操作。代码部分见lgraph文件夹下的lgraph_atomic.cpp文件。
TuGraph还自定义了4个常用的原子操作。当我们需要在多线程模式下修改点的数据时，我们都应该使用原子操作来确保并行环境下修改操作的正确性。除了这4个原子操作外，用户也可以使用“cas”来构建自己的原子操作函数。  
- `bool cas(T * ptr, T oldv, T newv)`：如果ptr指向的值等于oldv，则将ptr指向的值赋为newv并返回true，否则返回false
- `bool write_min(T *a, T b)`：如果b比a指向的值更小，那么将a指向的值赋为b并返回true，否则返回false。
- `bool write_max(T *a, T b)`：如果b比a指向的值更大，那么将a指向的值赋为b并返回true，否则返回false。
- `void write_add(T *a, T b)`：将b的值加到a指向的值上。
- `void write_sub(T *a, T b)`：将a指向的值减去b的值。' metadata={'Header 1': 'OlapBase API', 'Header 2': '3. 原子操作'}"
Date 类的默认构造函数设置的日期是什么？,"page_content='GeaFlow支持以下日期函数：
* [from_unixtime](#from_unixtime)
* [from_unixtime_millis](#from_unixtime_millis)
* [unix_timestamp](#unix_timestamp)
* [unix_timestamp_millis](#unix_timestamp_millis)
* [isdate](#isdate)
* [now](#now)
* [day](#day)
* [weekday](#weekday)
* [lastday](#lastday)
* [day_of_month](#day_of_month)
* [week_of_year](#week_of_year)
* [date_add](#date_add)
* [date_sub](#date_sub)
* [date_diff](#date_diff)
* [add_months](#add_months)
* [date_format](#date_format)
* [date_part](#date_part)
* [date_trunc](#date_trunc)'","page_content='TuGraph图模型说明

1. 数据模型

1.2. 数据类型

TuGraph支持多种可用于属性的数据类型。具体支持的数据类型如下：  
| **数据类型** | **最小值**          | **最大值**          | **描述**                            |
| ------------ | ------------------- | ------------------- | ----------------------------------- |
| BOOL         | false               | true                | 布尔值                              |
| INT8         | -128                | 127                 | 8位整型                          |
| INT16        | -32768              | 32767               | 16位整型                         |
| INT32        | - 2^31              | 2^31 - 1            | 32位整型                         |
| INT64        | - 2^63              | 2^63 - 1            | 64位整型                         |
| DATE         | 0000-00-00          | 9999-12-31          | ""YYYY-MM-DD"" 格式的日期             |
| DATETIME     | 0000-00-00 00:00:00.000000 | 9999-12-31 23:59:59.999999 | ""YYYY-MM-DD HH:mm:ss[.ffffff]"" 格式的日期时间 |
| FLOAT        |                     |                     | 32位浮点数                       |
| DOUBLE       |                     |                     | 64位浮点数                       |
| STRING       |                     |                     | 不定长度的字符串                    |
| BLOB         |                     |                     | 二进制数据（在输入输出时使用Base64编码） |
| POINT        |                     |                     | EWKB格式数据，表示点              |
| LINESTRING   |                     |                     | EWKB格式数据，表示线              |
| POLYGON      |                     |                     | EWKB格式数据，表示面(多边形)       |
| FLOAT_VECTOR |                     |                     | 包含32位浮点数的动态向量               |' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.2. 数据类型'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}"
在使用 bool DeleteVertexIndex 函数时，如果给定的 vertex_label 或 field 不存在会发生什么？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.deleteLabel(label_type, label_name)

Delete a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |  
**Output:**  
| field_name | field_type | description              |
| ---------- | ---------- | -------------------------------- |
| affected   | integer    | number of vertexes/edges deleted |  
**Example input:**  
```
CALL db.deleteLabel('vertex', 'Person')
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.deleteLabel(label_type, label_name)'}","page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

TuGraph 是一个具备多图能力的强模式属性图数据库。在每一张子图中，每种点和边都需要有预定义的数据格式。数据格式由 Label 决定，每种 Label 都有自己的数据格式。用户可以使用 REST API 添加，删除和查询 Label 及其对应的数据格式。  
Label 操作对应的 URI 格式为  
```
http://{host}:{port}/db/{graph_name}/label/{type}/{label_name}
```  
其中{type}可以是 node 或者 relationship。  
#### 6.6.1.创建Label  
创建 Label 的过程同时也是定义其数据类型的过程。只有创建了 Label 才能在图中插入相应类型的点或者边。  
- **URI**: `/db/{graph_name}/label`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | Label 名 | 字符串 |
| fields | 数据列定义 | 列表 |
| is_vertex | 是否是点 Label | 布尔值 |
| primary | 点的主键属性 | 字符串 |
| edge_constraints | 边的约束 | 列表 |  
`primary` 在 `is_vertex` 为 `true` 的时候设置，这个字段只有点才有, 创建点的时候必须设置。  
`edge_constraints` 在 `is_vertex` 为 `false` 的时候设置，这个字段只有边有。这个字段限制了该边的起点和终点只能是哪些点的组合，比如：`[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]`，限制了该边只能是从 `vertex_label1` 到 `vertex_label2` 和 从 `vertex_label3` 到 `vertex_label4`。如果不想有任何限制，不设置该字段即可。  
其中`fields`为一个数组，其中每个元素定义数据的一列，内容如下：  
| 域名     | 说明                                     | 类型                                                                                                |
| -------- | ---------------------------------------- | --------------------------------------------------------------------------------------------------- |
| name     | 列名                                     | 字符串                                                                                              |
| type     | 列数据类型                               | 字符串，有以下类型： int8, int16, int32, int64, float, double, string, date, datetime, binary, bool |
| optional | 数据是否可以为空（可选，缺省值为 false） | 布尔值                                                                                              |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/label
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""name"":""Actor"",
""fields"": [
{""name"":""uid"", ""type"":""int64"", ""optional"":false},
{""name"":""name"", ""type"":""st' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelModFields(label_type, label_name, field_spec...)

Modifies the specified fields in the label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.The target field should exist.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelModFields(
'vertex',
'new_label',
['birth_date', DATETIME, true],
['gender', BOOL, true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelModFields(label_type, label_name, field_spec...)'}"
在单命令模式下，如何使用 lgraph_cypher 通过命令行参数来执行一条 Cypher 查询并将结果显示为表格格式？,"page_content='命令行工具

1.单命令模式

在单命令模式下，`lgraph_cypher`可用于提交单个 Cypher 查询并将结果直接打印到终端，打印结果也可以容易地重定向写入指定文件。当用户需要从服务器获取大量结果并将其保存在文件中时，这非常便利。
在此模式下，`lgraph_cypher`工具具有以下选项：' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式'}","page_content='命令行工具

1.单命令模式

1.2.命令示例:

**cypher 命令文件查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -f /home/usr/cypher.json
```  
**cypher 命令单句查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -s ""MATCH (n) RETURN n""
```' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式', 'Header 3': '1.2.命令示例:'}","page_content='命令行工具

2.交互模式

2.3.cypher 查询命令:

在交互模式下，用户也可直接输入单句 cypher 命令进行查询，以""`;`""结束。输入命令不区分大小写。例子如下：  
```
login success
>MATCH (n) RETURN n, n.name;
+---+---+-------------+
|   | n |n.name       |
+---+---+-------------+
| 0 | 0 |david        |
| 1 | 1 |Ann          |
| 2 | 2 |first movie  |
| 3 | 3 |Andres       |
+---+---+-------------+
time spent: 0.000520706176758
size of query: 4
>
```  
`lgraph_cypher`输入命令时支持多行输入，用户可使用`ENTER`键将长查询语句分多行输入。多行输入情况下命令行开头会从`>`变为`=>`，然后用户可以继续输入查询的其余部分。  
例子如下：  
```
login success
>MATCH (n)
=>WHERE n.uid='M11'
=>RETURN n, n.name;
```' metadata={'Header 1': '命令行工具', 'Header 2': '2.交互模式', 'Header 3': '2.3.cypher 查询命令:'}"
reduce_plus函数是如何处理它的两个参数的？,"page_content='OlapBase API

7. 图类OlapBase

7.4 批处理操作

TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程。分别是：  
```c++
/*
函数名称:ReducedSum ProcessVertexInRange(std::function<ReducedSum(size_t)> work, size_t lower, size_t upper,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考include/lgraph/olap_base.h中具体代码

使用示例:统计数组parent数组中有出边的点个数
*/

auto vertex_num = graph.ProcessVertexInRange<size_t>(
[&](size_t i) {
if (graph.OutDegree(parent[i]) > 0) {
return 1;
}
},
0, parent.Size()
);
printf(""the number is %lu\n"",vertex_num);
```  
其中graph为图类OlapBase的实例化对象  
```C++
/*
函数名称:ReducedSum ProcessVertexActive(std::function<ReducedSum(size_t)> work, ParallelBitset &active_vertices,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对active_vertices中对应为1的节点执行work函数，第三个参数表示累加的基数，默认为0；
第四个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考/include/lgraph/olap_base.h中具体代码

使用示例:输出Graph中节点1，2，3的所有出度邻居，并统计这三个节点的总出度
*/

auto active_in = graph.AllocVertexSubset();
active_in.Add(1);
active_in.Add(2);
active_in.Add(3);
auto total_outdegree = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t local_outdegree = 0;
for (auto & edge : graph.OutEdges(vi)) {
size_t dst = edge.neighbour;
printf(""node %lu has neighbour %lu\n"",vi,dst);
local_outdegree += 1;
}
return local_outdegree;
},
active_in
);
printf(""total outdegree of node1,2,3 is %lu\n"",total_outdegree);
```' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.4 批处理操作'}","page_content='业务开发指南

导入数据

批量upsert点数据

如果不存在就插入点，如果存在就更新点的属性，根据点的主键字段值判断是否存在。  
第二个参数是一个`list`类型，每个`list`里面的元素是个`map`类型，每个`map`里面是点的字段和对应的值。  
推荐使用driver里面的参数化特性，第二个参数直接传入一个 `list`结构体，避免自己构造语句。
```
CALL db.upsertVertex('node1', [{id:1, name:'name1'},{id:2, name:'name2'}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert点数据'}","page_content='OlapOnDisk API

3. 其他常用函数功能描述

3.1 图加载

TuGraph-Standalone对于图数据文件的加载来源主要分为三大类：文本文件、二进制文件和ODPS。二进制文件为将边数据的二进制表示按顺序排列的文件，能够节省大量存储空间。其加载函数分为三种，分别是：  
- `void Load(ConfigBase<EdgeData> config,EdgeDirectionPolicy edge_direction_policy = DUAL_DIRECTION)`：图数据文件的加载方式，包含两个参数，其含义分别表示：
- `config`：需要加载的配置参数。该参数内保存了该图的一般信息（如数据来源，算法名称，数据输入、输出路径，点个数等）以及根据不同数据来源、不同算法所配置的不同信息参数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。其中DUAL_DIRECTION为默认的图加载方式。
DUAL_DIRECTION : 输入文件为非对称图，加载图为非对称图。
MAKE_SYMMETRIC : 输入文件为非对称图，加载图为对称图。
INPUT_SYMMETRIC : 输入文件为对称图，加载图为对称图。
对应的详细介绍见lgraph文件夹下的olap_config.h文件的`enum EdgeDirectionPolicy`。  
- `void LoadVertexArrayTxt<V>(V * array, std::string path, std::function<size_t(const char *, const char *, VertexUnit<V> &)> parse_line)`：将文件中的点-数据对按照点id的顺序加载到数组中。各参数表示意义分别为：
- `array`：待读入数据的数组
- `path`：读取文件的路径，文件中每行表示一对点-数据对
- `parse_line`：用户自定义函数，告诉系统如何将一行文本数据解析为一个点-数据对。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '3. 其他常用函数功能描述', 'Header 3': '3.1 图加载'}"
是否支持无向边,"page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='QA汇总

内核引擎QA

边支持索引

Q: TuGraph 的边是否支持索引？
A: TuGraph 在引擎层支持边索引，可通过存储过程使用。Cypher的边索引功能正在开发支持中。' metadata={'Header 1': 'QA汇总', 'Header 2': '内核引擎QA', 'Header 3': '边支持索引'}","page_content='QA汇总

Cypher QA

长边条件查询

Q：是否支持不定长边的条件查询？
示例：  
```
MATCH p=(v)-[e:acted_in|:rate*1..3]-(v2) WHERE id(v) IN [3937] AND e.stars = 3 RETURN p LIMIT 100
```  
A：目前还不支持不定长边的过滤查询。目前的代替方案只能是分开写。上面的示例，就需要从 1 跳到 3 跳都写一遍。' metadata={'Header 1': 'QA汇总', 'Header 2': 'Cypher QA', 'Header 3': '长边条件查询'}"
FieldData类中提供哪些构造函数来初始化不同类型的数据？,"page_content='OlapOnDisk API

3. 其他常用函数功能描述

3.3 图解析函数

- `std::tuple<size_t, bool> parse_line_unweighted(const char *p, const char *end, EdgeUnit<EdgeData> &e)`：对图数据文件进行解析，加载图为无权图。  
- `std::tuple<size_t, bool> parse_line_weighted(const char* p, const char* end, EdgeUnit<EdgeData>& e)`：对图数据文件进行解析，加载图为有权图，权重数据类型可以通过修改<EdgeData>指定。  
该函数可通过MyConfig类定义时的构造函数parse_line进行指定。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '3. 其他常用函数功能描述', 'Header 3': '3.3 图解析函数'}","page_content='Python Olap API

4. Olap API

图类OlapOnDisk

#### ConfigBase：
- `ConfigBase()`: 构造函数
- `std::string input_dir`: 图边表数据路径
- `std::string output_dir`: 输出结果路径  
- `Load(config: ConfigBase[EdgeData], edge_direction_policy: EdgeDirectionPolicy)-> void`: 读入图数据' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapOnDisk'}","page_content='地理空间数据类型使用示例

2. 预备知识

2.4 常用函数

| Name                 | Description           | Signature                                                                 |
|----------------------|-----------------------|---------------------------------------------------------------------------|
| `dbms.graph.createGraph` | 创建子图           | `dbms.graph.createGraph(graph_name::STRING, description::STRING, max_size_GB::INTEGER) :: (::VOID)` |
| `db.createVertexLabel`  | 创建Vertex Label      | `db.createVertexLabel(label_name::STRING,field_specs::LIST) :: (::VOID)`      |
| `db.getLabelSchema`     | 列出label schema      | `db.getLabelSchema(label_type::STRING,label_name::STRING) :: (name::STRING,type::STRING,optional::BOOLEAN)` |
| `db.deleteLabel`        | 删除Vertex            | `db.deleteLabel(label_type::STRING,label_name::STRING) :: (::VOID)`         |  
更完整详细的函数使用以及插入数据的语句，可以参考 [Cypher API](../8.query/1.cypher.md)' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '2. 预备知识', 'Header 3': '2.4 常用函数'}"
TuGraph-DB是如何帮助解决旅行时选择路线的烦恼的？,"page_content='Round The World Demo

示例

查询示例

在左下角的城市列表中选择不超过8个城市，点击查询可返回推荐的航班规划，在满足前后航班间隔在2-6小时的要求下，返回费用最低和飞行时间最短的10条路径规划。  
![data](../../../../images/round-the-world/search_example.jpg)  
详细使用说明见 [Round The World Demo](https://github.com/TuGraph-family/tugraph-db-demo/tree/main/round_the_world) 文档。' metadata={'Header 1': 'Round The World Demo', 'Header 2': '示例', 'Header 3': '查询示例'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='技术规划

2. 已完成功能

TuGraph-DB于2022年9月1日开源，TuGraph-DB在社区的反馈声中，进行日常BUG修复，自身能力得到了完善。  
| 版本号   | 功能                               | 时间         |
|-------|----------------------------------|------------|
| 3.3.0 | 开源初版                             | 2022.9.1   |
| 3.3.1 | 图分析引擎重构，多模式支持                    | 2022.10.14 |
| 3.3.2 | OGM支持，UT覆盖率提升                    | 2022.11.21 |
| 3.3.3 | 链接认证机制迭代，加入英文文档                  | 2022.12.23 |
| 3.3.4 | 支持上云，梳理LDBC SNB Audit流程          | 2023.1.28  |
| 3.4.0 | 支持OLAP Python API, 离线导入升级        | 2023.3.11  |
| 3.5.0 | 支持POG，前端升级，文档梳理                  | 2023.6.5   |
| 3.5.1 | 图学习引擎，Procedure Rust API，存储属性分离  | 2023.7.14  |
| 3.6.0 | 高可用开源，日志系统升级                     | 2023.8.11  |
| 4.0.0 | ISO GQL支持，新增11个开源图算法，支持m1 Docker | 2023.9.6   |
| 4.0.1 | 支持时序边排序，新增5个开源图算法                | 2023.9.28  |
| 4.1.0 | 支持Bolt协议，支持快速在线全量导入，支持地理空间数据类型   | 2023.12.25 |  
除此之外，TuGraph-DB搭建了较为完善的质量体系，涵盖自动化的单元测试、集成测试、性能测试等。  
更详细的描述可以在源码目录在的 ""[root]/release/CHANGELOG.md"" 文件查看。' metadata={'Header 1': '技术规划', 'Header 2': '2. 已完成功能'}"
exists()函数用于检查什么？,"page_content='Cypher API

3.Functions

3.2.Predicate functions

- exists()
judge it whether a vertex or edge has the field .
**Scope:** whole instance.
**Example input:**  
```
MATCH (n)
WHERE exists(n.born)
RETURN n.name, n.born
```  
**Example output:**  
| exists(name) |
| ------------ |
| true         |' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.2.Predicate functions'}","page_content='Cypher API

2.Clauses

2.4.WHERE

- Basic usage
- ✓ Boolean operations  
```
MATCH (n)
WHERE n.name = 'Laurence Fishburne' XOR (n.born > 1965 AND n.name = 'Carrie-Anne Moss')
RETURN n.name, n.born
```  
- ✓ Filter on node label  
```
MATCH (n)
WHERE n:person
RETURN n.name, n.born
```  
- ✓ Filter on node property  
```
MATCH (n)
WHERE n.born > 2000
RETURN n.name, n.born
```  
- ✓ Filter on relationship property  
```
MATCH (n)-[k:acted_in]->(f)
WHERE k.role = ""Trinity""
RETURN f.title
```  
- ❏ Filter on dynamically-computed property  
```
WITH 'AGE' AS propname
MATCH (n)
WHERE n[toLower(propname)]< 30
RETURN n.name, n.age
```  
- ✓ Property existence checking  
```
MATCH (n)
WHERE exists(n.born)
RETURN n.name, n.born
```  
- String matching
- ✓ Match the beginning of a string  
```
MATCH (n)
WHERE n.name STARTS WITH 'Pet'
RETURN n.name, n.born
```  
- ✓ Match the ending of a string  
```
MATCH (n)
WHERE n.name ENDS WITH 'ter'
RETURN n.name, n.born
```  
- ✓ Match anywhere within a string  
```
MATCH (n)
WHERE n.name CONTAINS 'ete'
RETURN n.name, n.born
```  
- ✓ String matching negation  
```
MATCH (n)
WHERE NOT n.name ENDS WITH 's'
RETURN n.name, n.born
```  
- Using path patterns in `WHERE`
- ❏ Filter on patterns  
```
MATCH (tobias {name: 'Tobias'}), (others)
WHERE others.name IN ['Andres', 'Peter'] AND (tobias)<-[]-(others)
RETURN others.name, others.age
```  
- ❏ Filter on patterns using NOT  
```
MATCH (persons), (peter {name: 'Peter'})
WHERE NOT (persons)-[]->(peter)
RETURN persons.name, persons.age
```  
- ❏ Filter on patterns with properties  
```
MATCH (n)
WHERE (n)-[:KNOWS]-({name: 'Tobias'})
RETURN n.name, n.age
```  
- ✓ Filter on relationship type  
```
MATCH (n)-[r]->()
WHERE n.name='Laurence Fishburne' AND type(r) STARTS WITH 'ac'
RETURN type(r), r.role
```  
- Lists
- ✓ IN operator  
```
MATCH (a)
WHERE a.name IN ['Laurence Fishburne', 'Tobias']
RETURN a.name, a.born
```  
- Missing properties and values
- ✓ Default to false if property is missing  
```
MATCH (n)
WHERE n.belt = 'white'
RETURN n.n' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.4.WHERE'}","page_content='Cypher API

3.Functions

3.1.Whole List Of Functions

| 种类                   | 功能               | 备注                      |
| ---------------------- |------------------| ------------------------- |
| Predicate functions    | exists()         |                           |
|                        | all()            | 不支持                    |
|                        | any()            | 不支持                    |
|                        | single()         | 不支持                    |
|                        | none()           | 不支持                    |
| Scalar functions       | id()             |                           |
|                        | euid()           |                           |
|                        | properties()     |                           |
|                        | head()           |                           |
|                        | last()           |                           |
|                        | toBoolean()      |                           |
|                        | toFloat()        |                           |
|                        | toInteger()      |                           |
|                        | toString()       |                           |
|                        | type()           |                           |
|                        | startnode()      |                           |
|                        | endnode()        |                           |
|                        | size()           |                           |
|                        | length()         |                           |
|                        | substring()      |                           |
|                        | concat()         |                           |
|                        | label()          | OpenCypher扩展方法      |
| Aggregating functions  | avg()            |                           |
|                        | collect()        |                           |
|                        | count()          |                           |
|                 ' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.1.Whole List Of Functions'}"
安装部署TuGraph硬件的最低和建议CPU配置分别是多少个核心？,"page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='环境准备

1.硬件环境

1.3. 外存

我们强烈建议用户使用 NVMe SSD 作为外存，数据库有大量的写操作需要同步的外存，通常为随机写，外存的读写性能很容易成为整体数据库运行的性能瓶颈。因此，高IOPS、低延迟的 NVMe SSD 是最优的选择。  
如果现实条件只能使用 SATA接口的SSD，或者云上的网盘，性能虽然会受到影响，但 TuGraph 依然能正确的运行。  
外存大小建议为实际数据大小的4倍，比如数据为1TB，则准备4TB的硬盘会比较稳妥。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.3. 外存'}","page_content='环境和版本选择

3. 部署方式选择

TuGraph部署仅需一台服务器（高可用模式需要多台），可根据实际资源情况和使用场景，选择适合的部署方式。  
| 部署方式     | 描述                   | 备注                                                                                      |
|----------|----------------------|-----------------------------------------------------------------------------------------|
| 云部署      | 阿里云计算巢一键部署，免费试用      | 新手适用，流程参考 [链接](../5.installation&running/5.cloud-deployment.md)              |
| Docker部署 | 通过预先准备的Docker镜像跨平台部署 | 对硬件有要求的用户，比如性能测试，流程参考 [链接](../5.installation&running/3.docker-deployment.md) |
| 本地部署     | 在现有系统紧耦合部署           | 指定生产环境适用，流程参考 [链接](../5.installation&running/4.local-package-deployment.md)  |' metadata={'Header 1': '环境和版本选择', 'Header 2': '3. 部署方式选择'}"
MappedVid 函数是用于什么目的？,"page_content='OlapOnDB API

4. 其他常用函数功能描述

4.9 获取OlapOnDB中节点对应TuGraph的节点编号

```C++
size_t MappedVid(size_t original_vid)
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.9 获取OlapOnDB中节点对应TuGraph的节点编号'}","page_content='Cypher API

3.Functions

3.3.Scalar functions

- id()
get the id of vertex.
**Scope:** whole instance.
**Example input:**  
```
MATCH (a)
RETURN id(a)
```  
**Example output:**  
| vid |
| --- |
| 1   |
| 2   |
| ... |  
- properties()
get a map containing all the properties of a node or relationship.
**Scope:** whole instance.
**Example input:**  
```
MATCH (n:person {name: 'Laurence Fishburne'})
RETURN n
```  
- head()
get the first element of a list.
**Scope:** whole instance.
**Example input:**  
```
WITH ['one','two','three'] AS coll RETURN coll, head(coll)
```  
**Example output:**  
| coll                  | head(coll)    |
| --------------------- | ------------- |
| [""one"",""two"",""three""] | ""one""         |  
- last()
get the last element of a list.
**Scope:** whole instance.
**Example input:**  
```
WITH ['one','two','three'] AS coll RETURN coll, last(coll)
```  
**Example output:**  
| coll                  | last(coll)    |
| --------------------- | ------------- |
| [""one"",""two"",""three""] | ""three""       |  
- toFloat()
Converts an integer or string value to a floating point number.
**Scope:** whole instance.
**Example input:**  
```
RETURN toFloat('11.5')
```  
**Example output:**  
| float |
| ----- |
| 11.5  |  
- toInteger()
Converts a floating point or string value to an integer value.
**Scope:** whole instance.
**Example input:**  
```
RETURN toInteger('2.3') AS integer
```  
**Example output:**  
| integer |
| ------- |
| 2       |  
- toString()
Converts an integer, float, boolean value to a string.
**Scope:** whole instance.
**Example input:**  
```
RETURN toString(2.3)
```  
- type()
get the string representation of the relationship type.
**Scope:** whole instance.
**Example input:**  
```
MATCH (n)-[r]->()
WHERE n.name = 'Laurence Fishburne'
RETURN type(r)
```  
**Example output:**  
| type     |
| -------- |
| acted_in |
| acted_in |' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.3.Scalar functions'}","page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/node/{vid}
```  
Nodes 提供节点（Vertex）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。  
#### 6.7.1.列出点数量和label数量  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| num_label | 点 label 数量 | 整数 |
| num_vertex | 点数量 | 整数 |  
_注意 num_vertex 返回的并不是准确的点数量，只是一个估计值。_  
#### 6.7.2.创建一个点  
向数据库中插入一个点。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 点属性 | 字典，其中 key 是列名，value 是相应值。value 必须是与列类型相应的类型，如列为 int32，则 value 只能是整数。 |  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新点 vid。该 ID 可用于后续的点操作中。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""property"" : {
""name"" : ""Passerby A"",
""birthyear"" : 1989
}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
21
}
```  
#### 6.7.3.批量创建点  
TuGraph 允许一次性插入多个点，以减少网络开销。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| fields | 点属性 | 列表 |
| values | 点数据 | 列表 |  
其中 fields 是一个字符串列表，列出一系列列名；values 是一个列表，其中每个元素是一个列表，列表中每个元素是列数据。  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新增加的点的 vid 列表，该列表中每一个 vid 按顺序对应请求中的每一个点。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""fields"" : [""name"", ""birthyear""],
""values"" : [[""alex"", 2000],
[""bob"", 1999]]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
22,
23
]
}
```  
#### 6.7.4.获取点  
- **URI**: `/db/{graph_name}/node/{vertex_id}`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 属性 | 字典，格式为 { {列名 1}:{列值 1},...' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}"
当尝试更新一个存在的边但标签与指定的不符时，会发生什么？,"page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}","page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/relationship/{euid}
```  
与 Nodes 功能类似，Relationships 提供边（edge）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。每一条边都可以由一个唯一 ID（euid）来标识。这个 ID 可以从在插入边时获得，或者在 [列出所有边](#%E5%88%97%E5%87%BA%E6%89%80%E6%9C%89%E8%BE%B9) 操作中得到。  
#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| fields | 数据列名 | 列表 |
| edge | 边数据 | 列表 |  
其中 edge 是一个数据列表，其中每个元素都是一条边，其定义如下：  
| 域名        | 说明     | 类型                                                   |
| ----------- | -------- | ------------------------------------------------------ |
| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}"
"批量在线导入是通过”CREATE (n), (m)“吗？","page_content='Cypher API

2.Clauses

2.7.CREATE

- Create nodes  
> **Note**
> TuGraph不支持创建空的nodes，不支持多labels。  
- ☒ Create single node  
```
CREATE (n)
```  
- ☒ Create multiple nodes  
```
CREATE (n), (m)
```  
- ☒ Create a node with a label  
```
CREATE (n:person)
```  
- ☒ Create a node with multiple labels  
```
CREATE (n:Person:Swedish)
```  
- ✓ Create node and add labels and properties  
```
CREATE (n:person {id:2001, name: 'Andres'})
```  
- ✓ Return created node  
```
CREATE (n:person {id:2002, name: 'Andres'})
RETURN n
```  
- Create relationships
- ✓ Create a relationship between two nodes  
```
MATCH (n:person), (m:movie)
WHERE n.name = 'Jada Pinkett Smith' AND m.title = 'The Matrix'
CREATE (n)-[r:write]->(m)
```  
- ✓ Create a relationship and set properties  
```
MATCH (n:person), (m:movie)
WHERE n.name = 'Jada Pinkett Smith' AND m.title = 'The Matrix'
CREATE (n)-[r:acted_in{role: 'Trinity'}]->(m)
```  
- ❏ Create a full path  
```
CREATE p = (andres:person {id: 2005, name:'Andres'})-[:acted_in {role: 'Trinity'}]->
(m:movie {id: 2006})<-[:acted_in {role: 'Trinity'}]-(michael {id: 2006, name:'Michael'})
RETURN p
```  
- Use parameters with CREATE
- ❏ Create node with a parameter for the properties  
```
CREATE (n:Person $props)
RETURN n
```  
- ☒ Create multiple nodes with a parameter for their properties  
```
UNWIND $props AS map
CREATE (n)
SET n = map
```
cannot create vertex without label.' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.7.CREATE'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.6 通过OGM进行查操作**

**MATCH**  
session.load方法用于根据节点id查找节点。 session.loadALL方法用于批量查找节点，支持通过多个节点id查找节点、查找某一类型的所有节点、带有filter的查询。 filter查询需要新建Filter，传入参数ComparisonOperatorx0;可选为：EQUALSx0;、GREATER\_THANx0;、LESS\_THAN  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*J3Z1TrA0BncAAAAAAAAAAAAADgOBAQ/original)  
**QUERY WITH CYPHER**  
OGM支持通过queryForObject、query方法向TuGraph发送Cypher查询，由于Cypher查询的灵活性，需要用户自行指定返回结果格式。  
session.queryForObject方法：需要在方法第一个参数处指定返回类型，可设定为某一实体类或数字类型。  
session.query方法：Cypher查询的返回结果被存储为Result类型，其内部数据需要用户自行解析，以下方代码为例，传入数据库的Cypher为CREATE查询，返回结果createResult可被解析为QueryStatistics，可获取到此次查询被创建的节点与边的数目。  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*lkxXS660eEgAAAAAAAAAAAAADgOBAQ/original)' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.6 通过OGM进行查操作**'}","page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

#### 6.10.1.指定文件内容导入  
- **URI**: `/db/{graph_name}/import/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |
| data | 要导入的文件内容（建议最大在 16MB 左右，最长不超过 17MB） | 字符串 / 数组 / 对象 |
| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""description"": ""{\\""files\\"":[{\\""columns\\"":[\\""SRC_ID\\"",\\""role\\"",\\""DST_ID\\""],\\""format\\"":\\""CSV\\"",\\""label\\"":\\""role\\"",\\""SRC_ID\\"":\\""actor\\"",\\""DST_ID\\"":\\""movie\\""}]}""}"",
""data"": ""1,Role1,2\n3,Role2,4\n"",
""continue_on_error"": true,
""delimiter"": "",""
}
```  
上述 description 的值是如下 json 序列化后的字符串  
```json
{
""files"": [
{
""format"": ""CSV"",
""label"": ""role"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""log"": ""Missing src uid 1\n""
}
```  
由于请求中指定了在出错时继续，该返回信息说明 SRC_ID 为 1 的边没有被导入，而其他信息导入成功。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}"
lgraph_backup工具的主要功能是什么？,"page_content='备份恢复

1.数据备份

TuGraph 可以通过 `lgraph_backup` 工具来进行数据备份。
`lgraph_backup` 工具可以将一个 TuGraph 数据库中的数据备份到另一个目录下，它的用法如下：  
```bash
$ lgraph_backup -s {source_dir} -d {destination_dir} -c {true/false}
```  
其中：  
- `-s {source_dir}` 指定需要备份的数据库（源数据库）所在目录。
- `-d {destination_dir}` 指定备份文件（目标数据库）所在目录。
如果目标数据库不为空，`lgraph_backup` 会提示是否覆盖该数据库。
- `-c {true/false}` 指明是否在备份过程中进行 compaction。
compaction 能使产生的备份文件更紧凑，但备份时间也会变长。该选项默认为 `true`。' metadata={'Header 1': '备份恢复', 'Header 2': '1.数据备份'}","page_content='备份恢复

2.数据恢复

使用`lgraph_backup` 工具得到的目标数据库`{destination_dir}`备份了源数据库
`{source_dir}`的所有子图，但不包含HA集群的raft信息，从而保证服务和集群能
以备份数据库成功重启并与源数据库的数据一致。使用如下命令可以用备份数据库重启服务，
在服务启动时会恢复所有子图的存储过程，保证备份服务和原服务完全一致。  
```bash
$ lgraph_server -c lgraph.json --directory {destination_dir} -d start
```  
其中：  
- `-d {destination_dir}` 指定备份文件（目标数据库）所在目录。' metadata={'Header 1': '备份恢复', 'Header 2': '2.数据恢复'}","page_content='数据迁移

2. 兼容迁移

2.1. 备份数据

使用`lgraph_backup`工具备份数据
```bash
lgraph_backup -s db -d db.bck
```
本步骤也可以直接使用`cp`命令，不过`cp`命令会拷贝一些多余的元数据，HA模式下也会拷贝raft的元数据导致迁移之后集群重启失败，
因此建议数据迁移时使用`lgraph_backup`工具替代`cp`命令。' metadata={'Header 1': '数据迁移', 'Header 2': '2. 兼容迁移', 'Header 3': '2.1. 备份数据'}"
在获取某个节点的所有属性时，通过什么方法和URI可以实现？,"page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/node/{vid}
```  
Nodes 提供节点（Vertex）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。  
#### 6.7.1.列出点数量和label数量  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| num_label | 点 label 数量 | 整数 |
| num_vertex | 点数量 | 整数 |  
_注意 num_vertex 返回的并不是准确的点数量，只是一个估计值。_  
#### 6.7.2.创建一个点  
向数据库中插入一个点。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 点属性 | 字典，其中 key 是列名，value 是相应值。value 必须是与列类型相应的类型，如列为 int32，则 value 只能是整数。 |  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新点 vid。该 ID 可用于后续的点操作中。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""property"" : {
""name"" : ""Passerby A"",
""birthyear"" : 1989
}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
21
}
```  
#### 6.7.3.批量创建点  
TuGraph 允许一次性插入多个点，以减少网络开销。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| fields | 点属性 | 列表 |
| values | 点数据 | 列表 |  
其中 fields 是一个字符串列表，列出一系列列名；values 是一个列表，其中每个元素是一个列表，列表中每个元素是列数据。  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新增加的点的 vid 列表，该列表中每一个 vid 按顺序对应请求中的每一个点。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""fields"" : [""name"", ""birthyear""],
""values"" : [[""alex"", 2000],
[""bob"", 1999]]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
22,
23
]
}
```  
#### 6.7.4.获取点  
- **URI**: `/db/{graph_name}/node/{vertex_id}`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 属性 | 字典，格式为 { {列名 1}:{列值 1},...' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.6 通过OGM进行查操作**

**MATCH**  
session.load方法用于根据节点id查找节点。 session.loadALL方法用于批量查找节点，支持通过多个节点id查找节点、查找某一类型的所有节点、带有filter的查询。 filter查询需要新建Filter，传入参数ComparisonOperatorx0;可选为：EQUALSx0;、GREATER\_THANx0;、LESS\_THAN  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*J3Z1TrA0BncAAAAAAAAAAAAADgOBAQ/original)  
**QUERY WITH CYPHER**  
OGM支持通过queryForObject、query方法向TuGraph发送Cypher查询，由于Cypher查询的灵活性，需要用户自行指定返回结果格式。  
session.queryForObject方法：需要在方法第一个参数处指定返回类型，可设定为某一实体类或数字类型。  
session.query方法：Cypher查询的返回结果被存储为Result类型，其内部数据需要用户自行解析，以下方代码为例，传入数据库的Cypher为CREATE查询，返回结果createResult可被解析为QueryStatistics，可获取到此次查询被创建的节点与边的数目。  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*lkxXS660eEgAAAAAAAAAAAAADgOBAQ/original)' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.6 通过OGM进行查操作**'}","page_content='OlapOnDB API

3. 算法举例

3.1 主函数

主函数输入有三个参数，`TuGraph`数据库参数`db`，从网页端获取的请求`request`，给网页端的返回值`response`，整体流程可以分为一下几步：  
1. 相关参数的获取
2. 快照类的创建
3. PageRank算法主流程
4. 网页端返回值的获取和发送  
```C++
extern ""C"" bool Process(GraphDB & db, const std::string & request, std::string & response) {

// 从网页端请求中获取迭代次数（num_iterations），
int num_iterations = 20;
try {
json input = json::parse(request);
num_iterations = input[""num_iterations""].get<int>();
} catch (std::exception & e) {
throw std::runtime_error(""json parse error"");
return false;
}

// 读事务的创建以及快照类的创建
auto txn = db.CreateReadTxn();
OlapOnDB<Empty> olapondb(
db,
txn,
SNAPSHOT_PARALLEL
);

// 创建pr数组用于存储每个节点的pr值
ParallelVector<double> pr = olapondb.AllocVertexArray<double>();
// pagerank算法主流程，获取每个节点的pagerank值
PageRankCore(olapondb, num_iterations, pr);

auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
/*
函数用途：从所有节点中获取pagerank值最大的节点编号

函数流程描述：该函数对点集合all_vertices中所有为1的位对应的节点vi（又称为活跃点）执行Func A，再将Func A的返回值作为Func B的第二个输入参数，得到局部最大值（因为第一个输入参数为0，因此实际上返回值就是每个节点的pagerank值），最后再将所有线程的返回值汇总，再次 执行Func B得到全局返回值，并存入max_pr_vi变量中
*/
size_t max_pr_vi = olapondb.ProcessVertexActive<size_t>(

//Func A
[&](size_t vi) {
return vi;
},
all_vertices,
0,

//Func B
[&](size_t a, size_t b) {
return pr[a] > pr[b] ? a : b;
}
);

// 网页端返回值的获取和发送
json output;
output[""max_pr_vid""] = olapondb.OriginalVid(max_pr_vi);
output[""max_pr_val""] = pr[max_pr_vi];
response = output.dump();
return true;
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.1 主函数'}"
知识图谱的基本元素包括哪些？,"page_content='图数据库智能化建设与探索

**03.技术分享｜知识图谱语义框架SPG及图谱推理**

“当前，我们正处于图谱技术发展的第三阶段，这一阶段的核心是将图谱与大型模型相结合。目标转向了知识的标准化、跨领域数据的联通与复用。随着这个阶段的深入，简单地在推理过程中融入文本概念和信息，或者是加入交易与社交的实体关系，已经不能明显提升推理效果了。关键的做法应当是结合实体信息的多元素特征进行深度协作，从而更精准地关联相关性，揭示那些稀疏的实体间关系，并实现意义解释的密集化。”' metadata={'Header 1': '图数据库智能化建设与探索', 'Header 2': '**03.技术分享｜知识图谱语义框架SPG及图谱推理**'}","page_content='RESTful API Legacy

6.Deprecated

6.11.其他

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/misc
```  
#### 6.11.1.提取子图  
给出点 id 集合，返回包含该集合的最小子图。  
- **URI**: `/db/{graph_name}/misc/sub_graph`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| vertex_ids | 点 id 集合 | 列表 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| nodes | 点数据 | 列表，每元素包含 vid, label, 以及属性 |
| relationships | 边数据 | 列表，每元素包含 src, dst, euid, label, 以及属性 |  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/misc/sub_graph
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""vertex_ids"": [2, 5, 14, 20]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""nodes"": [
{
""label"": ""Person"",
""properties"": {
""birthyear"": 1937,
""name"": ""Vanessa Redgrave""
},
""vid"": 2
},
{
""label"": ""Person"",
""properties"": {
""birthyear"": 1963,
""name"": ""Natasha Richardson""
},
""vid"": 5
},
{
""label"": ""City"",
""properties"": {
""name"": ""London""
},
""vid"": 14
},
{
""label"": ""Film"",
""properties"": {
""title"": ""Camelot""
},
""vid"": 20
}
],
""relationships"": [
{
""destination"": 5,
""label"": ""HAS_CHILD"",
""properties"": {
""birthyear"": 1937,
""name"": ""Vanessa Redgrave""
},
""source"": 2
},
{
""destination"": 14,
""label"": ""BORN_IN"",
""properties"": {
""birthyear"": 1937,
""name"": ""Vanessa Redgrave""
},
""source"": 2
},
{
""destination"": 20,
""label"": ""ACTED_IN"",
""properties"": {
""birthyear"": 1937,
""charactername"": ""Guenevere"",
""name"": ""Vanessa Redgrave""
},
""source"": 2
},
{
""destination"": 14,
""label"": ""BORN_IN"",
""properties"": {
""birthyear"": 1963,
""name"": ""Natasha Richardson""
},
""source"": 5
}
]
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.11.其他'}","page_content='图算法介绍

2\. 流图推理简介

TuGraph计算引擎（TuGraph Analytics\[1\]）是蚂蚁集团开源的大规模分布式实时图计算引擎（流图引擎），实现了流批一体的图计算模型，支持了丰富的图计算算法。TuGraph Analytics的流图计算能力，能处理连续输入的数据流，并支持增量的计算模式，极大得提高了数据的计算效率和实时性。TuGraph Analytics解决了业界大规模数据关联分析的实时计算问题，已广泛应用于数仓加速、金融风控、知识图谱以及社交推荐等场景。  
随着业务场景中问题复杂度的提升，基于传统的迭代图算法已无法满足业务的实际需求。例如在反洗钱场景中，利用图神经网络算法处理复杂的交易关系，能够捕获到节点的局部图结构信息。通过聚合邻接节点的特征信息，每个交易节点都可以感知到周边图网络结构的信息。类似的图神经网络等AI模型的推理逻辑，是无法基于传统的图迭代计算模式直接高效地表达的。  
受上述问题启发，我们思考是否可以将TuGraph Analytics的流图计算能力与图神经网络等深度学习模型相结合，开发一套基于流图计算的模型推理系统。最终期望的推理系统具备如下能力：  
-   对于图算法工程师，在图迭代计算过程中，能够方便地使用机器学习模型的推理能力。  
-   对于AI算法工程师，可以通过TuGraph Analytics分布式流式计算的能力实现实时的模型推理。  
众所周知，在深度学习为代表的数据科学领域，Python已经成为数据分析、模型训练和推理框架的主流开发语言，并提供了丰富的开发库和框架生态。而以Hadoop全家桶为代表的大数据计算引擎领域，基于Java语言开发的系统仍占据一席之地，当然TuGraph Analytics也在其中。这种语言差异带来的“互操作性”成本，使得相当一部分大数据和AI生态组件无法轻松地融合，这也是TuGraph Analytics支持图推理需要亟待解决的问题。' metadata={'Header 1': '图算法介绍', 'Header 2': '2\\. 流图推理简介'}"
TuGraph-DB是否支持存储过程？支持哪些编程语言的存储过程？,"page_content='RPC API

5.存储过程

为满足用户较为复杂的查询/更新逻辑，TuGraph支持 C 语言和 Python 语言编写的存储过程。
用户可以使用RPC请求对存储过程进行增删改查操作。' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程'}","page_content='Procedure API

3.存储过程语言支持

在 TuGraph 中，用户可以动态的加载，更新和删除存储过程。TuGraph 支持 C++ 语言、 Python 语言和 Rust 语言编写存储过程。在性能上 C++ 语言支持的最完整，性能最优。  
注意存储过程是在服务端编译执行的逻辑，和客户端的语言支持无关。' metadata={'Header 1': 'Procedure API', 'Header 2': '3.存储过程语言支持'}","page_content='功能概览

4.核心功能

4.2.存储过程

当用户需要表达的查询/更新逻辑较为复杂（例如 Cypher 无法描述，或是对性能要求较高）时，相比调用多个 REST 请求并在客户端完成整个
处理流程的方式，TuGraph 提供的存储过程（Procedure）是更简洁和高效的选择。  
从 3.5 版本开始，TuGraph 重新设计了新的存储过程编程范式，支持定义标准的签名和结果，支持POG编程。  
TuGraph 支持 POG (Procedres on Graph Query Languages) 编程和 POG 库，其中“Graph Query Languages”包含 Cypher 以及
制定中的 ISO GQL 等图查询语言。POG 库提供在查询语言中对用户定义的存储过程的访问，打破了查询语言和存储过程之间的界限，扩展了查询
语言的使用范围。  
> 这个文档描述了 [新的 Procedure 编程范式以及 POG](../9.olap&procedure/1.procedure/1.procedure.md)。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.2.存储过程'}"
GetEdgeProp操作的目的是什么？,"page_content='图算法介绍

5.2 图迭代推理

定义图迭代计算结合推理逻辑如下：  
```
public static class PRVertexCentricComputeFunction implements
IncVertexCentricComputeFunction<Integer, Integer, Integer, Integer> {

private IncGraphComputeContext<Integer, Integer, Integer, Integer> graphContext;
private IncGraphInferContext<String> inferContext;

@Override
public void init(IncGraphComputeContext<Integer, Integer, Integer, Integer> graphContext) {
this.graphContext = graphContext;
this.inferContext = (IncGraphInferContext<String>) graphContext;
}

@Override
public void evolve(Integer vertexId,
TemporaryGraph<Integer, Integer, Integer> temporaryGraph) {
long lastVersionId = 0L;
IVertex<Integer, Integer> vertex = temporaryGraph.getVertex();
HistoricalGraph<Integer, Integer, Integer> historicalGraph = graphContext
.getHistoricalGraph();
if (vertex == null) {
vertex = historicalGraph.getSnapShot(lastVersionId).vertex().get();
}

if (vertex != null) {
List<IEdge<Integer, Integer>> newEs = temporaryGraph.getEdges();
List<IEdge<Integer, Integer>> oldEs = historicalGraph.getSnapShot(lastVersionId)
.edges().getOutEdges();
if (newEs != null) {
for (IEdge<Integer, Integer> edge : newEs) {
graphContext.sendMessage(edge.getTargetId(), vertexId);
}
}
if (oldEs != null) {
for (IEdge<Integer, Integer> edge : oldEs) {
graphContext.sendMessage(edge.getTargetId(), vertexId);
}
}
}

}

@Override
public void compute(Integer vertexId, Iterator<Integer> messageIterator) {
int max = 0;
while (messageIterator.hasNext()) {
int value = messageIterator.next();
max = max > value ? max : value;
}
IVertex<Integer, Integer> vertex = graphContext.getTemporaryGraph().getVertex();
IVertex<Integer, Integer> historyVertex = graphContext.getHistoricalGraph().getSnapShot(0).vertex().get();
if (vertex != null && max < vertex.getValue()) {
max = vertex.getValue();
}
if (historyVertex != null && max < historyVertex.getValue()) {
max = historyVertex.getValue();
}
graphContext.getTemporaryGraph().updateVertexValue(max);
}

@Override
public void finish(Integer vertexId, MutableGraph<Integer, Integer' metadata={'Header 1': '图算法介绍', 'Header 2': '5.2 图迭代推理'}","page_content='业务开发指南

边类型操作

边类型添加索引

>该操作会同步构建索引数据，数据量大的时候，有时间消耗。  
如下例子，对于边类型`edge1`，给字段`field1`添加了一个非唯一索引。
```
CALL db.addEdgeIndex('edge1', 'field1', false, false)
```
如下例子，对于边类型`edge1`，给字段`field2`添加了一个唯一索引。
```
CALL db.addEdgeIndex('edge1', 'field2', true, false)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型添加索引'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/relationship/{euid}
```  
与 Nodes 功能类似，Relationships 提供边（edge）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。每一条边都可以由一个唯一 ID（euid）来标识。这个 ID 可以从在插入边时获得，或者在 [列出所有边](#%E5%88%97%E5%87%BA%E6%89%80%E6%9C%89%E8%BE%B9) 操作中得到。  
#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| fields | 数据列名 | 列表 |
| edge | 边数据 | 列表 |  
其中 edge 是一个数据列表，其中每个元素都是一条边，其定义如下：  
| 域名        | 说明     | 类型                                                   |
| ----------- | -------- | ------------------------------------------------------ |
| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}"
TuGraph-DB的主要功能是什么？,"page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='可视化操作手册（旧版）

作用

TuGraph Browser 的主要功能是为使用图数据库的开发人员，提供可视化的图数据开发，图数据管理和维护等功能。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '作用'}"
当Cypher请求的响应不包含正确的结果时，会抛出什么异常？,"page_content='RPC API

4.查询

用户可以通过Cypher查询和TuGraph进行绝大多数的交互，Cypher请求信息包含以下参数：
- query: 必要参数，Cypher查询语句
- param_names: 可选参数，参数名
- param_values: 可选参数，参数值
- result_in_json_format: 必要参数，查询结果是否以JSON格式返回
- graph: 可选参数，Cypher语句执行的子图名称
- timeout: 可选参数，Cypher语句执行的超时时间  
以C++为例，用户发送Cypher请求的方式如下所示：
```C++
LGraphResponse res;
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
LGraphRequest req;
req.set_client_version(server_version);
req.set_token(token);
lgraph::CypherRequest* cypher_req = req.mutable_cypher_request();
cypher_req->set_graph(graph);
cypher_req->set_query(query);
cypher_req->set_timeout(timeout);
cypher_req->set_result_in_json_format(true);
LGraphRPCService_Stub stub(channel.get());
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
server_version = std::max(server_version, res.server_version());
CypherResponse cypher_res = res.cypher_response();
```
Cypher请求响应为以下两个参数之一：
- json_result: JSON格式的cypher查询结果
- binary_result: CypherResult格式的cypher查询结果' metadata={'Header 1': 'RPC API', 'Header 2': '4.查询'}","page_content='RESTful API Legacy

4.查询

4.1.调用Cypher

- **URI**: `/cypher`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| graph | 数据库 | 字符串 |
| cypher | 查询语句 | 字符串 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| result | 运行结果 | 列表 |
| elapsed | 运行时间（秒） | 浮点数 |
| header | 返回结果的表头 | 列表 |
| size | 结果数 | 整型 |  
其中 header 是一个列表，每一元素格式如下：  
| 域名 | 说明                                        | 类型   |
| ---- | ------------------------------------------- | ------ |
| name | 列名                                        | 字符串 |
| type | 列数据类型，0 为标量，1 为点 id，2 为向量 |        |  
**Example request.**  
```
• POST http://localhost:7070/cypher
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""graph"": ""default"",
""script"": ""MATCH (n) RETURN n,n.name LIMIT 10""
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""elapsed"": 0.001224517822265625,
""header"": [
{
""name"": ""n"",
""type"": 1
},
{
""name"": ""n.name"",
""type"": 0
}
]
""result"": [
[
0,
""Rachel Kempson""
],
[
1,
""Michael Redgrave""
],
[
2,
""Vanessa Redgrave""
]
],
""size"": 3
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '4.查询', 'Header 3': '4.1.调用Cypher'}","page_content='RESTful API Legacy

4.查询

4.2.调用带参数的 Cypher

Cypher 支持使用参数进行查询。当调用带参数的 Cypher 查询时，TuGraph 会缓存该查询的
执行计划（execution plan），以加速后续同类查询的速度。  
- **URI**: `/cypher`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| graph | 数据库 | 字符串 |
| cypher | 查询语句 | 字符串 |
| parameters | 参数 | 列表 |  
- **RESPONSE**:  
与 [调用 Cypher](#%E8%B0%83%E7%94%A8Cypher) 相同。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/cypher
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""graph"": ""default"",
""script"": ""MATCH (n:Person {name:$param1}) RETURN n.birthyear"",
""parameters"": {
""$param1"": ""Lindsay Lohan""
}
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""elapsed"": 0.005886077880859375,
""header"": [
{
""name"": ""n.birthyear"",
""type"": 0
}
],
""result"": [
[
1986
]
],
""size"": 1
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '4.查询', 'Header 3': '4.2.调用带参数的 Cypher'}"
2024年度功能更新预计何时推出HA支持Witness角色和管理工具？,"page_content='技术规划

3. 2024年功能更新

在2024年度，我们计划的功能更新包括：  
| 版本号   | 功能                 | 计划时间    |
|-------|--------------------|---------|
| 4.2.x | HA支持Witness角色和管理工具 | 2024.3  |
| 4.2.x | Bolt支持流处理和参数化查询    | 2024.3  |
| x.x.x | GeaX支持Cypher       | 2024.6  |
| x.x.x | 支持组合索引             | 2024.6  |
| x.x.x | 数据导入功能优化           | 2024.6  |
| x.x.x | 【社区功能】支持地理数据类型使用   | 2024.6  |
| x.x.x | Cypher能力提升         | 2024.9  |
| x.x.x | 支持Schema快速变更       | 2024.9  |
| x.x.x | 向量化支持              | 2024.12 |
| x.x.x | RPQ支持              | 2024.12 |
| x.x.x | 【可选】查询引擎升级         | 2024.12 |
| x.x.x | 【社区功能】支持GraphAr    | 2024.12 |' metadata={'Header 1': '技术规划', 'Header 2': '3. 2024年功能更新'}","page_content='部署高可用模式

3.启动初始备份组

3.2.初始数据不一致

如果第一台服务器中已有数据（以`lgraph_import`工具导入或从非高可用模式的服务器传输得到），
并且之前并未在高可用模式下使用，则用户应使用boostrap方式启动。
以`ha_bootstrap_role`参数为1在bootstrap模式下启动有数据的服务器，并通过`ha_conf`参数指定本机为`leader`。
在bootstrap模式下，服务器在将新加入的服务器添加到备份组之前会将自己的
数据复制到新服务器中，以使每个服务器中的数据保持一致。  
启动有数据服务器的命令示例如下所示：  
```bash
$ ./lgraph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090 --ha_bootstrap_role 1
```  
其他无数据的服务器需要指定`ha_bootstrap_role`参数为2，并通过`ha_conf`参数指定`leader`即可，命令示例如下所示  
```bash
$ ./lgraph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090 --ha_bootstrap_role 2
```  
**使用bootstrap启动HA集群时需要注意两点：**
1. 需要等待`leader`节点生成snapshot并且成功启动之后再加入`follower`节点，否则`follower`节点可能加入失败。在启动`follower`节点时可以将`ha_node_join_group_s`参数配置的稍大，以在加入HA集群时多次等待和超时重试。
2. HA集群只有在第一次启动时可以使用bootstrap模式，后续再启动时只能使用普通模式(见3.1节)启动，尤其不能让同一个集群的多个节点以bootstrap模式启动，否则可能产生数据不一致的情况' metadata={'Header 1': '部署高可用模式', 'Header 2': '3.启动初始备份组', 'Header 3': '3.2.初始数据不一致'}","page_content='部署高可用模式

4.启动witness节点

4.2.允许witness节点成为leader

可以通过指定`ha_enable_witness_to_leader`参数为`true`，使得`witness`节点可以临时成为`leader`节点，在将新日志同步完成之后再主动切主  
启动允许成为`leader`节点的`witness`节点服务器的命令示例如下所示：  
```bash
$ ./lgraph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090 --ha_is_witness 1 --ha_enable_witness_to_leader 1
```  
注：尽管允许`witness`节点成为`leader`节点可以提高集群的可用性，但是在极端情况下可能会影响数据的一致性。因此一般应保证`witness`节点数量+1少于集群节点总数量的一半。' metadata={'Header 1': '部署高可用模式', 'Header 2': '4.启动witness节点', 'Header 3': '4.2.允许witness节点成为leader'}"
TuGraph-DB使用CMake作为编译工具，支持的C++标准为C++17,"page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='TuGraph-db

3. 从源代码编译

建议在Linux系统中构建TuGraph，Docker环境是个不错的选择。如果您想设置一个新的环境，请参考[Dockerfile]  
以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build
$ cmake .. -DOURSYSTEM=centos7
$ make
$ make package
```' metadata={'Header 1': 'TuGraph-db', 'Header 2': '3. 从源代码编译'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}"
Cython.cimports.libcpp.unordered_map是什么？,"page_content='Python Olap API

6. 算法插件示例

下面为Python实现的BFS算法的代码示例：
```python
# cython: language_level=3, cpp_locals=True, boundscheck=False, wraparound=False, initializedcheck=False
# distutils: language = c++

# 注释作用如下：
# language_level=3: 使用Python3
# cpp_locals=True: 需要c++17，使用std::optional管理Python代码中的C++对象，可以避免C++对象的拷贝构造
# boundscheck=False: 关闭索引的边界检查
# wraparound=False: 关闭负数下标的处理（类似Python List）
# initializedcheck=False: 关闭检查内存是否初始化，关闭检查后运行性能更快
# language = c++: 将此py文件翻译为C++而不是C文件，TuGraph使用大量模板函数，所以都应该使用C++

import json

import cython
from cython.cimports.olap_base import *
from cython.cimports.lgraph_db import *
# 从procedures/algo_cython/ 中cimportolap_base.pxd与lgraph_db.pxd, 类似C++中#include ""xxx.h""

from cython.cimports.libc.stdio import printf
# 类似C++中#include <stdio.h>
# 其他常见的还有cython.cimports.libcpp.unordered_map等

import time


@cython.cclass
# cython.cclass 表示BFSCore为C类型的Class
class BFSCore:
graph: cython.pointer(OlapBase[Empty])
# cython.pointer(OlapBase[Empty])表示OlapBase[Empty]的指针，类似C++中OlapBase[Empty]*
# cython提供了常见类型的指针，如cython.p_int, cython.p_char等，表示int*, char*, ...
parent: ParallelVector[size_t]
active_in: ParallelBitset
active_out: ParallelBitset
root: size_t
# root: size_t 声明root为C++ size_t类型变量，等效于root = cython.declare(size_t)
# 不声明类型的变量为Python object类型
# 声明变量类型会大幅提高性能，同时在多线程部分，只有C/C++类型的变量可以访问

@cython.cfunc
# cython.cfunc 表示Work为C类型的函数，参数与返回值应声明
# cfunc性能好，能接受C/C++对象为参数、返回值，但是不能在其他python文件中调用
# 类似的有cython.ccall，如Standalone函数，可以在其他python文件中调用
@cython.nogil
# cython.nogil 表示释放Python全局解释锁，在nogil修饰的部分，不能访问Python对象
# 在多线程部分，都应有nogil修饰器
@cython.exceptval(check=False)
# cython.exceptval(check=False) 表示禁用异常传播，将忽略函数内部引发的Python异常
def Work(self, vi: size_t) -> size_t:
degree = cython.declare(size_t, self.graph.OutDegree(vi))
out_edges = cython.declare(AdjList[Empty], self.graph.OutEdges(vi))
i = cython.declare(size_t, 0)
local_num_activations = cython.declare(size_t, 0)
dst: size_t
for i in range(degree):
dst = out_edges[i].neighbour
if self.parent[dst] == cython.cast(size_t, -1):
# parent[dst] == -1 表示dst没有被bfs访问过
if s' metadata={'Header 1': 'Python Olap API', 'Header 2': '6. 算法插件示例'}","page_content='RPC API

5.存储过程

5.1.加载存储过程

加载存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称
- read_only: 必要参数，是否只读
- code: 必要参数，存储过程文件读入生成的ByteString
- desc: 可选参数，存储过程描述
- code_type: 可选参数，存储过程代码类型，PY、SO、CPP、ZIP四者之一  
以C++为例，用户加载存储过程的方式如下所示：
```C++
std::string content;
if (!FieldSpecSerializer::FileReader(source_file, content)) {
std::swap(content, result);
return false;
}
LGraphRequest req;
req.set_is_write_op(true);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
pluginRequest->set_version(version);
lgraph::LoadPluginRequest* loadPluginRequest = pluginRequest->mutable_load_plugin_request();
loadPluginRequest->set_code_type([](const std::string& type) {
std::unordered_map<std::string, lgraph::LoadPluginRequest_CodeType> um{
{""SO"", lgraph::LoadPluginRequest::SO},
{""PY"", lgraph::LoadPluginRequest::PY},
{""ZIP"", lgraph::LoadPluginRequest::ZIP},
{""CPP"", lgraph::LoadPluginRequest::CPP}};
return um[type];
}(code_type));
loadPluginRequest->set_name(procedure_name);
loadPluginRequest->set_desc(procedure_description);
loadPluginRequest->set_read_only(read_only);
loadPluginRequest->set_code(content);
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
加载存储过程的响应不包含参数，如果加载失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.1.加载存储过程'}","page_content='Python Olap API

4. Olap API

见procedures/algo_cython/olap_base.pxd文件，用法与功能基本与C++接口相同，olap_base.pxd中声明的接口都由C++实现，在py文件中必须通过`from cython.cimports.olap_base import *`的方式导入，由Cython编译py文件后才能运行。' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API'}"
TuGraph 数据预热命令需要指定哪两个选项？,"page_content='数据预热

1.数据预热命令

数据预热可以通过工具 `lgraph_warmup` 来进行。它的使用示例如下：  
```bash
$ lgraph_warmup -d {directory} -g {graph_list}
```  
其中：  
- `-d {db_dir}` 选项指定了 TuGraph 服务器的数据目录  
- `-g {graph_list}` 选项指定需要进行数据预热的图名称，用逗号分隔  
根据数据大小和所使用的磁盘类型不同，预热过程运行时间也不同。机械磁盘上预热一个大数据库可能耗时较长，请耐心等待。' metadata={'Header 1': '数据预热', 'Header 2': '1.数据预热命令'}","page_content='数据库运行

4.服务配置

TuGraph 服务器在启动时从配置文件和命令行选项加载配置，如果在配置文件和命令行中同一选项指定了不同的值，将优先使用命令行中指定的值。' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置'}","page_content='功能概览

4.核心功能

4.5 数据预热

TuGraph 是基于磁盘的图数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.5 数据预热'}"
是否支持GQL语句？,"page_content='ISO GQL

1.GQL简介

Graph Query Language(GQL, 图查询语言)是一种国际标准语言，用于属性图查询，该语言建立在SQL的基础上，并整合了现有的[openCypher、PGQL、GSQL和G-CORE](https://gql.today/comparing-cypher-pgql-and-g-core/)语言的成熟思想。目前该标准仍然处于草稿阶段。  
TuGraph基于[ISO GQL (ISO/IEC 39075) Antlr4 语法文件](https://github.com/TuGraph-family/gql-grammar)实现了GQL，并做了一些扩展与改造。目前并未完全支持所有的GQL语法，我们会在未来逐步完善。' metadata={'Header 1': 'ISO GQL', 'Header 2': '1.GQL简介'}","page_content='Java客户端

2.使用示例

2.4.调用GQL

```java
String res = client.callGql(""CALL db.edgeLabels()"", ""default"", 10);
log.info(""db.edgeLabels() : "" + res);
```
```
@param gql: inquire statement.
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@param url: (Optional) Node address of calling GQL
@return: the result of GQL query execution
public String callGql(String gql, String graph, double timeout, String url)
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。
注：JAVA不支持默认参数，因此，JAVA中的默认参数是使用重载函数实现的。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.4.调用GQL'}","page_content='C++客户端

2.使用示例

2.4.调用GQL

```C++
std::string str;
bool ret = client.CallGql(str,
""CALL db.createVertexLabel('actor', 'name', 'name', string, false, 'age', int8, true)"");
```
```
bool CallGql(std::string& result, const std::string& gql,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0, const std::string& url = """");
@param [out] result      The result.
@param [in]  gql         inquire statement.
@param [in]  graph       (Optional) the graph to query.
@param [in]  json_format (Optional) Returns the format， true is json，Otherwise, binary
format.
@param [in]  timeout     (Optional) Maximum execution time, overruns will be interrupted.
@param [in]  url         (Optional) Node address of calling gql.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.4.调用GQL'}"
在配置中提到的“log4j-core”和“guava”的版本号分别是多少？,"page_content='TuGraph Java Client

用例

OGM 用例

```java
package test;

import com.alibaba.fastjson.JSONObject;
import com.antgroup.tugraph.TuGraphDbRpcException;
import com.antgroup.tugraph.ogm.driver.Driver;
import entity.Actor;
import entity.Movie;
import com.antgroup.tugraph.ogm.cypher.ComparisonOperator;
import com.antgroup.tugraph.ogm.model.QueryStatistics;
import com.antgroup.tugraph.ogm.model.Result;
import com.antgroup.tugraph.ogm.session.Session;
import com.antgroup.tugraph.ogm.session.SessionFactory;
import com.antgroup.tugraph.ogm.cypher.Filter;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.util.*;

import static java.util.Collections.emptyMap;
import static org.assertj.core.api.Assertions.*;


public class TestBase extends Client {
private static final Logger log = LoggerFactory.getLogger(TestBase.class);
private static SessionFactory sessionFactory;
private static Session session;

private static String host;

public static void main(String[] args) throws Exception {
if (args.length != 3 && args.length != 0) {
log.info(""java -jar target/tugraph-ogm-test-x.x.x.jar [host:port] [user] [password]"");
log.info(""java -jar target/tugraph-ogm-test-x.x.x.jar"");
return;
}
if (args.length == 0) {
haClientTest();
} else {
sessionFactory = new SessionFactory(getDriver(args), ""entity"");
session = sessionFactory.openSession();
testCreate();
testQuery();
testUpdate();
testDelete();
}
}

//--------------------------------    test base    ------------------------------------------------
private static void testDelete() {
log.info(""----------------testDelete--------------------"");
// Test1  CREATE -> DELETE
Actor a1 = new Actor();
Actor a2 = new Actor();
a1.setName(""ado"");
a2.setName(""abo"");
session.save(a1);
session.save(a2);
Collection<Actor> savedActors = session.loadAll(Actor.class);
assertThat(savedActors).hasSize(4);

List<Object> actorList = new ArrayList<>();
actorList.add(a1);
actorL' metadata={'Header 1': 'TuGraph Java Client', 'Header 2': '用例', 'Header 3': 'OGM 用例'}","page_content='Bolt客户端

使用示例

添加Maven依赖  
```xml
<dependency>
<groupId>org.neo4j.driver</groupId>
<artifactId>neo4j-java-driver</artifactId>
<version>4.4.2</version>
</dependency>
```
Client按照如下格式进行实例化:  
```java
Driver driver = GraphDatabase.driver(""bolt://ip:port"", AuthTokens.basic(""admin"", ""73@TuGraph""));
```  
常用语句  
```java
//通过 driver 对象创建一个 Session，设置会话连接到特定的数据库，用于执行Cypher语句
Session session = driver.session(SessionConfig.forDatabase(""default""));
//清空图项目，请不要轻易尝试，它会清空你选中的图项目的模型以及数据
session.run(""CALL db.dropDB()"");
//创建点模型
session.run(""CALL db.createVertexLabel('person', 'id' , 'id' ,INT32, false, 'name' ,STRING, false)"");
//创建边模型
session.run(""CALL db.createEdgeLabel('is_friend','[[\""person\"",\""person\""]]')"");
//创建索引
session.run(""CALL db.addIndex(\""person\"", \""name\"", false)"");
//插入点数据
session.run(""create (n1:person {name:'jack',id:1}), (n2:person {name:'lucy',id:2})"");
//插入边数据
session.run(""match (n1:person {id:1}), (n2:person {id:2}) create (n1)-[r:is_friend]->(n2)"");
//查询点和边
Result res = session.run(""match (n)-[r]->(m) return n,r,m"");
//Parameterized Query
String cypherQuery = ""MATCH (n1:person {id:$id})-[r]-(n2:person {name:$name}) RETURN n1, r, n2"";
Result result1 = session.run(cypherQuery, parameters(""id"", 1, ""name"", ""lucy""));
while (result1.hasNext()) {
Record record = result1.next();
System.out.println(""n1: "" + record.get(""n1"").asMap());
System.out.println(""r: "" + record.get(""r"").asMap());
System.out.println(""n2: "" + record.get(""n2"").asMap());
}
//删除点数据
session.run(""match (n1:person {id:1}) delete n1"");
//删除边数据
session.run(""match (n1:person {id:1})-[r]-(n2:person{id:2}) delete r"");
//删除边模型
session.run(""CALL db.deleteLabel('edge', 'is_friend')"");
//删除点模型
session.run(""CALL db.deleteLabel('vertex', 'person')"");
```  
详细Cypher和存储过程的使用可见[Cypher](../../8.query/1.cypher.md)' metadata={'Header 1': 'Bolt客户端', 'Header 2': '使用示例'}","page_content='TuGraph Java Client

版本选择

| Client Version | TuGraph Version |
|----------------|-----------------|
| 1.1.1          | 3.3.3           |
| 1.2.1, 1.2.2   | 3.4.x, 3.5.0    |
| 1.3.0          | 3.6.0           |
| 1.4.0, 1.4.1   | 4.0.0, 4.0.1    |  
**注意**:  
- 3.3.0~3.3.2 版本的 TuGraph Server 是在 java-client 重构前的遗留版本，本仓库不支持这些版本。
- 1.1.0 和 1.2.0 因 pom 文件中的 ${revision} 变量引入的无法使用的问题而不可用[1]。' metadata={'Header 1': 'TuGraph Java Client', 'Header 2': '版本选择'}"
类liblgraph_python_api.Galaxy的方法SetUserGraphAccess主要用于什么？,"page_content='Python Olap API

5. lgraph_db API

Galaxy

- `Galaxy(dir_path: std::string)`: 构造函数，dir_path为db路径
- `SetCurrentUser(user: std::string, password: std::string)-> cython.void`: 设置用户
- `SetUser(user: std::string)-> cython.void`: 设置用户
- `OpenGraph(graph: std::string, read_only: bint)-> GraphDB`: 创建GraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Galaxy'}","page_content='Python Olap API

5. lgraph_db API

PyGalaxy:

- `PyGalaxy(self, dir_path: str)`: 构造函数，dir_path为db路径
- `SetCurrentUser(self, user: str password: str)-> void`: 设置用户
- `SetUser(self, user: std::string)-> void`: 设置用户
- `OpenGraph(self, graph: str, read_only: bool)-> PyGraphDB`: 创建PyGraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'PyGalaxy:'}","page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.1.数据加载

```python
galaxy = PyGalaxy(args.db_path)
galaxy.SetCurrentUser(args.username, args.password)
db = galaxy.OpenGraph(args.graph_name, False)
```
如代码所示，根据图数据路径、用户名、密码和子图名称将数据加载到内存中。TuGraph可以载入多个子图用于图训练，在此处我们只载入一个子图。' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.1.数据加载'}"
TuGraph-DB如何在运行单元测试的过程中输出日志？,"page_content='数据库运行

2.运行模式

2.1.运行普通进程

`lgraph_server -d run`命令可以将 TuGraph 作为普通进程运行。普通进程依赖命令行终端，因此终端结束时，TuGraph 进程也会自动终止。普通进程模式配合`--log_dir """"`可以将进程日志直接输出到终端，因此更方便调试。注：当不使用`-d run`命令时，将默认运行普通进程。  
lgraph_server的默认路径为：/usr/local/bin/lgraph_server 。  
lgraph.json的默认路径为：/usr/local/etc/lgraph.json 。  
启动命令：  
```shell
$ ./lgraph_server -d run -c lgraph.json --log_dir """"
```
或者：
```shell
$ ./lgraph_server -c lgraph.json --log_dir """"
```  
普通模式的运行输出示例：  
```shell
**********************************************************************
*                  TuGraph Graph Database v4.3.2                     *
*                                                                    *
*    Copyright(C) 2018-2023 Ant Group. All rights reserved.          *
*                                                                    *
**********************************************************************
Server is configured with the following parameters:
Backup log enable:                   0
DB directory:                        /var/lib/lgraph/data
HA enable:                           0
HTTP port:                           7070
HTTP web dir:                        /usr/local/share/lgraph/browser-resource
RPC enable:                          1
RPC port:                            9090
SSL enable:                          0
Whether the token is unlimited:      0
audit log enable:                    0
bind host:                           0.0.0.0
bolt port:                           7687
disable auth:                        0
durable:                             0
log dir:                             """"
log verbose:                         1
number of bolt io threads:           1
optimistic transaction:              0
reset admin password if you forget:  0
subprocess idle limit:               600
thread limit:                        0
[20240730 15:34:27.848783 0x00007f81bb3889c0 INFO  src/server/lgraph_server.h:78] [StateMachine] Builtin services are disabled according to ServerOptions.has_builtin_services
[20240730 15:34:27.849116 0x00007f81bb3889c0 INFO ' metadata={'Header 1': '数据库运行', 'Header 2': '2.运行模式', 'Header 3': '2.1.运行普通进程'}","page_content='日志信息

2.服务器日志

2.3.存储过程日志

用户在存储过程的编写过程中可以使用日志功能将所需的调试信息输出到日志中进行查看，辅助开发。调试信息会输出到与服务器日志相同的日志文件中(如未指定`log_dir`则同样输出至console)  
#### 2.3.1.cpp存储过程
请使用2.2中提供的log宏输出调试信息，避免使用cout或者printf等输出方式。具体使用方式可参考如下示例代码（详见`procedures/demo/log_demo.cpp`）  
```
#include <stdlib.h>
#include ""lgraph/lgraph.h""
#include ""tools/lgraph_log.h""  // add log dependency
using namespace lgraph_api;

void LogExample() {
LOG_DEBUG() << ""This is a debug level log message."";
LOG_INFO() << ""This is a info level log message."";
LOG_WARN() << ""This is a warning level log message."";
LOG_ERROR() << ""This is a error level log message."";
}

extern ""C"" bool Process(GraphDB& db, const std::string& request, std::string& response) {
response = ""TuGraph log demo"";
LogExample();
return true;
}
```
将以上示例代码作为存储过程插入数据库并运行后，可以在日志文件中看到相应的日志条目。  
#### 2.3.1.python存储过程
请使用python自带的print输出调试信息，调试信息会在存储过程运行结束后合并为一条WARN等级的日志条目输出至日志文件中。' metadata={'Header 1': '日志信息', 'Header 2': '2.服务器日志', 'Header 3': '2.3.存储过程日志'}","page_content='日志信息

3.审计日志

审核日志记录每个请求和响应，以及发送请求的用户以及收到请求的时间。审核日志只能是打开或关闭状态。可以使用 TuGraph 可视化工具和 REST API 查询结果。  
开启审计日志需要在配置文件中将`enable_audit_log`参数设置为`true`。配置文件和配置参数说明详见：[数据库运行/服务配置](../../5.installation&running/7.tugraph-running.md)。' metadata={'Header 1': '日志信息', 'Header 2': '3.审计日志'}"
"GeaBase 查询中使用 ""Nav"" 语句的一种情况是什么?","page_content='State原理介绍

Geaflow 中的状态管理

Geaflow 中的状态是指图、流计算过程中的直接计算节点的中间计算结果，此中间结果可能是经过组织后的源数据信息，也有可能是计算产生的一些结果。状态管理负责这些数据的存取以及一致性保障，它作为Geaflow数据中枢存在于系统中，它的功能模型、性能和可靠性直接影响着Geaflow的整个使用过程，是作为整个系统的底盘存在。  
* 从功能来看，它支持Geaflow实时、多模的动态图引擎，包括低延迟流图融合计算、高性能长周期图仿真、大规模动态图探索等等。
* 从计算模型来看，Geaflow 中的状态管理属于实时模型和图模型的结合，需要克服实时计算中，带有状态的处理机制，时延低，容错和恢复机制；另外它也需要解决图模型中数据复杂、关联度高，计算由数据驱动、中间结果大等问题。
* 从性能上看，状态管理需要解决在低成本，多场景、大规模数据的前提下实现高吞吐、低延迟的存储和查询能力。包括在万亿边的规模下的存取，较大的属性信息的存取，带有多种下推语义的随机访问和遍历访问等。  
为此，我们有如下的架构图，整体结构上灵活可变、支持多种可插拔组件。' metadata={'Header 1': 'State原理介绍', 'Header 2': 'Geaflow 中的状态管理'}","page_content='地理空间数据类型使用示例

5. 美食探索

5.3 构建美食探索查询

能够根据用户的当前位置，寻找距离2.5以内的美食,根据距离进行升序排列。返回距离和评分让用户得倒更好的体验。  
**查询语句**  
```
match (n:person{id:1}),(m:food) with n.pointTest as p1,m.pointTest as p2,m.name as food,m.mark as mark
CALL spatial.distance(p1,p2) YIELD distance
WHERE distance<2.5
RETURN food,distance,mark ORDER by distance
```  
![image.png](../../../images/spatail/querryFood.png)  
此查询首先匹配特定的Person节点（以用户名“Tom”为例），然后找到所有Food节点，利用自定义的distance函数，计算Person节点当前位置与每个Food节点之间的直线距离，筛选出距离在2.5之内的美食。最后，按照美食的距离升序排列结果，附带评分参考，为用户提供最优质的推荐。' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '5. 美食探索', 'Header 3': '5.3 构建美食探索查询'}","page_content='Console平台介绍

部署架构

GeaFlow支持多种异构环境执行，以常见的K8S部署环境为例，GeaFlow物理部署架构如下：  
![deploy_arch](../../static/img/deploy_arch.png)  
在GeaFlow作业的全生命周期过程中，涉及的关键数据流程有：  
* **研发阶段**：Console平台提供了实例下所有的研发资源的管理，用户可以在创建任务前，提前准备所需的研发资源信息，并存储在Catalog。
* **构建阶段**：任务创建完成后，通过发布动作触发构建流水线，用户的JAR包、任务的ZIP包等会上传到RemoteFileStore。
* **提交阶段**：作业提交时，Console会根据作业的参数配置、运行时环境信息，以及远程文件地址等创建KubernetesJobClient，既而会拉起Client Pod，Client会拉起Master Pod，Master会拉起Container Pods和Driver Pod。所有的Pod拉起后，Client会把作业的Pipeline发送给Driver执行，Driver最终通过Cycle调度的Events与Containers交互。所有的Pod启动时都会从RemoteFileStore下载版本JAR包、用户JAR包、作业ZIP包等信息。Driver对DSL代码编译时，也需要通过Console提供的Catalog API操作Schema信息。
* **运行阶段**：作业运行时，各个组件会上报不同的数据和信息。Master会上报作业的心跳汇总信息，Driver会上报作业的Pipeline/Cycle指标以及错误信息，Container会上报作业的Offset、指标定义以及错误信息等。RuntimeMetaStore存储作业的Pipeline/Cycle指标、Offset、心跳汇总、错误等信息。HAMetaStore存储各个运行组件的地址信息。DataStore存储State数据和作业FailOver时所需的元数据信息。MetricStore存储运行时指标信息。
* **监控阶段**：Console会主要查询RuntimeMetaStore和MetricStore存储的信息用于作业的运行时监控。
* **清理阶段**：作业重置/删除时，Console会对作业的RuntimeMeta、HAMeta以及部分Data做清理操作。' metadata={'Header 1': 'Console平台介绍', 'Header 2': '部署架构'}"
我要快速定位到2个顶点间的某条关系边，通过pair unique索引查找关系边的接口有么，需求是根据pair_unique的值更新对应的边数据么,"page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='Learn Tutorial

1.TuGraph 图学习模块简介

图学习是一种机器学习方法，其核心思想是利用图结构中的拓扑信息，通过顶点之间的联系及规律来进行数据分析和建模。不同于传统机器学习方法，图学习利用的数据形式为图结构，其中顶点表示数据中的实体，而边则表示实体之间的关系。通过对这些顶点和边进行特征提取和模式挖掘，可以揭示出数据中深层次的关联和规律，从而用于各种实际应用中。  
这个模块是一个基于图数据库的图学习模块，主要提供了四种采样算子：Neighbor Sampling、Edge Sampling、Random Walk Sampling 和 Negative Sampling。这些算子可以用于对图中的顶点和边进行采样，从而生成训练数据。采样过程是在并行计算环境下完成的，具有高效性和可扩展性。  
在采样后，我们可以使用得到的训练数据来训练一个模型。该模型可以用于各种图学习任务，比如预测、分类等。通过训练，模型可以学习到图中的顶点和边之间的关系，从而能够对新的顶点和边进行预测和分类。在实际应用中，这个模块可以被用来处理各种大规模的图数据，比如社交网络、推荐系统、生物信息学等。' metadata={'Header 1': 'Learn Tutorial', 'Header 2': '1.TuGraph 图学习模块简介'}"
TuGraph Explorer 的功能现在在哪里可以找到？,"page_content='功能概览

6.生态工具

6.2.可视化交互

TuGraph Browser 是面向图数据库直接使用者的可视化交互界面，功能上覆盖了 TuGraph 的绝大部分能力，包括数据导入、图模型建立、数据增删查改、监控运维等操作链路。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.2.可视化交互'}","page_content='功能概览

6.生态工具

6.1.TuGraph DataX

![导入导出](../../../images/tugraph-datax.png)  
TuGraph 核心支持 CSV 和 JSON 合适的导入导出，提供空库导入和增量导入的模式。实际中会存在 MySQL、Kafka、Hive 等多数据源导入的需求，TuGraph 通过 DataX 做多数据源的对接。由于关系模型和图模型存在的差异，数据清洗的流程可以使用 SparkSQL 快速处理，TuGraph 本身仅关注 CSV 和 JSON 的简单场景导入可靠性和性能。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.1.TuGraph DataX'}","page_content='可视化操作手册（旧版）

作用

TuGraph Browser 的主要功能是为使用图数据库的开发人员，提供可视化的图数据开发，图数据管理和维护等功能。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '作用'}"
SybilRank算法的执行过程中主要采用什么方式来进行计算？,"page_content='内置算法

扩展算法包

Sybil检测算法

Sybil检测算法实现了Sybil Rank算法。SybilRank算法从非Sybil节点开始进行提前终止的随机游走。算法内容请参考论文：“Aiding the Detection of Fake Accounts in Large Scale Social Online Services”。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': 'Sybil检测算法'}","page_content='内置算法

基础算法包

网页排序

网页排序程序实现了常用的Pagerank算法。该算法根据图中边和边权值计算所有点的重要性排名，PageRank值越高，表示该点在图中的重要性越高。计算时以点数量的倒数为各点初始Rank值，然后将点的Rank值按照出边平均传递到相邻点，重复该传递过程直到满足给定的收敛阈值或达到给定迭代轮数。每轮传递结束后，所有点的Rank值会有一定的的比例随机传递到任意点上。算法内容请参考 [https://en.wikipedia.org/wiki/PageRank](https://en.wikipedia.org/wiki/PageRank ""pagerank wiki"")。' metadata={'Header 1': '内置算法', 'Header 2': '基础算法包', 'Header 3': '网页排序'}","page_content='内置算法

简介

扩展算法包：

| 中文算法名 | 英文算法名 | 程序名
| :----: | :----: | :----: |
| 全对最短路径 | All-Pair Shortest Path  | apsp
| 介数中心度 | Betweenness Centrality | bc
| 置信度传播 | Belief Propagation | bp
| 距离中心度 | Closeness Centrality | clce
| 共同邻居 | Common Neighborhood | cn
| 度数关联度 | Degree Correlation  | dc
| 直径估计 | Dimension Estimation | de
| EgoNet算法 | EgoNet | en
| 超链接主题搜索 | Hyperlink-Induced Topic Search | hits
| 杰卡德系数 | Jaccard Index | ji
| K核算法 | K-core | kcore
| 鲁汶社区发现 | Louvain | louvain
| 多源最短路径 | Multiple-source Shortest Paths | mssp
| 个性化网页排序 | Personalized PageRank | ppr
| 强连通分量 | Strongly Connected Components | scc
| 监听标签传播 | Speaker-listener Label Propagation Algorithm | slpa
| 两点间最短路径 | Single-Pair Shortest Path | spsp
| 三角计数 | Triangle Counting | triangle
| 信任指数排名 | Trustrank | trustrank
| 带权重的标签传播 | Weighted Label Propagation Algorithm | wlpa
| 带权重的网页排序 | Weighted Pagerank Algorithm | wpagerank
| 最大独立集算法 | Maximal independent set | mis
| sybil检测算法 | Sybil Rank | sybilrank
| 子图匹配算法 | Subgraph Isomorphism | subgraph_isomorphism
| 模式匹配算法 | Motif | motif
| k阶团计数算法 | Kcliques | kcliques
| k阶桁架计数算法 | Ktruss | ktruss
| 莱顿算法 | Leiden | leiden' metadata={'Header 1': '内置算法', 'Header 2': '简介', 'Header 3': '扩展算法包：'}"
节点和边的属性在知识图谱中有什么作用？,"page_content='Heterogeneous Graph

1. 异质图简介

异质图（Heterogeneous Graph）是指由不同类型的节点和边构成的图结构。在异质图中，节点和边可以具有多样化的属性和关系，代表了不同实体以及它们之间的复杂关联。  
在异质图中，节点类型可以代表不同的实体，如用户、商品、话题等，而边类型表示不同实体之间的关系，如用户之间的关注关系、用户与商品之间的购买关系等。节点和边可以具有不同的属性。  
异质图提供了一种强大的图模型，能够更好地表达和分析具有多种类型实体和复杂关系的现实世界系统。在不同领域的数据分析和应用中，异质图具有广泛的应用前景和研究价值。' metadata={'Header 1': 'Heterogeneous Graph', 'Header 2': '1. 异质图简介'}","page_content='Heterogeneous Graph

5. 异质图训练

异构图训练的目标是学习图中节点和边的表示，以便于进行后续的任务，如节点分类、链接预测、图聚类等。为了实现这一目标，研究者们提出了多种基于图神经网络（Graph Neural Networks，GNNs）的模型。这些模型通过聚合邻居节点的信息来更新节点的表示，进而捕捉图结构中的复杂关系。  
由于异构图中包含多种类型的节点和边，因此在设计GNN模型时需要考虑如何处理这些不同类型的信息。一种常见的方法是设计不同的聚合函数来分别处理不同类型的邻居节点。此外，还需要考虑如何将这些不同类型的信息整合到一起，以便于模型能够有效地学习到节点和边的表示。  
TuGraph 提供了使用裁剪版ogbn-mag数据集进行异质图训练的方法，可供使用者参考。  
TuGraph提供的官方docker中暂未提供异质图训练的环境，因此需要用户自行安装相关依赖包。
在训练之前需要下载ogb和pandas包，具体安装方式如下：
```shell
pip3 install ogb
pip3 install pandas==0.24.2
```  
训练代码如下所示：  
```python
def train(graph, model, model_save_path):
optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)
model.train()
s = time.time()
load_time = time.time()
graph = dgl.add_self_loop(graph)
logits = model(graph, graph.ndata['feat'])
loss = loss_fcn(logits, graph.ndata['label'])
optimizer.zero_grad()
loss.backward()
optimizer.step()
train_time = time.time()
current_loss = float(loss)
if model_save_path != """":
if 'min_loss' not in train.__dict__:
train.min_loss = current_loss
elif current_loss < train.min_loss:
train.min_loss = current_loss
model_save_path = 'best_model.pth'
torch.save(model.state_dict(), model_save_path)
return current_loss
```
全部训练代码可参考tugraph/learn/examples/train_full_mag.py文件。' metadata={'Header 1': 'Heterogeneous Graph', 'Header 2': '5. 异质图训练'}","page_content='Heterogeneous Graph

4. 异质图输出格式

和同质图相同的是，异质图的采样数据结果也存储在NodeInfo和EdgeInfo中。
可通过如下方式获取输出数据。
```python
NodeInfo = []
EdgeInfo = []
getdb.Process(db, olapondb, feature_len, NodeInfo, EdgeInfo)
```
其中getdb为获取全图数据的函数，db为图数据库实例，olapondb为图分析类。feature_len为节点特征长度，NodeInfo和EdgeInfo为输出的节点和边信息。  
其存储信息结果如下：
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 边类型 | EdgeInfo[2] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |
| 顶点类型 | NodeInfo[3] |' metadata={'Header 1': 'Heterogeneous Graph', 'Header 2': '4. 异质图输出格式'}"
在TuGraph项目中，为什么在提交代码前要先提交一个issue？,"page_content='如何贡献

4. 贡献代码流程

4.1. 提交issue

不论您是修复 TuGraph 的 bug 还是新增 TuGraph 的功能，在您提交代码之前，请在 TuGraph 的 GitHub 上提交一个 issue，描述您要修复的问题或者要增加的功能。这么做有几个好处:  
- 不会与其它开发者或是他们对这个项目的计划发生冲突，产生重复工作。
- TuGraph 的维护人员会对您提的 bug 或者新增功能进行相关讨论，确定该修改是不是必要，有没有提升的空间或更好的办法。
- 在达成一致后再开发，并提交代码，减少双方沟通成本，也减少 pull request 被拒绝的情况。' metadata={'Header 1': '如何贡献', 'Header 2': '4. 贡献代码流程', 'Header 3': '4.1. 提交issue'}","page_content='如何贡献

4. 贡献代码流程

4.2. 获取源码

要修改或新增功能，在提交 issue 后，fork一份 TuGraph  Master代码到您的代码仓库。' metadata={'Header 1': '如何贡献', 'Header 2': '4. 贡献代码流程', 'Header 3': '4.2. 获取源码'}","page_content='如何贡献

3. 准备工作

3.3. 许可协议

在贡献代码之前，请您稍微花一些时间了解为TuGraph贡献代码的流程，并阅读 [个人贡献者许可协议](3.individual-cla.md) 或 [公司贡献者许可协议](4.corporate-cla.md)，参与贡献则视为同意上述协议。' metadata={'Header 1': '如何贡献', 'Header 2': '3. 准备工作', 'Header 3': '3.3. 许可协议'}"
请问社区版本和企业版本，之间的差距在哪,"page_content='什么是TuGraph

4. TuGraph企业版

企业版对商业化功能支持更加完善，包括分布式集群架构，覆盖探索、研发、服务、运维管理全生命周期的一站式图平台，在线、近线、离线的图计算引擎，支持流式、大数据类数据源，多地多中心的部署形态，以及专家支持服务等。企业版是商业化解决方案的理想选择。  
如需商业支持，请联系我们：  
- 电话：400-903-0809
- 邮件：tugraph@service.alipay.com
- 官网：https://tugraph.antgroup.com' metadata={'Header 1': '什么是TuGraph', 'Header 2': '4. TuGraph企业版'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。  
<table><tbody><tr><td>算法类型</td><td>中文算法名</td><td>英文算法名</td><td>程序名</td></tr><tr><td rowspan=""5"">路径查询</td><td>广度优先搜索</td><td>Breadth-First Search</td><td>bfs</td></tr><tr><td>单源最短路径</td><td>Single-Source Shortest Path</td><td>sssp</td></tr><tr><td>全对最短路径</td><td>All-Pair Shortest Path</td><td>apsp</td></tr><tr><td>多源最短路径</td><td>Multiple-source Shortest Paths</td><td>mssp</td></tr><tr><td>两点间最短路径</td><td>Single-Pair Shortest Path</td><td>spsp</td></tr><tr><td rowspan=""9"">重要性分析</td><td>网页排序</td><td>Pagerank</td><td>pagerank</td></tr><tr><td>介数中心度</td><td>Betweenness Centrality</td><td>bc</td></tr><tr><td>置信度传播</td><td>Belief Propagation</td><td>bp</td></tr><tr><td>距离中心度</td><td>Closeness Centrality</td><td>clce</td></tr><tr><td>个性化网页排序</td><td>Personalized PageRank</td><td>ppr</td></tr><tr><td>带权重的网页排序</td><td>Weighted Pagerank Algorithm</td><td>wpagerank</td></tr><tr><td>信任指数排名</td><td>Trustrank</td><td>trustrank</td></tr><tr><td>sybil检测算法</td><td>Sybil Rank</td><td>sybilrank</td></tr><tr><td>超链接主题搜索</td><td>Hyperlink-Induced Topic Search</td><td>hits</td></tr><tr><td rowspan=""4"">关联性分析</td><td>平均集聚系数</td><td>Local Clustering Coefficient</td><td>lcc</td></tr><tr><td>共同邻居</td><td>Common Neighborhood</td><td>cn</td></tr><tr><td>度数关联度</td><td>Degree Correlation</td><td>dc</td></tr><tr><td>杰卡德系数</td><td>Jaccard Index</td><td>ji</td></tr><tr><td rowspan=""5"">图结构</td><td>直径估计</td><td>Dimension Estimation</td><td>de</td></tr><tr>' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}","page_content='云部署

2.实例说明

TuGraph部署的为社区开源版本，源码参考Github Repo，目前可以选择的实例规格如下：  
| 规格族         | vCPU与内存                 | 系统盘              | 公网带宽      |
|----------------|-------------------------|-------------------|-----------|
| ecs.r7a.xlarge | AMD 内存型 r7a，4vCPU 32GiB | ESSD云盘 200GiB PL0 | 固定带宽1Mbps |
| ecs.r6.xlarge  | 内存型r6，4vCPU 32GiB       | ESSD云盘 200GiB PL0 | 固定带宽1Mbps |  
预估费用在创建实例时可实时看到（目前为免费）。 如需更多规格、其他服务（如集群高可用性要求、企业级支持服务等），请联系我们 tugraph@service.alipay.com。' metadata={'Header 1': '云部署', 'Header 2': '2.实例说明'}"
bfs_standalone程序的输出结果是什么？,"page_content='OLAP API

4. Standalone 编译与运行

C++:

在tugraph-db/build编译standalone算法程序  
```bash
make bfs_standalone
```  
在tugraph-db/build/output目录下运行text源文件  
```bash
./output/algo/bfs_standalone --type text --input_dir ../test/integration/data/algo/fb_unweighted --root 0
```  
得到运行结果：  
```text
prepare_cost = 0.10(s)
core_cost = 0.02(s)
found_vertices = 3829
output_cost = 0.00(s)
total_cost = 0.11(s)
DONE.
```  
结果参数解释同上。  
对于新的算法，运行时不了解该算法的所需参数时，可通过`./output/algo/bfs_standalone -h`进行查阅对应参数。' metadata={'Header 1': 'OLAP API', 'Header 2': '4. Standalone 编译与运行', 'Header 3': 'C++:'}","page_content='OLAP API

4. Standalone 编译与运行

该文件主要用于在终端处直接加载图数据，并运行打印输出结果。使用方法如下：
在tugraph-db/build目录下执行`make bfs_standalone` (需要在g++默认include路径中包含boost/sort/sort.hpp)即可得到bfs_standalone文件,该文件生成于tugraph-db/build/output/algo文件夹下。
运行方式：在tugraph-db/build目录下执行`./output/algo/bfs_standalone -–type [type] –-input_dir [input_dir] --id_mapping [id_mapping] -–vertices [vertices] --root [root] –-output_dir [output_dir]`即可运行。  
- `[type]`：表示输入图文件的类型来源，包含text文本文件、BINARY_FILE二进制文件和ODPS源。
- `[input_dir]`：表示输入图文件的文件夹路径，文件夹下可包含一个或多个输入文件。TuGraph在读取输入文件时会读取[input_dir]下的所有文件，要求[input_dir]下只能包含输入文件，不能包含其它文件。参数不可省略。
- `[id_mapping]`：当读入边表时，是否对输入数据做id映射，使达到符合算法运行的形式。1为需要做id映射，0为不需要做。该过程会消耗一定时间。参数可省略，默认值为0。
- `[vertices]`：表示图的点个数，为0时表示用户希望系统自动识别点数量；为非零值时表示用户希望自定义点个数，要求用户自定义点个数需大于最大的点ID。参数可省略，默认值为0。
- `[root]`：表示进行bfs的起始点id。参数不可省略。
- `[output_dir]`：表示输出数据保存的文件夹路径，将输出内容保存至该文件中，参数不可省略。  
示例：' metadata={'Header 1': 'OLAP API', 'Header 2': '4. Standalone 编译与运行'}","page_content='OlapOnDisk API

1. 简介

TuGraph的Standalone模式可用于加载图数据文件，其中图数据文件来源可包含text文本文件、BINARY_FILE二进制文件和ODPS源。在该模式下，TuGraph可实现多数据来源快速加载成图，然后在该图上运行如BFS、WCC、SSSP等迭代式算法，并输出最终结果至终端。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph内置了大量的常见图分析算法和丰富的辅助接口，因此用户几乎不需要自己实现具体的图计算过程，只需要在实现自己的存储过程的时候将相应算法库的头文件(.h)包含到自己的程序中，并在编译阶段链接自己的动态库文件即可。  
该文档主要介绍了Standalone的常用接口，使用到的辅助函数主要包含在OlapOnDB类。同时为帮助用户理解方便，对BFS算法进行举例说明。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '1. 简介'}"
Key_start和key_end相等于v时，VertexIndexIterator是如何工作的？,"page_content='Python Olap API

5. lgraph_db API

Transaction：

```
GetVertexIndexIterator(
label: std::string,
field: std::string,
key_start: std::string,
key_end: std::string)-> VertexIndexIterator
```
获取索引迭代器。迭代器的field值为 [key_start, key_end]。所以在key_start=key_end=v时，返回指向field值为v的点的迭代器  
lgraph_db_python.py是lgraph_db.pxd中C++类 Galaxy与GraphDB的包装，将C++类包装为Python类，将lgraph_db_python.py编译为Python拓展后，可以直接在Python文件或Python命令行中`import lgraph_db_python`访问lgraph_db_python.PyGraphDB与PyGraphDB.PyGalaxy。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Transaction：'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends GraphSnapShot<K, VV, EV> {
/** 获取开始图遍历的点 */
Travers' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void init(IncGraphComputeContext<K, VV, EV, M> incGraphContext) | 图计算初始化接口 | incGraphContext： 增量动态图计算的上下文，K表示vertex id的类型，VV表示vertex value类型，EV表示edge value类型，M表示发送消息的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮迭代对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 迭代计算接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 迭代计算完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型 |  
- 详细接口  
```java
public interface IncVertexCentricFunction<K, VV, EV, M> extends Function {

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncGraphContext<K, VV, EV, M> {
/** 获取job id */
long getJobId();

/** 获取当前迭代 id */
long getIterationId();

/** 获取运行时上下文 */
RuntimeContext getRuntimeContext();

/** 获取可变图 */
MutableGraph<K, VV, EV> getMutableGraph();

/** 获取增量图 */
TemporaryGraph<K, VV, EV> getTemporaryGraph();

/** 获取图存储上的历史图 */
HistoricalGraph<K, VV, EV> getHistoricalGraph();

/** 给指定vertex发送消息 */
void sendMessage(K vertexId, M message);

/** 给当前vertex邻居节点发送消息 */
void sendMessageToNeighbors(M message);

}

interface TemporaryGraph<K, VV, EV> {
/** 从增量图中获取vertex */
IVertex<K, VV> getVertex();

/** 从增量图中获取edges */
List<IEdge<K, EV>> getEdges();

/** 更新vertex value */
void updateVertexValue(VV value);

}

interface HistoricalGraph<K, VV, EV> {
/** 获取图数据最新版本id */
Long getLatestVersionId();

/** 获取图数据所有版本 */
List<Long> getAllVersionIds();

/** 获取图数据所有vertex */
Map<Long, IVertex<K, VV>> getAllVertex();

/** 获取图数据指定版本的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions);

/** 获取图数据指定版本并满足过滤条件的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(L' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
应该如何写入图数据库中的顶点数据？,"page_content='Heterogeneous Graph

4. 异质图输出格式

和同质图相同的是，异质图的采样数据结果也存储在NodeInfo和EdgeInfo中。
可通过如下方式获取输出数据。
```python
NodeInfo = []
EdgeInfo = []
getdb.Process(db, olapondb, feature_len, NodeInfo, EdgeInfo)
```
其中getdb为获取全图数据的函数，db为图数据库实例，olapondb为图分析类。feature_len为节点特征长度，NodeInfo和EdgeInfo为输出的节点和边信息。  
其存储信息结果如下：
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 边类型 | EdgeInfo[2] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |
| 顶点类型 | NodeInfo[3] |' metadata={'Header 1': 'Heterogeneous Graph', 'Header 2': '4. 异质图输出格式'}","page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.2.构建采样器

训练过程中，首先使用GetDB算子从数据库中获取图数据并转换成所需数据结构，具体代码如下：
```python
GetDB.Process(db_: lgraph_db_python.PyGraphDB, olapondb: lgraph_db_python.PyOlapOnDB, feature_num: size_t, NodeInfo: list, EdgeInfo: list)
```
如代码所示，结果存储在NodeInfo和EdgeInfo中。NodeInfo和EdgeInfo是python list结果，其存储的信息结果如下：  
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |  
然后构建采样器
```python
batch_size = 5
count = 2708
sampler = TugraphSample(args)
dataloader = dgl.dataloading.DataLoader(fake_g,
torch.arange(count),
sampler,
batch_size=batch_size,
num_workers=0,
)
```' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.2.构建采样器'}","page_content='Learn Tutorial

1.TuGraph 图学习模块简介

图学习是一种机器学习方法，其核心思想是利用图结构中的拓扑信息，通过顶点之间的联系及规律来进行数据分析和建模。不同于传统机器学习方法，图学习利用的数据形式为图结构，其中顶点表示数据中的实体，而边则表示实体之间的关系。通过对这些顶点和边进行特征提取和模式挖掘，可以揭示出数据中深层次的关联和规律，从而用于各种实际应用中。  
这个模块是一个基于图数据库的图学习模块，主要提供了四种采样算子：Neighbor Sampling、Edge Sampling、Random Walk Sampling 和 Negative Sampling。这些算子可以用于对图中的顶点和边进行采样，从而生成训练数据。采样过程是在并行计算环境下完成的，具有高效性和可扩展性。  
在采样后，我们可以使用得到的训练数据来训练一个模型。该模型可以用于各种图学习任务，比如预测、分类等。通过训练，模型可以学习到图中的顶点和边之间的关系，从而能够对新的顶点和边进行预测和分类。在实际应用中，这个模块可以被用来处理各种大规模的图数据，比如社交网络、推荐系统、生物信息学等。' metadata={'Header 1': 'Learn Tutorial', 'Header 2': '1.TuGraph 图学习模块简介'}"
lgraph_api::Transaction的作用是什么？,"page_content='Python Olap API

5. lgraph_db API

GraphDB：

- `CreateReadTxn()-> Transaction`: 创建只读事务
- `CreateWriteTxn()-> Transaction`: 创建写事务
- `ForkTxn(txn: Transaction)-> Transaction`: 复制事务，只能复制读事务' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'GraphDB：'}","page_content='Python Olap API

5. lgraph_db API

Transaction：

```
GetVertexIndexIterator(
label: std::string,
field: std::string,
key_start: std::string,
key_end: std::string)-> VertexIndexIterator
```
获取索引迭代器。迭代器的field值为 [key_start, key_end]。所以在key_start=key_end=v时，返回指向field值为v的点的迭代器  
lgraph_db_python.py是lgraph_db.pxd中C++类 Galaxy与GraphDB的包装，将C++类包装为Python类，将lgraph_db_python.py编译为Python拓展后，可以直接在Python文件或Python命令行中`import lgraph_db_python`访问lgraph_db_python.PyGraphDB与PyGraphDB.PyGalaxy。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Transaction：'}","page_content='Procedure API

5.Procedure v2接口

5.1.编写存储过程

用户可以通过使用 lgraph API 来编写 C++ 存储过程。一个简单的 C++ 存储过程举例如下：  
```c++
// peek_some_node_salt.cpp
#include <cstdlib>
#include ""lgraph/lgraph.h""
#include ""lgraph/lgraph_types.h""
#include ""lgraph/lgraph_result.h""

#include ""tools/json.hpp""

using json = nlohmann::json;
using namespace lgraph_api;

extern ""C"" LGAPI bool GetSignature(SigSpec &sig_spec) {
sig_spec.input_list = {
{.name = ""limit"", .index = 0, .type = LGraphType::INTEGER},
};
sig_spec.result_list = {
{.name = ""node"", .index = 0, .type = LGraphType::NODE},
{.name = ""salt"", .index = 1, .type = LGraphType::FLOAT}
};
return true;
}

extern ""C"" LGAPI bool ProcessInTxn(Transaction &txn,
const std::string &request,
Result &response) {
int64_t limit;
try {
json input = json::parse(request);
limit = input[""limit""].get<int64_t>();
} catch (std::exception &e) {
response.ResetHeader({
{""errMsg"", LGraphType::STRING}
});
response.MutableRecord()->Insert(
""errMsg"",
FieldData::String(std::string(""error parsing json: "") + e.what()));
return false;
}

response.ResetHeader({
{""node"", LGraphType::NODE},
{""salt"", LGraphType::FLOAT}
});
for (size_t i = 0; i < limit; i++) {
auto r = response.MutableRecord();
auto vit = txn.GetVertexIterator(i);
r->Insert(""node"", vit);
r->Insert(""salt"", FieldData::Float(20.23*float(i)));
}
return true;
}
```  
从代码中我们可以看到：
- 存储过程定义了一个获取签名的方法`GetSignature`。该方法返回了存储过程的签名，其中包含输入参数名称及其类型，返回参数及其类型。这使得Cypher查询语句在调用存储过程能够利用签名信息校验输入数据以及返回数据是否合理。
- 入口函数是`ProcessInTxn`函数，它的参数有三个，分别为：  
- `txn`: 存储过程所处的事务，通常来说即调用该存储过程的Cypher语句所处事务。
- `request`: 输入数据，其内容为`GetSignature`中定义的输入参数类型及其Cypher查询语句中传入的值经过json序列化后的字符串。e.g. `{num_iteration: 10}`
- `response`: 输出数据，为保证在Cypher语言中能够兼容，用户可以通过往`lgraph_api::Result` 写入存储过程处理后的数据，最后用`lgraph_api::Result::Dump`来序列化成json格式的数据。  
`ProcessInTxn`函数的返回值是一个布尔值。当它返回`true`的时候，表示该请求顺利完成，反之表示这个存储过程在执行过程中发现了错误。  
C++存储过程编写完毕后需要编译成动态链接库。TuGraph 提供了`compile.sh`脚本来帮助用户自动编译存储过程。`compile.sh`脚本只有一个参数，是该存储过程的名称，在上面的例子中就是`custom_pagerank`。编译调用命令行如下：  
```bash
g++ -fno-gnu-unique -fPIC -g --std=c++14 -I/usr/lo' metadata={'Header 1': 'Procedure API', 'Header 2': '5.Procedure v2接口', 'Header 3': '5.1.编写存储过程'}"
在执行`ProcessVertexActive`函数时，如果运行时出现错误，会引发什么异常？,"page_content='OlapOnDB API

3. 算法举例

3.2 PageRank算法流程

`pagerank`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关数据结构的初始化
1. 每个节点pagerank值的初始化
1. 每个节点pagerank值的计算，活跃点为所有点（意味着所有点都需要计算pagerank值）
1. 得到每个节点经过`num_iterations`次迭代后的pagerank值  
```C++
void PageRankCore(OlapBase<Empty>& graph, int num_iterations, ParallelVector<double>& curr) {

// 相关数据结构的初始化
auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
auto curr = olapondb.AllocVertexArray<double>();
auto next = olapondb.AllocVertexArray<double>();
size_t num_vertices = olapondb.NumVertices();
double one_over_n = (double)1 / num_vertices;

// 每个节点pagerank值的初始化，和该节点的出度成反比
double delta = graph.ProcessVertexActive<double>(
[&](size_t vi) {
curr[vi] = one_over_n;
if (olapondb.OutDegree(vi) > 0) {
curr[vi] /= olapondb.OutDegree(vi);
}
return one_over_n;
},
all_vertices);

// 总迭代过程
double d = (double)0.85;
for (int ii = 0;ii < num_iterations;ii ++) {
printf(""delta(%d)=%lf\n"", ii, delta);
next.Fill((double)0);

/*
函数用途：计算所有节点的pagerank值

函数流程描述：该函数用于计算所有节点的pagerank值，对all_vertices中所有为1的位对应的节点vi执行Func C，得到本轮迭代中vi的pagerank值，并返回vi节点的pagerank变化值，最终经过函数内部处理汇总所有活跃节点的总变化值并返回，该值被存储在delta变量中
*/
delta = graph.ProcessVertexActive<double>(
// Func C
[&](size_t vi) {
double sum = 0;

// 从邻居中获取当前节点的pagerank值
for (auto & edge : olapondb.InEdges(vi)) {
size_t src = edge.neighbour;
sum += curr[src];
}
next[vi] = sum;

// pagerank值计算核心公式
next[vi] = (1 - d) * one_over_n + d * next[vi];
if (ii == num_iterations - 1) {
return (double)0;
} else {

// 相关中间变量统计
if (olapondb.OutDegree(vi) > 0) {
next[vi] /= olapondb.OutDegree(vi);
return fabs(next[vi] - curr[vi]) * olapondb.OutDegree(vi);
} else {
return fabs(next[vi] - curr[vi]);
}
}
},
all_vertices
);

// 将本轮迭代得到的pagerank值输出作为下一轮迭代的输入
curr.Swap(next);
}
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.2 PageRank算法流程'}","page_content='OlapBase API

7. 图类OlapBase

7.4 批处理操作

TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程。分别是：  
```c++
/*
函数名称:ReducedSum ProcessVertexInRange(std::function<ReducedSum(size_t)> work, size_t lower, size_t upper,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考include/lgraph/olap_base.h中具体代码

使用示例:统计数组parent数组中有出边的点个数
*/

auto vertex_num = graph.ProcessVertexInRange<size_t>(
[&](size_t i) {
if (graph.OutDegree(parent[i]) > 0) {
return 1;
}
},
0, parent.Size()
);
printf(""the number is %lu\n"",vertex_num);
```  
其中graph为图类OlapBase的实例化对象  
```C++
/*
函数名称:ReducedSum ProcessVertexActive(std::function<ReducedSum(size_t)> work, ParallelBitset &active_vertices,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对active_vertices中对应为1的节点执行work函数，第三个参数表示累加的基数，默认为0；
第四个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考/include/lgraph/olap_base.h中具体代码

使用示例:输出Graph中节点1，2，3的所有出度邻居，并统计这三个节点的总出度
*/

auto active_in = graph.AllocVertexSubset();
active_in.Add(1);
active_in.Add(2);
active_in.Add(3);
auto total_outdegree = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t local_outdegree = 0;
for (auto & edge : graph.OutEdges(vi)) {
size_t dst = edge.neighbour;
printf(""node %lu has neighbour %lu\n"",vi,dst);
local_outdegree += 1;
}
return local_outdegree;
},
active_in
);
printf(""total outdegree of node1,2,3 is %lu\n"",total_outdegree);
```' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.4 批处理操作'}","page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

`bfs`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关定义、数据结构的初始化
2. 使用批处理函数对每个节点进行循环计算，每一轮找到与当前节点相邻的全部节点，并在该轮次终止时进行交换。
3. 直到找到全部节点，返回节点个数discovered_vertices。  
```C++
size_t BFSCore(Graph<Empty>& graph, size_t root_vid, ParallelVector<size_t>& parent){

size_t root = root_vid;
auto active_in = graph.AllocVertexSubset();   //分配数组，active_in用于存放上一循环阶段已找到的节点
active_in.Add(root);            //把跟节点加入数组中
auto active_out = graph.AllocVertexSubset();  //分配数组active_out用于存放当前循环阶段找到的节点
parent.Fill((size_t)-1);               //将parent数组中的节点赋值为-1，-1表示未被找到
parent[root] = root;
size_t num_activations = 1;       //表示当前循环阶段找到的节点个数
size_t discovered_vertices = 0;    //表示当前循环阶段找到节点的总个数

for (int ii = 0; num_activations != 0; ii++) {       //num_activations表示当前循环阶段找到的节点个数
printf(""activates(%d) <= %lu\n"", ii, num_activations);
discovered_vertices += num_activations;         //discovered_vertices表示当前循环阶段找到节点的总个数
active_out.Clear();
num_activations = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t num_activations = 0;
for (auto& edge : graph.OutEdges(vi)) {   //每一次循环从根节点出发，查找邻近的相邻节点，对其parent值改变，并num_activations+1操作
size_t dst = edge.neighbour;
if (parent[dst] == (size_t)-1) {
auto lock = graph.GuardVertexLock(dst);
if (parent[dst] == (size_t)-1) {
parent[dst] = vi;
num_activations += 1;
active_out.Add(dst);       //存放当前循环阶段找到的节点
}
}
}
return num_activations;
},
active_in);
active_in.Swap(active_out);
}
// 返回全部节点数
return discovered_vertices;
}
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}"
如果在调用存储过程时，指定json_format参数为false，返回结果的格式是什么？,"page_content='Java客户端

2.使用示例

2.7.向leader调用存储过程

```java
String result = client.callProcedureToLeader(""CPP"", ""khop"", kHopParamGen(), 1000, false, ""default"");
log.info(""testCallProcedureToLeader : "" + result);
```
```
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param param: the execution parameters
@param procedureTimeOut: Maximum execution time, overruns will be interrupted
@param inProcess: Running query or not
@param graph: the graph to query
@param jsonFormat: (Optional) Return format of calling stored procedure
@return: the result of procedure execution
public String callProcedureToLeader(String procedureType, String procedureName, String param, double procedureTimeOut,
boolean inProcess, String graph)
```
本接口支持在HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.7.向leader调用存储过程'}","page_content='Java客户端

2.使用示例

2.6.调用存储过程

```java
String result = client.callProcedure(""CPP"", ""khop"", kHopParamGen(), 1000, false, ""default"");
log.info(""testCallProcedure : "" + result);
```
```
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param param: the execution parameters
@param procedureTimeOut: Maximum execution time, overruns will be interrupted
@param inProcess: Running query or not
@param graph: the graph to query
@param jsonFormat: (Optional) Return format of calling stored procedure
@param url: (Optional) Node address of calling procedure
@return: the result of procedure execution
public String callProcedure(String procedureType, String procedureName, String param, double procedureTimeOut,
boolean inProcess, String graph, String url)
```
本接口支持在单机模式和HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}","page_content='C++客户端

2.使用示例

2.7.向leader调用存储过程

```C++
std::string str;
bool ret = client.CallProcedureToLeader(str, ""CPP"", ""test_plugin1"", ""bcefg"");
```
```
bool CallProcedureToLeader(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& param,
double procedure_time_out = 0.0, bool in_process = false,
const std::string& graph = ""default"", bool json_format = true);
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@returns True if it succeeds, false if it fails.
```
本接口支持在HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.7.向leader调用存储过程'}"
Prometheus的地址是什么？,"page_content='运维监控

2.部署方案

2.3.第三步

+ 下载符合您机器架构以及系统版本的Prometheus tar包，下载地址: [https://prometheus.io/download/](https://prometheus.io/download/)  
+ 解压tar包，命令如下  
```shell
tar -zxvf prometheus-2.37.5.linux-amd64.tar.gz
```  
+ 修改配置文件prometheus.yml，新增如下配置，使其可以抓取TuGraph Monitor包装好的性能数据  
```yaml
scrape_configs:
# The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
- job_name: ""tugraph""

# metrics_path defaults to '/metrics'
# scheme defaults to 'http'.

static_configs:
- targets: [""localhost:9111""]
```  
+ 启动prometheus，具体的启动参数可以通过如下命令获取  
```shell
./prometheus -h
```  
+ 验证prometheus服务是否正常，可以通过web端登陆prometheus服务，查询监控指标resources_report是否已经获取到，能成功查询到数据则正确' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.3.第三步'}","page_content='运维监控

2.部署方案

2.4.第四步

+ 下载符合您机器架构以及系统版本的Grafana安装包，下载地址: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)  
+ 安装Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 启动Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 配置Grafana，首先在数据源设置中配置Prometheus的IP地址，配置完成后可以通过测试连接功能，验证是否成功连接数据源。然后，导入如下模版，并在页面中根据实际情况，修改正确的接口IP和端口。最后可以根据实际情况设置刷新时间和监控时间范围  
```json
{
""annotations"": {
""list"": [
{
""builtIn"": 1,
""datasource"": {
""type"": ""grafana""
},
""enable"": true,
""hide"": true,
""iconColor"": ""rgba(0, 211, 255, 1)"",
""name"": ""Annotations & Alerts"",
""target"": {
""limit"": 100,
""matchAny"": false,
""tags"": [],
""type"": ""dashboard""
},
""type"": ""dashboard""
}
]
},
""editable"": true,
""fiscalYearStartMonth"": 0,
""graphTooltip"": 0,
""id"": 2,
""links"": [],
""liveNow"": false,
""panels"": [
{
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
}
},
""mappings"": [],
""unit"": ""kbytes""
},
""overrides"": [
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {__name__=\""resources_report\"", instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
},
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""others""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-blue"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
}
}
]
}
]
},
""gridPos"": {
""h"": 16,
""w"": 6,
""x"": ' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}","page_content='运维监控

1.设计思路

1.3.Prometheus

Prometheus是一个开源的监控平台，并配备有专属的时序数据库，它会定期通过http请求从TuGraph Monitor服务获取统计指标，并保存在自己的时序数据库中。详细信息请参考官网: [https://prometheus.io/docs/introduction/first_steps](https://prometheus.io/docs/introduction/first_steps)' metadata={'Header 1': '运维监控', 'Header 2': '1.设计思路', 'Header 3': '1.3.Prometheus'}"
TuGraph图分析引擎主要面向哪类任务？,"page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。  
<table><tbody><tr><td>算法类型</td><td>中文算法名</td><td>英文算法名</td><td>程序名</td></tr><tr><td rowspan=""5"">路径查询</td><td>广度优先搜索</td><td>Breadth-First Search</td><td>bfs</td></tr><tr><td>单源最短路径</td><td>Single-Source Shortest Path</td><td>sssp</td></tr><tr><td>全对最短路径</td><td>All-Pair Shortest Path</td><td>apsp</td></tr><tr><td>多源最短路径</td><td>Multiple-source Shortest Paths</td><td>mssp</td></tr><tr><td>两点间最短路径</td><td>Single-Pair Shortest Path</td><td>spsp</td></tr><tr><td rowspan=""9"">重要性分析</td><td>网页排序</td><td>Pagerank</td><td>pagerank</td></tr><tr><td>介数中心度</td><td>Betweenness Centrality</td><td>bc</td></tr><tr><td>置信度传播</td><td>Belief Propagation</td><td>bp</td></tr><tr><td>距离中心度</td><td>Closeness Centrality</td><td>clce</td></tr><tr><td>个性化网页排序</td><td>Personalized PageRank</td><td>ppr</td></tr><tr><td>带权重的网页排序</td><td>Weighted Pagerank Algorithm</td><td>wpagerank</td></tr><tr><td>信任指数排名</td><td>Trustrank</td><td>trustrank</td></tr><tr><td>sybil检测算法</td><td>Sybil Rank</td><td>sybilrank</td></tr><tr><td>超链接主题搜索</td><td>Hyperlink-Induced Topic Search</td><td>hits</td></tr><tr><td rowspan=""4"">关联性分析</td><td>平均集聚系数</td><td>Local Clustering Coefficient</td><td>lcc</td></tr><tr><td>共同邻居</td><td>Common Neighborhood</td><td>cn</td></tr><tr><td>度数关联度</td><td>Degree Correlation</td><td>dc</td></tr><tr><td>杰卡德系数</td><td>Jaccard Index</td><td>ji</td></tr><tr><td rowspan=""5"">图结构</td><td>直径估计</td><td>Dimension Estimation</td><td>de</td></tr><tr>' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}","page_content='OLAP API

1. TuGraph 图分析引擎介绍

TuGraph的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助TuGraph的 C++ / Python 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如PageRank、LPA、WCC等迭代式图算法，最后根据运行结果做出相应的对策。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph图计算系统社区版内置6个算法，商业版内置了25种算法，用户几乎不需要自己实现具体的图计算过程。其详细介绍可参考algorithms.md。  
根据数据来源及实现不同，可分为Procedure、Embed和Standalone三种运行方式，均继承于OlapBase API，OlapBase API接口文档可参考olapbase-api.md。  
其中Procedure和Embed的数据来源是图数据库中预加载的db数据，可以分别编译生成tugraph-web加载使用的.so文件和后台终端使用的embed文件，输入的图数据均通过db的加载形式，其接口文档可参考olapondb-api.md。
Standalone用于编译生成standalone文件，区别于前者，该文件的输入图数据通过txt、二进制、ODPS文件的形式加载，其接口文档可参考olapondisk-api.md。' metadata={'Header 1': 'OLAP API', 'Header 2': '1. TuGraph 图分析引擎介绍'}","page_content='功能概览

3.计算层

计算层在功能上分成三个部分，包括TP类的图事务引擎，AP类的图分析引擎和图神经网络引擎。  
- __图事务引擎__，主要用来处理并发的图操作，包括单点查询、邻居查询、路径遍历。图事务引擎侧重并发操作的ACID事务，确保操作逻辑不会互相干扰，主要性能指标为 QPS，即每秒完成的查询数量。  
- __图分析引擎__，操作类型通常为全图迭代。部分简单的分析任务（比如SPSP）可以由图事务引擎完成，复杂的分析任务均由图分析引擎完成，单个任务通常需要数秒至数小时。因此单个图分析任务要并发利用所有的硬件资源，性能指标为任务完成的总时长。  
- __图神经网络引擎__，通常也为全图迭代。图神经网络引擎除了基于图拓扑的操作，也需要集成一个机器学习的框架来处理向量操作，比如 PyTorch、MXNet、TenserFlow。  
三个引擎的操作逻辑不尽相同，独立配置资源池。事图事务引擎基于RPC操作设置了一个线程池，每接受客户端的一个操作，从线程中取一个线程来处理，并发执行的数量等于RPC线程池的容量，通常配置为服务器的核数。图分析引擎有一个分析线程池，每个图分析任务会并发执行，即用所有的线程来执行一个任务，来加速操作的性能。TuGraph图分析操作串行执行的特性会一定程度限制用户的使用体验，并发的图分析的需求可以通过高可用部署的方式，增加机器资源来处理，或者接入外部的任务调度器，将数据传到实时调度的容器来计算。图神经网络操作在图上的操作会复用图事务引擎或图分析引擎的资源，向量的操作会起单独的资源，在机器学习框架中可以使用GPU等单独的加速硬件。' metadata={'Header 1': '功能概览', 'Header 2': '3.计算层'}"
在给定的XML配置中，如果表内属性字段名为id时，应该如何处理node_id字段以避免报错？,"page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}","page_content='RESTful API Legacy

6.Deprecated

6.11.其他

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/misc
```  
#### 6.11.1.提取子图  
给出点 id 集合，返回包含该集合的最小子图。  
- **URI**: `/db/{graph_name}/misc/sub_graph`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| vertex_ids | 点 id 集合 | 列表 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| nodes | 点数据 | 列表，每元素包含 vid, label, 以及属性 |
| relationships | 边数据 | 列表，每元素包含 src, dst, euid, label, 以及属性 |  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/misc/sub_graph
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""vertex_ids"": [2, 5, 14, 20]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""nodes"": [
{
""label"": ""Person"",
""properties"": {
""birthyear"": 1937,
""name"": ""Vanessa Redgrave""
},
""vid"": 2
},
{
""label"": ""Person"",
""properties"": {
""birthyear"": 1963,
""name"": ""Natasha Richardson""
},
""vid"": 5
},
{
""label"": ""City"",
""properties"": {
""name"": ""London""
},
""vid"": 14
},
{
""label"": ""Film"",
""properties"": {
""title"": ""Camelot""
},
""vid"": 20
}
],
""relationships"": [
{
""destination"": 5,
""label"": ""HAS_CHILD"",
""properties"": {
""birthyear"": 1937,
""name"": ""Vanessa Redgrave""
},
""source"": 2
},
{
""destination"": 14,
""label"": ""BORN_IN"",
""properties"": {
""birthyear"": 1937,
""name"": ""Vanessa Redgrave""
},
""source"": 2
},
{
""destination"": 20,
""label"": ""ACTED_IN"",
""properties"": {
""birthyear"": 1937,
""charactername"": ""Guenevere"",
""name"": ""Vanessa Redgrave""
},
""source"": 2
},
{
""destination"": 14,
""label"": ""BORN_IN"",
""properties"": {
""birthyear"": 1963,
""name"": ""Natasha Richardson""
},
""source"": 5
}
]
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.11.其他'}","page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}"
"使用OGM进行创建节点和边的代码示例中，哪部分代码用于创建边标签""DIRECT""?","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.1 构建图对象**

首先需要通过注解标明图中的实体。  
@NodeEntity：该注解标明的类为节点类。  
@Relationship：用于标明边，同时@Relationship中可指定label与边的指向。  
@Id：用于标明identity，是OGM中数据的唯一标识。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.1 构建图对象**'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.3 通过OGM进行增操作**

OGM支持对TuGraph的实体执行CRUD 操作，同时支持发送任意TuGraph支持的Cypher语句，包括通过CALL调用存储过程。  
**CREATE**  
在完成图对象的构建后，即可通过类的实例化创建节点，当两个节点互相存储在对方的集合（该集合在构建时被标注为边）中，就形成了一条边，最后使用session.save方法将数据存入数据库。  
注意：TuGraph数据库为强schema类型数据库，在创建实体前需要该数据的label已经存在，且新建过程中需要提供唯一的主键。  
```
Movie jokes = new Movie（""Jokes""，1990）； // 新建Movie节点jokes session.save(jokes); // 将jokes存储在TuGraph中

Movie speed = new Movie(""Speed"", 2019);

Actor alice = new Actor(""Alice Neeves"");

alice.actsIn(speed);

session.save(speed);

/1 将speed节点与alice节点通过ACTS_IN进行连接 11 存储speed节点以及speed关联的边和alice节点
```' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.3 通过OGM进行增操作**'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.6 通过OGM进行查操作**

**MATCH**  
session.load方法用于根据节点id查找节点。 session.loadALL方法用于批量查找节点，支持通过多个节点id查找节点、查找某一类型的所有节点、带有filter的查询。 filter查询需要新建Filter，传入参数ComparisonOperatorx0;可选为：EQUALSx0;、GREATER\_THANx0;、LESS\_THAN  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*J3Z1TrA0BncAAAAAAAAAAAAADgOBAQ/original)  
**QUERY WITH CYPHER**  
OGM支持通过queryForObject、query方法向TuGraph发送Cypher查询，由于Cypher查询的灵活性，需要用户自行指定返回结果格式。  
session.queryForObject方法：需要在方法第一个参数处指定返回类型，可设定为某一实体类或数字类型。  
session.query方法：Cypher查询的返回结果被存储为Result类型，其内部数据需要用户自行解析，以下方代码为例，传入数据库的Cypher为CREATE查询，返回结果createResult可被解析为QueryStatistics，可获取到此次查询被创建的节点与边的数目。  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*lkxXS660eEgAAAAAAAAAAAAADgOBAQ/original)' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.6 通过OGM进行查操作**'}"
"return n 和 return p.name,p.age 的数据结构不一致。 能统一返回可视化页面的这种结构么？","page_content='Cypher API

2.Clauses

2.3.RETURN

- ✓ Return nodes  
```
MATCH (n {name: 'Carrie-Anne Moss'}) RETURN n
```  
- ✓ Return relationships  
```
MATCH (n {name: 'Carrie-Anne Moss'})-[r:acted_in]->(c)
RETURN r
```  
- ✓ Return property  
```
MATCH (n {name: 'Carrie-Anne Moss'}) RETURN n.born
```  
- ❏ Return all elements  
```
MATCH p = (a {name: 'A'})-[r]->(b)
RETURN *
```  
- ❏ Variable with uncommon characters  
```
MATCH (`This isn\'t a common variable`)
WHERE `This isn\'t a common variable`.name = 'A'
RETURN `This isn\'t a common variable`.happy
```  
- ✓ Aliasing a field  
```
MATCH (a {name: 'Carrie-Anne Moss'})
RETURN a.born AS SomethingTotallyDifferent
```  
- ✓ Optional properties  
```
MATCH (n)
RETURN n.age
```  
- ❏ Other expressions  
```
MATCH (a {name: 'Carrie-Anne Moss'})
RETURN a.born > 1900, ""I'm a literal"", (a)-[]->()
```  
`(a)-[]->()` not supported.  
- ✓ Unique results  
```
MATCH (a {name: 'Carrie-Anne Moss'})-[]->(b)
RETURN DISTINCT b
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.3.RETURN'}","page_content='ISO GQL

2.Clauses

2.3.RETURN

`RETURN`子句指定返回结果，包括返回点、边、路径、属性等。  
#### 返回点  
```
MATCH (n)
RETURN n LIMIT 2
```  
返回结果
```JSON
[{""n"":{""identity"":0,""label"":""Person"",""properties"":{""birthyear"":1910,""name"":""Rachel Kempson""}}},{""n"":{""identity"":1,""label"":""Person"",""properties"":{""birthyear"":1908,""name"":""Michael Redgrave""}}}]
```  
#### 返回边  
```
MATCH (n)-[e]->(m)
RETURN e LIMIT 2
```  
返回结果  
```JSON
[{""e"":{""dst"":2,""forward"":false,""identity"":0,""label"":""HAS_CHILD"",""label_id"":0,""src"":0,""temporal_id"":0}},{""e"":{""dst"":3,""forward"":false,""identity"":0,""label"":""HAS_CHILD"",""label_id"":0,""src"":0,""temporal_id"":0}}]
```  
#### 返回属性  
```
MATCH (n:Person)
RETURN n.name LIMIT 2
```  
返回结果  
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```  
#### 不常见字符串作为变量名  
```
MATCH (`/uncommon variable`:Person)
RETURN `/uncommon variable`.name LIMIT 3
```  
返回结果  
```JSON
[{""`/uncommon variable`.name"":""Christopher Nolan""},{""`/uncommon variable`.name"":""Corin Redgrave""},{""`/uncommon variable`.name"":""Dennis Quaid""}]
```  
#### 列别名  
```
MATCH (n:Person)
RETURN n.name AS nname LIMIT 2
```  
返回结果  
```JSON
[{""nname"":""Christopher Nolan""},{""nname"":""Corin Redgrave""}]
```  
#### 可选属性  
```
MATCH (n:Person)
RETURN n.age LIMIT 2
```  
返回结果  
```JSON
[{""n.age"":null},{""n.age"":null}]
```  
#### 其它表达式  
```
MATCH (n:Person)
RETURN n.birthyear > 1970, ""I'm a literal"", 1 + 2, abs(-2)
LIMIT 2
```  
返回结果  
```JSON
[{""\""I'm a literal\"""":""I'm a literal"",""1 + 2"":3,""abs(-2)"":2,""n.birthyear > 1970"":false},{""\""I'm a literal\"""":""I'm a literal"",""1 + 2"":3,""abs(-2)"":2,""n.birthyear > 1970"":false}]
```  
#### 结果唯一性  
```
MATCH (n)
RETURN DISTINCT label(n) AS label
```  
返回结果  
```JSON
[{""label"":""Person""},{""label"":""City""},{""label"":""Film""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.3.RETURN'}","page_content='Cypher API

2.Clauses

2.9.UNION

- ✓ Combine two queries and retain duplicates  
```
MATCH (n:person)
RETURN n.name AS name
UNION ALL MATCH (n:movie)
RETURN n.title AS name
```  
- ❏ Combine two queries and remove duplicates  
```
MATCH (n:Actor)
RETURN n.name AS name
UNION
MATCH (n:Movie)
RETURN n.title AS name
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.9.UNION'}"
编译TuGraph时如何为基于ARM的机器（如Mac M1）配置CMake？,"page_content='从源码编译

2.编译介绍

以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`，如果在arm机器编译（如M1芯片的Mac中，需要加上` -DENABLE_BUILD_ON_AARCH64=ON`）
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build
$ cmake .. -DOURSYSTEM=centos7
$ make
$ make package
```' metadata={'Header 1': '从源码编译', 'Header 2': '2.编译介绍'}","page_content='TuGraph-db

3. 从源代码编译

建议在Linux系统中构建TuGraph，Docker环境是个不错的选择。如果您想设置一个新的环境，请参考[Dockerfile]  
以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build
$ cmake .. -DOURSYSTEM=centos7
$ make
$ make package
```' metadata={'Header 1': 'TuGraph-db', 'Header 2': '3. 从源代码编译'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}"
单机的配置大致是什么情况？,"page_content='环境准备

3.典型配置推荐

| 硬件      | 最低配置   | 建议配置                   |
| -------- | --------- | ------------------------ |
| CPU      | 4 Cores   | 64 Cores                 |
| 内存      | 4GB       | 512GB                    |
| 外存      | 100GB     | 2TB NVMe SSD             |
| OS       | Linux 4.9 | CentOS 7.3               |' metadata={'Header 1': '环境准备', 'Header 2': '3.典型配置推荐'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='快速上手

1.简介

1.2.硬件要求

_目前我们建议用户使用 NVMe SSD 配合较大的内存配置以获取最佳性能。_  
| 硬件   | 最低配置      | 建议配置                     |
|------|-----------|--------------------------|
| CPU  | X86_64    | Xeon E5 2670 v4          |
| 内存   | 4GB       | 256GB                    |
| 硬盘   | 100GB     | 1TB NVMe SSD             |
| 操作系统 | Linux 2.6 | Ubuntu 18.04, CentOS 7.3 |' metadata={'Header 1': '快速上手', 'Header 2': '1.简介', 'Header 3': '1.2.硬件要求'}"
如何查询两点间的一条通路？,"page_content='内置算法

扩展算法包

两点间最短路径

两点间最短路径程序实现了Bidirectional Breadth-First Search算法，在有向无权图上从起点沿着出边做正向宽度优先搜搜，从终点沿着入边做反向宽度优先搜索，通过起点和终点共同遍历到的点来确定从起点到终点的最短路径长度。算法内容请参考[https://en.wikipedia.org/wiki/Bidirectional_search](https://en.wikipedia.org/wiki/Bidirectional_search ""Bidirectional search"")。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': '两点间最短路径'}","page_content='内置算法

扩展算法包

全对最短路径

全对最短路径程序实现了All-Pair Shortest Path算法，计算图中任意两点间的最短路径。返回结果为任意存在路径的点对之间的最短路径长度。算法内容请参考[https://en.wikipedia.org/wiki/Floyd-Warshall_algorithm](https://en.wikipedia.org/wiki/Floyd-Warshall_algorithm ""Floyd-Warshall algorighm wiki"")' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': '全对最短路径'}","page_content='Cypher API

5.附录2. 内置procedures列表

* algo.shortestPath(startNode, endNode, config)

get one of the shortest paths between two vertexes.  
**Parameters:**  
| parameter | parameter type | description                          |
| --------- | -------------- | ------------------------------------------------------------ |
| startNode | Node       | the source node of paths                     |
| endNode   | Node       | the destination node paths                   |
| config    | MAP        | the filter of shortest paths, the formate as {maxHops:3, relationshipQuery:'HAS_CHILD'} |  
**Output:**  
If successful, it will returns one group result of the shortest path.  
**Example input:**  
```
MATCH (n1 {name:'Hugo Weaving'}),(n2 {title:'The Matrix'})
CALL algo.shortestPath(n1,n2) YIELD nodeCount,totalCost RETURN nodeCount,totalCost
```  
**Example output:**  
| nodeCount | totalCost |
| --------- | --------- |
| 2     | 1     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* algo.shortestPath(startNode, endNode, config)'}"
tugraph 支持通过cypher 或者python的形式修改schema吗,"page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}","page_content='试用体验：TuGraph — 简单高效的图数据库

支持RESTful API

除了支持Cypher查询语言，TuGraph还提供了RESTful API接口。这使得我可以通过编程方式与图数据库进行交互，更好地将TuGraph集成到我的应用程序中。API设计合理，易于使用，为我提供了灵活性和自由度。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持RESTful API'}","page_content='Procedure API

2.存储过程的版本支持

目前TuGraph支持两个版本的存储过程，适用于不同的场景，v3.5版本只支持v1，可通过REST或RPC接口直接调用；从v3.5版本开始支持v2，能够在图查询语言（比如Cypher）中嵌入调用，我们称之为POG（Procedure On Graph query language，APOC）。  
|                        | Procedure v1                       | Procedure v2               |
| ---------------------- | ---------------------------------- | -------------------------- |
| 适用场景                 | 极致性能，或者复杂的多事务管理情形       | 一般情况，与Cypher高度联动 |
| 事务                    | 函数内部创建，可自由控制多事务          | 外部传入函数，单一事务     |
| 签名（参数定义）          | 无                                 | 有                    |
| 输入输出参数类型          | 不需要指定                           | 需要指定参数类型        |
| Cypher Standalone Call | 支持                                | 支持                  |
| Cypher Embeded Call    | 不支持                              | 支持                  |
| 语言                    | C++/Python/Rust                    | C++                  |
| 调用模式                 | 直接传字符串，一般为JSON               | 通过Cypher语句中的变量  |  
在TuGraph中，存储过程v1和v2单独管理，支持增删查，但仍不建议重名。' metadata={'Header 1': 'Procedure API', 'Header 2': '2.存储过程的版本支持'}"
TuGraph-Restful-Server 使用哪种框架支持其HTTP协议，并提供了哪些主要功能？,"page_content='TuGraph-Restful-Server

1.TuGraph-Restful-Server 简介

TuGraph Restful Server 使用brpc框架支持的http协议，提供restful接口查询功能，在实现中，restful server 与rpc server 使用同一个端口。目前restful接口提供文件上传，数据导入，导入进度查询，cypher查询，文件删除等功能' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '1.TuGraph-Restful-Server 简介'}","page_content='功能概览

6.生态工具

6.3.运维监控

TuGraph 使用 Prometheus 加 Grafana 的监控框架，采用松耦合的方式。Prometheus 从 TuGraph 的监控接口获取监控信息，存储在本地时序数据库中，然后通过 Grafana 在网页端交互展示。  
TuGraph 提供的监控的状态包括图数据库的状态和服务器的状态，前者包括读写负载、点边数量等数据库端的状态，后者包括内存、CPU、硬盘等服务器的实时状态。如果某些监控状态超过了预期的阈值，就需要主动告警，通常需要对接其他运维管控系统，比如群消息、邮件告警等。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.3.运维监控'}","page_content='TuGraph Management

简介

TuGraph Management 是一款为TuGraph开发的算法任务管理工具。采用了sofastack与brpc作为通信框架，并使用sqlite进行持久化存储。  
主要功能：  
- 算法任务状态持久化存储  
- 算法任务结果持久化存储  
- 延时触发与定时触发算法任务支持' metadata={'Header 1': 'TuGraph Management', 'Header 2': '简介'}"
禁用角色后，具有该角色的用户会如何受影响？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLm' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='可视化操作手册

2.操作指南

2.5.控制台

`控制台`提供可视化的的账户管理和数据库信息查看功能，它为用户提供了全面的账户和角色管理功能，包括账户的增删改查以及禁用，角色的增删改查以及禁用。此外，它也为用户提供了便捷的数据库信息查看功能，让用户可以轻松地查看图数据库的基础信息和配置信息。其中，基础信息主要包括版本号、运行时间、CPP编译版本号等，而数据库配置信息则包括端口号、系统功能参数配置等。  
#### 2.5.1.账户管理  
##### 2.5.1.1.账户管理  
###### a.添加账户  
在`账户管理`界面点击`添加`按钮创建新的账户，用户需要输入账户名称、账户描述、账户密码以及相关角色。  
![账户管理-添加账户按钮](../../../images/browser/account-add-button.png)  
- 账户名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 相关角色：新建账户时必须要选择一个角色，在账户添加成功后，系统会自动生成一个与账户名称一样的角色。  
![账户管理-添加账户](../../../images/browser/account-add.png)  
###### b.编辑账户  
在`账户管理`界面点击`添加`按钮创建新的账户，用户可以编辑账户描述、账户密码以及相关角色。  
![账户管理-编辑账户](../../../images/browser/account-edit.png)  
###### c.禁用账户  
在`账户管理`界面点击`禁用`按钮禁止对应的账户登录和访问，点击`启用`按钮开启对应的账户登录和访问权限。  
![账户管理-禁用](../../../images/browser/account-disable.png)
![账户管理-启用](../../../images/browser/account-enable.png)  
###### d.删除账户  
在`账户管理`界面点击`删除`按钮删除对应的账户。  
![账户管理-删除](../../../images/browser/account-delete.png)  
##### 2.5.1.2.角色管理  
###### a.添加角色  
在`角色管理`界面点击`添加`按钮创建新的角色，用户需要输入角色名称、角色描述以及图权限。  
![角色管理-添加角色按钮](../../../images/browser/role-add-button.png)  
- 角色名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图权限：browser支持全部、读、写和无共四类图权限配置。
- 全部：对应图的读和写权限，包含编辑图模型权限（schema）。
- 读写：对应图的写权限，不包含编辑图模型权限（schema）。
- 只读：对应图的读权限。
- 无：无法访问和操作对应图。
- 角色冲突：当两个角色对同一个图有不同图权限，同时对一个账户授权了这两个角色，该账户对该图的图权限为两个角色的并集。  
![角色管理-添加角色](../../../images/browser/role-add.png)  
###### b.编辑角色  
在`角色管理`界面点击`编辑`按钮编辑已有角色，用户可以编辑角色描述以及图权限。  
![角色管理-编辑角色](../../../images/browser/role-edit.png)  
###### c.禁用角色  
在`角色管理`界面点击`禁用`按钮禁止对应的角色，点击`启用`按钮开启对应的角色。禁用角色后，对应角色图访问权限失效。  
- 禁用角色：禁用之后，对应角色图访问权限失效。
- 当一个用户拥有两个角色对同一个图有操作权限时，当禁用其中一个角色时，另一个角色权限同样有效。  
![角色管理-禁用](../../../images/browser/role-disable.png)
![角色管理-启用](../../../images/browser/role-enable.png)  
###### d.删除角色  
在`角色管理`界面点击`删除`按钮删除对应的角色。  
![角色管理-删除](../../../images/browser/role-delete.png)  
#### 2.5.2.数据库信息  
##### 2.5.2.1.基础信息  
`基础信息`获取当前系统运行的状态，并展示关键信息。  
![数据库信息-基础信息](../../../images/browser/db_basic.png)  
|参数    |含义    |
|-------|--------|
|TuGraph版本号|当前TuGraph的版本号，x.x.x|
|运行时间|TuGraph服务启动到现' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.5.控制台'}","page_content='用户权限

4.常用权限操作

4.2.角色操作

- 创建角色  
```cypher
CALL dbms.security.createRole(role_name::STRING,desc::STRING)
```  
- 删除角色  
```cypher
CALL dbms.security.deleteRole(role_name::STRING
```  
- 列出所有角色  
```cypher
CALL dbms.security.listRoles()
```  
- 禁用/启用角色  
```cypher
CALL dbms.security.disableRole(role::STRING,disable::BOOLEAN)
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.2.角色操作'}"
如果您作为公司员工提交贡献内容，应如何保证合法授权？,"page_content='如何贡献

3. 准备工作

3.3. 许可协议

在贡献代码之前，请您稍微花一些时间了解为TuGraph贡献代码的流程，并阅读 [个人贡献者许可协议](3.individual-cla.md) 或 [公司贡献者许可协议](4.corporate-cla.md)，参与贡献则视为同意上述协议。' metadata={'Header 1': '如何贡献', 'Header 2': '3. 准备工作', 'Header 3': '3.3. 许可协议'}","page_content='如何贡献

4. 贡献代码流程

4.8. 代码 Review

在您提交代码后，您的代码会被指派给维护人员 Review，请耐心等待。如果两个工作日后，仍然没有人对您的提交给予任何回复，可以在 PR 下面留言，并 @ 对应的人员。  
对于代码 Review 的意⻅会直接备注到到对应 PR 或者 Issue。如果觉得建议是合理的，也请您把这些建议更新到您的代码中。' metadata={'Header 1': '如何贡献', 'Header 2': '4. 贡献代码流程', 'Header 3': '4.8. 代码 Review'}","page_content='如何贡献

4. 贡献代码流程

4.3. 拉分支

TuGraph 所有修改都在分支上进行，修改完成后提交 pull request，在 Code Review 后由项目维护人员 Merge 到 Master。 因此，在获取源码步骤介绍后，您需要:  
1. 下载代码到本地，这一步您可以选择git/https方式，近年github的权限要求更加严格，比如git方式需要更复杂的ssh key([https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent))，https方式不能直接使用用户名密码验证，请按照指引授权。 git clone https://github.com/您的账号名/tugraph-db
2. 拉分支准备修改代码:
git branch add_xxx_feature
3. 执行完上述命令后，您的代码仓库就切换到相应分支了。执行如下命令可以看到您当前分支: git branch -a
4. 如果您想切换回 Master，执行下面命令: git checkout -b master
5. 如果您想切换回分支，执行下面命令: git checkout -b ""branchName""' metadata={'Header 1': '如何贡献', 'Header 2': '4. 贡献代码流程', 'Header 3': '4.3. 拉分支'}"
如何只清空数据，而保留schema？,"page_content='业务开发指南

子图操作

清空子图

#### 删除所有的点边数据和图schema
```
CALL db.dropDB()
```
#### 只删除所有点边数据, 保留图schema
```
CALL db.dropAllVertex()
```' metadata={'Header 1': '业务开发指南', 'Header 2': '子图操作', 'Header 3': '清空子图'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！

仅需 5 步，即可呈现 🎊

3. 添加组件

我们需要添加两个组件，在工具栏中添加 **清空画布**；然后在默认布局的侧边容器中添加**环路检测 Demo**  
<img width=""463"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/b01271b5-162c-4216-9a9c-bf7a5570c999"">
<img width=""474"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/238685ec-d9cf-4fcf-8357-56f4f8a8928d"">  
> 此时项目画布应该如下所示
> <img width=""1149"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/e660fa5b-aa31-4e7e-b295-cb071cc476c1"">  
点击工具栏中的`🧹清除`选项来清空画布节点  
<img width=""241"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/61316029-71ba-410f-94bf-47c6c65aec34"">  
默认情况下，添加完`环路检测Demo`组件后，会自动建立连接。  
<img width=""328"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/5246536b-ddb0-4c3c-91fb-e941101e272a"">  
Tugraph Analytics 端建立连接后同样会输出以下内容：  
<img width=""616"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/46be1e88-9c93-430e-92cc-db8024691095"">' metadata={'Header 1': '🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！', 'Header 2': '仅需 5 步，即可呈现 🎊', 'Header 3': '3. 添加组件'}"
OGM在哪些方面类似于MyBatis？,"page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

简介

TuGraph 图数据库提供了 JAVA、C++、Python 等多种语言的 SDK 支持，方便客户在各种场景下使用。用户使用 SDK 向TuGraph服务器发送Cypher请求，服务器则以 JSON形式返回数据。近日，TuGraph 推出了一款面向 JAVA 客户端用户的开发工具 TuGraph-OGM (Object Graph Mapping)，为用户提供了对象操作接口，相较 Cypher/JSON 接口应用起来更加便捷。  
OGM 类似于关系数据库中的 ORM（Object Relational Model），可以将数据库返回的数据自动映射成 JAVA 中的对象，方便用户读取，而用户对这些对象的更新操作也可以被自动翻译成 Cypher 语句发送给服务器。这样即便是完全不懂 Cypher 的用户，也可以通过操作对象与数据库进行交互，大大降低了图数据库的使用门槛。  
TuGraph-OGM 同时也兼容其他开源产品 OGM 工具如 Neo4j-OGM，方便用户将工程在不同数据库与 TuGraph数据库间无缝迁移。本文将对 TuGraph-OGM 进行全面的介绍。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '简介'}","page_content='TuGraph Java Client

特性

- Java中的RPC客户端
- OGM，即对象图映射，支持将图中的实体和关系映射到Java对象，从而加速Java开发过程。' metadata={'Header 1': 'TuGraph Java Client', 'Header 2': '特性'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.6 通过OGM进行查操作**

**MATCH**  
session.load方法用于根据节点id查找节点。 session.loadALL方法用于批量查找节点，支持通过多个节点id查找节点、查找某一类型的所有节点、带有filter的查询。 filter查询需要新建Filter，传入参数ComparisonOperatorx0;可选为：EQUALSx0;、GREATER\_THANx0;、LESS\_THAN  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*J3Z1TrA0BncAAAAAAAAAAAAADgOBAQ/original)  
**QUERY WITH CYPHER**  
OGM支持通过queryForObject、query方法向TuGraph发送Cypher查询，由于Cypher查询的灵活性，需要用户自行指定返回结果格式。  
session.queryForObject方法：需要在方法第一个参数处指定返回类型，可设定为某一实体类或数字类型。  
session.query方法：Cypher查询的返回结果被存储为Result类型，其内部数据需要用户自行解析，以下方代码为例，传入数据库的Cypher为CREATE查询，返回结果createResult可被解析为QueryStatistics，可获取到此次查询被创建的节点与边的数目。  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*lkxXS660eEgAAAAAAAAAAAAADgOBAQ/original)' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.6 通过OGM进行查操作**'}"
BROWSER 有 docker 部署么？,"page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

1. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7:${VERSION}
```  
2. 启动docker  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}","page_content='文档地图

快速上手

> 可以先了解[什么是图](./2.introduction/1.what-is-graph.md)、图[可以做什么](./2.introduction/8.scenarios.md)、以及[什么是TuGraph](./2.introduction/3.what-is-tugraph.md)。  
> 基于[阿里云计算巢](5.installation&running/5.cloud-deployment.md)或[Docker方式](5.installation&running/3.docker-deployment.md)快速部署TuGraph。  
> 通过产品内置的场景上手体验：[电影](./3.quick-start/2.demo/1.movie.md)、[流浪地球](./3.quick-start/2.demo/2.wandering-earth.md)、[三体](./3.quick-start/2.demo/3.the-three-body.md)、[三国](./3.quick-start/2.demo/4.three-kingdoms.md)。  
> 可视化操作手册看这里：[可视化操作手册](./4.user-guide/1.tugraph-browser.md)、[可视化操作手册（旧版）](./4.user-guide/2.tugraph-browser-legacy.md)。' metadata={'Header 1': '文档地图', 'Header 2': '快速上手'}","page_content='Docker部署

2.现有Docker Image

2.2.命名规范

#### 2.2.1.TuGraph Compile Image  
提供编译环境，可以用于TuGraph的编译。  
`tugraph/tugraph-compile-[os name & version]:[tugraph compile version]`  
例如： `tugraph/tugraph-compile-centos7:1.2.0`  
#### 2.2.2.TuGraph Runtime Image  
提供二进制可运行环境，附带TuGraph库和可执行文件。  
`tugraph/tugraph-runtime-[os name & version]:[tugraph-runtime version]`  
例如：`tugraph/tugraph-runtime-centos7:3.4.0`  
#### 2.2.3.TuGraph Mini Runtime Image  
提供二进制可运行环境，不包含TuGraph种Java、Python相关的功能，无C++ plugin编译运行，仅so上传。  
`tugraph/tugraph-mini-runtime-[os name & version]:[tugraph-runtime version]`  
例如： `tugraph/tugraph-mini-runtime-centos7:3.4.0`' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.2.命名规范'}"
TuGraph-DB是否有数据导入工具？相关代码在哪里？,"page_content='数据导入

1.简介

在图数据库服务安装成功后，您可以使用`lgraph_import`批量导入工具将现有数据导入 TuGraph。`lgraph_import`支持从 CSV 文件和 JSON 数据源导入数据。  
> CSV 格式  
```
[movies.csv]
id, name, year, rating
tt0188766,King of Comedy,1999,7.3
tt0286112,Shaolin Soccer,2001,7.3
tt4701660,The Mermaid,2016,6.3
```  
> jsonline 格式  
```json
[""tt0188766"",""King of Comedy"",1999,7.3]
[""tt0286112"",""Shaolin Soccer"",2001,7.3]
[""tt4701660"",""The Mermaid"",2016,6.3]
```  
TuGraph 支持两种导入模式：  
- _离线模式_：读取数据并将其导入指定服务器的数据文件，应仅在服务器离线时完成。
- _在线模式_：读取数据并将其发送到工作中的服务器，然后将数据导入其数据库。' metadata={'Header 1': '数据导入', 'Header 2': '1.简介'}","page_content='数据导出

1.简介

TuGraph 可以通过 `lgraph_export` 工具来对已经存放在TuGraph的图数据进行数据导出。 `lgraph_export` 工具可以将指定 TuGraph 数据库的数据以 `csv` 或者 `json` 文件形式导出到指定目录，同时导出这些数据进行再导入时需要的配置文件 `import.config` ，详细描述可参见[配置文件](1.data-import.md)。' metadata={'Header 1': '数据导出', 'Header 2': '1.简介'}","page_content='功能概览

6.生态工具

6.1.TuGraph DataX

![导入导出](../../../images/tugraph-datax.png)  
TuGraph 核心支持 CSV 和 JSON 合适的导入导出，提供空库导入和增量导入的模式。实际中会存在 MySQL、Kafka、Hive 等多数据源导入的需求，TuGraph 通过 DataX 做多数据源的对接。由于关系模型和图模型存在的差异，数据清洗的流程可以使用 SparkSQL 快速处理，TuGraph 本身仅关注 CSV 和 JSON 的简单场景导入可靠性和性能。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.1.TuGraph DataX'}"
图数据库相比关系型数据库有哪些独特的优势？,"page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.2. 兼容性

现实中，项目进程通常不断演变，数据的内容甚至数据格式也在不断变化。在关系型数据库中，这意味着表结构的变化或建立多个新表，对源数据的修改非常大。而在图数据库中，仅需添加新的点、边和属性，并将其设置为对应的类型即可。从本质上说，一个表代表一种类型的数据，一个点代表一个特定的数据。这意味着关系型数据库更关注数据类型，而图数据库更关注数据个体及其关联关系。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.2. 兼容性'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.3. 直观性

使用图的方式表达现实世界的关系更直接和自然，在万物互联的时代尤为突出。如果使用关系型数据，先建立实体表，再建立关系表，最后映射数据，需要高度的抽象思维。在图数据上进行分析查询时，可以直观地通过点边连接的拓扑结构找到所需数据，无需任何专业知识。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.3. 直观性'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.1. 性能

在关联关系处理上，使用关系型数据库不可避免地要使用表的JOIN操作，这会对性能产生较大影响；而图数据库则直接跳转访问类指针，操作关联数据的效率更高，比关系型数据库提高2到4个数量级的性能。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.1. 性能'}"
TuGraph 产品架构中，客户端 SDK 支持哪些编程语言？,"page_content='TuGraph产品架构

1.简介

![产品架构](../../../images/architecture.png)  
上图从功能模块的角度，以 TuGraph 为例，给出了企业级图数据库的整体架构，自下而上包括：  
- 软硬件环境。涉及图数据库的开发和使用环境。TuGraph 主要基于底层的 C++语言开发，能够兼容市面上大部分操作系统和 CPU。
- 存储层，包括 KV 存储层和图存储层。存储层需要支持计算层所需的各个功能。
- 计算层。计算层应包括图事务引擎、图分析引擎和图神经网络引擎，也包含了服务端提供的多种编程接口，包括描述式查询语言 Cypher，存储过程等。
- 客户端。客户端 SDK 应支持 Java、Python、C++ 等多种语言，也支持命令行的交互方式。Browser 和 Explorer 通过网页端交互的方式，降低了图数据库的使用门槛。
- 在生态工具方面，覆盖了企业级图数据库的开发、运维、管理等链路，提升可用性。' metadata={'Header 1': 'TuGraph产品架构', 'Header 2': '1.简介'}","page_content='功能概览

5.客户端工具

客户端主要分为各种编程语言的SDK，OGM以及命令行工具。  
客户端 SDK 主要用于二次开发，可以通过 RPC 或 REST 协议链接服务端。RPC 基于长链接有较好的性能，数据需要通过 protobuf 统一序列化。TuGraph 使用brpc，支持 Java、Python、C++ 的 rpc 客户端。REST 的协议比较宽泛，能够简单适配更加多样的环境，不同的编程语言能够简单对接。TuGraph 给出了 Python 的REST 客户端实例，命令行的交互也是用 REST 实现。  
OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。  
命令行工具`lgraph_cypher`是查询客户端，可用于向 TuGraph 服务器提交 OpenCypher 请求。`lgraph_cypher`客户端有两种执行模式：单命令模式和交互式模式。' metadata={'Header 1': '功能概览', 'Header 2': '5.客户端工具'}","page_content='QA汇总

Client QA

支持语言

Q：client 目前有哪些编程语言，是否支持 node js？
A：目前主要支持的编程语言有 c++,python,java；目前不支持 node js。使用 node 作为主要开发语言的用户，可以使用 tugraph 提供的 restful api 来调用。建议使用 Cypher 来封装调用接口。后续版本 restful api 将不再进行更新维护，只会保留登录、登出、刷新 token、cypher 调用这几个常见的 api。' metadata={'Header 1': 'QA汇总', 'Header 2': 'Client QA', 'Header 3': '支持语言'}"
OGC定义了哪些空间数据的标准表示格式？,"page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

OGC(Open Geospatial Consortium) 定义了空间数据的标准表示格式，分别为EWKT(extended well known text)与EWKB(extended well known binary)格式，用于在不同系统和平台之间交换和存储空间数据，现已被广泛采用。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现'}","page_content='地理空间数据类型使用示例

2. 预备知识

2.3 数据存储格式

OGC(Open Geospatial Consortium) 定义了空间数据的标准表示格式，分别为WKT与WKB格式，用于在不同系统和平台之间交换和存储空间数据，现已被广泛采用。其中WKT(well-kown text)格式, 是一种文本标记语言,易于人类阅读和编写，而WKB(Well-Known Binary)格式采用一系列字节来编码空间数据，更适合在计算机中存储;  
**WKT:**  
```
POINT(<x> <y>)
LINESTRING(<x1> <y1>, <x2><y2>, ...)
```  
WKT格式的数据如上例所示，先指定空间数据类型，再在括号内指定具体的坐标，一个坐标对表示一个点，每个坐标对之间用逗号隔开。对于Polygon类型的数据，第一个坐标对需要与最后一个坐标对相同，形成闭合的面。  
**WKB:**  
![image.png](../../../images/spatail/WKB.png)  
针对EWKB格式的编码，说明如下:  
- 第0 - 1位: 编码方式;
- 第2 - 5位: 空间数据类型;
- 0100: point
- 0200: linestring
- 0300: polygon
- 第6 - 9位: 数据维度;
- 0020: 二维
- 0030: 三维
- 第10 - 17位: 坐标系的EPSG编码;
- 第18 - n位: double类型的坐标对的16进制表示。' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '2. 预备知识', 'Header 3': '2.3 数据存储格式'}","page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的表示

空间数据类型可以用不同的坐标系来表示，EPSG<sup>[1]</sup>是一个标准化的地理空间参考系统标识符集合， 用于标识不同的地理空间参考系统，包括坐标系统、地理坐标系、投影坐标系等。通常使用EPSG编码表示数据的坐标系。行业内一般采用  
-   •WGS84坐标系（没错，就是GPS系统的坐标系），标识符为EPSG 4326  
-   •Cartesian（笛卡尔）坐标系（没错，就是你高中数学学的直角坐标系），标识符为EPSG 7203  
WGS84是全球定位系统(GPS)的基础，允许全球的GPS接收器确定精确位置。几乎所有现代GPS设备都是基于WGS84坐标系来提供位置信息。在地图制作和GIS（地图制作和地理信息系统）领域，WGS84被广泛用于定义地球上的位置。这包括各种类型的地图创建、空间数据分析和管理等。  
Cartesian（笛卡尔）坐标系，又称直角坐标系，是一种最基本、最广泛应用的坐标系统。它通过两条数轴定义一个平面，三条数轴定义一个空间，这些轴互相垂直，在数学、物理、工程、天文和许多其他领域中有着广泛的应用。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的表示'}"
db.importor.dataImportor函数的目的是什么？,"page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

#### 6.10.1.指定文件内容导入  
- **URI**: `/db/{graph_name}/import/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |
| data | 要导入的文件内容（建议最大在 16MB 左右，最长不超过 17MB） | 字符串 / 数组 / 对象 |
| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""description"": ""{\\""files\\"":[{\\""columns\\"":[\\""SRC_ID\\"",\\""role\\"",\\""DST_ID\\""],\\""format\\"":\\""CSV\\"",\\""label\\"":\\""role\\"",\\""SRC_ID\\"":\\""actor\\"",\\""DST_ID\\"":\\""movie\\""}]}""}"",
""data"": ""1,Role1,2\n3,Role2,4\n"",
""continue_on_error"": true,
""delimiter"": "",""
}
```  
上述 description 的值是如下 json 序列化后的字符串  
```json
{
""files"": [
{
""format"": ""CSV"",
""label"": ""role"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""log"": ""Missing src uid 1\n""
}
```  
由于请求中指定了在出错时继续，该返回信息说明 SRC_ID 为 1 的边没有被导入，而其他信息导入成功。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}","page_content='数据导出

2.导出命令

该工具的命令示例如下：  
```bash
$ lgraph_export -d {database_dir} -e {export_destination_dir} -g {graph_to_use} -u {username} -p {password} -f {output_format}
```  
其中：  
- `-d {database_dir}` 指定需要进行数据导出的数据库所在目录，默认值为 `./testdb`。
- `-e {export_destination_dir}` 指定导出文件存放的目录，默认值为 `./exportdir`。
- `-g {graph_to_use}` 指定图数据库的种类，默认为 `default` 。
- `-u {username}` 指定进行该导出操作的用户的用户名。
- `-p {password}` 指定进行该导出操作的用户的用户密码。
- `-s {field_separator}` 指定导出文件的分隔符，默认为逗号。
- `-f {output_format}` 指定导出数据的格式，`json`或者`csv`，默认为`csv`。
- `-h` 除上述指定参数外，也可以使用该参数查看该工具的使用帮助。' metadata={'Header 1': '数据导出', 'Header 2': '2.导出命令'}","page_content='集成测试

2.TuGraph集成测试框架

2.1.组件描述

| 组件名称            | 组件功能                       | 实现方式                                  |
|-----------------|----------------------------|---------------------------------------|
| server          | TuGraph单机服务                | 开启子进程并在子进程中启动服务                       |
| client          | TuGraph Rpc Client         | 当前进程中开启TuGraph Python Rpc Client发送请求  |
| importor        | TuGraph Importor           | 开启子进程并在子进程中处理导入请求                     |
| exportor        | TuGraph Exportor           | 开启子进程并在子进程中处理导出请求                     |
| backup_binlog   | TuGraph Backup Binlog      | 开启子进程并在子进程中处理备份binlog的请求              |
| backup_copy_dir | TuGraph Backup             | 开启子进程并在子进程中处理备份完整db的请求                |
| build_so        | 编译c++动态连接库的组件              | 开启子进程并在子进程中处理gcc编译逻辑                  |
| copy_snapshot   | TuGraph Copy Snapshot      | 当前进程中处理备份snapshot的请求                  |
| copydir         | 文件夹拷贝                      | 当前进程中处理文件夹拷贝请求                        |
| exec            | 执行c++/java可执行文件            | 开启子进程并在子进程中启动C++可执行文件                 |
| algo            | 执行算法                       | 开启子进程并在子进程中执行算法                       |
| bash            | 执行bash命令                   | 开启子进程并在子进程中执行bash命令                   |
| rest            | TuGraph Python Rest Client | 当前进程中开启TuGraph Python Rest Client发送请求 |' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.1.组件描述'}"
TuGraph企业版是什么？,"page_content='什么是TuGraph

4. TuGraph企业版

企业版对商业化功能支持更加完善，包括分布式集群架构，覆盖探索、研发、服务、运维管理全生命周期的一站式图平台，在线、近线、离线的图计算引擎，支持流式、大数据类数据源，多地多中心的部署形态，以及专家支持服务等。企业版是商业化解决方案的理想选择。  
如需商业支持，请联系我们：  
- 电话：400-903-0809
- 邮件：tugraph@service.alipay.com
- 官网：https://tugraph.antgroup.com' metadata={'Header 1': '什么是TuGraph', 'Header 2': '4. TuGraph企业版'}","page_content='TuGraph在图计算系统建设中的作用

TuGraph 技术优势

TuGraph 企业版特色

除了开源版本，我们也继续提供商业版本。这个版本包含一个分布式图数据库，以及离线计算引擎和流式图计算功能。此外，我们还提供了 TuGraph Platform 一站式图平台，包括运维、可视化等功能。在这个平台上，用户可以在图数据库中执行流式计算，并在线写回数据库。这种方式通常用于实时查询结果，因为流式计算的时间可能比较长，但用户可以立即查询到较早的结果。这对于在线业务来说非常重要。  
商业化产品还提供私有化部署，也可以通过一体机的方式部署硬件，并将很快推出云上部署方案，这样大家就可以在云上体验我们的产品。' metadata={'Header 1': 'TuGraph在图计算系统建设中的作用', 'Header 2': 'TuGraph 技术优势', 'Header 3': 'TuGraph 企业版特色'}","page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}"
请求存储过程列表时，应该使用哪种HTTP方法和URI？,"page_content='RESTful API Legacy

5.存储过程

5.2.列出所有存储过程

- **URI**: `/db/{graph_name}/cpp_plugin|python_plugin`
- **METHOD**: GET
- **RESPONSE**: 存储过程列表，其中每个元素是一个 plugin 的描述，其格式为：
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | 存储过程名 | 字符串 |
| description | 存储过程描述 | 字符串 |
| read_only | 存储过程是否只读 | 布尔值 |  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/cpp_plugin
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
Output:
{
[
{
""description"":""adds a vertex label to the db"",
""name"":""add_label"",
""read_only"":false
},
{
""description"": ""scans graph and get number of edges"",
""name"": ""scan_graph"",
""read_only"": true
}
]
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程', 'Header 3': '5.2.列出所有存储过程'}","page_content='Procedure API

4.2.如何使用存储过程

4.2.2.列出已加载的存储过程

在服务器运行过程中，用户可以随时获取存储过程列表。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin')
>>> r.status_code
200
>>> r.text
'{""plugins"":[{""description"":""Custom Page Rank Procedure"", ""name"":""age_10"", ""read_only"":true}]}'
```' metadata={'Header 1': 'Procedure API', 'Header 2': '4.2.如何使用存储过程', 'Header 3': '4.2.2.列出已加载的存储过程'}","page_content='RPC API

5.存储过程

5.4.列举存储过程

列举存储过程请求不需要参数，以C++为例，用户列举存储过程的方式如下所示：
```C++
LGraphRequest req;
req.set_is_write_op(false);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
pluginRequest->mutable_list_plugin_request();
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
result = res.mutable_plugin_response()->mutable_list_plugin_response()->reply();
```
列举存储过程的响应的参数如下所示：
- reply: JSON格式的procedure列表' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.4.列举存储过程'}"
TuGraph基础算法包包含哪些算法？,"page_content='内置算法

简介

TuGraph目前包含以下6个基础算法28种扩展算法，共34个图算法：' metadata={'Header 1': '内置算法', 'Header 2': '简介'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。  
<table><tbody><tr><td>算法类型</td><td>中文算法名</td><td>英文算法名</td><td>程序名</td></tr><tr><td rowspan=""5"">路径查询</td><td>广度优先搜索</td><td>Breadth-First Search</td><td>bfs</td></tr><tr><td>单源最短路径</td><td>Single-Source Shortest Path</td><td>sssp</td></tr><tr><td>全对最短路径</td><td>All-Pair Shortest Path</td><td>apsp</td></tr><tr><td>多源最短路径</td><td>Multiple-source Shortest Paths</td><td>mssp</td></tr><tr><td>两点间最短路径</td><td>Single-Pair Shortest Path</td><td>spsp</td></tr><tr><td rowspan=""9"">重要性分析</td><td>网页排序</td><td>Pagerank</td><td>pagerank</td></tr><tr><td>介数中心度</td><td>Betweenness Centrality</td><td>bc</td></tr><tr><td>置信度传播</td><td>Belief Propagation</td><td>bp</td></tr><tr><td>距离中心度</td><td>Closeness Centrality</td><td>clce</td></tr><tr><td>个性化网页排序</td><td>Personalized PageRank</td><td>ppr</td></tr><tr><td>带权重的网页排序</td><td>Weighted Pagerank Algorithm</td><td>wpagerank</td></tr><tr><td>信任指数排名</td><td>Trustrank</td><td>trustrank</td></tr><tr><td>sybil检测算法</td><td>Sybil Rank</td><td>sybilrank</td></tr><tr><td>超链接主题搜索</td><td>Hyperlink-Induced Topic Search</td><td>hits</td></tr><tr><td rowspan=""4"">关联性分析</td><td>平均集聚系数</td><td>Local Clustering Coefficient</td><td>lcc</td></tr><tr><td>共同邻居</td><td>Common Neighborhood</td><td>cn</td></tr><tr><td>度数关联度</td><td>Degree Correlation</td><td>dc</td></tr><tr><td>杰卡德系数</td><td>Jaccard Index</td><td>ji</td></tr><tr><td rowspan=""5"">图结构</td><td>直径估计</td><td>Dimension Estimation</td><td>de</td></tr><tr>' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}","page_content='OlapOnDisk API

1. 简介

TuGraph的Standalone模式可用于加载图数据文件，其中图数据文件来源可包含text文本文件、BINARY_FILE二进制文件和ODPS源。在该模式下，TuGraph可实现多数据来源快速加载成图，然后在该图上运行如BFS、WCC、SSSP等迭代式算法，并输出最终结果至终端。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph内置了大量的常见图分析算法和丰富的辅助接口，因此用户几乎不需要自己实现具体的图计算过程，只需要在实现自己的存储过程的时候将相应算法库的头文件(.h)包含到自己的程序中，并在编译阶段链接自己的动态库文件即可。  
该文档主要介绍了Standalone的常用接口，使用到的辅助函数主要包含在OlapOnDB类。同时为帮助用户理解方便，对BFS算法进行举例说明。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '1. 简介'}"
REST 服务器的默认端口号是多少？,"page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

#### 2.3.1.rest  
样例代码中在test_get_info函数执行之前先启动server，server启动后启动了rest client，进入test_get_info函数后获取server的一些信息，并通过assert判断是否有获取到cpu的信息。  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7073 --rpc_port 9093"",
""cleanup_dir"":[""./testdb""]}
RESTTOPT = {""port"":""7073"", ""user"":""admin"", ""password"":""73@TuGraph""}
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""rest"", [RESTTOPT], indirect=True)
def test_get_info(self, server, rest):
res = rest.get_server_info()
log.info(""res : %s"", res)
assert('cpu' in res)
```  
#### 2.3.2.client  
样例代码中在test_flushdb函数执行之前先执行了数据离线导入逻辑，并启动server后，通过client创建链接，进入test_flushdb函数后，通过查询点的个数判断导入是否成功，导入成功后执行flushDB操作，再次通过assert判断是否能正常清空db  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}

CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}

IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}

@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_flushdb(self, importor, server, client):
ret = client.callCypher(""MATCH (n) RETURN n LIMIT 100"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert len(res) == 21
ret = client.callCypher(""CALL db.flushDB()"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}","page_content='Bolt客户端

开启Bolt端口

Bolt端口是默认开启的，默认端口是7687。如果需要修改端口，请在配置文件中自行修改。基于docker方式部署的服务，配置文件在容器内 `/usr/local/etc/lgraph.json`文件中；如果是用rpm包部署的服务，配置文件在服务器的`/usr/local/etc/lgraph.json`。 修改端口后为了使端口生效，需要重启服务，重启服务的具体操作可见[数据库运行](../../5.installation&running/7.tugraph-running.md)。另外，配置文件中的详细配置项，可见[数据库运行](../../5.installation&running/7.tugraph-running.md)中的服务配置章节。' metadata={'Header 1': 'Bolt客户端', 'Header 2': '开启Bolt端口'}","page_content='TuGraph-Restful-Server

1.TuGraph-Restful-Server 简介

TuGraph Restful Server 使用brpc框架支持的http协议，提供restful接口查询功能，在实现中，restful server 与rpc server 使用同一个端口。目前restful接口提供文件上传，数据导入，导入进度查询，cypher查询，文件删除等功能' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '1.TuGraph-Restful-Server 简介'}"
如果需要对一个角色进行禁用，调用何种函数，并且该函数在何种情况下返回true？,"page_content='可视化操作手册

2.操作指南

2.5.控制台

`控制台`提供可视化的的账户管理和数据库信息查看功能，它为用户提供了全面的账户和角色管理功能，包括账户的增删改查以及禁用，角色的增删改查以及禁用。此外，它也为用户提供了便捷的数据库信息查看功能，让用户可以轻松地查看图数据库的基础信息和配置信息。其中，基础信息主要包括版本号、运行时间、CPP编译版本号等，而数据库配置信息则包括端口号、系统功能参数配置等。  
#### 2.5.1.账户管理  
##### 2.5.1.1.账户管理  
###### a.添加账户  
在`账户管理`界面点击`添加`按钮创建新的账户，用户需要输入账户名称、账户描述、账户密码以及相关角色。  
![账户管理-添加账户按钮](../../../images/browser/account-add-button.png)  
- 账户名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 相关角色：新建账户时必须要选择一个角色，在账户添加成功后，系统会自动生成一个与账户名称一样的角色。  
![账户管理-添加账户](../../../images/browser/account-add.png)  
###### b.编辑账户  
在`账户管理`界面点击`添加`按钮创建新的账户，用户可以编辑账户描述、账户密码以及相关角色。  
![账户管理-编辑账户](../../../images/browser/account-edit.png)  
###### c.禁用账户  
在`账户管理`界面点击`禁用`按钮禁止对应的账户登录和访问，点击`启用`按钮开启对应的账户登录和访问权限。  
![账户管理-禁用](../../../images/browser/account-disable.png)
![账户管理-启用](../../../images/browser/account-enable.png)  
###### d.删除账户  
在`账户管理`界面点击`删除`按钮删除对应的账户。  
![账户管理-删除](../../../images/browser/account-delete.png)  
##### 2.5.1.2.角色管理  
###### a.添加角色  
在`角色管理`界面点击`添加`按钮创建新的角色，用户需要输入角色名称、角色描述以及图权限。  
![角色管理-添加角色按钮](../../../images/browser/role-add-button.png)  
- 角色名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图权限：browser支持全部、读、写和无共四类图权限配置。
- 全部：对应图的读和写权限，包含编辑图模型权限（schema）。
- 读写：对应图的写权限，不包含编辑图模型权限（schema）。
- 只读：对应图的读权限。
- 无：无法访问和操作对应图。
- 角色冲突：当两个角色对同一个图有不同图权限，同时对一个账户授权了这两个角色，该账户对该图的图权限为两个角色的并集。  
![角色管理-添加角色](../../../images/browser/role-add.png)  
###### b.编辑角色  
在`角色管理`界面点击`编辑`按钮编辑已有角色，用户可以编辑角色描述以及图权限。  
![角色管理-编辑角色](../../../images/browser/role-edit.png)  
###### c.禁用角色  
在`角色管理`界面点击`禁用`按钮禁止对应的角色，点击`启用`按钮开启对应的角色。禁用角色后，对应角色图访问权限失效。  
- 禁用角色：禁用之后，对应角色图访问权限失效。
- 当一个用户拥有两个角色对同一个图有操作权限时，当禁用其中一个角色时，另一个角色权限同样有效。  
![角色管理-禁用](../../../images/browser/role-disable.png)
![角色管理-启用](../../../images/browser/role-enable.png)  
###### d.删除角色  
在`角色管理`界面点击`删除`按钮删除对应的角色。  
![角色管理-删除](../../../images/browser/role-delete.png)  
#### 2.5.2.数据库信息  
##### 2.5.2.1.基础信息  
`基础信息`获取当前系统运行的状态，并展示关键信息。  
![数据库信息-基础信息](../../../images/browser/db_basic.png)  
|参数    |含义    |
|-------|--------|
|TuGraph版本号|当前TuGraph的版本号，x.x.x|
|运行时间|TuGraph服务启动到现' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.5.控制台'}","page_content='用户权限

4.常用权限操作

4.2.角色操作

- 创建角色  
```cypher
CALL dbms.security.createRole(role_name::STRING,desc::STRING)
```  
- 删除角色  
```cypher
CALL dbms.security.deleteRole(role_name::STRING
```  
- 列出所有角色  
```cypher
CALL dbms.security.listRoles()
```  
- 禁用/启用角色  
```cypher
CALL dbms.security.disableRole(role::STRING,disable::BOOLEAN)
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.2.角色操作'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLm' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}"
TuGraph更新之后，原库的数据会丢吗？,"page_content='数据迁移

1. 简介

数据迁移是指将数据从一个系统、存储介质或应用程序迁移到另一个系统、存储介质或应用程序的过程。当TuGraph要升级或者系统硬件环境发生变化时，
需要对原TuGraph服务中的数据进行迁移。以系统硬件环境和软件版本为依据进行划分，本文将数据迁移分为三种方案：
1. 兼容迁移：当迁移前后系统环境一致且TuGraph软件兼容时，可以直接使用备份恢复的方式迁移数据；
2. 升级迁移：当迁移前后系统环境不一致或TuGraph软件不兼容时，需要使用先导出数据再重新导入的方式迁移数据；
3. 在线迁移：当对高可用集群进行数据迁移且集群网络环境良好时，可以使用增删节点的的方式将原集群平滑切换到新集群。
接下来本文将详细介绍这三种方案。' metadata={'Header 1': '数据迁移', 'Header 2': '1. 简介'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

一、高可用架构介绍

4.TuGraph-DB高可用架构—Raft 共识算法

针对上述缺点，我们选用了 Raft 算法来实现高可用架构。Raft 算法的优点包括：  
-   首先，它保持了一主多备的易用性。它有一个强leader可以对外提供服务。
-   第二是一致性。一主多备的模式是通过定期复制的方式去进行数据备份。但是Raft算法采用的是日志复制方式，复制的是日志并不是数据，当写请求的日志到来之后，会逐个按顺序发送给每一个节点，当超过半数的节点达成一致之后才会提交，所以它不仅不会丢失数据，甚至也不会存在日志空洞或乱序的情况。
-   有了一致性的保证后，安全性也就有了保证，当超过半数的节点达成一致之后，才应用日志，这样就能解决网络分区延迟、丢包、冗余和乱序的错误。
-   基于一致性和安全性，它的可用性也就得到了保证，只要少于半数的节点宕机，即使主机宕机，也可以快速恢复应用，通过一次选举的时间就可以重新选出一个leader对外提供服务。  
国标对于高可用系统的指标评估，RTO 和 RPO 分别是恢复时间指标和恢复点目标，有 6 个等级，TuGraph-DB 已经达到了最高等级。当少量节点故障时，RPO 是 0，也就是没有数据损失，数据恢复时间点指标是小于 15 秒。即使是在部署的时候，无论是在同城的两中心、三中心，还是多地的多中心，都可以达成 RTO 小于 15 秒的标准。  
Raft算法优点:  
• 易用性：状态简单，强Leader  
• 一致性：日志逐个复制，超过半数节点达成一致才提交，不存在日志空洞  
• 安全性：超半数节点达成一致才应用日志，能解决网络延迟、分区、丢包、冗余和乱序等错误  
• 可用性：能容忍少于半数的节点宕机，主机宕机时自动触发选举流程，选出Leader后快速恢复应用用户价值  
• 支持多地多中心部署，容灾和恢复能力强  
• RPO=0（少数节点故障），RTO<15S，超越国标恢复能力6级' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '一、高可用架构介绍', 'Header 3': '4.TuGraph-DB高可用架构—Raft 共识算法'}","page_content='数据迁移

2. 兼容迁移

兼容迁移指的是在系统环境不变，且TuGraph软件版本兼容时，原服务的数据和存储过程可以在新服务中使用，所以可以直接迁移。
用户可以先使用`lgraph_backup`工具备份数据，然后将数据传输到新机器中并重启服务。具体迁移步骤如下：' metadata={'Header 1': '数据迁移', 'Header 2': '2. 兼容迁移'}"
"如果节点中未包含属性""belt""，应该返回什么值？","page_content='RESTful API Legacy

6.Deprecated

6.3.服务器状态

#### 6.3.1.修改服务器配置  
修改服务器配置，配置修改后立即生效，并将影响所有服务器。这些配置的优先级高于配置文件以及命令行参数。  
- **URI**: `/config`
- **METHOD**: PUT
- **REQUEST**:  
请求为一个字典，使用 `{""opt1"":v1}` 可以将名为`opt1`的配置修改为`v1`。  
| 配置名               | 说明                   | 值类型 |
| -------------------- | ---------------------- | ------ |
| OPT_DB_ASYNC         | 是否启用异步模式       | 布尔值 |
| OPT_TXN_OPTIMISTIC   | 是否默认使用乐观事务锁 | 布尔值 |
| OPT_AUDIT_LOG_ENABLE | 是否启用审计日志       | 布尔值 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• PUT http://localhost:7070/config
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""OPT_DB_ASYNC"": true,
""OPT_AUDIT_LOG_ENABLE"": false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.3.2.当前服务器状态  
- **URI**: `/info`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| lgraph_version | 服务器版本号 | 字符串 |
| git_branch | 服务器代码分支 | 字符串 |
| git_commit | 服务器代码版本 | 字符串 |
| web_commit | 前端码版本 | 字符串 |
| cpp_id | CPP 编译器 ID | 字符串 |
| cpp_version | CPP 编译器版本 | 字符串 |
| python_version | PYTHON 版本 | 字符串 |
| node | 点 uri | 字符串 |
| relationship | 边 uri | 字符串 |
| cpu | cpu 信息 | 字典，格式参见[服务器 CPU 状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8CPU%E7%8A%B6%E6%80%81) |
| disk | 硬盘 IO 信息 | 字典，格式参见[服务器硬盘状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E7%9B%98%E7%8A%B6%E6%80%81) |
| memory | 内存信息 | 字典，格式参见[服务器内存状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%86%85%E5%AD%98%E7%8A%B6%E6%80%81) |
| db_space | 图数据库占用空间 | 字典，格式参见[图数据库占用空间](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4) |
| db_config | 图数据库配置信息 | 字典，格式参见[图数据库配置信息](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF) |
| up_time | 数据库在线时长（秒） | 整型 |  
**Example request.**  
```
• GET http://localhost:7070/info
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""lgraph_version"": ""1.2.0"",
""git_branch"": ""master"",
""git_commit"": ""9e2977d"",
""web_commit"": ""1e2823d"",
""cpu_id"": ""GUN"",
""cpu_' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.3.服务器状态'}","page_content='Geaflow支持以下逻辑运算：  
操作|描述
----------------------|------
boolean1 OR boolean2 | 如果boolean1为true或boolean2为true，则返回true。
boolean1 AND boolean2 | 仅在boolean1为true和boolean2为true时才返回true。
NOT boolean | 返回给定布尔变量的NOT操作的结果。
boolean IS FALSE | 如果布尔变量为false，则返回true。如果布尔变量是UNKNOWN，则返回false。
boolean IS NOT FALSE | 如果布尔变量为true，则返回true。如果布尔变量是UNKNOWN，则返回true。
boolean IS TRUE | 如果布尔变量为true，则返回true。如果布尔变量是UNKNOWN，则返回false。
boolean IS NOT TRUE | 如果布尔变量为false，则返回true。如果布尔变量是UNKNOWN，则返回true。
value1 = value2 | 如果value1等于value2，则返回true。
value1 <> value2 | 如果value1不等于value2，则返回true。
value1 > value2 | 如果value1大于value2，则返回true。
value1 >= value2 | 如果value1大于或等于value2，则返回true。
value1 < value2 | 如果value1小于value2，则返回true。
value1 <= value2 | 如果value1小于或等于value2，则返回true。
value IS NULL | 如果value为null，则返回true。
value IS NOT NULL | 如果value不为null，则返回true。
value1 IS DISTINCT FROM value2 | 如果value1与value2不同，则返回true。如果value1和value2都为null，则它们被视为相等。
value1 IS NOT DISTINCT FROM value2 | 如果value1等于value2，则返回true。如果value1和value2都为null，则它们被视为相等。
value1 BETWEEN value2 AND value3 | 如果value1大于或等于value2且小于value3，则返回true。
value1 NOT BETWEEN value2 AND value3 | 如果value1小于value2或大于或等于value3，则返回true。
string1 LIKE string2 [ ESCAPE string3 ] | 对字符串string1进行模糊匹配，如果匹配到模式string2则返回true，如果不匹配则返回false。
string1 NOT LIKE string2 [ ESCAPE string3 ] | 对字符串string1进行模糊匹配，如果匹配到模式string2则返回false，如果不匹配则返回true。
value IN (value [, value]* ) | 如果value等于列表中的任何一个值，则返回true。
value NOT IN (value [, value]* ) | 如果value不等于列表中的任何一个值，则返回true。'","page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

TuGraph 是一个具备多图能力的强模式属性图数据库。在每一张子图中，每种点和边都需要有预定义的数据格式。数据格式由 Label 决定，每种 Label 都有自己的数据格式。用户可以使用 REST API 添加，删除和查询 Label 及其对应的数据格式。  
Label 操作对应的 URI 格式为  
```
http://{host}:{port}/db/{graph_name}/label/{type}/{label_name}
```  
其中{type}可以是 node 或者 relationship。  
#### 6.6.1.创建Label  
创建 Label 的过程同时也是定义其数据类型的过程。只有创建了 Label 才能在图中插入相应类型的点或者边。  
- **URI**: `/db/{graph_name}/label`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | Label 名 | 字符串 |
| fields | 数据列定义 | 列表 |
| is_vertex | 是否是点 Label | 布尔值 |
| primary | 点的主键属性 | 字符串 |
| edge_constraints | 边的约束 | 列表 |  
`primary` 在 `is_vertex` 为 `true` 的时候设置，这个字段只有点才有, 创建点的时候必须设置。  
`edge_constraints` 在 `is_vertex` 为 `false` 的时候设置，这个字段只有边有。这个字段限制了该边的起点和终点只能是哪些点的组合，比如：`[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]`，限制了该边只能是从 `vertex_label1` 到 `vertex_label2` 和 从 `vertex_label3` 到 `vertex_label4`。如果不想有任何限制，不设置该字段即可。  
其中`fields`为一个数组，其中每个元素定义数据的一列，内容如下：  
| 域名     | 说明                                     | 类型                                                                                                |
| -------- | ---------------------------------------- | --------------------------------------------------------------------------------------------------- |
| name     | 列名                                     | 字符串                                                                                              |
| type     | 列数据类型                               | 字符串，有以下类型： int8, int16, int32, int64, float, double, string, date, datetime, binary, bool |
| optional | 数据是否可以为空（可选，缺省值为 false） | 布尔值                                                                                              |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/label
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""name"":""Actor"",
""fields"": [
{""name"":""uid"", ""type"":""int64"", ""optional"":false},
{""name"":""name"", ""type"":""st' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}"
磁盘IO警报是在什么情况下触发的？,"page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客户端端口。默认端口为 7687。                                ' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='自定义Connector

TableSource

TableSource 接口用于从连接器中读取数据。  
```java
/**
* Interface for table source.
*/
public interface TableSource extends Serializable {

/**
* The init method for compile time.
*/
void init(Configuration tableConf, TableSchema tableSchema);

/**
* The init method for runtime.
*/
void open(RuntimeContext context);

/**
* List all the partitions for the source.
*/
List<Partition> listPartitions();

/**
* Returns the {@link TableDeserializer} for the source to convert data read from
* the source to {@link Row}.
*/
<IN> TableDeserializer<IN> getDeserializer(Configuration conf);

/**
* Fetch data for the partition from start offset. if the windowSize is -1, it represents an
* all-window which will read all the data from the source, else return widow size for data.
*/
<T> FetchData<T> fetch(Partition partition, Optional<Offset> startOffset, long windowSize) throws IOException;

/**
* The close callback for the job finish the execution.
*/
void close();
}

```' metadata={'Header 1': '自定义Connector', 'Header 2': 'TableSource'}","page_content='数据预热

1.简介

TuGraph 是基于磁盘的数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '数据预热', 'Header 2': '1.简介'}"
调用 Close() 函数后 InEdgeIterator 的状态是怎样的？,"page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentric function进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |  
- 详细接口  
```java
public interface VertexCentricTraversalFunction<K, VV, EV, M, R> extends VertexCentricFunction<K, VV
, EV, M> {

void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);
/** 图遍历算法初始化方法 */
void init(ITraversalRequest<K> traversalRequest);
/** 实现图遍历逻辑 */
void compute(K vertexId, Iterator<M> messageIterator);

void finish();

void close();

interface VertexCentricTraversalFuncContext<K, VV, EV, M, R> extends VertexCentricFuncContext<K,
VV, EV, M> {
/** 获取图遍历结果 */
void takeResponse(ITraversalResponse<R> response);
/** 获取开始图遍历的点 */
TraversalVertexQuery<K, VV> vertex();
/** 获取开始图遍历的边 */
TraversalEdgeQuery<K, EV> edges();

void broadcast(IGraphMessage<K, M> message);
}

interface TraversalVertexQuery<K, VV> extends VertexQuery<K, VV> {
/** 获取图遍历中点的迭代器 */
Iterator<K> loadIdIterator();
}

interface TraversalEdgeQuery<K, EV> extends EdgeQuery<K, EV> {
/** 通过指定的点id，获取对应的图遍历起点 */
TraversalEdgeQuery<K, EV> withId(K vertexId);
}
}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}","page_content='Python Olap API

4. Olap API

图类OlapBase

- `NumVertices()-> size_t`：获取点数
- `NumEdges()-> size_t`：获取边数
- `OutDegree(size_t vid)-> size_t`：点vid的出度
- `InDegree(size_t vid)-> size_t`：点vid的入度  
- `AllocVertexArray[VertexData]() ->ParallelVector[VertexData]`：分配一个类型为VertexData的数组，大小为点个数
- `AllocVertexSubset()-> ParallelBitset`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `OutEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有出边集合
- `InEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有入边集合
- `Transpose()-> cython.void`：对有向图进行图反转
- `LoadFromArray(edge_array: cython.p_char, input_vertices: size_t, input_edges: size_t, edge_direction_policy: EdgeDirectionPolicy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。  
- `AcquireVertexLock(vid: size_t)-> cython.void`：对点vid加锁，禁止其它线程对该锁对应的点数据进行访存
- `void ReleaseVertexLock(vid: size_t)-> cython.void`：对点vid解锁，所有线程均可访存该锁对应的点数据  
TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程，在Python中与C++使用方法稍有不同。  
```python
# 函数名称:ProcessVertexInRange[ReducedSum, Algorithm](
#           work: (algo: Algorithm, vi: size_t)-> ReducedSum,
#           lower: size_t, upper: size_t,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#     函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
#     第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
#     具体实现请参考include/lgraph/olap_base.h中具体代码
#
#     使用示例:统计数组parent数组中有出边的点个数

import cython
from cython.cimports.olap_base import *


@cython.cclass
class CountCore:
graph: cython. pointer(OlapBase[Empty])
parent: ParallelVector[size_t]

@cython.cfunc
@cython.nogil
def Work(self, vi: size_t) -> size_t:
if self.graph.OutDegree(self.parent[vi]) > 0:
return 1
return 0

def run(self, pointer_g: cython. pointer(OlapBase[Empty])):
self.graph = pointe' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}","page_content='自定义Connector

TableSource

TableSource 接口用于从连接器中读取数据。  
```java
/**
* Interface for table source.
*/
public interface TableSource extends Serializable {

/**
* The init method for compile time.
*/
void init(Configuration tableConf, TableSchema tableSchema);

/**
* The init method for runtime.
*/
void open(RuntimeContext context);

/**
* List all the partitions for the source.
*/
List<Partition> listPartitions();

/**
* Returns the {@link TableDeserializer} for the source to convert data read from
* the source to {@link Row}.
*/
<IN> TableDeserializer<IN> getDeserializer(Configuration conf);

/**
* Fetch data for the partition from start offset. if the windowSize is -1, it represents an
* all-window which will read all the data from the source, else return widow size for data.
*/
<T> FetchData<T> fetch(Partition partition, Optional<Offset> startOffset, long windowSize) throws IOException;

/**
* The close callback for the job finish the execution.
*/
void close();
}

```' metadata={'Header 1': '自定义Connector', 'Header 2': 'TableSource'}"
DUAL_DIRECTION表示什么？,"page_content='OlapOnDisk API

3. 其他常用函数功能描述

3.1 图加载

TuGraph-Standalone对于图数据文件的加载来源主要分为三大类：文本文件、二进制文件和ODPS。二进制文件为将边数据的二进制表示按顺序排列的文件，能够节省大量存储空间。其加载函数分为三种，分别是：  
- `void Load(ConfigBase<EdgeData> config,EdgeDirectionPolicy edge_direction_policy = DUAL_DIRECTION)`：图数据文件的加载方式，包含两个参数，其含义分别表示：
- `config`：需要加载的配置参数。该参数内保存了该图的一般信息（如数据来源，算法名称，数据输入、输出路径，点个数等）以及根据不同数据来源、不同算法所配置的不同信息参数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。其中DUAL_DIRECTION为默认的图加载方式。
DUAL_DIRECTION : 输入文件为非对称图，加载图为非对称图。
MAKE_SYMMETRIC : 输入文件为非对称图，加载图为对称图。
INPUT_SYMMETRIC : 输入文件为对称图，加载图为对称图。
对应的详细介绍见lgraph文件夹下的olap_config.h文件的`enum EdgeDirectionPolicy`。  
- `void LoadVertexArrayTxt<V>(V * array, std::string path, std::function<size_t(const char *, const char *, VertexUnit<V> &)> parse_line)`：将文件中的点-数据对按照点id的顺序加载到数组中。各参数表示意义分别为：
- `array`：待读入数据的数组
- `path`：读取文件的路径，文件中每行表示一对点-数据对
- `parse_line`：用户自定义函数，告诉系统如何将一行文本数据解析为一个点-数据对。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '3. 其他常用函数功能描述', 'Header 3': '3.1 图加载'}","page_content='OlapBase API

7. 图类OlapBase

7.2 点集和边集及其相关操作

- `ParallelVector<VertexData> AllocVertexArray<VertexData>()`：分配一个类型为VertexData的数组，大小为点个数
- `void fill_vertex_array<V>(V * array, V value)`：将数组array中的所有元素赋值为value
- `ParallelBitset AllocVertexSubset()`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `AdjList<EdgeData> OutEdges(size_t vid)`：获取点v的所有出边集合
- `AdjList<EdgeData> InEdges(size_t vid)`：获取点v的所有入边集合
- `void Transpose()`：对有向图进行图反转
- `LoadFromArray(char * edge_array, VertexId input_vertices, EdgeId input_edges,  EdgeDirectionPolicy edge_direction_policy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.2 点集和边集及其相关操作'}","page_content='OlapOnDisk API

2. 算法举例

2.3 主函数

```C++
int main(int argc, char** argv) {
double start_time;
// 统计内存消耗类MemUsage实例化
MemUsage memUsage;
memUsage.startMemRecord();

// prepare
start_time = get_time();
// 配置类MyConfig实例化
MyConfig config(argc, argv);
size_t root_vid = config.root;
// OlapOnDisk类实例化
OlapOnDisk<Empty> graph;
graph.Load(config, DUAL_DIRECTION);
memUsage.print();
memUsage.reset();
// 统计图加载消耗时间
auto prepare_cost = get_time() - start_time;
printf(""prepare_cost = %.2lf(s)\n"", prepare_cost);

// core
start_time = get_time();
// 创建数组用于统计某节点是否遍历过
auto parent = graph.AllocVertexArray<size_t>();
// 宽度优先搜索算法，返回图内root_vid根结点连接的节点个数
size_t count = BFSCore(graph, root_vid, parent);
memUsage.print();
memUsage.reset();
auto core_cost = get_time() - start_time;
printf(""core_cost = %.2lf(s)\n"", core_cost);

// output
start_time = get_time();
// 打印相关信息至终端
printf(""found_vertices = %ld\n"", count);
auto output_cost = get_time() - start_time;
printf(""output_cost = %.2lf(s)\n"", output_cost);

printf(""total_cost = %.2lf(s)\n"", prepare_cost + core_cost + output_cost);
printf(""DONE."");

return 0;
}
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.3 主函数'}"
当指定的顶点ID不存在，并且nearest参数为true时，Goto函数将如何处理？,"page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.2.构建采样器

训练过程中，首先使用GetDB算子从数据库中获取图数据并转换成所需数据结构，具体代码如下：
```python
GetDB.Process(db_: lgraph_db_python.PyGraphDB, olapondb: lgraph_db_python.PyOlapOnDB, feature_num: size_t, NodeInfo: list, EdgeInfo: list)
```
如代码所示，结果存储在NodeInfo和EdgeInfo中。NodeInfo和EdgeInfo是python list结果，其存储的信息结果如下：  
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |  
然后构建采样器
```python
batch_size = 5
count = 2708
sampler = TugraphSample(args)
dataloader = dgl.dataloading.DataLoader(fake_g,
torch.arange(count),
sampler,
batch_size=batch_size,
num_workers=0,
)
```' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.2.构建采样器'}","page_content='Heterogeneous Graph

4. 异质图输出格式

和同质图相同的是，异质图的采样数据结果也存储在NodeInfo和EdgeInfo中。
可通过如下方式获取输出数据。
```python
NodeInfo = []
EdgeInfo = []
getdb.Process(db, olapondb, feature_len, NodeInfo, EdgeInfo)
```
其中getdb为获取全图数据的函数，db为图数据库实例，olapondb为图分析类。feature_len为节点特征长度，NodeInfo和EdgeInfo为输出的节点和边信息。  
其存储信息结果如下：
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 边类型 | EdgeInfo[2] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |
| 顶点类型 | NodeInfo[3] |' metadata={'Header 1': 'Heterogeneous Graph', 'Header 2': '4. 异质图输出格式'}","page_content='Cypher API

5.附录2. 内置procedures列表

* algo.algo.native.extract(id, config))

get the field values of a list of vertexes or edges.  
**Parameters:**  
| parameter | parameter type | description                        |
| --------- | -------------- | ---------------------------------------------------------- |
| id    | ANY        | the id of vertexes or edges , the id must be variable      |
| config    | MAP        | the configuration of  this extraction of vertexes or edges |  
in which each `config` is a map in the form of `{isNode:true, filed:'HAS_CHILD'}`, if `isNode` is specified true, the `id` is a vertex id, or  it is an edge id.  
**Output:**  
If successful, it returns a list of the value of vertexes or edges specified field .  
**Example input:**  
```
with [2,3] as vids CALL algo.native.extract(vids,{isNode:true, field:'id'})
YIELD value  RETURN value
```  
**Example output:**  
| value |
| ----- |
| [4,5] |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* algo.algo.native.extract(id, config))'}"
在BFS算法中，最终返回的结果是什么？,"page_content='内置算法

基础算法包

广度优先搜索

广度优先搜索实现了Breadth-first Search算法，从根点开始，沿着图的宽度遍历所有可访问点。返回结果为遍历点个数。算法内容请参考 [https://en.wikipedia.org/wiki/Breadth-first_search](https://en.wikipedia.org/wiki/Breadth-first_search ""bfs wiki"")。' metadata={'Header 1': '内置算法', 'Header 2': '基础算法包', 'Header 3': '广度优先搜索'}","page_content='OlapOnDisk API

1. 简介

TuGraph的Standalone模式可用于加载图数据文件，其中图数据文件来源可包含text文本文件、BINARY_FILE二进制文件和ODPS源。在该模式下，TuGraph可实现多数据来源快速加载成图，然后在该图上运行如BFS、WCC、SSSP等迭代式算法，并输出最终结果至终端。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph内置了大量的常见图分析算法和丰富的辅助接口，因此用户几乎不需要自己实现具体的图计算过程，只需要在实现自己的存储过程的时候将相应算法库的头文件(.h)包含到自己的程序中，并在编译阶段链接自己的动态库文件即可。  
该文档主要介绍了Standalone的常用接口，使用到的辅助函数主要包含在OlapOnDB类。同时为帮助用户理解方便，对BFS算法进行举例说明。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '1. 简介'}","page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

`bfs`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关定义、数据结构的初始化
2. 使用批处理函数对每个节点进行循环计算，每一轮找到与当前节点相邻的全部节点，并在该轮次终止时进行交换。
3. 直到找到全部节点，返回节点个数discovered_vertices。  
```C++
size_t BFSCore(Graph<Empty>& graph, size_t root_vid, ParallelVector<size_t>& parent){

size_t root = root_vid;
auto active_in = graph.AllocVertexSubset();   //分配数组，active_in用于存放上一循环阶段已找到的节点
active_in.Add(root);            //把跟节点加入数组中
auto active_out = graph.AllocVertexSubset();  //分配数组active_out用于存放当前循环阶段找到的节点
parent.Fill((size_t)-1);               //将parent数组中的节点赋值为-1，-1表示未被找到
parent[root] = root;
size_t num_activations = 1;       //表示当前循环阶段找到的节点个数
size_t discovered_vertices = 0;    //表示当前循环阶段找到节点的总个数

for (int ii = 0; num_activations != 0; ii++) {       //num_activations表示当前循环阶段找到的节点个数
printf(""activates(%d) <= %lu\n"", ii, num_activations);
discovered_vertices += num_activations;         //discovered_vertices表示当前循环阶段找到节点的总个数
active_out.Clear();
num_activations = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t num_activations = 0;
for (auto& edge : graph.OutEdges(vi)) {   //每一次循环从根节点出发，查找邻近的相邻节点，对其parent值改变，并num_activations+1操作
size_t dst = edge.neighbour;
if (parent[dst] == (size_t)-1) {
auto lock = graph.GuardVertexLock(dst);
if (parent[dst] == (size_t)-1) {
parent[dst] = vi;
num_activations += 1;
active_out.Add(dst);       //存放当前循环阶段找到的节点
}
}
}
return num_activations;
},
active_in);
active_in.Swap(active_out);
}
// 返回全部节点数
return discovered_vertices;
}
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}"
TuGraph“refresh_time”的默认设置是什么？,"page_content='TuGraph-DataX

4.导出TuGraph

4.2.参数说明

在使用DataX导出TuGraph数据时，需要将reader设置为tugraphreader并配置以下5个参数：  
* **url**
* 描述：TuGraph的bolt server地址 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **username**
* 描述：TuGraph的用户名 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **password**
* 描述：TuGraph的密码 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **graphName**
* 描述：所选取的需要同步的TuGraph子图 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **queryCypher**
* 描述：通过cypher语句读取TuGraph中的数据 <br />
* 必选：否 <br />
* 默认值：无 <br />' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '4.导出TuGraph', 'Header 3': '4.2.参数说明'}","page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='功能概览

4.核心功能

4.5 数据预热

TuGraph 是基于磁盘的图数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.5 数据预热'}"
GetEdgeProp命令中，如果要查找特定的时间戳的边属性，该如何指定timestamp字段？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='图相关DDL

Create Graph

**Syntax**
一个图至少包含一对点边，点表必须包含一个id字段作为主键，边表必须包含srcId和targetId作为主键，边表还可以有一个时间戳字段标识时间。  
```
CREATE GRAPH <graph name>
(
<graph vertex>
[ { , <graph vertex> } ... ]
, <graph edge>
[ { , <graph edge> } ... ]
) WITH （
storeType = <graph store type>
[ { , <config key> = <config value> } ... ]
);

<graph vertex>  ::=
VERTEX <vertex name>
(
<column name> <data type> ID
[ {, <column name> <data type> } ... ]
)

<graph edge>  ::=
Edge <edge name>
(
<column name> <data type> SOURCE ID
, <column name> <data type> DESTINATION ID
[ , <column name> <data type> TIMESTAMP ]
[ {, <column name> <data type> } ... ]
)

```  
**Example**
```sql
CREATE GRAPH dy_modern (
Vertex person (
id bigint ID,
name varchar,
age int
),
Vertex software (
id bigint ID,
name varchar,
lang varchar
),
Edge knows (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
),
Edge created (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
)
) WITH (
storeType = 'rocksdb',
shardCount = 2
);
```
这个例子创建了一张包含2个点2个边的图，存储类型为rocksdb, 分片数2个。' metadata={'Header 1': '图相关DDL', 'Header 2': 'Create Graph'}","page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}"
使用TuGraph Browser时，默认的端口号是多少？,"page_content='可视化操作手册

2.操作指南

2.1.访问

当用户完成图数据库的安装后，可以通过浏览器访问Browser。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7070。  
- 例如：127.0.0.1:7070。
- 推荐使用Chrome。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.1.访问'}","page_content='可视化操作手册（旧版）

操作详情

1.连接数据库

当用户完成图数据库的安装后，可以通过浏览器进行访问，TuGraph Browser 工具。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7090。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '1.连接数据库'}","page_content='TuGraph Management

使用

TuGraph Management使用Maven进行管理，请运行如下命令启动TuGraph Management  
`mvn spring-boot:run`  
TuGraph Management 使用了sofastack框架，并使用brpc与TuGraph进行通信，sofastack默认端口为`6071`，brpc默认端口为`6091`，如需修改服务端口，请修改`./src/main/resources/application.properties`文件中的对应配置项。' metadata={'Header 1': 'TuGraph Management', 'Header 2': '使用'}"
TuGraph-DB是否支持运行图算法？是否有示例图算法可以参考？,"page_content='图算法介绍

2\. 流图推理简介

TuGraph计算引擎（TuGraph Analytics\[1\]）是蚂蚁集团开源的大规模分布式实时图计算引擎（流图引擎），实现了流批一体的图计算模型，支持了丰富的图计算算法。TuGraph Analytics的流图计算能力，能处理连续输入的数据流，并支持增量的计算模式，极大得提高了数据的计算效率和实时性。TuGraph Analytics解决了业界大规模数据关联分析的实时计算问题，已广泛应用于数仓加速、金融风控、知识图谱以及社交推荐等场景。  
随着业务场景中问题复杂度的提升，基于传统的迭代图算法已无法满足业务的实际需求。例如在反洗钱场景中，利用图神经网络算法处理复杂的交易关系，能够捕获到节点的局部图结构信息。通过聚合邻接节点的特征信息，每个交易节点都可以感知到周边图网络结构的信息。类似的图神经网络等AI模型的推理逻辑，是无法基于传统的图迭代计算模式直接高效地表达的。  
受上述问题启发，我们思考是否可以将TuGraph Analytics的流图计算能力与图神经网络等深度学习模型相结合，开发一套基于流图计算的模型推理系统。最终期望的推理系统具备如下能力：  
-   对于图算法工程师，在图迭代计算过程中，能够方便地使用机器学习模型的推理能力。  
-   对于AI算法工程师，可以通过TuGraph Analytics分布式流式计算的能力实现实时的模型推理。  
众所周知，在深度学习为代表的数据科学领域，Python已经成为数据分析、模型训练和推理框架的主流开发语言，并提供了丰富的开发库和框架生态。而以Hadoop全家桶为代表的大数据计算引擎领域，基于Java语言开发的系统仍占据一席之地，当然TuGraph Analytics也在其中。这种语言差异带来的“互操作性”成本，使得相当一部分大数据和AI生态组件无法轻松地融合，这也是TuGraph Analytics支持图推理需要亟待解决的问题。' metadata={'Header 1': '图算法介绍', 'Header 2': '2\\. 流图推理简介'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='技术规划

2. 已完成功能

TuGraph-DB于2022年9月1日开源，TuGraph-DB在社区的反馈声中，进行日常BUG修复，自身能力得到了完善。  
| 版本号   | 功能                               | 时间         |
|-------|----------------------------------|------------|
| 3.3.0 | 开源初版                             | 2022.9.1   |
| 3.3.1 | 图分析引擎重构，多模式支持                    | 2022.10.14 |
| 3.3.2 | OGM支持，UT覆盖率提升                    | 2022.11.21 |
| 3.3.3 | 链接认证机制迭代，加入英文文档                  | 2022.12.23 |
| 3.3.4 | 支持上云，梳理LDBC SNB Audit流程          | 2023.1.28  |
| 3.4.0 | 支持OLAP Python API, 离线导入升级        | 2023.3.11  |
| 3.5.0 | 支持POG，前端升级，文档梳理                  | 2023.6.5   |
| 3.5.1 | 图学习引擎，Procedure Rust API，存储属性分离  | 2023.7.14  |
| 3.6.0 | 高可用开源，日志系统升级                     | 2023.8.11  |
| 4.0.0 | ISO GQL支持，新增11个开源图算法，支持m1 Docker | 2023.9.6   |
| 4.0.1 | 支持时序边排序，新增5个开源图算法                | 2023.9.28  |
| 4.1.0 | 支持Bolt协议，支持快速在线全量导入，支持地理空间数据类型   | 2023.12.25 |  
除此之外，TuGraph-DB搭建了较为完善的质量体系，涵盖自动化的单元测试、集成测试、性能测试等。  
更详细的描述可以在源码目录在的 ""[root]/release/CHANGELOG.md"" 文件查看。' metadata={'Header 1': '技术规划', 'Header 2': '2. 已完成功能'}"
Python存储过程接口包含哪些重要组件和功能？,"page_content='Procedure API

5.Procedure v2接口

5.2.加载存储过程

用户可以通过 REST API 和 RPC 来加载存储过程。以 REST API 为例，加载`custom_pagerank.so`的 C++代码如下：  
```python
import requests
import json
import base64

data = {'name':'custom_pagerank'}
f = open('./custom_pagerank.so','rb')
content = f.read()
data['code_base64'] = base64.b64encode(content).decode()
data['description'] = 'Custom Page Rank Procedure'
data['read_only'] = true
data['code_type'] = 'so'
js = json.dumps(data)
r = requests.post(url='http://127.0.0.1:7071/db/school/cpp_plugin', data=js,
headers={'Content-Type':'application/json'})
print(r.status_code)    ## 正常时返回200
```  
需要注意的是，这时的`data['code']`是一个经过 base64 处理的字符串，`custom_pagerank.so`中的二进制代码是无法通过 JSON 直接传输的。此外，存储过程的加载和删除都只能由具有管理员权限的用户来操作。  
存储过程加载之后会被保存在数据库中，在服务器重启后也会被自动加载。此外，如果需要对存储过程进行更新，调用的 REST API 也是同样的。建议用户在更新存储过程时更新相应描述，以便区分不同版本的存储过程。  
#### 5.2.1.列出已加载的存储过程  
在服务器运行过程中，用户可以随时获取存储过程列表。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin')
>>> r.status_code
200
>>> r.text
'{""plugins"":[{""description"":""Custom Page Rank Procedure"", ""name"":""custom_pagerank"", ""read_only"":true}]}'
```  
#### 5.2.2.获取存储过程详情  
在服务器运行过程中，用户可以随时获取单个存储过程的详情，包括代码。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin/custom_pagerank')
>>> r.status_code
200
>>> r.text
'{""description"":""Custom Page Rank Procedure"", ""name"":""custom_pagerank"", ""read_only"":true, ""code_base64"":<CODE>, ""code_type"":""so""}'
```  
#### 5.2.3.调用存储过程  
调用存储过程的代码示例如下：  
```Cypher
CALL plugin.cpp.custom_pagerank(10)
YIELD node, pr WITH node, pr
MATCH(node)-[r]->(n) RETURN node, r, n, pr
```  
#### 5.2.4.删除存储过程  
删除存储过程只需要如下调用：  
```python
>>> r = requests.delete(url='http://127.0.0.1:7071/db/school/cpp_plugin/custom_pagerank')
>>> r.status_code
200
```  
与加载存储过程类似，只有管理员用户才能删除存储过程。  
#### 5.2.5.更新存储过程  
更新存储过程需要执行如下两个步骤：  
1.  删除已存在的存储过程
2.  安装新的存储过程  
TuGraph 较为谨慎地管理存储过程操作的并发性，更新存储过程不会影响现有存储过程的运行。' metadata={'Header 1': 'Procedure API', 'Header 2': '5.Procedure v2接口', 'Header 3': '5.2.加载存储过程'}","page_content='Procedure API

4.1.编写存储过程

4.1.2.编写Python存储过程

与 C++类似，Python 存储过程也可以调用 core API，一个简单的例子如下：  
```python
def Process(db, input):
txn = db.CreateReadTxn()
it = txn.GetVertexIterator()
n = 0
while it.IsValid():
if it.GetLabel() == 'student' and it['age'] and it['age'] == 10:
n = n + 1
it.Next()
return (True, str(nv))
```  
Python 存储过程返回的是一个 tuple，其中第一个元素是一个布尔值，表示该存储过程是否成功执行；第二个元素是一个`str`，里面是需要返回的结果。  
Python 存储过程不需要编译，可以直接加载。' metadata={'Header 1': 'Procedure API', 'Header 2': '4.1.编写存储过程', 'Header 3': '4.1.2.编写Python存储过程'}","page_content='日志信息

2.服务器日志

2.3.存储过程日志

用户在存储过程的编写过程中可以使用日志功能将所需的调试信息输出到日志中进行查看，辅助开发。调试信息会输出到与服务器日志相同的日志文件中(如未指定`log_dir`则同样输出至console)  
#### 2.3.1.cpp存储过程
请使用2.2中提供的log宏输出调试信息，避免使用cout或者printf等输出方式。具体使用方式可参考如下示例代码（详见`procedures/demo/log_demo.cpp`）  
```
#include <stdlib.h>
#include ""lgraph/lgraph.h""
#include ""tools/lgraph_log.h""  // add log dependency
using namespace lgraph_api;

void LogExample() {
LOG_DEBUG() << ""This is a debug level log message."";
LOG_INFO() << ""This is a info level log message."";
LOG_WARN() << ""This is a warning level log message."";
LOG_ERROR() << ""This is a error level log message."";
}

extern ""C"" bool Process(GraphDB& db, const std::string& request, std::string& response) {
response = ""TuGraph log demo"";
LogExample();
return true;
}
```
将以上示例代码作为存储过程插入数据库并运行后，可以在日志文件中看到相应的日志条目。  
#### 2.3.1.python存储过程
请使用python自带的print输出调试信息，调试信息会在存储过程运行结束后合并为一条WARN等级的日志条目输出至日志文件中。' metadata={'Header 1': '日志信息', 'Header 2': '2.服务器日志', 'Header 3': '2.3.存储过程日志'}"
当执行 CallGql 函数时，如果操作成功和失败分别返回什么？,"page_content='C++客户端

2.使用示例

2.4.调用GQL

```C++
std::string str;
bool ret = client.CallGql(str,
""CALL db.createVertexLabel('actor', 'name', 'name', string, false, 'age', int8, true)"");
```
```
bool CallGql(std::string& result, const std::string& gql,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0, const std::string& url = """");
@param [out] result      The result.
@param [in]  gql         inquire statement.
@param [in]  graph       (Optional) the graph to query.
@param [in]  json_format (Optional) Returns the format， true is json，Otherwise, binary
format.
@param [in]  timeout     (Optional) Maximum execution time, overruns will be interrupted.
@param [in]  url         (Optional) Node address of calling gql.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.4.调用GQL'}","page_content='C++客户端

2.使用示例

2.5.向leader发送GQL请求

```C++
std::string str;
bool ret = client.CallGqlToLeader(str,
""CALL db.createVertexLabel('actor', 'name', 'name', string, false, 'age', int8, true)"");
```
```
bool CallGqlToLeader(std::string& result, const std::string& gql,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0);
@param [out] result      The result.
@param [in]  gql         inquire statement.
@param [in]  graph       (Optional) the graph to query.
@param [in]  json_format (Optional) Returns the format， true is json，Otherwise, binary
format.
@param [in]  timeout     (Optional) Maximum execution time, overruns will be interrupted.
@returns True if it succeeds, false if it fails.
```
本接口只支持在HA模式下使用，在HA模式下的client中，为防止向未同步数据的follower发送请求，
用户可以直接向leader发送请求，leader由集群选出。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.5.向leader发送GQL请求'}","page_content='Java客户端

2.使用示例

2.4.调用GQL

```java
String res = client.callGql(""CALL db.edgeLabels()"", ""default"", 10);
log.info(""db.edgeLabels() : "" + res);
```
```
@param gql: inquire statement.
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@param url: (Optional) Node address of calling GQL
@return: the result of GQL query execution
public String callGql(String gql, String graph, double timeout, String url)
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。
注：JAVA不支持默认参数，因此，JAVA中的默认参数是使用重载函数实现的。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.4.调用GQL'}"
TuGraph 中复杂图分析操作如何执行？,"page_content='HTAP

2.设计

在 TuGraph 中，OLTP 为图事务引擎，在图 4.4对应事务操作；OLAP 为图分析引擎，对应简单图分析操作（比如 SPSP）和复杂图分析操作（比如 PageRank），前者可以直接在图存储上执行，而后者需要额外导出快照执行。  
- 事务操作，即图事务引擎测的操作，为局部图的增删查改操作，典型的应用为 K 跳访问 K-Hop。
- 简单分析操作，是图分析引擎中较为简单的部分，通常也是局部的图分析操作，比如两点间最短路算法 SPSP、Jaccard 算法。
- 复杂分析操作，是图分析引擎中较为复杂的部分，通常涉及全图的多轮数据迭代操作，比如网页排序算法 PageRank、社区发现算法 Louvain。  
如架构图所示，我们在图中增加了外部存储，使得图分析的数据源不局限在图数据库中，可以直接从文本文件读取。  
- 图存储，即图数据库中的存储，有精心设计的数据结构，能够完成实时增删查改。
- 外部存储，可以是 RDBMS 或文本文件，以边表的简单方式存储，仅供一次性批量读取，和批量结果写入。在计算层，和整体架构图中的接口对应。
- Cypher，描述式图查询语言，可以并发执行。
- Procedure API，过程式图查询语言，其灵活性能够同时支持事务操作和图分析操作，但效率上不足以完成复杂图分析操作，可以并发执行。
- OLAP API，针对多轮迭代的复杂图分析。应用需要先将存储中的图数据导出成内存中的一个快照，该快照仅用来快速访问，而不需要考虑 ACID 的写支持，因此可以排布地更加紧凑，CSR 排布的读效率要远高于图存储的数据排布。OLAP API 只能串行执行，每个操作都用满 CPU 资源。  
OLAP API 的快照可以从外部存储创建，即将边表数据构成件 CSR 的格式；或者从图存储中创建。需要注意的是，OLAP API 要求点的 ID 是连续的自然数，可能需要额外的 ID 映射，该步骤在创建快照时可以在指定一个属性进行映射，或直接取属性值作为 ID。  
与计算接口和存储相对应，有四种运行模式。  
- 事务模式，每个操作对应一条 Cypher 语句，默认是一个事务。
- Plugin 模式，通过插件的方式，在计算逻辑加载到服务端后调用，也叫存储过程。
- Embed 模式，和 Plugin 模式的使用接口一致，区别是图数据库服务不需要起来，就可以直接用接口调用数据库中的数据，通常用于调试 Procedure API 和OLAP API 的代码，调试信息和操作步骤比 Plugin 模式更加友好。
- Standalone 模式，最大程度剥离与图数据库的关系，仅想用图分析引擎做数据分析时，该模式会比较直接。Standalone 模式会直接使用外部存储的数据。  
图神经网络引擎的使用方式和 ‘复杂图分析操作’ 类似，会同时调用部分 OLAP API 和 GNN API，不在这里展开。' metadata={'Header 1': 'HTAP', 'Header 2': '2.设计'}","page_content='功能概览

3.计算层

计算层在功能上分成三个部分，包括TP类的图事务引擎，AP类的图分析引擎和图神经网络引擎。  
- __图事务引擎__，主要用来处理并发的图操作，包括单点查询、邻居查询、路径遍历。图事务引擎侧重并发操作的ACID事务，确保操作逻辑不会互相干扰，主要性能指标为 QPS，即每秒完成的查询数量。  
- __图分析引擎__，操作类型通常为全图迭代。部分简单的分析任务（比如SPSP）可以由图事务引擎完成，复杂的分析任务均由图分析引擎完成，单个任务通常需要数秒至数小时。因此单个图分析任务要并发利用所有的硬件资源，性能指标为任务完成的总时长。  
- __图神经网络引擎__，通常也为全图迭代。图神经网络引擎除了基于图拓扑的操作，也需要集成一个机器学习的框架来处理向量操作，比如 PyTorch、MXNet、TenserFlow。  
三个引擎的操作逻辑不尽相同，独立配置资源池。事图事务引擎基于RPC操作设置了一个线程池，每接受客户端的一个操作，从线程中取一个线程来处理，并发执行的数量等于RPC线程池的容量，通常配置为服务器的核数。图分析引擎有一个分析线程池，每个图分析任务会并发执行，即用所有的线程来执行一个任务，来加速操作的性能。TuGraph图分析操作串行执行的特性会一定程度限制用户的使用体验，并发的图分析的需求可以通过高可用部署的方式，增加机器资源来处理，或者接入外部的任务调度器，将数据传到实时调度的容器来计算。图神经网络操作在图上的操作会复用图事务引擎或图分析引擎的资源，向量的操作会起单独的资源，在机器学习框架中可以使用GPU等单独的加速硬件。' metadata={'Header 1': '功能概览', 'Header 2': '3.计算层'}","page_content='Traversal API

1. 简介

TuGraph 强大的在线分析处理（OLAP）能力是其区别于其它图数据库的一个重要特性。
借助 C++ OLAP API（olap_on_db.h），用户可以快速地导出一个需要进行复杂分析的子图，然后在其上运行诸如 PageRank、连通分量、社区发现等迭代式图计算过程，最后根据结果做出相应决策。
导出和计算的过程都可以通过并行处理的方式进行加速，从而实现几乎实时的分析处理，避免了传统解决方案需要将数据导出、转换、再导入（ETL）到专门的分析系统进行离线处理的冗长步骤。  
TuGraph 内置了大量常用的图分析算法和丰富的辅助接口，因此用户几乎不需要自己来实现具体的图计算过程，只需在实现自己的存储过程时将相应算法库的头文件（.h 文件）包含到自己程序中，并在编译时链接相应的动态库文件（.so）即可。
一般情况下，用户需要自己实现的只有将需要分析的子图抽取出来的过程。  
目前 Traversal API 仅支持 C++。' metadata={'Header 1': 'Traversal API', 'Header 2': '1. 简介'}"
filter_output_default函数的主要作用是什么？,"page_content='OlapOnDisk API

3. 其他常用函数功能描述

3.2 图写入

- `void Write(ConfigBase<EdgeData> & config, ParallelVector<VertexData>& array, size_t array_size, std::string name, std::function<bool(VertexData &)> filter_output = filter_output_default<VertexData&>)`：把array中数据写回文件中，各参数表示意义分别是：
- `config`：需要加载的配置参数。该参数内保存了该图的一般信息（如数据来源，算法名称，数据输入、输出路径，点个数等）以及根据不同数据来源、不同算法所配置的不同信息参数。
- `array`：待写入数据的数组
- `array_size`：待写入数据的数字长度
- `name`：算法名称
- `filter_output`：写入数据规则函数，待写入数据需要满足该函数的要求。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '3. 其他常用函数功能描述', 'Header 3': '3.2 图写入'}","page_content='功能概览

Stream API

Stream API提供了一套通用计算的编程接口，包括source构建、流批计算及sink输出。具体的API说明如下表格所示：
<table>
<tr>
<td>类型</td>
<td>API</td>
<td>说明</td>
</tr>
<tr>
<td rowspan=""4"">流</td>
<td>PStreamView<T> init(IViewDesc viewDesc)</td>
<td>传入StreamViewDesc进行初始化</td>
</tr>
<tr>
<td>PIncStreamView<T> append(PWindowStream<T> windowStream)     </td>
<td>将分布式数据作为streamView增量的数据集</td>
</tr>
<tr>
<td>PWindowStream<T> reduce(ReduceFunction<T> reduceFunction)     </td>
<td>在动态streamView上进行增量reduce聚合计算</td>
</tr>
<tr>
<td><ACC, OUT> PWindowStream<OUT> aggregate(AggregateFunction<T, ACC, OUT> aggregateFunction)     </td>
<td>在动态streamView上进行增量aggregate聚合计算</td>
</tr>
<tr>
<td rowspan=""12"">批</td>
<td>PStreamView<T> <R> PWindowStream<R> map(MapFunction<T, R> mapFunction)</td>
<td>进行map操作</td>
</tr>
<tr>
<td>PWindowStream<T> filter(FilterFunction<T> filterFunction)     </td>
<td>进行filter操作</td>
</tr>
<tr>
<td><R> PWindowStream<R> flatMap(FlatMapFunction<T, R> flatMapFunction)      </td>
<td>进行flatmap操作</td>
</tr>
<tr>
<td><ACC, OUT> PWindowStream<T> union(PStream<T> uStream)     </td>
<td>将两个流进行union合并</td>
</tr>
<tr>
<td>PWindowBroadcastStream<T> broadcast()     </td>
<td>将流广播到下游</td>
</tr>
<tr>
<td><KEY> PWindowKeyStream<KEY, T> keyBy(KeySelector<T, KEY> selectorFunction)     </td>
<td>按照selectorFunction规则进行keyby</td>
</tr>
<tr>
<td>PStreamSink<T> sink(SinkFunction<T> sinkFunction)     </td>
<td>将结果输出</td>
</tr>
<tr>
<td>PWindowCollect<T> collect()     </td>
<td>触发数据结果的收集</td>
</tr>
<tr>
<td>PWindowStream<T> reduce(ReduceFunction<T> reduceFunction)     </td>
<td>进行一个window内的reduce聚合计算</td>
</tr>
<tr>
<td><ACC, OUT> PWindowStream<OUT> aggregate(AggregateFunction<T, ACC, OUT> aggregateFunction)     </td>
<td>进行一个window内的aggregate聚合计算</td>
</tr>
<tr>
<td><ACC, OUT> PIncStreamView<T> materialize()     </td>
<td>将PWindowKeyStream作为动态streamView，默认keyby后生成IncstreamView</td>
</tr>
</table>' metadata={'Header 1': '功能概览', 'Header 2': 'Stream API'}","page_content='Traversal API

2. 接口说明

2.1. Snapshot

C++ OLAP API 中的 Snapshot 模版类用于表示抽取出来的静态子图，其中 EdgeData 用来表示该子图上每条边所用权值的数据类型（如果边不需要权值，使用 Empty 作为 EdgeData 即可）。  
抽取的子图通过 Snapshot 类的构造函数来描述：  
```c
Snapshot::Snapshot(
GraphDB & db,
Transaction & txn,
size_t flags = 0,
std::function<bool(VertexIterator &)> vertex_filter = nullptr,
std::function<bool(OutEdgeIterator &, EdgeData &)> out_edge_filter = nullptr
);
```  
其中，db 为数据库句柄，txn 为事务句柄，flags 为生成时使用的选项，可选值包括以下的组合：SNAPSHOT_PARALLEL 表示导出时使用多个线程进行并行；SNAPSHOT_UNDIRECTED 表示需要将导出的图变为无向图。
vertex_filter 是面向点的用户自定义过滤函数，返回值为 true 表示该点需要被包含到待抽取的子图中，反之则表示需要被排除。
out_edge_filter 是面向边的用户自定义过滤函数，返回值为 true 表示该边需要被包含到待抽取的子图中，反之则表示需要被排除。
当过滤函数为缺省值时，则表示需要将所有点/边都包含进来。  
Snapshot 类提供的其它方法请参考详细的 C++ API 文档（olap_on_db.h）。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.1. Snapshot'}"
在Java运行时，MyBatis Generator的XML配置文件应如何配置targetProject？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='数据导入

3.配置文件

3.2.配置文件示例

```json
{
""schema"": [
{
""label"": ""actor"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""aid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" }
],
""primary"": ""aid""
},
{
""label"": ""movie"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""mid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" },
{ ""name"": ""year"", ""type"": ""INT16"" },
{ ""name"": ""rate"", ""type"": ""FLOAT"", ""optional"": true }
],
""primary"": ""mid"",
""detach_property"": false
},
{
""label"": ""play_in"",
""type"": ""EDGE"",
""properties"": [{ ""name"": ""role"", ""type"": ""STRING"", ""optional"": true }],
""constraints"": [[""actor"", ""movie""]]
}
],
""files"": [
{
""path"": ""actors.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""actor"",
""columns"": [""aid"", ""name""]
},
{
""path"": ""movies.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""movie"",
""columns"": [""mid"", ""name"", ""year"", ""rate""]
},
{
""path"": ""roles.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""play_in"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
对于上述配置文件，定义了三个 label：两个点类型`actor`和`movie`，一个边类型`role`。每个 label 都描述了：label 的名字、类型（点还是边）、属性字段有哪些以及每个字段的类型。对于点，另外定义了 primary 字段是哪个；对于边，另外定义了 constraints 字段，用来限制边的起点和终点只能是哪些组合。  
还描述了三个数据文件，两个点的数据文件`actors.csv`和`movies.csv`，一个边的数据文件`roles.csv`。每个部分都描述了：文件的路径（path）、数据类型（format）、信息头占开头几行（header）、是哪个 label 的数据（label）、文件中每行数据中的每个列对应的字段是哪个。  
对于上述配置文件，import 工具在执行的过程中会先在 TuGraph 中创建`actor`、`movie`、`role`这三个 label，然后再执行三个文件的数据导入。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.2.配置文件示例'}","page_content='Bolt客户端

使用示例

添加Maven依赖  
```xml
<dependency>
<groupId>org.neo4j.driver</groupId>
<artifactId>neo4j-java-driver</artifactId>
<version>4.4.2</version>
</dependency>
```
Client按照如下格式进行实例化:  
```java
Driver driver = GraphDatabase.driver(""bolt://ip:port"", AuthTokens.basic(""admin"", ""73@TuGraph""));
```  
常用语句  
```java
//通过 driver 对象创建一个 Session，设置会话连接到特定的数据库，用于执行Cypher语句
Session session = driver.session(SessionConfig.forDatabase(""default""));
//清空图项目，请不要轻易尝试，它会清空你选中的图项目的模型以及数据
session.run(""CALL db.dropDB()"");
//创建点模型
session.run(""CALL db.createVertexLabel('person', 'id' , 'id' ,INT32, false, 'name' ,STRING, false)"");
//创建边模型
session.run(""CALL db.createEdgeLabel('is_friend','[[\""person\"",\""person\""]]')"");
//创建索引
session.run(""CALL db.addIndex(\""person\"", \""name\"", false)"");
//插入点数据
session.run(""create (n1:person {name:'jack',id:1}), (n2:person {name:'lucy',id:2})"");
//插入边数据
session.run(""match (n1:person {id:1}), (n2:person {id:2}) create (n1)-[r:is_friend]->(n2)"");
//查询点和边
Result res = session.run(""match (n)-[r]->(m) return n,r,m"");
//Parameterized Query
String cypherQuery = ""MATCH (n1:person {id:$id})-[r]-(n2:person {name:$name}) RETURN n1, r, n2"";
Result result1 = session.run(cypherQuery, parameters(""id"", 1, ""name"", ""lucy""));
while (result1.hasNext()) {
Record record = result1.next();
System.out.println(""n1: "" + record.get(""n1"").asMap());
System.out.println(""r: "" + record.get(""r"").asMap());
System.out.println(""n2: "" + record.get(""n2"").asMap());
}
//删除点数据
session.run(""match (n1:person {id:1}) delete n1"");
//删除边数据
session.run(""match (n1:person {id:1})-[r]-(n2:person{id:2}) delete r"");
//删除边模型
session.run(""CALL db.deleteLabel('edge', 'is_friend')"");
//删除点模型
session.run(""CALL db.deleteLabel('vertex', 'person')"");
```  
详细Cypher和存储过程的使用可见[Cypher](../../8.query/1.cypher.md)' metadata={'Header 1': 'Bolt客户端', 'Header 2': '使用示例'}"
"在给定的代码中，`@Property(""class"")`注解指定了什么数据库字段名？","page_content='业务开发指南

点类型操作

创建点类型

如下json定义了一个点类型，名字是`node1`。
```json
{
""label"": ""node1"",
""primary"": ""id"",
""type"": ""VERTEX"",
""detach_property"": true,
""properties"": [{
""name"": ""id"",
""type"": ""INT32"",
""optional"": false
}, {
""name"": ""name"",
""type"": ""STRING"",
""optional"": false,
""index"": true
}, {
""name"": ""num"",
""type"": ""INT32"",
""optional"": false,
""index"": true,
""unique"": true
}, {
""name"": ""desc"",
""type"": ""STRING"",
""optional"": true
}]
}

```
把上面这个json序列化成字符串，作为参数传入，建议使用驱动的参数化特性，避免自己拼接语句。
```
CALL db.createVertexLabelByJson($json_data)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '点类型操作', 'Header 3': '创建点类型'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.subgraph()

**Scope:** whole instance.  
**Parameters:**  
| parameter  | parameter type | description                                                           |
| ---------- | -------------- | --------------------------------------------------------------------- |
| vids       | list           | list of vertex id                                                     |  
**Output:**  
Get a json containing all the properties of nodes and relationships.  
**Example input:**  
```
CALL db.subgraph([3937,4126,4066,4010])
```  
**Example output**  
| subgraph |
| -------- |
| {""nodes"":[{""identity"":3937,""label"":""movie"",""properties"":{""duration"":136,""id"":1,""poster_image"":""http://image.tmdb.org/t/p/w185/gynBNzwyaHKtXqlEKKLioNkjKgN.jpg"",""rated"":""R"",""summary"":""Thomas A. Anderson is a man living two lives. By day he is an average computer programmer and by night a malevolent hacker known as Neo who finds himself targeted by the police when he is contacted by Morpheus a legendary computer hacker who reveals the shocking truth about our reality."",""tagline"":""Welcome to the Real World."",""title"":""The Matrix""}},{""identity"":4010,""label"":""user"",""properties"":{""id"":44,""login"":""Howard""}},{""identity"":4066,""label"":""user"",""properties"":{""id"":202,""login"":""Enoch""}},{""identity"":4126,""label"":""user"",""properties"":{""id"":464,""login"":""Wilburn""}}],""relationships"":[{""dst"":4126,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4010,""temporal_id"":0},{""dst"":4010,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4066,""temporal_id"":0},{""dst"":4066,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4126,""temporal_id"":0}]} |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.subgraph()'}","page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/node/{vid}
```  
Nodes 提供节点（Vertex）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。  
#### 6.7.1.列出点数量和label数量  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| num_label | 点 label 数量 | 整数 |
| num_vertex | 点数量 | 整数 |  
_注意 num_vertex 返回的并不是准确的点数量，只是一个估计值。_  
#### 6.7.2.创建一个点  
向数据库中插入一个点。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 点属性 | 字典，其中 key 是列名，value 是相应值。value 必须是与列类型相应的类型，如列为 int32，则 value 只能是整数。 |  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新点 vid。该 ID 可用于后续的点操作中。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""property"" : {
""name"" : ""Passerby A"",
""birthyear"" : 1989
}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
21
}
```  
#### 6.7.3.批量创建点  
TuGraph 允许一次性插入多个点，以减少网络开销。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| fields | 点属性 | 列表 |
| values | 点数据 | 列表 |  
其中 fields 是一个字符串列表，列出一系列列名；values 是一个列表，其中每个元素是一个列表，列表中每个元素是列数据。  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新增加的点的 vid 列表，该列表中每一个 vid 按顺序对应请求中的每一个点。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""fields"" : [""name"", ""birthyear""],
""values"" : [[""alex"", 2000],
[""bob"", 1999]]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
22,
23
]
}
```  
#### 6.7.4.获取点  
- **URI**: `/db/{graph_name}/node/{vertex_id}`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 属性 | 字典，格式为 { {列名 1}:{列值 1},...' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}"
在tugraph中是否能通过cypher语句删除图中的重复关系？,"page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

二、TuGraph-DB高可用架构与规划

2.Server架构设计—请求同步

集群建立好之后，可以向其发送读写请求。发送读请求非常简单，client 发送一个读请求给 TuGraph server，server 接到读请求之后，去进行处理。图中给出的一个 cypher 语句，是查询图中边的 label 的数量。在 server 端，会对 cypher 语句进行解析，辨别它是一个只读的请求，一旦确定就会直接发送给 TuGraph-DB，由 TuGraph-DB 进行响应。  
写请求会涉及到 DB 数据的变化。Client 发送给 server 之后，server 会通过一些自有的逻辑去判断，如果是一个写请求，那么它会传给内部的一个 raft node，这个 raft node 可以看作是一个 client。因为是三个节点，每个节点持有其它节点的一个 client，每个节点既是 server，也是 client。当收到这个请求之后，只有 leader 节点会处理写请求。它并不会直接应用到 TuGraph-DB 上面，而是先调用客户端把日志去发送给其它节点，当超过半数的节点响应之后，才会应用到 TuGraph-DB 内部，保证写请求日志的一致性。  
在高可用集群使用过程中，有很多不可预知的情况，比如正好在应用日志的时候，集群突然挂了或者突然重启了。即使这种情况发生的概率非常低，但在大规模应用中仍然有可能发生。因此，写请求必须是幂等的，请求的 log index 必须是一致的，当它应用到 DB 里时，不能产生重复的提交。所以我们在 DB 内部持有 log 的 index，当 client 由于超时重发或节点的状态发生变化而重复提交时，都不会对 DB 状态产生污染。' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '二、TuGraph-DB高可用架构与规划', 'Header 3': '2.Server架构设计—请求同步'}","page_content='Procedure API

2.存储过程的版本支持

目前TuGraph支持两个版本的存储过程，适用于不同的场景，v3.5版本只支持v1，可通过REST或RPC接口直接调用；从v3.5版本开始支持v2，能够在图查询语言（比如Cypher）中嵌入调用，我们称之为POG（Procedure On Graph query language，APOC）。  
|                        | Procedure v1                       | Procedure v2               |
| ---------------------- | ---------------------------------- | -------------------------- |
| 适用场景                 | 极致性能，或者复杂的多事务管理情形       | 一般情况，与Cypher高度联动 |
| 事务                    | 函数内部创建，可自由控制多事务          | 外部传入函数，单一事务     |
| 签名（参数定义）          | 无                                 | 有                    |
| 输入输出参数类型          | 不需要指定                           | 需要指定参数类型        |
| Cypher Standalone Call | 支持                                | 支持                  |
| Cypher Embeded Call    | 不支持                              | 支持                  |
| 语言                    | C++/Python/Rust                    | C++                  |
| 调用模式                 | 直接传字符串，一般为JSON               | 通过Cypher语句中的变量  |  
在TuGraph中，存储过程v1和v2单独管理，支持增删查，但仍不建议重名。' metadata={'Header 1': 'Procedure API', 'Header 2': '2.存储过程的版本支持'}","page_content='RESTful API Legacy

2.请求与数据格式

2.4.URI格式

TuGraph REST API 提供以下功能：Service Root, login, info, label, index, node, relationship, cypher, cpp_plugin, 以及 python_plugin。
各功能使用的 URI 格式如下：  
| URI     | 说明                 |
| ------- | -------------------- |
| /web    | web 可视化界面       |
| /cypher | cypher 请求          |
| /acl    | 权限控制             |
| /user   | 用户管理             |
| /login  | 用户登录             |
| /info   | 数据库状态及提示信息 |
| /task   | 任务管理             |
| /db     | 子图操作             |  
其中子图操作又分为：  
| URI                              | 说明                 |
| -------------------------------- | -------------------- |
| /db                              | 子图的创建，删除     |
| /db/_{graph_name}_/node          | 点操作             |
| /db/_{graph_name}_/relationship  | 边操作               |
| /db/_{graph_name}_/label         | Label 相关操作       |
| /db/_{graph_name}_/index         | 索引相关操作         |
| /db/_{graph_name}_/cypher        | 子图相关 cypher 操作 |
| /db/_{graph_name}_/cpp_plugin    | C++存储过程          |
| /db/_{graph_name}_/python_plugin | Python 存储过程      |
| /db/_{graph_name}_/import        | 在线导入             |
| /db/_{graph_name}_/misc          | 其它操作             |' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '2.请求与数据格式', 'Header 3': '2.4.URI格式'}"
在默认情况下，第一次快照的时间如何设置？,"page_content='集群管理

4. 生成snapshot

出于节点启动时设置ha_snapshot_interval_s为-1以默认不打snapshot或其他原因，
当需要让某个节点手动生成snapshot时，可以使用`lgraph_peer`的`snapshot`命令。命令示例如下所示：  
```shell
$ lgraph_peer --command snapshot --peer {peer_id}
```  
其中：  
- `--command snapshot` 指定要执行的操作为snapshot，即生成快照。
- `--peer {peer_id}` 指定要生成快照的节点的rpc网络地址，如 `127.0.0.1:9092`。' metadata={'Header 1': '集群管理', 'Header 2': '4. 生成snapshot'}","page_content='可视化操作手册（旧版）

操作详情

3.工作台

#### 3.1 快速上手  
- 首次登录，系统会默认创建 default 空图  
![alt 快速上手](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/2.tugraph-browser-quickstart-01.png)  
- 用户点击帮助选项，并选择快速上手  
![alt 帮助](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/3.tugraph-browser-quickstart-02.png)  
- 然后点击“一键创建模型”——>""一键创建数据""，就可以完成内置的 Movie 数据图谱的构建  
#### 3.2 创建子图和示例  
##### 3.2.1 创建子图  
- 点击新建子图
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/4.tugraph-browser-create-subgraph-01.png)
- 填写表单信息
![alt 填写表单](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/5.tugraph-browser-create-subgraph-02.png)
- 子图名称
- 子图描述
- 配置信息
- 点击确认，提示创建成功
- 切换子图
![alt 切换子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/6.tugraph-browser-use-graph-01.png)  
- 点击新建示例
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/create-scene-01.png)
- 选择示例并点击创建
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/select-scene.png)  
#### 3.3 查询  
![alt 查询](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/7.tugraph-browser-query-01.png)  
##### 3.3.1 页面组成  
- cypher 输入框
- 结果集展示区域  
##### 3.3.2 结果集展示区域功能详情  
- 结果集标签展示及功能
![alt 结果集标签](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/tugraph-browser-result.png)
- 这里展示了结果集的所有类型统计
- 点击不同的“label（标签）”，可以进行以下修改操作
- 修改展示颜色
- 修改节点大小或边的粗细
- 修改默认展示属性或系统属性
- 布局修改
- 力导布局
- 网格布局
- 树形布局
- 环境布局
- 边聚合
- 相同类型，方向的边可以进行合并
- 创建节点
- 点击创建节点按钮
- 选择节点类型
- 添写节点内容
- 创建关系
- 在画布中选择起点和终点
- 选择可以匹配的类型
- 填写节点信息
- 停止布局
- 当数据量过大，导致浏览器页面卡顿时候，可以点击这个停止布局的按钮，能够提高体验的流畅度
- 鼠标悬停
- 开启此功能，可以高亮显示鼠标悬停节点的一度邻居节点
- 结果集导出
- 可以将结果集导出为 png，json，csv 三种不同的文件形式
- 刷新
- 点击刷新按钮，会重新执行当前页面的初始 cypher 语句，并刷新结果集
- 最大化
- 点击最大化，结果集展示区域将全屏展示
- 结果集展示形式切换
- 支持图谱、表格、文本三种形式  
##### 3.3.3 建模  
- 点边模型
![alt 建模](https://tugraph-w' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '3.工作台'}","page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

`bfs`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关定义、数据结构的初始化
2. 使用批处理函数对每个节点进行循环计算，每一轮找到与当前节点相邻的全部节点，并在该轮次终止时进行交换。
3. 直到找到全部节点，返回节点个数discovered_vertices。  
```C++
size_t BFSCore(Graph<Empty>& graph, size_t root_vid, ParallelVector<size_t>& parent){

size_t root = root_vid;
auto active_in = graph.AllocVertexSubset();   //分配数组，active_in用于存放上一循环阶段已找到的节点
active_in.Add(root);            //把跟节点加入数组中
auto active_out = graph.AllocVertexSubset();  //分配数组active_out用于存放当前循环阶段找到的节点
parent.Fill((size_t)-1);               //将parent数组中的节点赋值为-1，-1表示未被找到
parent[root] = root;
size_t num_activations = 1;       //表示当前循环阶段找到的节点个数
size_t discovered_vertices = 0;    //表示当前循环阶段找到节点的总个数

for (int ii = 0; num_activations != 0; ii++) {       //num_activations表示当前循环阶段找到的节点个数
printf(""activates(%d) <= %lu\n"", ii, num_activations);
discovered_vertices += num_activations;         //discovered_vertices表示当前循环阶段找到节点的总个数
active_out.Clear();
num_activations = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t num_activations = 0;
for (auto& edge : graph.OutEdges(vi)) {   //每一次循环从根节点出发，查找邻近的相邻节点，对其parent值改变，并num_activations+1操作
size_t dst = edge.neighbour;
if (parent[dst] == (size_t)-1) {
auto lock = graph.GuardVertexLock(dst);
if (parent[dst] == (size_t)-1) {
parent[dst] = vi;
num_activations += 1;
active_out.Add(dst);       //存放当前循环阶段找到的节点
}
}
}
return num_activations;
},
active_in);
active_in.Swap(active_out);
}
// 返回全部节点数
return discovered_vertices;
}
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}"
如果您想提交非原创作品给蚂蚁集团，您需要标注哪些信息？,"page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。  
蚂蚁集团 2015 年开始自主研发分布式图数据库、流式图计算等图相关技术，2016 年发布自研分布式图数据库，并应用于支付宝。至今 TuGraph 已应用于蚂蚁内部 150 多个场景，包括在线支付的实时链路，以支付宝风险识别能力提升近 10 倍、风险审理分析效率提升 90%的成绩，验证了其高可靠性。  
LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，TuGraph 在功能完整性、吞吐率、响应速度等层面全球领先。  
目前，蚂蚁集团已形成了一套以图数据库为底座、同时包含流式图计算，离线图学习的大规模图计算系统。  
蚂蚁集团图数据库负责人洪春涛表示，图技术是未来大数据、人工智能和高性能计算产业发展的关键所在，它很有可能会成为下一代的数据底座。蚂蚁集团愿意通过开源持续输出核心技术优势，推动图数据库更广泛的应用生态，携手行业抢占技术高地，不断探索技术的可能性。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}","page_content='如何贡献

4. 贡献代码流程

4.5. 配置 Github 信息

在您的机器执行 git config  --list ，查看 git 的全局用户名和邮箱。检查显示的 user.name 和 user.email 是不是与自己 github 的用户名和邮箱相匹配。  
如果公司内部有自己的 gitlab 或者使用了其他商业化的 gitlab，则可能会出现不匹配的情况。这时候，您需要为 TuGraph DB 项目单独设置用户名和邮箱。设置用户名和邮箱的方式请参考 github 官方文档。' metadata={'Header 1': '如何贡献', 'Header 2': '4. 贡献代码流程', 'Header 3': '4.5. 配置 Github 信息'}","page_content='开始上手(Geaflow Kubernetes Operator运行)

通过Geaflow Kubernetes Operator提交作业

提交作业

geaflow-kubernetes-operator成功部署并运行后，就可以编写作业的yaml文件进行作业提交了。
首先我们编写一个geaflow内置示例作业的yaml文件。  
```yaml
apiVersion: geaflow.antgroup.com/v1
kind: GeaflowJob
metadata:
# 作业名称
name: geaflow-example
spec:
# 作业使用的GeaFlow镜像
image: geaflow:0.1
# 作业拉取镜像的策略
imagePullPolicy: IfNotPresent
# 作业使用的k8s service account
serviceAccount: geaflow
# 作业java进程的主类
entryClass: com.antgroup.geaflow.example.graph.statical.compute.khop.KHop
clientSpec:
# client pod相关的资源设置
resource:
cpuCores: 1
memoryMb: 1000
jvmOptions: -Xmx800m,-Xms800m,-Xmn300m
masterSpec:
# master pod相关的资源设置
resource:
cpuCores: 1
memoryMb: 1000
jvmOptions: -Xmx800m,-Xms800m,-Xmn300m
driverSpec:
# driver pod相关的资源设置
resource:
cpuCores: 1
memoryMb: 1000
jvmOptions: -Xmx800m,-Xms800m,-Xmn300m
# driver个数
driverNum: 1
containerSpec:
# container pod相关的资源设置
resource:
cpuCores: 1
memoryMb: 1000
jvmOptions: -Xmx800m,-Xms800m,-Xmn300m
# container个数
containerNum: 1
# 每个container内部的worker个数(线程数)
workerNumPerContainer: 4
userSpec:
# 作业指标相关配置
metricConfig:
geaflow.metric.reporters: slf4j
geaflow.metric.stats.type: memory
# 作业存储相关配置
stateConfig:
geaflow.file.persistent.type: LOCAL
geaflow.store.redis.host: host.minikube.internal
geaflow.store.redis.port: ""6379""
# 用户自定义参数配置
additionalArgs:
kubernetes.resource.storage.limit.size: 12Gi
geaflow.system.state.backend.type: MEMORY
```  
Geaflow 作业依赖于redis组件，可以通过docker快速启动一个redis容器并将端口映射到localhost。
```shell
docker pull redis:latest
docker run -p 6379:6379 --name geaflow_redis redis:latest
```
若你已经部署了一个redis组件，则可以将example.yaml中的以下参数替换为已有的redis host和端口号。
```yaml
spec:
userSpec:
stateConfig:
geaflow.store.redis.host: ${your.redis.host}
geaflow.store.redis.port: ${your.redis.port}
```  
然后通过如下命令即可将作业提交到k8s集群。
```shell
cd tugraph-analysis/geaflow-kubernetes-operator/example
kubectl apply example_hla.yml
```' metadata={'Header 1': '开始上手(Geaflow Kubernetes Operator运行)', 'Header 2': '通过Geaflow Kubernetes Operator提交作业', 'Header 3': '提交作业'}"
web端导入点数据后，不同的方式查询得到结果不同,"page_content='性能优先

4.数据编码

对于属性图模型而言，除了图拓扑编码外，属性数据也会很大程度影响功能和性能，我们先讨论属性数据如何与拓扑数据共存的编码格式。从目前的调研来看，属性编码有两种方式，我们称之为基于指针索引将属性数据单独存储的离散编码，和将属性数据和拓扑数据打包在一起的紧凑编码。离散编码根据程度的不同，可以每个属性都单独存储，或者每条边的属性打包后各自存储，下面的讨论对两种情况都适用。  
点查询。属性编码主要针对边，不涉及点查询。  
单边查询。离散编码通过指针定位边，紧凑编码则需要二分查找定位边的位置，离散编码有略微的优势。  
边遍历。离散编码在边遍历过程需要不断地进行指针跳转进行随机数据访问，而紧凑编码提前把数据排列在一起，顺序访问的特性使得效率大大提升。 由规律三知对边的遍历操作很普遍，紧凑编码在边遍历的优势明显。  
单边更新。离散编码对边的更新仅需找到对应的指针位置，插入数据后修改前后指针指向。紧凑编码则需要对紧凑排列的数据进行重编码，对整个边值进行重新写入，开销显著大于离散编码的情形。  
批量边更新。批量更新可以在内存中预先构建点的所有边属性，一次性编码写入，离散编码和紧凑编码相当。但紧凑编码不需要存储指针变量，更少的存储空间效率也会更高。  
以上离散编码和紧凑编码在某一类的查询的性能问题，可以通过优化的来缓解。整体上说，由于图负载读写 20:1 的特性，读性能在整体性能中占比更高。以及规律三所揭示的对属性访问的特征，TuGraph 更倾向于采用紧凑编码来保证读性能。其主要弱势为单边更新时重编码的开销，可以用自适应映射的技术来解决。' metadata={'Header 1': '性能优先', 'Header 2': '4.数据编码'}","page_content='TuGraph-Restful-Server

7.接口

7.10. 导入进度查询请求

用户通过此类请求获得导入任务的状态
#### 7.10.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_progress
#### 7.10.2 REQUEST
|  body参数  |          参数说明           |  参数类型  |  是否必填  |
|:--------:|:-----------------------:|:------:| :-----: |
| taskId |           任务编号           |  字符串  |  是  |  
#### 7.10.3 RESPONSE
| body参数 |                  参数说明                   |  参数类型  |  是否必填  |
|:------:|:---------------------------------------:|:------:| :-----: |
| state  | 状态标记，为0表示准备导入，为1表示导入中，为2表示导入成功，为3表示导入失败 |  字符串  |  是  |
|  progress  |             导入进度，state为1时包含             |  字符串  |  否  |
|  reason  |             失败原因，state为3时包含             |  字符串  |  否  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.10. 导入进度查询请求'}","page_content='业务开发指南

导入数据

批量upsert点数据

如果不存在就插入点，如果存在就更新点的属性，根据点的主键字段值判断是否存在。  
第二个参数是一个`list`类型，每个`list`里面的元素是个`map`类型，每个`map`里面是点的字段和对应的值。  
推荐使用driver里面的参数化特性，第二个参数直接传入一个 `list`结构体，避免自己构造语句。
```
CALL db.upsertVertex('node1', [{id:1, name:'name1'},{id:2, name:'name2'}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert点数据'}"
对象图映射（OGM）支持什么？,"page_content='TuGraph-OGM

1.简介

> TuGraph-OGM 项目在其他仓库开源。  
TuGraph-OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。同时 TuGraph-OGM 兼容 Neo4j-OGM，Neo4j 生态用户可以无缝迁移到 TuGraph 数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '1.简介'}","page_content='TuGraph Java Client

特性

- Java中的RPC客户端
- OGM，即对象图映射，支持将图中的实体和关系映射到Java对象，从而加速Java开发过程。' metadata={'Header 1': 'TuGraph Java Client', 'Header 2': '特性'}","page_content='TuGraph-OGM

简介

TuGraph-OGM(Object Graph Mapping), 源自 `Neo4j-OGM` 项目，TuGraph-OGM
支持将JAVA对象（POJO）映射到TuGraph中，JAVA中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此JAVA开发人员可以在熟悉的生态中轻松地使用TuGraph数据库。同时TuGraph-OGM兼容Neo4j-OGM，Neo4j生态用户可以无缝迁移到TuGraph数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '简介'}"
如何在单节点模式下实例化liblgraph_client_python.client对象？,"page_content='Python客户端

3.RPC Client

3.1.实例化client对象

#### 3.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
```python
client = liblgraph_client_python.client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, url: str, user: str, password: str)
```  
#### 3.1.2.实例化HA集群直连连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化。
```python
client = liblgraph_client_python.client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, url: str, user: str, password: str)
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 3.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化
```python
client = liblgraph_client_python.client([""189.33.97.23:9091"",""189.33.97.24:9091"", ""189.33.97.25:9091""], ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, urls: list, user: str, password: str)
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.1.实例化client对象'}","page_content='Python客户端

3.RPC Client

3.11.从字节流中导入schema

```python
ret, res = client.importSchemaFromContent(schema, ""default"", 1000)
```
```
importSchemaFromContent(self: liblgraph_client_python.client, schema: str, graph: str, json_format: bool, timeout: float) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，由于导入schema是写请求，HA模式下的client只能向leader发送导入schema请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.11.从字节流中导入schema'}","page_content='Python客户端

3.RPC Client

3.13.从文件中导入schema

```python
ret, res = client.importSchemaFromFile(""./test/data/yago.conf"", ""default"", 1000)
```
```
importSchemaFromFile(self: liblgraph_client_python.client, schema_file: str, graph: str, json_format: bool, timeout: float) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，由于导入schema是写请求，HA模式下的client只能向leader发送导入schema请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.13.从文件中导入schema'}"
如果传递给 `GetRoleInfo` 函数的角色名非法，会抛出哪种异常？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLm' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='数据导入

3.配置文件

3.2.配置文件示例

```json
{
""schema"": [
{
""label"": ""actor"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""aid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" }
],
""primary"": ""aid""
},
{
""label"": ""movie"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""mid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" },
{ ""name"": ""year"", ""type"": ""INT16"" },
{ ""name"": ""rate"", ""type"": ""FLOAT"", ""optional"": true }
],
""primary"": ""mid"",
""detach_property"": false
},
{
""label"": ""play_in"",
""type"": ""EDGE"",
""properties"": [{ ""name"": ""role"", ""type"": ""STRING"", ""optional"": true }],
""constraints"": [[""actor"", ""movie""]]
}
],
""files"": [
{
""path"": ""actors.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""actor"",
""columns"": [""aid"", ""name""]
},
{
""path"": ""movies.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""movie"",
""columns"": [""mid"", ""name"", ""year"", ""rate""]
},
{
""path"": ""roles.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""play_in"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
对于上述配置文件，定义了三个 label：两个点类型`actor`和`movie`，一个边类型`role`。每个 label 都描述了：label 的名字、类型（点还是边）、属性字段有哪些以及每个字段的类型。对于点，另外定义了 primary 字段是哪个；对于边，另外定义了 constraints 字段，用来限制边的起点和终点只能是哪些组合。  
还描述了三个数据文件，两个点的数据文件`actors.csv`和`movies.csv`，一个边的数据文件`roles.csv`。每个部分都描述了：文件的路径（path）、数据类型（format）、信息头占开头几行（header）、是哪个 label 的数据（label）、文件中每行数据中的每个列对应的字段是哪个。  
对于上述配置文件，import 工具在执行的过程中会先在 TuGraph 中创建`actor`、`movie`、`role`这三个 label，然后再执行三个文件的数据导入。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.2.配置文件示例'}","page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

#### 2.3.1.rest  
样例代码中在test_get_info函数执行之前先启动server，server启动后启动了rest client，进入test_get_info函数后获取server的一些信息，并通过assert判断是否有获取到cpu的信息。  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7073 --rpc_port 9093"",
""cleanup_dir"":[""./testdb""]}
RESTTOPT = {""port"":""7073"", ""user"":""admin"", ""password"":""73@TuGraph""}
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""rest"", [RESTTOPT], indirect=True)
def test_get_info(self, server, rest):
res = rest.get_server_info()
log.info(""res : %s"", res)
assert('cpu' in res)
```  
#### 2.3.2.client  
样例代码中在test_flushdb函数执行之前先执行了数据离线导入逻辑，并启动server后，通过client创建链接，进入test_flushdb函数后，通过查询点的个数判断导入是否成功，导入成功后执行flushDB操作，再次通过assert判断是否能正常清空db  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}

CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}

IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}

@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_flushdb(self, importor, server, client):
ret = client.callCypher(""MATCH (n) RETURN n LIMIT 100"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert len(res) == 21
ret = client.callCypher(""CALL db.flushDB()"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}"
TuGraph 的部署方式有哪些？,"page_content='功能概览

1.1.部署方式

TuGraph目前提供云部署、Docker部署以及安装包部署三种部署方式，用户可根据实际情况选择适合的部署方式。' metadata={'Header 1': '功能概览', 'Header 2': '1.1.部署方式'}","page_content='环境和版本选择

3. 部署方式选择

TuGraph部署仅需一台服务器（高可用模式需要多台），可根据实际资源情况和使用场景，选择适合的部署方式。  
| 部署方式     | 描述                   | 备注                                                                                      |
|----------|----------------------|-----------------------------------------------------------------------------------------|
| 云部署      | 阿里云计算巢一键部署，免费试用      | 新手适用，流程参考 [链接](../5.installation&running/5.cloud-deployment.md)              |
| Docker部署 | 通过预先准备的Docker镜像跨平台部署 | 对硬件有要求的用户，比如性能测试，流程参考 [链接](../5.installation&running/3.docker-deployment.md) |
| 本地部署     | 在现有系统紧耦合部署           | 指定生产环境适用，流程参考 [链接](../5.installation&running/4.local-package-deployment.md)  |' metadata={'Header 1': '环境和版本选择', 'Header 2': '3. 部署方式选择'}","page_content='部署高可用模式

1.原理

TuGraph 通过多机热备份来提供高可用（HA）模式。在高可用模式下，对数据库的写操作会被同步到所有服务器（非witness）上，这样即使有部分服务器宕机也不会影响服务的可用性。  
高可用模式启动时，多个 TuGraph 服务器组成一个备份组，即高可用集群。每个备份组由三个或更多 TuGraph 服务器组成，其中某台服务器会作为`leader`，而其他复制组服务器则作为`follower`。写入请求由`leader`
提供服务，该`leader`将每个请求复制同步到`follower`，并在请求同步到服务器后才能响应客户端。这样，如果任何服务器发生故障，其他服务器仍将具有到目前为止已写入的所有数据。如果`leader`
服务器发生故障，其他服务器将自动选择出新的`leader`。  
TuGraph的高可用模式提供两种类型的节点：`replica`节点和`witness`节点。其中，`replica`节点是普通节点，有日志有数据，可对外提供服务。
而`witness`节点是一种只接收心跳和日志但不保存数据的节点。根据部署需求，`leader`节点和`follower`节点可以灵活的部署为`replica`节点或`witness`节点。
基于此，TuGraph高可用模式的部署方式有两种：一是普通部署模式，二是带witness的简约部署模式。  
对于普通部署模式，`leader`和所有`follower`均为`replica`类型的节点。写入请求由`leader`提供服务，该`leader`将每个请求复制同步到`follower`，
并在请求同步到超过半数的服务器后才能响应客户端。这样，如果少于半数的服务器发生故障，其他服务器仍将具有到目前为止已写入的所有数据。如果`leader`
服务器发生故障，其他服务器将自动选举出新的`leader`，通过这种方式保证数据的一致性和服务的可用性。  
然而，在用户服务器资源不够或者发生网络分区时，不能建立正常的HA集群。此时，由于`witness`节点没有数据，对资源占用小，可以将`witness`节点和`replica`节点部署在一台机器上。
例如，当只有2台机器的情况下，可以在一台机器上部署`replica`节点，在另一台机器上部署`replica`节点和`witness`节点，不仅节省资源，而且不需要把日志应用到状态机上，
也不需要生成和安装快照，因此响应请求的速度很快，可以在集群崩溃或网络分区时协助快速选举出新的`leader`，这就是TuGraph HA集群的简约部署模式。
尽管`witness`节点有诸多好处，但是由于没有数据，集群实际上增加了一个不能成为`leader`的节点，因此可用性会略有降低。为提高集群的可用性，
可通过指定`ha_enable_witness_to_leader`参数为`true`，允许`witness`节点临时当主。`witness`节点在把新日志同步到其他节点之后，
会将leader角色主动切换到有最新日志的节点。  
v3.6及以上版本支持此功能。' metadata={'Header 1': '部署高可用模式', 'Header 2': '1.原理'}"
根据使用MATCH和SKIP语句的查询结果，跳过第一行后返回的第一位人物的名字是什么？,"page_content='ISO GQL

2.Clauses

2.7.SKIP

`SKIP`指定结果偏移行数。  
#### 未使用SKIP  
```
MATCH (n:Person)
RETURN n.name LIMIT 3
```  
返回结果  
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""},{""n.name"":""Dennis Quaid""}]
```  
#### 使用SKIP  
```
MATCH (n:Person)
RETURN n.name SKIP 1 LIMIT 2
```  
返回结果
```JSON
[{""n.name"":""Corin Redgrave""},{""n.name"":""Dennis Quaid""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.7.SKIP'}","page_content='Cypher API

2.Clauses

2.5.SKIP

- ✓ Skip first three records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 3
```  
- ✓ Return middle two records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 1
LIMIT 2
```  
- ❏ Using an expression with SKIP to return a subset of the records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP toInteger(3*rand())+ 1
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.5.SKIP'}","page_content='Cypher API

3.Functions

3.3.Scalar functions

- id()
get the id of vertex.
**Scope:** whole instance.
**Example input:**  
```
MATCH (a)
RETURN id(a)
```  
**Example output:**  
| vid |
| --- |
| 1   |
| 2   |
| ... |  
- properties()
get a map containing all the properties of a node or relationship.
**Scope:** whole instance.
**Example input:**  
```
MATCH (n:person {name: 'Laurence Fishburne'})
RETURN n
```  
- head()
get the first element of a list.
**Scope:** whole instance.
**Example input:**  
```
WITH ['one','two','three'] AS coll RETURN coll, head(coll)
```  
**Example output:**  
| coll                  | head(coll)    |
| --------------------- | ------------- |
| [""one"",""two"",""three""] | ""one""         |  
- last()
get the last element of a list.
**Scope:** whole instance.
**Example input:**  
```
WITH ['one','two','three'] AS coll RETURN coll, last(coll)
```  
**Example output:**  
| coll                  | last(coll)    |
| --------------------- | ------------- |
| [""one"",""two"",""three""] | ""three""       |  
- toFloat()
Converts an integer or string value to a floating point number.
**Scope:** whole instance.
**Example input:**  
```
RETURN toFloat('11.5')
```  
**Example output:**  
| float |
| ----- |
| 11.5  |  
- toInteger()
Converts a floating point or string value to an integer value.
**Scope:** whole instance.
**Example input:**  
```
RETURN toInteger('2.3') AS integer
```  
**Example output:**  
| integer |
| ------- |
| 2       |  
- toString()
Converts an integer, float, boolean value to a string.
**Scope:** whole instance.
**Example input:**  
```
RETURN toString(2.3)
```  
- type()
get the string representation of the relationship type.
**Scope:** whole instance.
**Example input:**  
```
MATCH (n)-[r]->()
WHERE n.name = 'Laurence Fishburne'
RETURN type(r)
```  
**Example output:**  
| type     |
| -------- |
| acted_in |
| acted_in |' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.3.Scalar functions'}"
导入数据时，如果操作失败，是否可以继续导入？,"page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

#### 6.10.1.指定文件内容导入  
- **URI**: `/db/{graph_name}/import/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |
| data | 要导入的文件内容（建议最大在 16MB 左右，最长不超过 17MB） | 字符串 / 数组 / 对象 |
| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""description"": ""{\\""files\\"":[{\\""columns\\"":[\\""SRC_ID\\"",\\""role\\"",\\""DST_ID\\""],\\""format\\"":\\""CSV\\"",\\""label\\"":\\""role\\"",\\""SRC_ID\\"":\\""actor\\"",\\""DST_ID\\"":\\""movie\\""}]}""}"",
""data"": ""1,Role1,2\n3,Role2,4\n"",
""continue_on_error"": true,
""delimiter"": "",""
}
```  
上述 description 的值是如下 json 序列化后的字符串  
```json
{
""files"": [
{
""format"": ""CSV"",
""label"": ""role"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""log"": ""Missing src uid 1\n""
}
```  
由于请求中指定了在出错时继续，该返回信息说明 SRC_ID 为 1 的边没有被导入，而其他信息导入成功。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}","page_content='C++客户端

2.使用示例

2.12.从字节流中导入点边数据

```C++
std::string str;
ret = client.ImportDataFromContent(str, sImportContent[""person_desc""], sImportContent[""person""],"","");
```
```
bool ImportDataFromContent(std::string& result, const std::string& desc,
const std::string& data, const std::string& delimiter,
bool continue_on_error = false, int thread_nums = 8,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0);
@param [out] result              The result.
@param [in]  desc                data format description.
@param [in]  data                the data to be imported.
@param [in]  delimiter           data separator.
@param [in]  continue_on_error   (Optional) whether to continue when importing data fails.
@param [in]  thread_nums         (Optional) maximum number of threads.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  timeout             (Optional) Maximum execution time, overruns will be
interrupted.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='TuGraph-Restful-Server

7.接口

7.8 数据导入请求

用户通过此类请求导入已经上传的数据文件。导入不论成功或失败，都将删除已上传文件。数据导入请求在server中实现为一个异步任务，响应返回并不意味着导入已完成，返回的是任务id，后续可以通过此任务id查询导入进度
#### 7.8.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_data
#### 7.8.2 REQUEST
|  body参数  |          参数说明           |  参数类型  | 是否必填 |
|:--------:|:-----------------------:|:------:|:----:|
| graph |         导入目标子图          |  字符串  |  是   |
| schema |       导入schema描述        | json字符串  |  是   |
| delimiter |           分隔符           |  字符串  |  是   |
| continueOnError |     单行数据出错是否跳过错误并继续     |  boolean  |  否   |
| skipPackages |         跳过的包个数          |  字符串  |  否   |
| taskId |  任务id   |  字符串  |  否   |
| other | 其他参数 |  json字符串  |  否   |  
#### 7.8.3 RESPONSE
|    body参数     |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| taskId | 任务编号 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.8 数据导入请求'}"
如果不定义表头并使用空的Result()初始化表，你接下来应该使用什么方法为表设置表头？,"page_content='RESTful API Legacy

4.查询

4.1.调用Cypher

- **URI**: `/cypher`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| graph | 数据库 | 字符串 |
| cypher | 查询语句 | 字符串 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| result | 运行结果 | 列表 |
| elapsed | 运行时间（秒） | 浮点数 |
| header | 返回结果的表头 | 列表 |
| size | 结果数 | 整型 |  
其中 header 是一个列表，每一元素格式如下：  
| 域名 | 说明                                        | 类型   |
| ---- | ------------------------------------------- | ------ |
| name | 列名                                        | 字符串 |
| type | 列数据类型，0 为标量，1 为点 id，2 为向量 |        |  
**Example request.**  
```
• POST http://localhost:7070/cypher
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""graph"": ""default"",
""script"": ""MATCH (n) RETURN n,n.name LIMIT 10""
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""elapsed"": 0.001224517822265625,
""header"": [
{
""name"": ""n"",
""type"": 1
},
{
""name"": ""n.name"",
""type"": 0
}
]
""result"": [
[
0,
""Rachel Kempson""
],
[
1,
""Michael Redgrave""
],
[
2,
""Vanessa Redgrave""
]
],
""size"": 3
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '4.查询', 'Header 3': '4.1.调用Cypher'}","page_content='Use Graph

Example

```sql
-- Set current using graph.
USE GRAPH modern;

INSERT INTO tbl_result
SELECT
a.id,
b.id,
c.id,
c.kind,
d.id,
d.type
FROM (
MATCH (a) -> (b) where b.id > 0 and a.lang is null
MATCH (a) <- (c) where label(c) = 'person'
Let c.kind = 'k' || cast(c.age / 10 as varchar)
MATCH (c) -> (d) where d != b
Let d.type = if (label(d) = 'person', 1, 0)
RETURN a, b, c, d
)
;
```' metadata={'Header 1': 'Use Graph', 'Header 2': 'Example'}","page_content='Bolt客户端

使用示例

添加Maven依赖  
```xml
<dependency>
<groupId>org.neo4j.driver</groupId>
<artifactId>neo4j-java-driver</artifactId>
<version>4.4.2</version>
</dependency>
```
Client按照如下格式进行实例化:  
```java
Driver driver = GraphDatabase.driver(""bolt://ip:port"", AuthTokens.basic(""admin"", ""73@TuGraph""));
```  
常用语句  
```java
//通过 driver 对象创建一个 Session，设置会话连接到特定的数据库，用于执行Cypher语句
Session session = driver.session(SessionConfig.forDatabase(""default""));
//清空图项目，请不要轻易尝试，它会清空你选中的图项目的模型以及数据
session.run(""CALL db.dropDB()"");
//创建点模型
session.run(""CALL db.createVertexLabel('person', 'id' , 'id' ,INT32, false, 'name' ,STRING, false)"");
//创建边模型
session.run(""CALL db.createEdgeLabel('is_friend','[[\""person\"",\""person\""]]')"");
//创建索引
session.run(""CALL db.addIndex(\""person\"", \""name\"", false)"");
//插入点数据
session.run(""create (n1:person {name:'jack',id:1}), (n2:person {name:'lucy',id:2})"");
//插入边数据
session.run(""match (n1:person {id:1}), (n2:person {id:2}) create (n1)-[r:is_friend]->(n2)"");
//查询点和边
Result res = session.run(""match (n)-[r]->(m) return n,r,m"");
//Parameterized Query
String cypherQuery = ""MATCH (n1:person {id:$id})-[r]-(n2:person {name:$name}) RETURN n1, r, n2"";
Result result1 = session.run(cypherQuery, parameters(""id"", 1, ""name"", ""lucy""));
while (result1.hasNext()) {
Record record = result1.next();
System.out.println(""n1: "" + record.get(""n1"").asMap());
System.out.println(""r: "" + record.get(""r"").asMap());
System.out.println(""n2: "" + record.get(""n2"").asMap());
}
//删除点数据
session.run(""match (n1:person {id:1}) delete n1"");
//删除边数据
session.run(""match (n1:person {id:1})-[r]-(n2:person{id:2}) delete r"");
//删除边模型
session.run(""CALL db.deleteLabel('edge', 'is_friend')"");
//删除点模型
session.run(""CALL db.deleteLabel('vertex', 'person')"");
```  
详细Cypher和存储过程的使用可见[Cypher](../../8.query/1.cypher.md)' metadata={'Header 1': 'Bolt客户端', 'Header 2': '使用示例'}"
蚂蚁集团的个人贡献者许可协议主要目的是什么？,"page_content='如何贡献

3. 准备工作

3.3. 许可协议

在贡献代码之前，请您稍微花一些时间了解为TuGraph贡献代码的流程，并阅读 [个人贡献者许可协议](3.individual-cla.md) 或 [公司贡献者许可协议](4.corporate-cla.md)，参与贡献则视为同意上述协议。' metadata={'Header 1': '如何贡献', 'Header 2': '3. 准备工作', 'Header 3': '3.3. 许可协议'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

当 TuGraph 遇见 Antlr4

ISO GQL（ISO/IEC 39075）是一种标准化的图数据库查询语言，蚂蚁集团是其主要贡献者之一。因此，Antlr4 作为一种强大的解析器生成器，成为了蚂蚁图数据库 TuGraph 生成 GQL 解释器的理想选择。Antlr4 能够帮助团队更快、更准确地构建图数据库的查询语言，从而提高产品性能和用户体验。  
然而，当我们从开发场景来到生产场景，超高的并发量带来一个严重问题：Antlr4 C++ target 的并发性能不足以支持所需的超高并发 GQL 请求。经过调研并与 Antlr 开源社区讨论，我们发现\*\*并发性能这个问题普遍存在，并且在过去 5 年中持续困扰着 C++生态的开发者。\*\*我们决定解决这个问题。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '当 TuGraph 遇见 Antlr4'}","page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。  
蚂蚁集团 2015 年开始自主研发分布式图数据库、流式图计算等图相关技术，2016 年发布自研分布式图数据库，并应用于支付宝。至今 TuGraph 已应用于蚂蚁内部 150 多个场景，包括在线支付的实时链路，以支付宝风险识别能力提升近 10 倍、风险审理分析效率提升 90%的成绩，验证了其高可靠性。  
LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，TuGraph 在功能完整性、吞吐率、响应速度等层面全球领先。  
目前，蚂蚁集团已形成了一套以图数据库为底座、同时包含流式图计算，离线图学习的大规模图计算系统。  
蚂蚁集团图数据库负责人洪春涛表示，图技术是未来大数据、人工智能和高性能计算产业发展的关键所在，它很有可能会成为下一代的数据底座。蚂蚁集团愿意通过开源持续输出核心技术优势，推动图数据库更广泛的应用生态，携手行业抢占技术高地，不断探索技术的可能性。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}"
TuGraph Mini Runtime Image 不包含哪些功能？,"page_content='Docker部署

1.简介

- TuGraph Compile Image：提供编译环境，可以用于TuGraph的编译，测试；
- TuGraph Runtime Image：提供二进制可运行环境，附带TuGraph库和可执行文件；
- TuGraph Mini Runtime Image: 提供二进制可运行环境，不包含TuGraph中Java、Python相关的功能，无C++ plugin编译运行，仅so上传。' metadata={'Header 1': 'Docker部署', 'Header 2': '1.简介'}","page_content='Docker部署

2.现有Docker Image

2.2.命名规范

#### 2.2.1.TuGraph Compile Image  
提供编译环境，可以用于TuGraph的编译。  
`tugraph/tugraph-compile-[os name & version]:[tugraph compile version]`  
例如： `tugraph/tugraph-compile-centos7:1.2.0`  
#### 2.2.2.TuGraph Runtime Image  
提供二进制可运行环境，附带TuGraph库和可执行文件。  
`tugraph/tugraph-runtime-[os name & version]:[tugraph-runtime version]`  
例如：`tugraph/tugraph-runtime-centos7:3.4.0`  
#### 2.2.3.TuGraph Mini Runtime Image  
提供二进制可运行环境，不包含TuGraph种Java、Python相关的功能，无C++ plugin编译运行，仅so上传。  
`tugraph/tugraph-mini-runtime-[os name & version]:[tugraph-runtime version]`  
例如： `tugraph/tugraph-mini-runtime-centos7:3.4.0`' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.2.命名规范'}","page_content='环境分类

1.分类

根据环境所承载功能的不同，区分为编译环境，运行环境，以及精简运行环境。
* 编译环境，具备TuGraph编译的所有依赖库，包含运行环境的所有依赖，并且能够编译TuGraph源码，但不包含预编译好的TuGraph可执行文件和库文件，供开发者编译源码使用。
* 运行环境，具备GCC/Java/Python环境，能够运行TuGraph的所有功能，并且能承载全文索引，java client，c++源码上传为plugin，以及python plugin的完整功能，内置TuGraph预编译好的可执行文件和库文件，供客户直接安装使用，无需编译源码。
* 精简运行环境，约等于裸系统加预编译TuGraph，仅能运行TuGraph的基本功能，无C++ plugin编译运行，仅so上传，无全文索引，无python plugin，供快速搭建试用。  
TuGraph编译后，会把所有的依赖库以.a的形式打包在一起，因此原则上运行不需要的其他的依赖库。但TuGraph支持存储过程，即在服务端编译C++代码，因此在环境中依然需要涉及的编译器。' metadata={'Header 1': '环境分类', 'Header 2': '1.分类'}"
OlapOnDB API文档中介绍的Procedure及Embed主要使用了哪些辅助函数？,"page_content='OlapOnDB API

2. 模型

Procedure及Embed使用到的辅助函数主要包含在OlapOnDB类，还有一些使用频率较高的函数都会逐一介绍  
在TuGraph中OLAP相关的有以下常用的数据结构：  
1. DB图分析类 `OlapOnDB<EdgeData>`
2. 点数组`ParallelVector<VertexData>`
3. 点集合`ParallelBitset`
4. 边数据结构`AdjUnit/AdjUnit<Empty>`
5. 边集合数据结构`AdjList<EdgeData>`' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '2. 模型'}","page_content='OlapOnDB API

1. 简介

一般用户需要自己实现的只是将需要分析的子图抽取出来的过程。用户也可以通过使用TuGraph中丰富的辅助接口实现自己的图分析算法。  
该文档主要介绍Procedure及Embed的接口设计，并介绍部分常用接口，具体的接口信息参见include/lgraph/olap_on_db.h文件。' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '1. 简介'}","page_content='OlapOnDisk API

1. 简介

TuGraph的Standalone模式可用于加载图数据文件，其中图数据文件来源可包含text文本文件、BINARY_FILE二进制文件和ODPS源。在该模式下，TuGraph可实现多数据来源快速加载成图，然后在该图上运行如BFS、WCC、SSSP等迭代式算法，并输出最终结果至终端。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph内置了大量的常见图分析算法和丰富的辅助接口，因此用户几乎不需要自己实现具体的图计算过程，只需要在实现自己的存储过程的时候将相应算法库的头文件(.h)包含到自己的程序中，并在编译阶段链接自己的动态库文件即可。  
该文档主要介绍了Standalone的常用接口，使用到的辅助函数主要包含在OlapOnDB类。同时为帮助用户理解方便，对BFS算法进行举例说明。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '1. 简介'}"
在尝试为用户设置新密码时，哪些异常可能会被抛出？,"page_content='RESTful API Legacy

6.Deprecated

6.1.用户管理

系统默认创建一个管理员，管理员用户名为 _admin_，密码为 _73@TuGraph_。为了安全起见，请用户在第一次启动服务器后更改密码。  
#### 6.1.1.添加用户  
添加一个新的用户，并为其设置初始密码。只有管理员有权限进行此操作。其中用户名只能由字母，数字以及下划线构成，密码则可以包含任意字符。用户名和密码长度不能超过 64 字节。添加用户时还可以为用户增加一个描述，用户描述可以包含任意字符，最长不超过 512 字节。  
新用户默认拥有同名的角色，不具备任何图的权限。  
- **URI**: `/user`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |
| description | 用户描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""user"": ""USER1"",
""password"": ""AN_INITIAL_PASSWORD"",
""description"": ""This is a user""
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.1.2.列出所有用户  
列出数据库的所有用户。只有管理员拥有该操作权限。  
- **URI**: `/user/`
- **METHOD**: GET
- **RESPONSE**: 所有用户及其信息。  
**Example request.**  
```
• GET http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
Output:
{
""admin"": {
""disabled"": false,
""description"": ""Builtin admin user"",
""roles"": [""admin""]
},
""guest1"": {
""disabled"": true,
""description"": """",
""roles"": [""guest1"", ""some_other_role""]
}
}
```  
#### 6.1.3.获取用户信息  
列出给定用户的信息。  
- **URI**: `/user/{user_name}`
- **METHOD**: GET
- **RESPONSE**: 用户信息。  
**Example request.**  
```
• GET http://localhost:7070/user/guest1
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_z' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.1.用户管理'}","page_content='RESTful API

2.请求与响应格式

2.2请求类型

#### 2.2.1. 用户登陆
用户在登陆请求中携带用户名和密码发送到服务端。登录成功会收到带有签名的令牌(Json Web Token)和判断是否为默认密码的布尔型变量，客户端储存该令牌，在后续的请求中将令牌加入请求头的Authorization域中。如果登录失败会收到“Authentication failed”错误。  
- **URI**:     /login
- **METHOD**:  POST
- **REQUEST**:  
| body参数  | 参数说明 | 参数类型  | 是否必填       |
| ------- |------|-------|------------|
| userName   | 用户名  | 字符串类型   | 是          |
| password   | 用户密码 | 字符串类型 | 是          |  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data中包含令牌  
| body参数  | 参数说明 | 参数类型  | 是否必填       |
| ------- |------|-------|------------|
| authorization   | 令牌  | 字符串类型   | 是          |
| default_password  | 默认密码 | 布尔类型 | 是          |  
**Example request.**  
```
{""userName"" : ""test"", ""password"" : ""123456""}
```  
#### 2.2.2. 用户登出
用户登出，同时删除已经认证的token，用户后续发送请求时，需要重新登陆，并获取新的token。  
- **URI**:     /logout
- **METHOD**:  POST
- **REQUEST**:
http request header中携带调用login接口时返回的token，body中没有参数  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data为空  
#### 2.2.3. 身份刷新
已下发的token失效后，需要调用本接口重新认证。后端验证token合法性。token在初次登录后，1小时内有效，过期需要刷新  
- **URI**:     /refresh
- **METHOD**:  POST
- **REQUEST**:
http request header中携带调用login接口时返回的token，body中没有参数  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data中包含令牌  
| body参数  | 参数说明 | 参数类型  | 是否必填       |
| ------- |------|-------|------------|
| authorization   | 令牌  | 字符串类型   | 是          |  
#### 2.2.4. 调用cypher
用户对TuGraph的增删改查请求需要调用cypher接口，并通过标准的cypher查询语言发起  
- **URI**:     /cypher
- **METHOD**:  POST
- **REQUEST**:  
| body参数  | 参数说明     | 参数类型  | 是否必填       |
| ------- |----------|-------|------------|
| graph   | 查询的子图名称  | 字符串类型   | 是          |
| script   | cypher语句 | 字符串类型 | 是          |  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data中包含查询结果  
| body参数  | 参数说明 | 参数类型    | 是否必填       |
| ------- |------|---------|------------|
| result   | 查询结果 | json字符串 | 是          |  
**Example request.**  
```
{""script"" : ""Match (n) return n"", ""graph"" : ""default""}
```  
#### 2.2.5. 上传文件
接口用于将本地文件上传至TuGraph所在机器。可以上传文本文件，二进制文件，可以上传大文件，也可以上传小文件，对于大文件，客户端在上传时应该对文件做切分，每个文件分片不大于1MB，参数Begin-Pos和' metadata={'Header 1': 'RESTful API', 'Header 2': '2.请求与响应格式', 'Header 3': '2.2请求类型'}","page_content='RESTful API Legacy

3.登录

3.1.登录

用户通过用户名和密码发送登录请求。登录成功会收到带有签名的令牌(Json Web Token)和判断是否为默认密码的布尔型变量，客户端储存该令牌，并且用于以后的每次发送请求。如果登录失败会收到“Authentication failed”错误。  
- **URI**: `/login`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| jwt | 令牌 | 字符串 |
| default_password | 是否为默认密码 | 布尔值 |  
**Example request.**  
```
• POST http://localhost:7070/login
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""user"":""admin"",
""password"":""73@TuGraph""
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""jwt"": ""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek"",
""default_password"": true
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '3.登录', 'Header 3': '3.1.登录'}"
如何使用 liblgraph_python_api.Galaxy 类创建一个新的用户账户？,"page_content='Python Olap API

5. lgraph_db API

PyGalaxy:

- `PyGalaxy(self, dir_path: str)`: 构造函数，dir_path为db路径
- `SetCurrentUser(self, user: str password: str)-> void`: 设置用户
- `SetUser(self, user: std::string)-> void`: 设置用户
- `OpenGraph(self, graph: str, read_only: bool)-> PyGraphDB`: 创建PyGraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'PyGalaxy:'}","page_content='Python Olap API

5. lgraph_db API

Galaxy

- `Galaxy(dir_path: std::string)`: 构造函数，dir_path为db路径
- `SetCurrentUser(user: std::string, password: std::string)-> cython.void`: 设置用户
- `SetUser(user: std::string)-> cython.void`: 设置用户
- `OpenGraph(graph: std::string, read_only: bint)-> GraphDB`: 创建GraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Galaxy'}","page_content='Sampling API

2. 图数据预处理

在采样操作之前，根据图数据路径加载图数据，并映射成olapondb图分析类，代码如下：  
```python
galaxy = PyGalaxy(args.db_path) # 根据路径创建一个galaxy实例
galaxy.SetCurrentUser(args.username, args.password) # 设置当前用户
db = galaxy.OpenGraph('default', False) # 打开图数据库指定db
txn = db.CreateReadTxn() # 创建一个事务实例
olapondb = PyOlapOnDB('Empty', db, txn) # 根据图加载方式、图数据库实例、事务实例实例化OlapOnDB
del txn
del db
del galaxy
```' metadata={'Header 1': 'Sampling API', 'Header 2': '2. 图数据预处理'}"
调用liblgraph_python_api.GraphDB的哪个方法可以删除一个顶点标签？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.deleteLabel(label_type, label_name)

Delete a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |  
**Output:**  
| field_name | field_type | description              |
| ---------- | ---------- | -------------------------------- |
| affected   | integer    | number of vertexes/edges deleted |  
**Example input:**  
```
CALL db.deleteLabel('vertex', 'Person')
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.deleteLabel(label_type, label_name)'}","page_content='业务开发指南

边类型操作

边类型删除索引

如下例子，对于边类型`edge1`，删除字段`field1`上的索引。
```
CALL db.deleteEdgeIndex('edge1', 'field1')
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型删除索引'}","page_content='Heterogeneous Graph

4. 异质图输出格式

和同质图相同的是，异质图的采样数据结果也存储在NodeInfo和EdgeInfo中。
可通过如下方式获取输出数据。
```python
NodeInfo = []
EdgeInfo = []
getdb.Process(db, olapondb, feature_len, NodeInfo, EdgeInfo)
```
其中getdb为获取全图数据的函数，db为图数据库实例，olapondb为图分析类。feature_len为节点特征长度，NodeInfo和EdgeInfo为输出的节点和边信息。  
其存储信息结果如下：
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 边类型 | EdgeInfo[2] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |
| 顶点类型 | NodeInfo[3] |' metadata={'Header 1': 'Heterogeneous Graph', 'Header 2': '4. 异质图输出格式'}"
角色被禁用后，用户将从该角色中获得什么权限？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLm' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='用户权限

1.介绍

> TuGraph 的权限是基于角色的访问控制进行管理，定义访问控制的权限分配给角色，角色再分配给用户。' metadata={'Header 1': '用户权限', 'Header 2': '1.介绍'}","page_content='用户权限

4.常用权限操作

4.2.角色操作

- 创建角色  
```cypher
CALL dbms.security.createRole(role_name::STRING,desc::STRING)
```  
- 删除角色  
```cypher
CALL dbms.security.deleteRole(role_name::STRING
```  
- 列出所有角色  
```cypher
CALL dbms.security.listRoles()
```  
- 禁用/启用角色  
```cypher
CALL dbms.security.disableRole(role::STRING,disable::BOOLEAN)
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.2.角色操作'}"
TuGraph的可视化监控主要使用了哪些软件？,"page_content='运维监控

1.设计思路

可视化监控并不是TuGraph自身不可或缺的一部分，因此在设计时将可视化监控作为TuGraph周边生态中的一个应用，来减少和TuGraph数据库的耦合度，以及对于TuGraph自身的影响。TuGraph可视化监控采用目前最火热的开源解决方案，TuGraph Monitor + Prometheus + Grafana来实现。其中TuGraph Monitor作为TuGraph服务的客户端，通过TCP链接向TuGraph服务发起Procedure请求，TuGraph服务在接收到请求后收集自身所在机器的cpu，memory，disk，io，以及请求数量等指标的统计结果进行响应。TuGraph Monitor在接收到TuGraph响应的指标数据后，将数据包装成prometheus需要的格式，保存在内存中，等待Prometheus服务通过http请求获取。Prometheus服务会定期通过http请求从TuGraph Monitor获取封装好的请求数据，按照获取的时间保存在自己的时序数据库中。Grafana可以根据用户的配置，从Prometheus处获取某个时间段内的统计数据，并在web界面上绘制浅显易懂的图形来展示最终结果。整个请求链路中，都采用了主动获取，即PULL的模型，好处之一是它能最大限度的避免数据生产者和数据消费者之间的耦合度，使得开发更简单，好处之二是数据生产者不需要考虑数据消费者的数据处理能力，即使某个消费者的数据处理能力较弱，也不会因为生产者生产数据过快而压垮消费者。主动拉取模型的不足之处在于数据的实时性不够，但在这个场景中，数据并没有很高的实时性要求。' metadata={'Header 1': '运维监控', 'Header 2': '1.设计思路'}","page_content='功能概览

6.生态工具

6.3.运维监控

TuGraph 使用 Prometheus 加 Grafana 的监控框架，采用松耦合的方式。Prometheus 从 TuGraph 的监控接口获取监控信息，存储在本地时序数据库中，然后通过 Grafana 在网页端交互展示。  
TuGraph 提供的监控的状态包括图数据库的状态和服务器的状态，前者包括读写负载、点边数量等数据库端的状态，后者包括内存、CPU、硬盘等服务器的实时状态。如果某些监控状态超过了预期的阈值，就需要主动告警，通常需要对接其他运维管控系统，比如群消息、邮件告警等。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.3.运维监控'}","page_content='功能概览

6.生态工具

6.2.可视化交互

TuGraph Browser 是面向图数据库直接使用者的可视化交互界面，功能上覆盖了 TuGraph 的绝大部分能力，包括数据导入、图模型建立、数据增删查改、监控运维等操作链路。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.2.可视化交互'}"
TuGraph 服务在哪个文件中读取其配置？,"page_content='数据库运行

4.服务配置

4.2.服务器配置文件

TuGraph 的配置文件以 JSON 格式存储。建议将大多数配置存储在配置文件中，并且仅在需要时使用命令行选项临时修改某些配置参数。
一个典型的配置文件如下：  
```json
{
""directory"" : ""/var/lib/lgraph/data"",
""host"" : ""0.0.0.0"",
""port"" : 7070,
""rpc_port"" : 9090,
""enable_rpc"" : true,
""bolt_port"": 7687,
""enable_ha"" : false,
""verbose"" : 1,
""log_dir"" : ""/var/log/lgraph_log"",
""disable_auth"" : false,
""ssl_auth"" : false,
""server_key"" : ""/usr/local/etc/lgraph/server-key.pem"",
""server_cert"" : ""/usr/local/etc/lgraph/server-cert.pem"",
""web"" : ""/usr/local/share/lgraph/browser-resource""
}
```' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.2.服务器配置文件'}","page_content='数据库运行

4.服务配置

TuGraph 服务器在启动时从配置文件和命令行选项加载配置，如果在配置文件和命令行中同一选项指定了不同的值，将优先使用命令行中指定的值。' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置'}","page_content='数据库运行

1.前置条件

TuGraph 运行的前置条件为 TuGraph 正确安装，参考[安装流程](1.environment.md)。  
TuGraph 运行需要保证库文件 liblgraph.so 的文件位置在环境变量 LD_LIBRARY_PATH。  
运行 TuGraph 进程的用户不需要超级权限，但需要对配置文件（一般为lgraph.json）及文件中涉及的文件有读权限，并且对数据文件夹、日志文件夹等有写权限。' metadata={'Header 1': '数据库运行', 'Header 2': '1.前置条件'}"
该接口`StudentMapper`中`selectVertex`方法的超时设置是多少毫秒？,"page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

二、TuGraph-DB高可用架构与规划

1.Server架构设计—启动集群

上面是我们选择的一个基础算法，下面介绍 TuGraph-DB 具体的高可用架构是怎样设计的。通过一个 CASE 来进行讲解。  
首先建立一个集群，启动集群的方式跟单机版几乎是一致的，只不过要加上 enable\_ha 参数和 ha\_conf 参数去指定集群里面所有节点的 URL，并且要保证三个或者五个节点是可以进行通信的。在三个节点同时启动后，最先启动的节点的计时器会超时，把自己选成一个候选者，之后向其它节点发送一个投票请求，其它节点接收到请求之后，会返回给候选者一个 success 的 response，当超过半数之后，这个 leader 就当选了。一般来说，在同城的情况下，延迟不会超过 2 毫秒，在两地的情况下，比如上海到深圳，最高延迟不会超过 30 毫秒，所以集群建立的时间和选举的时间是非常快的。' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '二、TuGraph-DB高可用架构与规划', 'Header 3': '1.Server架构设计—启动集群'}","page_content='RESTful API Legacy

5.存储过程

5.4.调用存储过程

- **URI**: `/db/{graph_name}/cpp_plugin|python_plugin/{plugin_name}`
- **METHOD**: POST
- **REQUEST**: 字符串输入
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| data | 输入数据 | 字符串 |
| timeout | 超时长度（秒，可选，缺省值为 0） | 浮点 |
| in_process | 是否在本进程调用（可选，缺省值为 false） | 布尔值 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| result | 运行结果 | 字符串 |  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/python_plugin/echo
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
data : ""Hello!\n你好！\nKonichiwa!"",
timeout : 0,
in_process : true
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""result"": ""Hello!\n你好！\nKonichiwa!""
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程', 'Header 3': '5.4.调用存储过程'}","page_content='Procedure API

4.1.编写存储过程

4.1.1.编写C++存储过程

用户可以通过使用 Procedure API 或者 Traversal API 来编写 C 存储过程。一个简单的 C 存储过程举例如下：  
```
#include <iostream>
#include ""lgraph.h""
using namespace lgraph_api;

extern ""C"" LGAPI bool Process(GraphDB& db, const std::string& request, std::string& response) {
auto txn = db.CreateReadTxn();
size_t n = 0;
for (auto vit = txn.GetVertexIterator(); vit.IsValid(); vit.Next()) {
if (vit.GetLabel() == ""student"") {
auto age = vit.GetField(""age"");
if (!age.is_null() && age.integer() == 10) n++; ## 统计所有年龄为10的学生数量
}
}
output = std::to_string(n);
return true;
}
```  
从代码中我们可以看到，存储过程的入口函数是`Process`函数，它的参数有三个，分别为：  
- `db`: 数据库实例
- `request`: 输入请求数据，可以是二进制字节数组，或者 JSON 串等其它任意格式。
- `response`: 输出数据，可以是字符串，也可以直接返回二进制数据。  
`Process`函数的返回值是一个布尔值。当它返回`true`的时候，表示该请求顺利完成，反之表示这个存储过程在执行过程中发现了错误，此时用户可以通过`response`来返回错误信息以方便调试。  
C++存储过程编写完毕后需要编译成动态链接库。TuGraph 提供了`compile.sh`脚本来帮助用户自动编译存储过程。`compile.sh`脚本只有一个参数，是该存储过程的名称，在上面的例子中就是`age_10`。编译调用命令行如下：  
```bash
g++ -fno-gnu-unique -fPIC -g --std=c++14 -I/usr/local/include/lgraph -rdynamic -O3 -fopenmp -o age_10.so age_10.cpp /usr/local/lib64/liblgraph.so -shared
```  
如果编译顺利，会生成 age_10.so，然后用户就可以将它加载到服务器中了。' metadata={'Header 1': 'Procedure API', 'Header 2': '4.1.编写存储过程', 'Header 3': '4.1.1.编写C++存储过程'}"
PathTraversal 类中展开当前前沿的操作可以使用哪些类型的过滤函数？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bo' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.1. Snapshot

C++ OLAP API 中的 Snapshot 模版类用于表示抽取出来的静态子图，其中 EdgeData 用来表示该子图上每条边所用权值的数据类型（如果边不需要权值，使用 Empty 作为 EdgeData 即可）。  
抽取的子图通过 Snapshot 类的构造函数来描述：  
```c
Snapshot::Snapshot(
GraphDB & db,
Transaction & txn,
size_t flags = 0,
std::function<bool(VertexIterator &)> vertex_filter = nullptr,
std::function<bool(OutEdgeIterator &, EdgeData &)> out_edge_filter = nullptr
);
```  
其中，db 为数据库句柄，txn 为事务句柄，flags 为生成时使用的选项，可选值包括以下的组合：SNAPSHOT_PARALLEL 表示导出时使用多个线程进行并行；SNAPSHOT_UNDIRECTED 表示需要将导出的图变为无向图。
vertex_filter 是面向点的用户自定义过滤函数，返回值为 true 表示该点需要被包含到待抽取的子图中，反之则表示需要被排除。
out_edge_filter 是面向边的用户自定义过滤函数，返回值为 true 表示该边需要被包含到待抽取的子图中，反之则表示需要被排除。
当过滤函数为缺省值时，则表示需要将所有点/边都包含进来。  
Snapshot 类提供的其它方法请参考详细的 C++ API 文档（olap_on_db.h）。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.1. Snapshot'}","page_content='静态图

示例

```java
public class StaticGraphTraversalAllExample {
private static final Logger LOGGER =
LoggerFactory.getLogger(StaticGraphTraversalAllExample.class);

public static void main(String[] args) {
Environment environment = EnvironmentFactory.onLocalEnvironment();
Pipeline pipeline = PipelineFactory.buildPipeline(environment);
pipeline.submit(new PipelineTask() {
@Override
public void execute(IPipelineTaskContext pipelineTaskCxt) {
PWindowSource<IVertex<Integer, Integer>> prVertices =
pipelineTaskCxt.buildSource(new FileSource<>(""data/input/email_vertex"",
line -> {
String[] fields = line.split("","");
IVertex<Integer, Integer> vertex = new ValueVertex<>(Integer.valueOf(fields[0]),
Integer.valueOf(fields[1]));
return Collections.singletonList(vertex);
}), AllWindow.getInstance()).withParallelism(1);

PWindowSource<IEdge<Integer, Integer>> prEdges =
pipelineTaskCxt.buildSource(new FileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IEdge<Integer, Integer> edge = new ValueEdge<>(Integer.valueOf(fields[0]),
Integer.valueOf(fields[1]), 1);
return Collections.singletonList(edge);
}), AllWindow.getInstance()).withParallelism(1);

GraphViewDesc graphViewDesc = GraphViewBuilder
.createGraphView(GraphViewBuilder.DEFAULT_GRAPH)
.withShardNum(1)
.withBackend(BackendType.Memory)
.build();

PGraphWindow<Integer, Integer, Integer> graphWindow =
pipelineTaskCxt.buildWindowStreamGraph(prVertices, prEdges, graphViewDesc);

graphWindow.traversal(new VertexCentricTraversal<Integer, Integer, Integer, Integer, Integer>(3) {
@Override
public VertexCentricTraversalFunction<Integer, Integer, Integer, Integer,
Integer> getTraversalFunction() {
return new VertexCentricTraversalFunction<Integer, Integer, Integer, Integer, Integer>() {

private VertexCentricTraversalFuncContext<Integer, Integer, Integer, Integer, Integer> vertexCentricFuncContext;

@Override
public void open(
VertexCentricTraversalFuncContext<Integer, Integer, Integer, Integer, Integer> vertexCentricFuncContext) {
this.vertexCentricFuncCon' metadata={'Header 1': '静态图', 'Header 2': '示例'}"
当在只读交易中调用函数时，会抛出哪种异常？,"page_content='Procedure API

5.Procedure v2接口

5.1.编写存储过程

用户可以通过使用 lgraph API 来编写 C++ 存储过程。一个简单的 C++ 存储过程举例如下：  
```c++
// peek_some_node_salt.cpp
#include <cstdlib>
#include ""lgraph/lgraph.h""
#include ""lgraph/lgraph_types.h""
#include ""lgraph/lgraph_result.h""

#include ""tools/json.hpp""

using json = nlohmann::json;
using namespace lgraph_api;

extern ""C"" LGAPI bool GetSignature(SigSpec &sig_spec) {
sig_spec.input_list = {
{.name = ""limit"", .index = 0, .type = LGraphType::INTEGER},
};
sig_spec.result_list = {
{.name = ""node"", .index = 0, .type = LGraphType::NODE},
{.name = ""salt"", .index = 1, .type = LGraphType::FLOAT}
};
return true;
}

extern ""C"" LGAPI bool ProcessInTxn(Transaction &txn,
const std::string &request,
Result &response) {
int64_t limit;
try {
json input = json::parse(request);
limit = input[""limit""].get<int64_t>();
} catch (std::exception &e) {
response.ResetHeader({
{""errMsg"", LGraphType::STRING}
});
response.MutableRecord()->Insert(
""errMsg"",
FieldData::String(std::string(""error parsing json: "") + e.what()));
return false;
}

response.ResetHeader({
{""node"", LGraphType::NODE},
{""salt"", LGraphType::FLOAT}
});
for (size_t i = 0; i < limit; i++) {
auto r = response.MutableRecord();
auto vit = txn.GetVertexIterator(i);
r->Insert(""node"", vit);
r->Insert(""salt"", FieldData::Float(20.23*float(i)));
}
return true;
}
```  
从代码中我们可以看到：
- 存储过程定义了一个获取签名的方法`GetSignature`。该方法返回了存储过程的签名，其中包含输入参数名称及其类型，返回参数及其类型。这使得Cypher查询语句在调用存储过程能够利用签名信息校验输入数据以及返回数据是否合理。
- 入口函数是`ProcessInTxn`函数，它的参数有三个，分别为：  
- `txn`: 存储过程所处的事务，通常来说即调用该存储过程的Cypher语句所处事务。
- `request`: 输入数据，其内容为`GetSignature`中定义的输入参数类型及其Cypher查询语句中传入的值经过json序列化后的字符串。e.g. `{num_iteration: 10}`
- `response`: 输出数据，为保证在Cypher语言中能够兼容，用户可以通过往`lgraph_api::Result` 写入存储过程处理后的数据，最后用`lgraph_api::Result::Dump`来序列化成json格式的数据。  
`ProcessInTxn`函数的返回值是一个布尔值。当它返回`true`的时候，表示该请求顺利完成，反之表示这个存储过程在执行过程中发现了错误。  
C++存储过程编写完毕后需要编译成动态链接库。TuGraph 提供了`compile.sh`脚本来帮助用户自动编译存储过程。`compile.sh`脚本只有一个参数，是该存储过程的名称，在上面的例子中就是`custom_pagerank`。编译调用命令行如下：  
```bash
g++ -fno-gnu-unique -fPIC -g --std=c++14 -I/usr/lo' metadata={'Header 1': 'Procedure API', 'Header 2': '5.Procedure v2接口', 'Header 3': '5.1.编写存储过程'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='RPC API

5.存储过程

5.1.加载存储过程

加载存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称
- read_only: 必要参数，是否只读
- code: 必要参数，存储过程文件读入生成的ByteString
- desc: 可选参数，存储过程描述
- code_type: 可选参数，存储过程代码类型，PY、SO、CPP、ZIP四者之一  
以C++为例，用户加载存储过程的方式如下所示：
```C++
std::string content;
if (!FieldSpecSerializer::FileReader(source_file, content)) {
std::swap(content, result);
return false;
}
LGraphRequest req;
req.set_is_write_op(true);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
pluginRequest->set_version(version);
lgraph::LoadPluginRequest* loadPluginRequest = pluginRequest->mutable_load_plugin_request();
loadPluginRequest->set_code_type([](const std::string& type) {
std::unordered_map<std::string, lgraph::LoadPluginRequest_CodeType> um{
{""SO"", lgraph::LoadPluginRequest::SO},
{""PY"", lgraph::LoadPluginRequest::PY},
{""ZIP"", lgraph::LoadPluginRequest::ZIP},
{""CPP"", lgraph::LoadPluginRequest::CPP}};
return um[type];
}(code_type));
loadPluginRequest->set_name(procedure_name);
loadPluginRequest->set_desc(procedure_description);
loadPluginRequest->set_read_only(read_only);
loadPluginRequest->set_code(content);
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
加载存储过程的响应不包含参数，如果加载失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.1.加载存储过程'}"
UDF的支持中，如果开发的函数的语言是Python，模块通常放在什么位置？,"page_content='图算法介绍

4.2 跨进程数据交换

对于推理数据的交换部分，底层通过C++开发共享内存管理模块，实现两个进程之间的数据交互。在推理初始化阶段，由InferenceContext对象开辟进程共享内存，Java进程负责创建并初始化推理（Python）进程，通知推理进程共享内存的地址信息，并映射到相应的进程。如图，Java进程和推理进程均采用C++作为桥梁语言，实现共享内存中数据的流动操作。  
在推理系统的性能测试阶段，我们发现推理进程读写进程时，接口的调用开销不容忽视。常规的理解认为C++能够优化Python的执行效率，但前提是Python的执行内存足够复杂，优化执行内容的收益远大于接口的调用开销。然而，在我们系统设计中，共享内存的读写接口只是操作了内存地址，实现读写指针的移动。因此，接口的调用开销也是影响推理性能的关键因素，为此，我们充分调研了业界主流的方案。  
| **解决方案** | **描述** |
| --- | --- |
| CPython | C语言实现Python及其解释器（JIT编译器） |
| ctypes | Python标准库 |
| SWIG | 开发工具，封装native程序接口 |
| Pybind11/Boost.python/Nanobind | 轻量级头文件库 |
| Cython | Python的超集，使用C语言特性，静态编译 |  
如图所示，我们对比了多种Python调用C链接库的方案，性能是第一要素，因此选择Cython作为推理进程和底层内存交互的工具。Cython是一个编程语言，是Python语言的一个超集，它将/C++的静态类型系统融合在了Python中，允许开发者可以在Python代码中直接使用C语言的特性，从而提高程序的执行效率。Cython将Python源代码翻译为C或C++代码，然后将其编译为二进制代码，能够显著提高数值计算和循环场景的代码执行性能' metadata={'Header 1': '图算法介绍', 'Header 2': '4.2 跨进程数据交换'}","page_content='开始上手(Geaflow Kubernetes Operator运行)

通过Geaflow Kubernetes Operator提交作业

提交DSL作业

对于提交DSL作业的情况，需要额外注意以下几个参数：
* entryClass不填，留空。
* gqlFile必填，请填写自己文件的名称和url地址。
* udfJars选填，如有的话请填写自己文件的url地址。  
```yaml
spec:
# 不填
# entryClass: com.example.MyEntryClass
# 必填
gqlFile:
# name必须填写正确，否则无法找到对应文件
name: myGql.gql
url: http://localhost:8888/download/myGql.gql
# 可选
udfJars:
- name: myUdf.jar
url: http://localhost:8888/download/myUdf.jar
```
关于DSL作业和HLA作业的更多参数，我们在项目目录geaflow-kubernetes-operator/example目录中准备了两个demo作业供大家参考，请分别参考项目中的示例文件：
* example/example-dsl.yml
* example/example-hla.yml。' metadata={'Header 1': '开始上手(Geaflow Kubernetes Operator运行)', 'Header 2': '通过Geaflow Kubernetes Operator提交作业', 'Header 3': '提交DSL作业'}","page_content='开始上手(Geaflow Kubernetes Operator运行)

通过Geaflow Kubernetes Operator提交作业

提交HLA作业

对于提交HLA作业的情况，需要额外注意以下几个参数：
* entryClass必填。
* udfJars选填，如有的话请填写自己文件的url地址。  
```yaml
spec:
# 必填
entryClass: com.example.MyEntryClass
# 可选
udfJars:
- name: myUdf.jar
url: http://localhost:8888/download/myUdf.jar
```' metadata={'Header 1': '开始上手(Geaflow Kubernetes Operator运行)', 'Header 2': '通过Geaflow Kubernetes Operator提交作业', 'Header 3': '提交HLA作业'}"
在文本中，哪种资源名称对应的颜色设置为固定的“light-orange”？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='可视化操作手册

2.操作指南

2.5.控制台

`控制台`提供可视化的的账户管理和数据库信息查看功能，它为用户提供了全面的账户和角色管理功能，包括账户的增删改查以及禁用，角色的增删改查以及禁用。此外，它也为用户提供了便捷的数据库信息查看功能，让用户可以轻松地查看图数据库的基础信息和配置信息。其中，基础信息主要包括版本号、运行时间、CPP编译版本号等，而数据库配置信息则包括端口号、系统功能参数配置等。  
#### 2.5.1.账户管理  
##### 2.5.1.1.账户管理  
###### a.添加账户  
在`账户管理`界面点击`添加`按钮创建新的账户，用户需要输入账户名称、账户描述、账户密码以及相关角色。  
![账户管理-添加账户按钮](../../../images/browser/account-add-button.png)  
- 账户名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 相关角色：新建账户时必须要选择一个角色，在账户添加成功后，系统会自动生成一个与账户名称一样的角色。  
![账户管理-添加账户](../../../images/browser/account-add.png)  
###### b.编辑账户  
在`账户管理`界面点击`添加`按钮创建新的账户，用户可以编辑账户描述、账户密码以及相关角色。  
![账户管理-编辑账户](../../../images/browser/account-edit.png)  
###### c.禁用账户  
在`账户管理`界面点击`禁用`按钮禁止对应的账户登录和访问，点击`启用`按钮开启对应的账户登录和访问权限。  
![账户管理-禁用](../../../images/browser/account-disable.png)
![账户管理-启用](../../../images/browser/account-enable.png)  
###### d.删除账户  
在`账户管理`界面点击`删除`按钮删除对应的账户。  
![账户管理-删除](../../../images/browser/account-delete.png)  
##### 2.5.1.2.角色管理  
###### a.添加角色  
在`角色管理`界面点击`添加`按钮创建新的角色，用户需要输入角色名称、角色描述以及图权限。  
![角色管理-添加角色按钮](../../../images/browser/role-add-button.png)  
- 角色名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图权限：browser支持全部、读、写和无共四类图权限配置。
- 全部：对应图的读和写权限，包含编辑图模型权限（schema）。
- 读写：对应图的写权限，不包含编辑图模型权限（schema）。
- 只读：对应图的读权限。
- 无：无法访问和操作对应图。
- 角色冲突：当两个角色对同一个图有不同图权限，同时对一个账户授权了这两个角色，该账户对该图的图权限为两个角色的并集。  
![角色管理-添加角色](../../../images/browser/role-add.png)  
###### b.编辑角色  
在`角色管理`界面点击`编辑`按钮编辑已有角色，用户可以编辑角色描述以及图权限。  
![角色管理-编辑角色](../../../images/browser/role-edit.png)  
###### c.禁用角色  
在`角色管理`界面点击`禁用`按钮禁止对应的角色，点击`启用`按钮开启对应的角色。禁用角色后，对应角色图访问权限失效。  
- 禁用角色：禁用之后，对应角色图访问权限失效。
- 当一个用户拥有两个角色对同一个图有操作权限时，当禁用其中一个角色时，另一个角色权限同样有效。  
![角色管理-禁用](../../../images/browser/role-disable.png)
![角色管理-启用](../../../images/browser/role-enable.png)  
###### d.删除角色  
在`角色管理`界面点击`删除`按钮删除对应的角色。  
![角色管理-删除](../../../images/browser/role-delete.png)  
#### 2.5.2.数据库信息  
##### 2.5.2.1.基础信息  
`基础信息`获取当前系统运行的状态，并展示关键信息。  
![数据库信息-基础信息](../../../images/browser/db_basic.png)  
|参数    |含义    |
|-------|--------|
|TuGraph版本号|当前TuGraph的版本号，x.x.x|
|运行时间|TuGraph服务启动到现' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.5.控制台'}","page_content='运维监控

2.部署方案

2.4.第四步

+ 下载符合您机器架构以及系统版本的Grafana安装包，下载地址: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)  
+ 安装Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 启动Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 配置Grafana，首先在数据源设置中配置Prometheus的IP地址，配置完成后可以通过测试连接功能，验证是否成功连接数据源。然后，导入如下模版，并在页面中根据实际情况，修改正确的接口IP和端口。最后可以根据实际情况设置刷新时间和监控时间范围  
```json
{
""annotations"": {
""list"": [
{
""builtIn"": 1,
""datasource"": {
""type"": ""grafana""
},
""enable"": true,
""hide"": true,
""iconColor"": ""rgba(0, 211, 255, 1)"",
""name"": ""Annotations & Alerts"",
""target"": {
""limit"": 100,
""matchAny"": false,
""tags"": [],
""type"": ""dashboard""
},
""type"": ""dashboard""
}
]
},
""editable"": true,
""fiscalYearStartMonth"": 0,
""graphTooltip"": 0,
""id"": 2,
""links"": [],
""liveNow"": false,
""panels"": [
{
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
}
},
""mappings"": [],
""unit"": ""kbytes""
},
""overrides"": [
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {__name__=\""resources_report\"", instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
},
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""others""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-blue"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
}
}
]
}
]
},
""gridPos"": {
""h"": 16,
""w"": 6,
""x"": ' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}"
导入图库的数据如何删除,"page_content='TuGraph-Restful-Server

7.接口

7.8 数据导入请求

用户通过此类请求导入已经上传的数据文件。导入不论成功或失败，都将删除已上传文件。数据导入请求在server中实现为一个异步任务，响应返回并不意味着导入已完成，返回的是任务id，后续可以通过此任务id查询导入进度
#### 7.8.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_data
#### 7.8.2 REQUEST
|  body参数  |          参数说明           |  参数类型  | 是否必填 |
|:--------:|:-----------------------:|:------:|:----:|
| graph |         导入目标子图          |  字符串  |  是   |
| schema |       导入schema描述        | json字符串  |  是   |
| delimiter |           分隔符           |  字符串  |  是   |
| continueOnError |     单行数据出错是否跳过错误并继续     |  boolean  |  否   |
| skipPackages |         跳过的包个数          |  字符串  |  否   |
| taskId |  任务id   |  字符串  |  否   |
| other | 其他参数 |  json字符串  |  否   |  
#### 7.8.3 RESPONSE
|    body参数     |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| taskId | 任务编号 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.8 数据导入请求'}","page_content='业务开发指南

子图操作

清空子图

#### 删除所有的点边数据和图schema
```
CALL db.dropDB()
```
#### 只删除所有点边数据, 保留图schema
```
CALL db.dropAllVertex()
```' metadata={'Header 1': '业务开发指南', 'Header 2': '子图操作', 'Header 3': '清空子图'}","page_content='Cypher API

5.附录2. 内置procedures列表

* dbms.graph.deleteGraph(graph_name)

delete a subgraph in this graph database .  
| parameter  | parameter type | description              |
| ---------- | -------------- | ------------------------------------ |
| graph_name | string     | the name of subgraph to been deleted |  
**Output:**  
if successful , it will return true.  
**Example input:**  
```
CALL dbms.graph.deleteGraph('graph1')
```  
**Example output:**  
| success |
| ------- |
| true    |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* dbms.graph.deleteGraph(graph_name)'}"
当使用 TuGraph 批量创建边时，如果请求成功，响应中将返回什么内容？,"page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/relationship/{euid}
```  
与 Nodes 功能类似，Relationships 提供边（edge）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。每一条边都可以由一个唯一 ID（euid）来标识。这个 ID 可以从在插入边时获得，或者在 [列出所有边](#%E5%88%97%E5%87%BA%E6%89%80%E6%9C%89%E8%BE%B9) 操作中得到。  
#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| fields | 数据列名 | 列表 |
| edge | 边数据 | 列表 |  
其中 edge 是一个数据列表，其中每个元素都是一条边，其定义如下：  
| 域名        | 说明     | 类型                                                   |
| ----------- | -------- | ------------------------------------------------------ |
| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}","page_content='TuGraph-Restful-Server

7.接口

7.7 批量创建schema请求

用户通过此类请求批量创建schema，请求报文在http body 中将创建schema的目标子图和schema信息发送给server，如果拿到返回errorCode为200的响应报文即为正常创建
#### 7.7.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_schema
#### 7.7.2 REQUEST
|  body参数  |    参数说明    |  参数类型  |  是否必填  |
|:--------:|:----------:|:------:| :-----: |
| graph |   创建目标子图   |  字符串  |  是  |
| schema | schema描述信息 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.7 批量创建schema请求'}","page_content='TuGraph-Restful-Server

7.接口

7.8 数据导入请求

用户通过此类请求导入已经上传的数据文件。导入不论成功或失败，都将删除已上传文件。数据导入请求在server中实现为一个异步任务，响应返回并不意味着导入已完成，返回的是任务id，后续可以通过此任务id查询导入进度
#### 7.8.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_data
#### 7.8.2 REQUEST
|  body参数  |          参数说明           |  参数类型  | 是否必填 |
|:--------:|:-----------------------:|:------:|:----:|
| graph |         导入目标子图          |  字符串  |  是   |
| schema |       导入schema描述        | json字符串  |  是   |
| delimiter |           分隔符           |  字符串  |  是   |
| continueOnError |     单行数据出错是否跳过错误并继续     |  boolean  |  否   |
| skipPackages |         跳过的包个数          |  字符串  |  否   |
| taskId |  任务id   |  字符串  |  否   |
| other | 其他参数 |  json字符串  |  否   |  
#### 7.8.3 RESPONSE
|    body参数     |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| taskId | 任务编号 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.8 数据导入请求'}"
TuGraph为什么选择使用B+树作为其底层存储数据结构？,"page_content='性能优先

3.存储数据结构

TuGraph底层采用B+树来支持实时的增删查改事务。  
在排序树的数据结构中，B+树和LSM树为主要代表。B+树在树节点中使用拆分和合并式来更新排序数据，而 LSM 树在日志中追加更新，以进行延迟数据合并。B+ 早期用在文件系统的实现中，通过将数据保存 在自适应长度的叶子节点中，解决硬盘顺序操作和随机操作性能存在数据量级差别的问题，有较均衡的读写性能。LSM 树的主要优势使用 WAL(Write Ahead Log) 进行更新，将更新操作变成顺序操作，在键值较小时性能优势尤为突出。WAL 意味着将数据的更新合并推迟，批量更新能提升综合效率，也使得系统的调度变得复杂。如果更新合并完成前，恰好对其中的数据继续读取，LSM 树就需要读取几个层级局部合并的日志，会导致读取放大和空间放大，从而影响读效率。  
总结来说，B+ 树有较好的顺序读写性能，而 LSM 树在数据随机写方面占优。此外 LSM 树采用后台合并的方式，使得性能的波动难以预期，性能波动和上层存储和计算的关联性较弱，增加了整体设计的成本。综上考虑，TuGraph 选用 B+ 树作为读性能优先的实现。' metadata={'Header 1': '性能优先', 'Header 2': '3.存储数据结构'}","page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}","page_content='TuGraph在图计算系统建设中的作用

TuGraph 技术优势

TuGraph 开源版特色

为什么要去开源单机版而不是分布式版本？主要是考虑到它的部署和使用成本比分布式版本要低得多，同时功能也很完整、独立。我们希望这样可以让许多刚开始使用图数据库或有使用图数据库解决问题的想法的人，可以先尝试用我们的单机版图数据库。因为它的部署非常简单，如果跑起来没有问题，那么再考虑是否需要分布式版本。如果确实需要，我们可以再跟进这个问题。  
我们的单机版图数据库已经能够支持 TB 级别的数据，我们内部也有很多情况使用单机版图数据库。在单台机器上，我们最大的数据量也达到了 2TB 多，在线上运行，能够处理百亿级别的点边。事实上，大多数用户使用单机版图数据库都是足够的。由于单机版的图数据库很容易优化，我们对它进行了极致的优化，因此单机版图数据库在性能上可以满足绝大多数场景的需求。此外，它的系统特性也很全面，包括高可用性、多图支持、权限管理、日志记录等，它可以被看作是一个成熟、易用的图数据库，类似于 MySQL。  
开源TuGraph特点包括:  
-   单机版图数据库能够处理数据量几个 TB 的数据，前提是磁盘足够大。
-   成本很低，因为是单机版，部署和运维都很容易。
-   性能很好，我们对其进行了大量优化。TuGraph 的 LDBC-SNB 测试目前是世界第一，大家可以在 GitHub 上获取测试 SNB 的条款并进行测试。
-   单机版图数据库是一个非常易用的完整系统，我们提供了导入导出工具和查询语言。此外，还提供了底层 API，用户可以使用它来编写复杂的程序。  
我们的开源版本的目标主要有三点：  
首先，我们希望提供一个免费的图数据库产品，能够让更多的人使用图数据库，尝试用它来解决问题。  
其次，我们希望促进图数据库标准的成形。目前图数据库的差异太大，每个数据库都有所不同，我们希望通过提供一个参考答案来帮助大家达成趋同。这样大家就可以根据我们提供的设计来判断哪些特征合理，如果觉得合理就可以遵循这个设计，慢慢地大家就会逐渐靠近。假如所有产品在主要特征上保持一致，这样所有人的学习成本就会降低。  
最后，基础研究性问题可以不断优化发展，包括存储方面的问题，例如哈希可能是理论上最优的，但是是否还有其他需要调整的东西？目前没有一个很好的研究性平台让大家去进行这些尝试和研究，我们希望提供的开源 TuGraph-DB 能成为这些研究人员的对比基线，促进研究的发展。' metadata={'Header 1': 'TuGraph在图计算系统建设中的作用', 'Header 2': 'TuGraph 技术优势', 'Header 3': 'TuGraph 开源版特色'}"
"接口 ""CallProcedureToLeader"" 支持哪些参数设置以改变返回结果的格式？","page_content='Java客户端

2.使用示例

2.7.向leader调用存储过程

```java
String result = client.callProcedureToLeader(""CPP"", ""khop"", kHopParamGen(), 1000, false, ""default"");
log.info(""testCallProcedureToLeader : "" + result);
```
```
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param param: the execution parameters
@param procedureTimeOut: Maximum execution time, overruns will be interrupted
@param inProcess: Running query or not
@param graph: the graph to query
@param jsonFormat: (Optional) Return format of calling stored procedure
@return: the result of procedure execution
public String callProcedureToLeader(String procedureType, String procedureName, String param, double procedureTimeOut,
boolean inProcess, String graph)
```
本接口支持在HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.7.向leader调用存储过程'}","page_content='Python客户端

3.RPC Client

3.7.向leader调用存储过程

```python
ret, res = client.callProcedureToLeader(""CPP"", ""khop"", kHopParamGen(), 1000, false, ""default"")
```
```
callProcedureToLeader(self: liblgraph_client_python.client, procedure_type: str, procedure_name: str, param: str, procedure_time_out: float, in_process: bool, graph: str, json_format: bool) -> (bool, str)
```
本接口支持在HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.7.向leader调用存储过程'}","page_content='C++客户端

2.使用示例

2.7.向leader调用存储过程

```C++
std::string str;
bool ret = client.CallProcedureToLeader(str, ""CPP"", ""test_plugin1"", ""bcefg"");
```
```
bool CallProcedureToLeader(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& param,
double procedure_time_out = 0.0, bool in_process = false,
const std::string& graph = ""default"", bool json_format = true);
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@returns True if it succeeds, false if it fails.
```
本接口支持在HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.7.向leader调用存储过程'}"
如何提高查询效率？,"page_content='性能优先

4.数据编码

对于属性图模型而言，除了图拓扑编码外，属性数据也会很大程度影响功能和性能，我们先讨论属性数据如何与拓扑数据共存的编码格式。从目前的调研来看，属性编码有两种方式，我们称之为基于指针索引将属性数据单独存储的离散编码，和将属性数据和拓扑数据打包在一起的紧凑编码。离散编码根据程度的不同，可以每个属性都单独存储，或者每条边的属性打包后各自存储，下面的讨论对两种情况都适用。  
点查询。属性编码主要针对边，不涉及点查询。  
单边查询。离散编码通过指针定位边，紧凑编码则需要二分查找定位边的位置，离散编码有略微的优势。  
边遍历。离散编码在边遍历过程需要不断地进行指针跳转进行随机数据访问，而紧凑编码提前把数据排列在一起，顺序访问的特性使得效率大大提升。 由规律三知对边的遍历操作很普遍，紧凑编码在边遍历的优势明显。  
单边更新。离散编码对边的更新仅需找到对应的指针位置，插入数据后修改前后指针指向。紧凑编码则需要对紧凑排列的数据进行重编码，对整个边值进行重新写入，开销显著大于离散编码的情形。  
批量边更新。批量更新可以在内存中预先构建点的所有边属性，一次性编码写入，离散编码和紧凑编码相当。但紧凑编码不需要存储指针变量，更少的存储空间效率也会更高。  
以上离散编码和紧凑编码在某一类的查询的性能问题，可以通过优化的来缓解。整体上说，由于图负载读写 20:1 的特性，读性能在整体性能中占比更高。以及规律三所揭示的对属性访问的特征，TuGraph 更倾向于采用紧凑编码来保证读性能。其主要弱势为单边更新时重编码的开销，可以用自适应映射的技术来解决。' metadata={'Header 1': '性能优先', 'Header 2': '4.数据编码'}","page_content='QA汇总

Cypher QA

拼接查询慢

Q：查询语句 Where 后使用 and 进行拼接查询速度较慢，语句应如何优化改进？
示例：  
```
MATCH (n1),(n2) CALL algo.allShortestPaths(n1,n2)
YIELD nodeIds,relationshipIds,cost
WHERE id(n1) IN [0] AND id(n2) IN [3938]
RETURN nodeIds,relationshipIds,cost
```  
A：目前 cypher 查询引擎正在优化中。现阶段语句改写可以通过 with 向下传递进行优化。
示例：  
```
MATCH (n1) where id(n1) in [0] with n1
MATCH (n2) where id(n2) in [3938] with n1, n2
CALL algo.allShortestPaths(n1,n2) YIELD nodeIds,relationshipIds,cost
RETURN nodeIds,relationshipIds,cost
```' metadata={'Header 1': 'QA汇总', 'Header 2': 'Cypher QA', 'Header 3': '拼接查询慢'}","page_content='为什么使用图进行关联运算比表Join更具吸引力？

关系模型并不适合处理关系

痛点二：数据冗余，时效性低

在很多数仓分析的场景中，为了提高数据查询性能，往往将多张表提前物化成一张大宽表。  
大宽表虽然可以加速查询性能，然而其数据膨胀和冗余非常严重。由于表与表之间一对多的关联关系，导致一张表的数据通过关联会放大多份，造成数据量指数级膨胀和冗余。  
而且宽表一经生成就难以更改，否则需要重新生成新宽表，费时费力，不够灵活。  
此时利用图模型建模，可以轻易解决这个问题。 图是对关系的一种天然描述，以点代表实体，以边代表关系。  
比如在人际关系图里面，每一个人可以用一个点来表示，人和人之间的关系通过边来表示，人与人之间可以存在各种各样的复杂关系，这些关系都可以通过不同的边来表示。  
显然，**构造图的过程本质上是对事物之间关系的提炼，在数据存储层面实质是对关系做了物化，以获取更好的关联计算性能**。  
相比宽表的关系物化方式，由于图结构本身的点边聚合性，构图表现得十分节约。 下图是GeaFlow中高性能构图的表现，可见构图操作本身极为迅速，且由于图可以分片的特性，具有十分良好的可扩展性。  
![insert_throuput](../../static/img/insert_throuput_cn.jpg)
<center>图2</center>  
在图一的实验中也可以发现，实质上我们用少量的插入图(青色的insert to graph部分开销)耗时，换取了图建模方式对之后关联查询的加速效果。' metadata={'Header 1': '为什么使用图进行关联运算比表Join更具吸引力？', 'Header 2': '关系模型并不适合处理关系', 'Header 3': '痛点二：数据冗余，时效性低'}"
FieldData 类中的 integer() 方法在什么情况下会抛出 std::bad_cast 异常？,"page_content='Procedure API

5.Procedure v2接口

5.1.编写存储过程

用户可以通过使用 lgraph API 来编写 C++ 存储过程。一个简单的 C++ 存储过程举例如下：  
```c++
// peek_some_node_salt.cpp
#include <cstdlib>
#include ""lgraph/lgraph.h""
#include ""lgraph/lgraph_types.h""
#include ""lgraph/lgraph_result.h""

#include ""tools/json.hpp""

using json = nlohmann::json;
using namespace lgraph_api;

extern ""C"" LGAPI bool GetSignature(SigSpec &sig_spec) {
sig_spec.input_list = {
{.name = ""limit"", .index = 0, .type = LGraphType::INTEGER},
};
sig_spec.result_list = {
{.name = ""node"", .index = 0, .type = LGraphType::NODE},
{.name = ""salt"", .index = 1, .type = LGraphType::FLOAT}
};
return true;
}

extern ""C"" LGAPI bool ProcessInTxn(Transaction &txn,
const std::string &request,
Result &response) {
int64_t limit;
try {
json input = json::parse(request);
limit = input[""limit""].get<int64_t>();
} catch (std::exception &e) {
response.ResetHeader({
{""errMsg"", LGraphType::STRING}
});
response.MutableRecord()->Insert(
""errMsg"",
FieldData::String(std::string(""error parsing json: "") + e.what()));
return false;
}

response.ResetHeader({
{""node"", LGraphType::NODE},
{""salt"", LGraphType::FLOAT}
});
for (size_t i = 0; i < limit; i++) {
auto r = response.MutableRecord();
auto vit = txn.GetVertexIterator(i);
r->Insert(""node"", vit);
r->Insert(""salt"", FieldData::Float(20.23*float(i)));
}
return true;
}
```  
从代码中我们可以看到：
- 存储过程定义了一个获取签名的方法`GetSignature`。该方法返回了存储过程的签名，其中包含输入参数名称及其类型，返回参数及其类型。这使得Cypher查询语句在调用存储过程能够利用签名信息校验输入数据以及返回数据是否合理。
- 入口函数是`ProcessInTxn`函数，它的参数有三个，分别为：  
- `txn`: 存储过程所处的事务，通常来说即调用该存储过程的Cypher语句所处事务。
- `request`: 输入数据，其内容为`GetSignature`中定义的输入参数类型及其Cypher查询语句中传入的值经过json序列化后的字符串。e.g. `{num_iteration: 10}`
- `response`: 输出数据，为保证在Cypher语言中能够兼容，用户可以通过往`lgraph_api::Result` 写入存储过程处理后的数据，最后用`lgraph_api::Result::Dump`来序列化成json格式的数据。  
`ProcessInTxn`函数的返回值是一个布尔值。当它返回`true`的时候，表示该请求顺利完成，反之表示这个存储过程在执行过程中发现了错误。  
C++存储过程编写完毕后需要编译成动态链接库。TuGraph 提供了`compile.sh`脚本来帮助用户自动编译存储过程。`compile.sh`脚本只有一个参数，是该存储过程的名称，在上面的例子中就是`custom_pagerank`。编译调用命令行如下：  
```bash
g++ -fno-gnu-unique -fPIC -g --std=c++14 -I/usr/lo' metadata={'Header 1': 'Procedure API', 'Header 2': '5.Procedure v2接口', 'Header 3': '5.1.编写存储过程'}","page_content='QA汇总

数据导入QA

读取oracle数据报错

Q：读取oracle数据报错
""error_message"":""Error parsing file memory_file_stream\n\tError occurred at offset 0, exception detail:\n\tjson reading failed, error msg : std::bad_cast\n>Error line....""，如何解决？
A：看起来像在处理数据的时候遇到特使符号导致报错的，建议用相对较小的表以及数据可以尝试测一下' metadata={'Header 1': 'QA汇总', 'Header 2': '数据导入QA', 'Header 3': '读取oracle数据报错'}","page_content='RPC API

5.存储过程

5.3.删除存储过程

删除存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称  
以C++为例，用户删除存储过程的方式如下所示：
```C++
LGraphRequest req;
req.set_is_write_op(true);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
lgraph::DelPluginRequest* dpRequest = pluginRequest->mutable_del_plugin_request();
dpRequest->set_name(procedure_name);
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
删除存储过程的响应不包含参数，如果删除失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.3.删除存储过程'}"
TuGraph-DB的存储引擎用了kv数据库么？如果是，基于什么kv数据库构建的？,"page_content='TuGraph产品架构

1.简介

![产品架构](../../../images/architecture.png)  
上图从功能模块的角度，以 TuGraph 为例，给出了企业级图数据库的整体架构，自下而上包括：  
- 软硬件环境。涉及图数据库的开发和使用环境。TuGraph 主要基于底层的 C++语言开发，能够兼容市面上大部分操作系统和 CPU。
- 存储层，包括 KV 存储层和图存储层。存储层需要支持计算层所需的各个功能。
- 计算层。计算层应包括图事务引擎、图分析引擎和图神经网络引擎，也包含了服务端提供的多种编程接口，包括描述式查询语言 Cypher，存储过程等。
- 客户端。客户端 SDK 应支持 Java、Python、C++ 等多种语言，也支持命令行的交互方式。Browser 和 Explorer 通过网页端交互的方式，降低了图数据库的使用门槛。
- 在生态工具方面，覆盖了企业级图数据库的开发、运维、管理等链路，提升可用性。' metadata={'Header 1': 'TuGraph产品架构', 'Header 2': '1.简介'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}"
请问下怎么没找到新版的browser-resource，怎么进行新旧版本的web切换呢,"page_content='数据库运行

3.服务操作

3.4.新旧前端切换

进入容器，可以通过修改配置文件""/usr/local/etc/lgraph.json""中的""web""参数来选择使用老版本或新版本的前端。对于老版本，可以将""web""的值设为""/usr/local/share/lgraph/resource""；对于新版本，可以将""web""的值设为""/usr/local/share/lgraph/browser-resource""。完成配置文件的修改后，请执行命令 `docker restart tugraph` 以使更改生效。需要注意的是，新版本是默认选项。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.4.新旧前端切换'}","page_content='快速上手

2.安装

2.2.新旧前端说明

进入容器，可以通过修改配置文件""/usr/local/etc/lgraph.json""中的""web""参数来选择使用老版本或新版本的前端。对于老版本，可以将""web""的值设为""/usr/local/share/lgraph/resource""；对于新版本，可以将""web""的值设为""/usr/local/share/lgraph/browser-resource""。完成配置文件的修改后，请执行命令 `docker restart tugraph` 以使更改生效。需要注意的是，新版本是默认选项。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.2.新旧前端说明'}","page_content='可视化操作手册（旧版）

操作详情

3.工作台

#### 3.1 快速上手  
- 首次登录，系统会默认创建 default 空图  
![alt 快速上手](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/2.tugraph-browser-quickstart-01.png)  
- 用户点击帮助选项，并选择快速上手  
![alt 帮助](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/3.tugraph-browser-quickstart-02.png)  
- 然后点击“一键创建模型”——>""一键创建数据""，就可以完成内置的 Movie 数据图谱的构建  
#### 3.2 创建子图和示例  
##### 3.2.1 创建子图  
- 点击新建子图
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/4.tugraph-browser-create-subgraph-01.png)
- 填写表单信息
![alt 填写表单](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/5.tugraph-browser-create-subgraph-02.png)
- 子图名称
- 子图描述
- 配置信息
- 点击确认，提示创建成功
- 切换子图
![alt 切换子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/6.tugraph-browser-use-graph-01.png)  
- 点击新建示例
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/create-scene-01.png)
- 选择示例并点击创建
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/select-scene.png)  
#### 3.3 查询  
![alt 查询](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/7.tugraph-browser-query-01.png)  
##### 3.3.1 页面组成  
- cypher 输入框
- 结果集展示区域  
##### 3.3.2 结果集展示区域功能详情  
- 结果集标签展示及功能
![alt 结果集标签](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/tugraph-browser-result.png)
- 这里展示了结果集的所有类型统计
- 点击不同的“label（标签）”，可以进行以下修改操作
- 修改展示颜色
- 修改节点大小或边的粗细
- 修改默认展示属性或系统属性
- 布局修改
- 力导布局
- 网格布局
- 树形布局
- 环境布局
- 边聚合
- 相同类型，方向的边可以进行合并
- 创建节点
- 点击创建节点按钮
- 选择节点类型
- 添写节点内容
- 创建关系
- 在画布中选择起点和终点
- 选择可以匹配的类型
- 填写节点信息
- 停止布局
- 当数据量过大，导致浏览器页面卡顿时候，可以点击这个停止布局的按钮，能够提高体验的流畅度
- 鼠标悬停
- 开启此功能，可以高亮显示鼠标悬停节点的一度邻居节点
- 结果集导出
- 可以将结果集导出为 png，json，csv 三种不同的文件形式
- 刷新
- 点击刷新按钮，会重新执行当前页面的初始 cypher 语句，并刷新结果集
- 最大化
- 点击最大化，结果集展示区域将全屏展示
- 结果集展示形式切换
- 支持图谱、表格、文本三种形式  
##### 3.3.3 建模  
- 点边模型
![alt 建模](https://tugraph-w' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '3.工作台'}"
tugraph进行大规模数据查询时是否对图数据进行了压缩？,"page_content='TuGraph与ARM架构

内容：

**测试介绍：**

TuGraph在测试中使用Client/Server分离的模式，来模拟真实的用户使用场景。在结果中，TuGraph在不同规模的数据集下均表现优异，在大规模100GB的数据集（2.8亿个点，18亿条边）上，TuGraph的吞吐率较上一次官方纪录提升了31%。在300GB数据集上，TuGraph测试了超过内存容量的数据吞吐量，虽然较100GB的性能有所下降，但考虑内存和硬盘的读写性能鸿沟，该结果也在预期之内。**除了性能测试，TuGraph在****系统事务性、可恢复性、正确性、稳定性等方面均达到官方标准，体现了TuGraph高并发低延迟的强大性能优势。**  
在性能测试中，我们发现并解决了一些值得注意的问题。其一是有的系统页大小默认为64KB，这个对图系统随机数据读写并不友好，调整为X86更普遍的4KB有助于提升性能。其二是在云上使用云盘，会比本地硬盘的读写带宽和稳定性差很多，如果能够在测试前进行数据预热和及时的硬盘性能监控，更有助于获得理想的结果。' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '内容：', 'Header 3': '**测试介绍：**'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

0 映射原理

TuGraph-OGM 将 JAVA 对象映射为图的对象，类映射为点，类的属性映射为图中的属性，类中的方法映射为操作 TuGraph 的查询语句。  
以电影场景为例，对演员、电影、导演之间的关系进行数据化，就形成了非常典型的图数据。举一个简单的示例，演员Alice在1990年和2019年分别出演了两部电影《Jokes》和《Speed》，其中《Jokes》的导演是Frank Darabont。  
以图的思维来看，演员、导演、电影可以被映射为三种不同的节点，而出演、执导可以被映射为两种边，映射结果如上图所示，将数据存入图数据库后，相关的开发人员就可以使用各类图查询语言对数据进行查询。  
但对非图数据库相关的开发人员来说，这个例子中的演员、导演、电影作为实体，同样可以映射为类中的对象，而与实体相关联的对象可以通过集合存储，这是大多数开发人员熟悉的领域。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '0 映射原理'}","page_content='TuGraph与ARM架构

摘要：

- TuGraph适配国产ARM架构处理器，又双叒叕打破了LDBC SNB世界纪录，较之前纪录提升31%，云端机器开销降低了40%，大大提升了资源能效。  
- 验证了TuGraph对于ARM架构的兼容性，成为对X86和ARM架构均完整适配的图数据库，也使得TuGraph继麒麟、鲲鹏、海光等国产操作系统和处理器之后，**实现了对国产软硬件的全面支持，为用户的机器选型提供更多选择**。  
- 我们还测试了数据量大于内存的情况，结果显示，性能只下降了20%左右，显示了TuGraph在大规模数据下的适用性。  
TuGraph图数据库GitHub仓库：https://github.com/tugraph-family/tugraph-db' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '摘要：'}"
TuGraph选择使用哪一种树结构作为其存储数据结构，并简述选择这种结构的主要原因是什么？,"page_content='性能优先

3.存储数据结构

TuGraph底层采用B+树来支持实时的增删查改事务。  
在排序树的数据结构中，B+树和LSM树为主要代表。B+树在树节点中使用拆分和合并式来更新排序数据，而 LSM 树在日志中追加更新，以进行延迟数据合并。B+ 早期用在文件系统的实现中，通过将数据保存 在自适应长度的叶子节点中，解决硬盘顺序操作和随机操作性能存在数据量级差别的问题，有较均衡的读写性能。LSM 树的主要优势使用 WAL(Write Ahead Log) 进行更新，将更新操作变成顺序操作，在键值较小时性能优势尤为突出。WAL 意味着将数据的更新合并推迟，批量更新能提升综合效率，也使得系统的调度变得复杂。如果更新合并完成前，恰好对其中的数据继续读取，LSM 树就需要读取几个层级局部合并的日志，会导致读取放大和空间放大，从而影响读效率。  
总结来说，B+ 树有较好的顺序读写性能，而 LSM 树在数据随机写方面占优。此外 LSM 树采用后台合并的方式，使得性能的波动难以预期，性能波动和上层存储和计算的关联性较弱，增加了整体设计的成本。综上考虑，TuGraph 选用 B+ 树作为读性能优先的实现。' metadata={'Header 1': '性能优先', 'Header 2': '3.存储数据结构'}","page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}","page_content='TuGraph在图计算系统建设中的作用

TuGraph 技术优势

蚂蚁自己开发了一套图计算系统 TuGraph，既能解决图数据的存储问题，也能解决流式计算、离线计算和图学习的问题。目前，超过 100 个业务线和 300 多个场景都在使用这套系统。这套系统在 2021 年获得了世界互联网大会领先科技成果奖。  
在 TuGraph 中，性能是一个重要的因素，因为图数据集的体积很大，如果性能不佳就会浪费机器资源，导致许多情况下无法完成任务。比如，希望业务的查询能在几十毫秒内返回结果，但是如果做的性能不好，几秒钟才能返回结果，就无法作为在线查询使用。因此，我们是非常对性能是很重视的，其中在 LDBC-SNB 标准测试中（类似于数据库领域性能标准测试 TPC-C），TuGraph 仍然是世界纪录的保持者。  
TuGraph 的整个图存储是建立在完美哈希的基础上的，这是我们与其他图系统的一个重要区别。目前，大多数图系统使用的是基于数的存储，但数的问题在于永远存在一个 LogN 的查找操作。然而，在图中可以看到，不同的顶点之间实际上是无序的，不需要有顺序，所以顶点这个级别实际上是基于哈希的，理论上，顶点的读取是最优的。  
此外，TuGraph 还参与了许多标准的定制，整个系统在尽量往标准化的方向去做。  
除了为内部提供服务，我们还向外提供服务，主要是因为，作为一个系统，如果只为有限的客户提供服务，就很容易构建成一个专有系统。我们希望这是一个标准化、开放的系统，所以我们也在对外提供图计算系统的产品和服务。目前，我们也有很多外部客户，包括金融、工业、互联网以及政企领域。  
开源开放，共建发展  
整个图计算系统目前仍处于较早期的阶段，我们认为还有很多工作要做，包括提升应用性、性能和降低成本。所有的系统都会有这些问题。但是，如果希望普及，我们认为最重要的是有健康的生态，来推动图计算系统的发展，需要有更多的用户和更多的场景使用这个系统。  
所有的计算机系统都需要去有一个更开放、更大的生态才能促进发展。蚂蚁有一句话叫做“成熟一个、开放一个”，一个系统成熟以后，我们就会试着开放出去，让更多的人去用。今年 9 月，我们已经在 GitHub 上开源了 TuGraph 中的单机版图数据库，以及一个离线图分析引擎 TuGraph Compute。分布式图数据库和流式图计算现在已经包含在我们的商业化版本中，包括一站式图研发平台。我们计划在未来迭代更多更丰富的系统功能，希望能做得更好。' metadata={'Header 1': 'TuGraph在图计算系统建设中的作用', 'Header 2': 'TuGraph 技术优势'}"
TuGraph-DB使用的boost库是什么版本？,"page_content='技术规划

2. 已完成功能

TuGraph-DB于2022年9月1日开源，TuGraph-DB在社区的反馈声中，进行日常BUG修复，自身能力得到了完善。  
| 版本号   | 功能                               | 时间         |
|-------|----------------------------------|------------|
| 3.3.0 | 开源初版                             | 2022.9.1   |
| 3.3.1 | 图分析引擎重构，多模式支持                    | 2022.10.14 |
| 3.3.2 | OGM支持，UT覆盖率提升                    | 2022.11.21 |
| 3.3.3 | 链接认证机制迭代，加入英文文档                  | 2022.12.23 |
| 3.3.4 | 支持上云，梳理LDBC SNB Audit流程          | 2023.1.28  |
| 3.4.0 | 支持OLAP Python API, 离线导入升级        | 2023.3.11  |
| 3.5.0 | 支持POG，前端升级，文档梳理                  | 2023.6.5   |
| 3.5.1 | 图学习引擎，Procedure Rust API，存储属性分离  | 2023.7.14  |
| 3.6.0 | 高可用开源，日志系统升级                     | 2023.8.11  |
| 4.0.0 | ISO GQL支持，新增11个开源图算法，支持m1 Docker | 2023.9.6   |
| 4.0.1 | 支持时序边排序，新增5个开源图算法                | 2023.9.28  |
| 4.1.0 | 支持Bolt协议，支持快速在线全量导入，支持地理空间数据类型   | 2023.12.25 |  
除此之外，TuGraph-DB搭建了较为完善的质量体系，涵盖自动化的单元测试、集成测试、性能测试等。  
更详细的描述可以在源码目录在的 ""[root]/release/CHANGELOG.md"" 文件查看。' metadata={'Header 1': '技术规划', 'Header 2': '2. 已完成功能'}","page_content='TuGraph Java Client

版本选择

| Client Version | TuGraph Version |
|----------------|-----------------|
| 1.1.1          | 3.3.3           |
| 1.2.1, 1.2.2   | 3.4.x, 3.5.0    |
| 1.3.0          | 3.6.0           |
| 1.4.0, 1.4.1   | 4.0.0, 4.0.1    |  
**注意**:  
- 3.3.0~3.3.2 版本的 TuGraph Server 是在 java-client 重构前的遗留版本，本仓库不支持这些版本。
- 1.1.0 和 1.2.0 因 pom 文件中的 ${revision} 变量引入的无法使用的问题而不可用[1]。' metadata={'Header 1': 'TuGraph Java Client', 'Header 2': '版本选择'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

三、TuGraph-DB高可用集群部署与应用

1.TuGraph-DB高可用（V3.6）

关于 TuGraph-DB 高可用集群的部署方式和 client 应用，相关文档已经放到了 tugraph-db.readthedocs.io 网站上。  
现在支持 C++、Java 和 Python 多种版本的 client SDK。' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '三、TuGraph-DB高可用集群部署与应用', 'Header 3': '1.TuGraph-DB高可用（V3.6）'}"
TuGraph适合哪些类型的用户？,"page_content='环境和版本选择

1. 简介

TuGraph为不同需求的用户提供了差异化的系统环境和部署方式，来满足新手、系统开发者、生产运维人员、研究人员等不同用户的需求。' metadata={'Header 1': '环境和版本选择', 'Header 2': '1. 简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}","page_content='环境和版本选择

3. 部署方式选择

TuGraph部署仅需一台服务器（高可用模式需要多台），可根据实际资源情况和使用场景，选择适合的部署方式。  
| 部署方式     | 描述                   | 备注                                                                                      |
|----------|----------------------|-----------------------------------------------------------------------------------------|
| 云部署      | 阿里云计算巢一键部署，免费试用      | 新手适用，流程参考 [链接](../5.installation&running/5.cloud-deployment.md)              |
| Docker部署 | 通过预先准备的Docker镜像跨平台部署 | 对硬件有要求的用户，比如性能测试，流程参考 [链接](../5.installation&running/3.docker-deployment.md) |
| 本地部署     | 在现有系统紧耦合部署           | 指定生产环境适用，流程参考 [链接](../5.installation&running/4.local-package-deployment.md)  |' metadata={'Header 1': '环境和版本选择', 'Header 2': '3. 部署方式选择'}"
TuGraph的REST API中，POST请求主要用途是什么？,"page_content='RESTful API Legacy

2.请求与数据格式

2.1请求

TuGraph 支持 HTTP GET/POST/PUT/DELETE 请求。其中：  
- GET 请求用于只读请求，如读取点属性，边属性等操作；
- POST 请求用于创建实体，提交 Cypher，以及加载和调用存储过程；
- PUT 请求用于修改已有实体，如修改点属性，边属性等；
- DELETE 请求用于删除已有实体，如删除点，边等。  
在高可用模式下，用户可以在请求的报头(request header)中设置 `server_version` 来保证请求的服务器有足够新的数据。
当前的 `server_version` 可以从服务器返回的报头中获取。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '2.请求与数据格式', 'Header 3': '2.1请求'}","page_content='RESTful API

1.简介

TuGraph 提供遵从 REST 规范的 HTTP API，以供开发者通过 HTTP 请求远程调用 TuGraph 提供的服务。  
本文档描述 TuGraph 的 HTTP API 使用方式。' metadata={'Header 1': 'RESTful API', 'Header 2': '1.简介'}","page_content='RESTful API Legacy

4.查询

4.2.调用带参数的 Cypher

Cypher 支持使用参数进行查询。当调用带参数的 Cypher 查询时，TuGraph 会缓存该查询的
执行计划（execution plan），以加速后续同类查询的速度。  
- **URI**: `/cypher`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| graph | 数据库 | 字符串 |
| cypher | 查询语句 | 字符串 |
| parameters | 参数 | 列表 |  
- **RESPONSE**:  
与 [调用 Cypher](#%E8%B0%83%E7%94%A8Cypher) 相同。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/cypher
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""graph"": ""default"",
""script"": ""MATCH (n:Person {name:$param1}) RETURN n.birthyear"",
""parameters"": {
""$param1"": ""Lindsay Lohan""
}
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""elapsed"": 0.005886077880859375,
""header"": [
{
""name"": ""n.birthyear"",
""type"": 0
}
],
""result"": [
[
1986
]
],
""size"": 1
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '4.查询', 'Header 3': '4.2.调用带参数的 Cypher'}"
安装部署TuGraph外存配置的最低和建议分别是多少？,"page_content='环境准备

1.硬件环境

1.3. 外存

我们强烈建议用户使用 NVMe SSD 作为外存，数据库有大量的写操作需要同步的外存，通常为随机写，外存的读写性能很容易成为整体数据库运行的性能瓶颈。因此，高IOPS、低延迟的 NVMe SSD 是最优的选择。  
如果现实条件只能使用 SATA接口的SSD，或者云上的网盘，性能虽然会受到影响，但 TuGraph 依然能正确的运行。  
外存大小建议为实际数据大小的4倍，比如数据为1TB，则准备4TB的硬盘会比较稳妥。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.3. 外存'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='TuGraph在图计算系统建设中的作用

TuGraph 技术优势

TuGraph 开源版特色

为什么要去开源单机版而不是分布式版本？主要是考虑到它的部署和使用成本比分布式版本要低得多，同时功能也很完整、独立。我们希望这样可以让许多刚开始使用图数据库或有使用图数据库解决问题的想法的人，可以先尝试用我们的单机版图数据库。因为它的部署非常简单，如果跑起来没有问题，那么再考虑是否需要分布式版本。如果确实需要，我们可以再跟进这个问题。  
我们的单机版图数据库已经能够支持 TB 级别的数据，我们内部也有很多情况使用单机版图数据库。在单台机器上，我们最大的数据量也达到了 2TB 多，在线上运行，能够处理百亿级别的点边。事实上，大多数用户使用单机版图数据库都是足够的。由于单机版的图数据库很容易优化，我们对它进行了极致的优化，因此单机版图数据库在性能上可以满足绝大多数场景的需求。此外，它的系统特性也很全面，包括高可用性、多图支持、权限管理、日志记录等，它可以被看作是一个成熟、易用的图数据库，类似于 MySQL。  
开源TuGraph特点包括:  
-   单机版图数据库能够处理数据量几个 TB 的数据，前提是磁盘足够大。
-   成本很低，因为是单机版，部署和运维都很容易。
-   性能很好，我们对其进行了大量优化。TuGraph 的 LDBC-SNB 测试目前是世界第一，大家可以在 GitHub 上获取测试 SNB 的条款并进行测试。
-   单机版图数据库是一个非常易用的完整系统，我们提供了导入导出工具和查询语言。此外，还提供了底层 API，用户可以使用它来编写复杂的程序。  
我们的开源版本的目标主要有三点：  
首先，我们希望提供一个免费的图数据库产品，能够让更多的人使用图数据库，尝试用它来解决问题。  
其次，我们希望促进图数据库标准的成形。目前图数据库的差异太大，每个数据库都有所不同，我们希望通过提供一个参考答案来帮助大家达成趋同。这样大家就可以根据我们提供的设计来判断哪些特征合理，如果觉得合理就可以遵循这个设计，慢慢地大家就会逐渐靠近。假如所有产品在主要特征上保持一致，这样所有人的学习成本就会降低。  
最后，基础研究性问题可以不断优化发展，包括存储方面的问题，例如哈希可能是理论上最优的，但是是否还有其他需要调整的东西？目前没有一个很好的研究性平台让大家去进行这些尝试和研究，我们希望提供的开源 TuGraph-DB 能成为这些研究人员的对比基线，促进研究的发展。' metadata={'Header 1': 'TuGraph在图计算系统建设中的作用', 'Header 2': 'TuGraph 技术优势', 'Header 3': 'TuGraph 开源版特色'}"
在创建一个TuGraph数据库时，如果指定的目录不存在，构造函数会如何处理？,"page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客户端端口。默认端口为 7687。                                ' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
EXPO' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}","page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}"
VertexIterator 的 GetNumOutEdges 方法默认的 n_limit 参数值是多少？,"page_content='Traversal API

2. 接口说明

2.1. Snapshot

C++ OLAP API 中的 Snapshot 模版类用于表示抽取出来的静态子图，其中 EdgeData 用来表示该子图上每条边所用权值的数据类型（如果边不需要权值，使用 Empty 作为 EdgeData 即可）。  
抽取的子图通过 Snapshot 类的构造函数来描述：  
```c
Snapshot::Snapshot(
GraphDB & db,
Transaction & txn,
size_t flags = 0,
std::function<bool(VertexIterator &)> vertex_filter = nullptr,
std::function<bool(OutEdgeIterator &, EdgeData &)> out_edge_filter = nullptr
);
```  
其中，db 为数据库句柄，txn 为事务句柄，flags 为生成时使用的选项，可选值包括以下的组合：SNAPSHOT_PARALLEL 表示导出时使用多个线程进行并行；SNAPSHOT_UNDIRECTED 表示需要将导出的图变为无向图。
vertex_filter 是面向点的用户自定义过滤函数，返回值为 true 表示该点需要被包含到待抽取的子图中，反之则表示需要被排除。
out_edge_filter 是面向边的用户自定义过滤函数，返回值为 true 表示该边需要被包含到待抽取的子图中，反之则表示需要被排除。
当过滤函数为缺省值时，则表示需要将所有点/边都包含进来。  
Snapshot 类提供的其它方法请参考详细的 C++ API 文档（olap_on_db.h）。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.1. Snapshot'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bo' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Python Olap API

4. Olap API

图类OlapBase

- `NumVertices()-> size_t`：获取点数
- `NumEdges()-> size_t`：获取边数
- `OutDegree(size_t vid)-> size_t`：点vid的出度
- `InDegree(size_t vid)-> size_t`：点vid的入度  
- `AllocVertexArray[VertexData]() ->ParallelVector[VertexData]`：分配一个类型为VertexData的数组，大小为点个数
- `AllocVertexSubset()-> ParallelBitset`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `OutEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有出边集合
- `InEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有入边集合
- `Transpose()-> cython.void`：对有向图进行图反转
- `LoadFromArray(edge_array: cython.p_char, input_vertices: size_t, input_edges: size_t, edge_direction_policy: EdgeDirectionPolicy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。  
- `AcquireVertexLock(vid: size_t)-> cython.void`：对点vid加锁，禁止其它线程对该锁对应的点数据进行访存
- `void ReleaseVertexLock(vid: size_t)-> cython.void`：对点vid解锁，所有线程均可访存该锁对应的点数据  
TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程，在Python中与C++使用方法稍有不同。  
```python
# 函数名称:ProcessVertexInRange[ReducedSum, Algorithm](
#           work: (algo: Algorithm, vi: size_t)-> ReducedSum,
#           lower: size_t, upper: size_t,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#     函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
#     第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
#     具体实现请参考include/lgraph/olap_base.h中具体代码
#
#     使用示例:统计数组parent数组中有出边的点个数

import cython
from cython.cimports.olap_base import *


@cython.cclass
class CountCore:
graph: cython. pointer(OlapBase[Empty])
parent: ParallelVector[size_t]

@cython.cfunc
@cython.nogil
def Work(self, vi: size_t) -> size_t:
if self.graph.OutDegree(self.parent[vi]) > 0:
return 1
return 0

def run(self, pointer_g: cython. pointer(OlapBase[Empty])):
self.graph = pointe' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}"
试图加入高可用集群时节点的默认等待秒数是多少？,"page_content='部署高可用模式

3.启动初始备份组

3.2.初始数据不一致

如果第一台服务器中已有数据（以`lgraph_import`工具导入或从非高可用模式的服务器传输得到），
并且之前并未在高可用模式下使用，则用户应使用boostrap方式启动。
以`ha_bootstrap_role`参数为1在bootstrap模式下启动有数据的服务器，并通过`ha_conf`参数指定本机为`leader`。
在bootstrap模式下，服务器在将新加入的服务器添加到备份组之前会将自己的
数据复制到新服务器中，以使每个服务器中的数据保持一致。  
启动有数据服务器的命令示例如下所示：  
```bash
$ ./lgraph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090 --ha_bootstrap_role 1
```  
其他无数据的服务器需要指定`ha_bootstrap_role`参数为2，并通过`ha_conf`参数指定`leader`即可，命令示例如下所示  
```bash
$ ./lgraph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090 --ha_bootstrap_role 2
```  
**使用bootstrap启动HA集群时需要注意两点：**
1. 需要等待`leader`节点生成snapshot并且成功启动之后再加入`follower`节点，否则`follower`节点可能加入失败。在启动`follower`节点时可以将`ha_node_join_group_s`参数配置的稍大，以在加入HA集群时多次等待和超时重试。
2. HA集群只有在第一次启动时可以使用bootstrap模式，后续再启动时只能使用普通模式(见3.1节)启动，尤其不能让同一个集群的多个节点以bootstrap模式启动，否则可能产生数据不一致的情况' metadata={'Header 1': '部署高可用模式', 'Header 2': '3.启动初始备份组', 'Header 3': '3.2.初始数据不一致'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

二、TuGraph-DB高可用架构与规划

1.Server架构设计—启动集群

上面是我们选择的一个基础算法，下面介绍 TuGraph-DB 具体的高可用架构是怎样设计的。通过一个 CASE 来进行讲解。  
首先建立一个集群，启动集群的方式跟单机版几乎是一致的，只不过要加上 enable\_ha 参数和 ha\_conf 参数去指定集群里面所有节点的 URL，并且要保证三个或者五个节点是可以进行通信的。在三个节点同时启动后，最先启动的节点的计时器会超时，把自己选成一个候选者，之后向其它节点发送一个投票请求，其它节点接收到请求之后，会返回给候选者一个 success 的 response，当超过半数之后，这个 leader 就当选了。一般来说，在同城的情况下，延迟不会超过 2 毫秒，在两地的情况下，比如上海到深圳，最高延迟不会超过 30 毫秒，所以集群建立的时间和选举的时间是非常快的。' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '二、TuGraph-DB高可用架构与规划', 'Header 3': '1.Server架构设计—启动集群'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

三、TuGraph-DB高可用集群部署与应用

2.高可用集群部署

当原始数据一致的时候，可以直接指定 HA configure 参数启动集群。当初始数据不一致的时候，假如有一个节点有数据，其它节点没有数据，需要把数据同步到其它节点，但是又不能通过 SCP 传，那么就可以通过初始数据不一致的方式去启动。有数据的节点用 bootstrap 方式启动，预先生成一个快照，然后其它节点以 follower 的身份加入集群，加入集群时会安装快照，安装快照之后才会进行选举和 follower 身份的确认。  
初始数据一致:  
• 所有节点数据相同或没有数据时，可以直接指定ha_conf参数启动集群  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true \ --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090`  
初始数据不一致:  
• 有数据的节点使用bootstrap方式启动，预先生成快照  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090 --ha_bootstrap_role 1`  
• 无数据的节点直接以follower的身份加入安装快照，无需再选举  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090 —-ha_bootstrap_role 2`' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '三、TuGraph-DB高可用集群部署与应用', 'Header 3': '2.高可用集群部署'}"
生成Mapper接口的时候，XMLMAPPER类型将如何实现接口方法？,"page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends GraphSnapShot<K, VV, EV> {
/** 获取开始图遍历的点 */
Travers' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentric function进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |  
- 详细接口  
```java
public interface VertexCentricTraversalFunction<K, VV, EV, M, R> extends VertexCentricFunction<K, VV
, EV, M> {

void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);
/** 图遍历算法初始化方法 */
void init(ITraversalRequest<K> traversalRequest);
/** 实现图遍历逻辑 */
void compute(K vertexId, Iterator<M> messageIterator);

void finish();

void close();

interface VertexCentricTraversalFuncContext<K, VV, EV, M, R> extends VertexCentricFuncContext<K,
VV, EV, M> {
/** 获取图遍历结果 */
void takeResponse(ITraversalResponse<R> response);
/** 获取开始图遍历的点 */
TraversalVertexQuery<K, VV> vertex();
/** 获取开始图遍历的边 */
TraversalEdgeQuery<K, EV> edges();

void broadcast(IGraphMessage<K, M> message);
}

interface TraversalVertexQuery<K, VV> extends VertexQuery<K, VV> {
/** 获取图遍历中点的迭代器 */
Iterator<K> loadIdIterator();
}

interface TraversalEdgeQuery<K, EV> extends EdgeQuery<K, EV> {
/** 通过指定的点id，获取对应的图遍历起点 */
TraversalEdgeQuery<K, EV> withId(K vertexId);
}
}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void init(IncGraphComputeContext<K, VV, EV, M> incGraphContext) | 图计算初始化接口 | incGraphContext： 增量动态图计算的上下文，K表示vertex id的类型，VV表示vertex value类型，EV表示edge value类型，M表示发送消息的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮迭代对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 迭代计算接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 迭代计算完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型 |  
- 详细接口  
```java
public interface IncVertexCentricFunction<K, VV, EV, M> extends Function {

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncGraphContext<K, VV, EV, M> {
/** 获取job id */
long getJobId();

/** 获取当前迭代 id */
long getIterationId();

/** 获取运行时上下文 */
RuntimeContext getRuntimeContext();

/** 获取可变图 */
MutableGraph<K, VV, EV> getMutableGraph();

/** 获取增量图 */
TemporaryGraph<K, VV, EV> getTemporaryGraph();

/** 获取图存储上的历史图 */
HistoricalGraph<K, VV, EV> getHistoricalGraph();

/** 给指定vertex发送消息 */
void sendMessage(K vertexId, M message);

/** 给当前vertex邻居节点发送消息 */
void sendMessageToNeighbors(M message);

}

interface TemporaryGraph<K, VV, EV> {
/** 从增量图中获取vertex */
IVertex<K, VV> getVertex();

/** 从增量图中获取edges */
List<IEdge<K, EV>> getEdges();

/** 更新vertex value */
void updateVertexValue(VV value);

}

interface HistoricalGraph<K, VV, EV> {
/** 获取图数据最新版本id */
Long getLatestVersionId();

/** 获取图数据所有版本 */
List<Long> getAllVersionIds();

/** 获取图数据所有vertex */
Map<Long, IVertex<K, VV>> getAllVertex();

/** 获取图数据指定版本的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions);

/** 获取图数据指定版本并满足过滤条件的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(L' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
GCN模型的主要组成部分是什么？,"page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.4.构建GCN模型

```python
class GCN(nn.Module):
def __init__(self, in_size, hid_size, out_size):
super().__init__()
self.layers = nn.ModuleList()
# two-layer GCN
self.layers.append(dgl.nn.GraphConv(in_size, hid_size, activation=F.relu))
self.layers.append(dgl.nn.GraphConv(hid_size, out_size))
self.dropout = nn.Dropout(0.5)

def forward(self, g, features):
h = features
for i, layer in enumerate(self.layers):
if i != 0:
h = self.dropout(h)
h = layer(g, h)
return h

def build_model():
in_size = feature_len  #feature_len为feature的长度，在此处为1433
out_size = classes  #classes为类别数，在此处为7
model = GCN(in_size, 16, out_size)  #16为隐藏层大小
return model
```
本教程将构建一个两层图卷积网络（GCN）。每层通过聚合邻居信息来计算新的点表示。' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.4.构建GCN模型'}","page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.5.训练GCN模型

```python
loss_fcn = nn.CrossEntropyLoss()
def train(graph, model, model_save_path):
optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)
model.train()
s = time.time()
load_time = time.time()
graph = dgl.add_self_loop(graph)
logits = model(graph, graph.ndata['feat'])
loss = loss_fcn(logits, graph.ndata['label'])
optimizer.zero_grad()
loss.backward()
optimizer.step()
train_time = time.time()
current_loss = float(loss)
if model_save_path != """":   #如果需要保存模型，则给出模型保存路径
if 'min_loss' not in train.__dict__:
train.min_loss = current_loss
elif current_loss < train.min_loss:
train.min_loss = current_loss
model_save_path = 'best_model.pth'
torch.save(model.state_dict(), model_save_path)
return current_loss

for epoch in range(50):
model.train()
total_loss = 0
loss = train(g, model)
if epoch % 5 == 0:
print('In epoch', epoch, ', loss', loss)
sys.stdout.flush()
```
如代码所示，根据定义好的采样器、优化器和模型进行迭代训练50次，训练后的模型保存至model_save_path路径中。  
输出结果如下：
```bash
In epoch 0 , loss 1.9586775302886963
In epoch 5 , loss 1.543689250946045
In epoch 10 , loss 1.160698413848877
In epoch 15 , loss 0.8862786889076233
In epoch 20 , loss 0.6973256468772888
In epoch 25 , loss 0.5770673751831055
In epoch 30 , loss 0.5271289348602295
In epoch 35 , loss 0.45514997839927673
In epoch 40 , loss 0.43748989701271057
In epoch 45 , loss 0.3906335234642029
```  
同时，图学习模块可采用GPU进行加速，用户如果需要再GPU上运行，需要用户自行安装相应的GPU驱动和环境。具体可参考learn/README.md。  
完整代码可参考learn/examples/train_full_cora.py' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.5.训练GCN模型'}","page_content='Heterogeneous Graph

5. 异质图训练

异构图训练的目标是学习图中节点和边的表示，以便于进行后续的任务，如节点分类、链接预测、图聚类等。为了实现这一目标，研究者们提出了多种基于图神经网络（Graph Neural Networks，GNNs）的模型。这些模型通过聚合邻居节点的信息来更新节点的表示，进而捕捉图结构中的复杂关系。  
由于异构图中包含多种类型的节点和边，因此在设计GNN模型时需要考虑如何处理这些不同类型的信息。一种常见的方法是设计不同的聚合函数来分别处理不同类型的邻居节点。此外，还需要考虑如何将这些不同类型的信息整合到一起，以便于模型能够有效地学习到节点和边的表示。  
TuGraph 提供了使用裁剪版ogbn-mag数据集进行异质图训练的方法，可供使用者参考。  
TuGraph提供的官方docker中暂未提供异质图训练的环境，因此需要用户自行安装相关依赖包。
在训练之前需要下载ogb和pandas包，具体安装方式如下：
```shell
pip3 install ogb
pip3 install pandas==0.24.2
```  
训练代码如下所示：  
```python
def train(graph, model, model_save_path):
optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)
model.train()
s = time.time()
load_time = time.time()
graph = dgl.add_self_loop(graph)
logits = model(graph, graph.ndata['feat'])
loss = loss_fcn(logits, graph.ndata['label'])
optimizer.zero_grad()
loss.backward()
optimizer.step()
train_time = time.time()
current_loss = float(loss)
if model_save_path != """":
if 'min_loss' not in train.__dict__:
train.min_loss = current_loss
elif current_loss < train.min_loss:
train.min_loss = current_loss
model_save_path = 'best_model.pth'
torch.save(model.state_dict(), model_save_path)
return current_loss
```
全部训练代码可参考tugraph/learn/examples/train_full_mag.py文件。' metadata={'Header 1': 'Heterogeneous Graph', 'Header 2': '5. 异质图训练'}"
TuGraph-DB的单元测试使用的是什么框架？,"page_content='单元测试

1.简介

TuGraph单元测试采用gtest框架，可以选择一次跑全部test或者制定某些test。' metadata={'Header 1': '单元测试', 'Header 2': '1.简介'}","page_content='集成测试

2.TuGraph集成测试框架

TuGraph采用pytest框架作为自己的集成测试框架，pytest框架作为目前使用最广泛的cs端集成测试框架，以其灵活简单，容易上手，并且支持参数化的使用方式而著称，TuGraph基于pytest提供的功能，抽象出了不同的工具，通过参数来控制各个工具的处理逻辑，以方便大家进行高效的测试代码开发。  
更多pytest信息请参考官网: [https://docs.pytest.org/en/7.2.x/getting-started.html](https://docs.pytest.org/en/7.2.x/getting-started.html)' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架'}","page_content='集成测试

1.TuGraph集成测试的意义

在单元测试与功能测试中，有部分用例直接开启galaxy或statemachine来进行测试，这并不是一个完整的流程。在完整的cs架构中，用户请求是通过客户端发往服务端，网络通信是必不可少的，为了避免单元测试不完整带来的bug，针对这种情况，使用集成测试框架进行全链路的完整测试。' metadata={'Header 1': '集成测试', 'Header 2': '1.TuGraph集成测试的意义'}"
tugraph-db可以先用cypher找一个子图，然后在这个子图上跑图分析吗？例如pagerank、kcore什么的！,"page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}","page_content='OLAP API

1. TuGraph 图分析引擎介绍

TuGraph的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助TuGraph的 C++ / Python 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如PageRank、LPA、WCC等迭代式图算法，最后根据运行结果做出相应的对策。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph图计算系统社区版内置6个算法，商业版内置了25种算法，用户几乎不需要自己实现具体的图计算过程。其详细介绍可参考algorithms.md。  
根据数据来源及实现不同，可分为Procedure、Embed和Standalone三种运行方式，均继承于OlapBase API，OlapBase API接口文档可参考olapbase-api.md。  
其中Procedure和Embed的数据来源是图数据库中预加载的db数据，可以分别编译生成tugraph-web加载使用的.so文件和后台终端使用的embed文件，输入的图数据均通过db的加载形式，其接口文档可参考olapondb-api.md。
Standalone用于编译生成standalone文件，区别于前者，该文件的输入图数据通过txt、二进制、ODPS文件的形式加载，其接口文档可参考olapondisk-api.md。' metadata={'Header 1': 'OLAP API', 'Header 2': '1. TuGraph 图分析引擎介绍'}","page_content='HTAP

2.设计

在 TuGraph 中，OLTP 为图事务引擎，在图 4.4对应事务操作；OLAP 为图分析引擎，对应简单图分析操作（比如 SPSP）和复杂图分析操作（比如 PageRank），前者可以直接在图存储上执行，而后者需要额外导出快照执行。  
- 事务操作，即图事务引擎测的操作，为局部图的增删查改操作，典型的应用为 K 跳访问 K-Hop。
- 简单分析操作，是图分析引擎中较为简单的部分，通常也是局部的图分析操作，比如两点间最短路算法 SPSP、Jaccard 算法。
- 复杂分析操作，是图分析引擎中较为复杂的部分，通常涉及全图的多轮数据迭代操作，比如网页排序算法 PageRank、社区发现算法 Louvain。  
如架构图所示，我们在图中增加了外部存储，使得图分析的数据源不局限在图数据库中，可以直接从文本文件读取。  
- 图存储，即图数据库中的存储，有精心设计的数据结构，能够完成实时增删查改。
- 外部存储，可以是 RDBMS 或文本文件，以边表的简单方式存储，仅供一次性批量读取，和批量结果写入。在计算层，和整体架构图中的接口对应。
- Cypher，描述式图查询语言，可以并发执行。
- Procedure API，过程式图查询语言，其灵活性能够同时支持事务操作和图分析操作，但效率上不足以完成复杂图分析操作，可以并发执行。
- OLAP API，针对多轮迭代的复杂图分析。应用需要先将存储中的图数据导出成内存中的一个快照，该快照仅用来快速访问，而不需要考虑 ACID 的写支持，因此可以排布地更加紧凑，CSR 排布的读效率要远高于图存储的数据排布。OLAP API 只能串行执行，每个操作都用满 CPU 资源。  
OLAP API 的快照可以从外部存储创建，即将边表数据构成件 CSR 的格式；或者从图存储中创建。需要注意的是，OLAP API 要求点的 ID 是连续的自然数，可能需要额外的 ID 映射，该步骤在创建快照时可以在指定一个属性进行映射，或直接取属性值作为 ID。  
与计算接口和存储相对应，有四种运行模式。  
- 事务模式，每个操作对应一条 Cypher 语句，默认是一个事务。
- Plugin 模式，通过插件的方式，在计算逻辑加载到服务端后调用，也叫存储过程。
- Embed 模式，和 Plugin 模式的使用接口一致，区别是图数据库服务不需要起来，就可以直接用接口调用数据库中的数据，通常用于调试 Procedure API 和OLAP API 的代码，调试信息和操作步骤比 Plugin 模式更加友好。
- Standalone 模式，最大程度剥离与图数据库的关系，仅想用图分析引擎做数据分析时，该模式会比较直接。Standalone 模式会直接使用外部存储的数据。  
图神经网络引擎的使用方式和 ‘复杂图分析操作’ 类似，会同时调用部分 OLAP API 和 GNN API，不在这里展开。' metadata={'Header 1': 'HTAP', 'Header 2': '2.设计'}"
HA集群的snapshot何时删除？,"page_content='集群管理

4. 生成snapshot

出于节点启动时设置ha_snapshot_interval_s为-1以默认不打snapshot或其他原因，
当需要让某个节点手动生成snapshot时，可以使用`lgraph_peer`的`snapshot`命令。命令示例如下所示：  
```shell
$ lgraph_peer --command snapshot --peer {peer_id}
```  
其中：  
- `--command snapshot` 指定要执行的操作为snapshot，即生成快照。
- `--peer {peer_id}` 指定要生成快照的节点的rpc网络地址，如 `127.0.0.1:9092`。' metadata={'Header 1': '集群管理', 'Header 2': '4. 生成snapshot'}","page_content='集群管理

1. 简介

HA集群启动之后，可以使用`lgraph_peer`工具进行集群管理，可以执行删除节点，转移leader和生成snapshot等功能。' metadata={'Header 1': '集群管理', 'Header 2': '1. 简介'}","page_content='部署高可用模式

3.启动初始备份组

3.2.初始数据不一致

如果第一台服务器中已有数据（以`lgraph_import`工具导入或从非高可用模式的服务器传输得到），
并且之前并未在高可用模式下使用，则用户应使用boostrap方式启动。
以`ha_bootstrap_role`参数为1在bootstrap模式下启动有数据的服务器，并通过`ha_conf`参数指定本机为`leader`。
在bootstrap模式下，服务器在将新加入的服务器添加到备份组之前会将自己的
数据复制到新服务器中，以使每个服务器中的数据保持一致。  
启动有数据服务器的命令示例如下所示：  
```bash
$ ./lgraph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090 --ha_bootstrap_role 1
```  
其他无数据的服务器需要指定`ha_bootstrap_role`参数为2，并通过`ha_conf`参数指定`leader`即可，命令示例如下所示  
```bash
$ ./lgraph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090 --ha_bootstrap_role 2
```  
**使用bootstrap启动HA集群时需要注意两点：**
1. 需要等待`leader`节点生成snapshot并且成功启动之后再加入`follower`节点，否则`follower`节点可能加入失败。在启动`follower`节点时可以将`ha_node_join_group_s`参数配置的稍大，以在加入HA集群时多次等待和超时重试。
2. HA集群只有在第一次启动时可以使用bootstrap模式，后续再启动时只能使用普通模式(见3.1节)启动，尤其不能让同一个集群的多个节点以bootstrap模式启动，否则可能产生数据不一致的情况' metadata={'Header 1': '部署高可用模式', 'Header 2': '3.启动初始备份组', 'Header 3': '3.2.初始数据不一致'}"
TuGraph-DB目前支持哪种查询语言，并计划在将来支持哪种查询语言？,"page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='试用体验：TuGraph — 简单高效的图数据库

支持RESTful API

除了支持Cypher查询语言，TuGraph还提供了RESTful API接口。这使得我可以通过编程方式与图数据库进行交互，更好地将TuGraph集成到我的应用程序中。API设计合理，易于使用，为我提供了灵活性和自由度。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持RESTful API'}"
语句里面有没有开启事务和结束事务的关键字,"page_content='TuGraph console client

`lgraph_cli`使用

语句以分号结束，输入`exit`, `quit`或者Ctrl-C退出客户端。  
```powershell
lgraph_cli --ip 127.0.0.1 --port 7687 --graph default --user admin --password 73@TuGraph

Welcome to the TuGraph console client. Commands end with ';'.
Copyright(C) 2018-2023 Ant Group. All rights reserved.
Type 'exit', 'quit' or Ctrl-C to exit.

TuGraph> match(n) return n limit 1;
+-------------------------------------------------------------------------------------------------------------------------------------+
| n                                                                                                                                   |
+-------------------------------------------------------------------------------------------------------------------------------------+
| (:person {id:2,born:1961,poster_image:""https://image.tmdb.org/t/p/w185/mh0lZ1XsT84FayMNiT6Erh91mVu.jpg"",name:""Laurence Fishburne""}) |
+-------------------------------------------------------------------------------------------------------------------------------------+

TuGraph>
```  
语句可以中间换行，多行输入。  
```powershell
TuGraph> match(n)
-> return n
-> limit 1;
+-------------------------------------------------------------------------------------------------------------------------------------+
| n                                                                                                                                   |
+-------------------------------------------------------------------------------------------------------------------------------------+
| (:person {id:2,born:1961,poster_image:""https://image.tmdb.org/t/p/w185/mh0lZ1XsT84FayMNiT6Erh91mVu.jpg"",name:""Laurence Fishburne""}) |
+-------------------------------------------------------------------------------------------------------------------------------------+

TuGraph>
```  
非交互式
```powershell

echo ""match(n) return n limit 1;"" | lgraph_cli --ip 127.0.0.1 --port 7687 --graph default --user admin --password 73@TuGraph
+-----------------------------------------------------------' metadata={'Header 1': 'TuGraph console client', 'Header 2': '`lgraph_cli`使用'}","page_content='Cypher API

1.Operators

1.1.Summary

Operators支持进度一览：  
| 类别                                 | 支持                                                                                                        | 待支持                             |
| ------------------------------------ | ----------------------------------------------------------------------------------------------------------- | ---------------------------------- |
| General operators                    | `DISTINCT`, `.` for property access                                                                     | `[]` for dynamic property access |
| Mathematical operators               | `+`, `-`, `*`, `/`, `%`, `^`                                                                    |                                    |
| Comparison operators                 | `=`, `<>`, `<`, `>`, `<=`, `>=`, `IS NULL`, `IS NOT NULL`                                   |                                    |
| String-specific comparison operators | `STARTS WITH`, `ENDS WITH`, `CONTAINS`, `REGEXP`                                                    |                                    |
| Boolean operators                    | `AND`, `OR`, `XOR`, `NOT`                                                                           |                                    |
| String operators                     | `+` for concatenation                                                                                     |                                    |
| List operators                       | `+` for concatenation, `IN` to check existence of an element in a list, `[]` for accessing element(s) |                                    |' metadata={'Header 1': 'Cypher API', 'Header 2': '1.Operators', 'Header 3': '1.1.Summary'}","page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}"
如何使用命令创建一个新的角色，并为其提供描述信息？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLm' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='用户权限

4.常用权限操作

4.2.角色操作

- 创建角色  
```cypher
CALL dbms.security.createRole(role_name::STRING,desc::STRING)
```  
- 删除角色  
```cypher
CALL dbms.security.deleteRole(role_name::STRING
```  
- 列出所有角色  
```cypher
CALL dbms.security.listRoles()
```  
- 禁用/启用角色  
```cypher
CALL dbms.security.disableRole(role::STRING,disable::BOOLEAN)
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.2.角色操作'}","page_content='RESTful API Legacy

6.Deprecated

6.1.用户管理

系统默认创建一个管理员，管理员用户名为 _admin_，密码为 _73@TuGraph_。为了安全起见，请用户在第一次启动服务器后更改密码。  
#### 6.1.1.添加用户  
添加一个新的用户，并为其设置初始密码。只有管理员有权限进行此操作。其中用户名只能由字母，数字以及下划线构成，密码则可以包含任意字符。用户名和密码长度不能超过 64 字节。添加用户时还可以为用户增加一个描述，用户描述可以包含任意字符，最长不超过 512 字节。  
新用户默认拥有同名的角色，不具备任何图的权限。  
- **URI**: `/user`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |
| description | 用户描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""user"": ""USER1"",
""password"": ""AN_INITIAL_PASSWORD"",
""description"": ""This is a user""
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.1.2.列出所有用户  
列出数据库的所有用户。只有管理员拥有该操作权限。  
- **URI**: `/user/`
- **METHOD**: GET
- **RESPONSE**: 所有用户及其信息。  
**Example request.**  
```
• GET http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
Output:
{
""admin"": {
""disabled"": false,
""description"": ""Builtin admin user"",
""roles"": [""admin""]
},
""guest1"": {
""disabled"": true,
""description"": """",
""roles"": [""guest1"", ""some_other_role""]
}
}
```  
#### 6.1.3.获取用户信息  
列出给定用户的信息。  
- **URI**: `/user/{user_name}`
- **METHOD**: GET
- **RESPONSE**: 用户信息。  
**Example request.**  
```
• GET http://localhost:7070/user/guest1
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_z' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.1.用户管理'}"
TuGraph查询语句不支持任意长度路径吧？,"page_content='TuGraph-Restful-Server

7.接口

7.6 文件认证请求

用户通过此类请求验证发送到server端的文件是否与期望一致，server端使用两种验证方式，md5值和文件长度，目前已支持文件长度验证。
#### 7.6.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/check_file
#### 7.6.2 REQUEST
|  body参数  |          参数说明           |  参数类型  |  是否必填  |
|:--------:|:-----------------------:|:------:| :-----: |
| fileName |           文件名           |  字符串  |  是  |
| checkSum |        文件对应md5值         |  字符串  |  否  |
| fileSize |       文件长度(以字节计算)       |  字符串  |  否  |
| flag | 标记位，为1时校验md5值，为2时校验文件长度 |  字符串  |  是  |  
#### 7.6.3 RESPONSE
|    body参数     |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| pass | 检查成功为true，否则为false |  bool  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.6 文件认证请求'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属性不会存在相同的值。
由于底层存储设计，组合索引key需要保存属性的长度，因此，
组合唯一索引k' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='RESTful API Legacy

4.查询

4.2.调用带参数的 Cypher

Cypher 支持使用参数进行查询。当调用带参数的 Cypher 查询时，TuGraph 会缓存该查询的
执行计划（execution plan），以加速后续同类查询的速度。  
- **URI**: `/cypher`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| graph | 数据库 | 字符串 |
| cypher | 查询语句 | 字符串 |
| parameters | 参数 | 列表 |  
- **RESPONSE**:  
与 [调用 Cypher](#%E8%B0%83%E7%94%A8Cypher) 相同。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/cypher
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""graph"": ""default"",
""script"": ""MATCH (n:Person {name:$param1}) RETURN n.birthyear"",
""parameters"": {
""$param1"": ""Lindsay Lohan""
}
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""elapsed"": 0.005886077880859375,
""header"": [
{
""name"": ""n.birthyear"",
""type"": 0
}
],
""result"": [
[
1986
]
],
""size"": 1
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '4.查询', 'Header 3': '4.2.调用带参数的 Cypher'}"
如果在Java运行时，targetProject在xml配置文件中应如何配置？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='数据导入

3.配置文件

3.2.配置文件示例

```json
{
""schema"": [
{
""label"": ""actor"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""aid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" }
],
""primary"": ""aid""
},
{
""label"": ""movie"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""mid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" },
{ ""name"": ""year"", ""type"": ""INT16"" },
{ ""name"": ""rate"", ""type"": ""FLOAT"", ""optional"": true }
],
""primary"": ""mid"",
""detach_property"": false
},
{
""label"": ""play_in"",
""type"": ""EDGE"",
""properties"": [{ ""name"": ""role"", ""type"": ""STRING"", ""optional"": true }],
""constraints"": [[""actor"", ""movie""]]
}
],
""files"": [
{
""path"": ""actors.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""actor"",
""columns"": [""aid"", ""name""]
},
{
""path"": ""movies.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""movie"",
""columns"": [""mid"", ""name"", ""year"", ""rate""]
},
{
""path"": ""roles.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""play_in"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
对于上述配置文件，定义了三个 label：两个点类型`actor`和`movie`，一个边类型`role`。每个 label 都描述了：label 的名字、类型（点还是边）、属性字段有哪些以及每个字段的类型。对于点，另外定义了 primary 字段是哪个；对于边，另外定义了 constraints 字段，用来限制边的起点和终点只能是哪些组合。  
还描述了三个数据文件，两个点的数据文件`actors.csv`和`movies.csv`，一个边的数据文件`roles.csv`。每个部分都描述了：文件的路径（path）、数据类型（format）、信息头占开头几行（header）、是哪个 label 的数据（label）、文件中每行数据中的每个列对应的字段是哪个。  
对于上述配置文件，import 工具在执行的过程中会先在 TuGraph 中创建`actor`、`movie`、`role`这三个 label，然后再执行三个文件的数据导入。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.2.配置文件示例'}","page_content='Java客户端

2.使用示例

2.1.实例化client对象

添加maven依赖  
```xml
<dependency>
<groupId>com.antgroup.tugraph</groupId>
<artifactId>tugraph-db-java-rpc-client</artifactId>
<version>1.4.1</version>
</dependency>
```  
引入依赖
```java
import com.antgroup.tugraph.TuGraphDbRpcClient;
```  
#### 2.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
```java
TuGraphDbRpcClient client = new TuGraphDbRpcClient(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(String url, String user, String pass)
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```  
#### 2.1.2.实例化HA集群直连连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化。
```java
TuGraphDbRpcClient client = new TuGraphDbRpcClient(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(String url, String user, String pass)
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 2.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化
```java
List<String> urls = new ArrayList<>();
urls.add(""189.33.97.23:9091"");
urls.add(""189.33.97.24:9091"");
urls.add(""189.33.97.25:9091"");
TuGraphDbRpcClient client = new TuGraphDbRpcClient(urls, ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(List<String> urls, String user, String password)
@param urls: tugraph host list
@param user: login user name
@param password: login password
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.1.实例化client对象'}"
2024年功能更新计划中支持什么角色和工具？,"page_content='技术规划

3. 2024年功能更新

在2024年度，我们计划的功能更新包括：  
| 版本号   | 功能                 | 计划时间    |
|-------|--------------------|---------|
| 4.2.x | HA支持Witness角色和管理工具 | 2024.3  |
| 4.2.x | Bolt支持流处理和参数化查询    | 2024.3  |
| x.x.x | GeaX支持Cypher       | 2024.6  |
| x.x.x | 支持组合索引             | 2024.6  |
| x.x.x | 数据导入功能优化           | 2024.6  |
| x.x.x | 【社区功能】支持地理数据类型使用   | 2024.6  |
| x.x.x | Cypher能力提升         | 2024.9  |
| x.x.x | 支持Schema快速变更       | 2024.9  |
| x.x.x | 向量化支持              | 2024.12 |
| x.x.x | RPQ支持              | 2024.12 |
| x.x.x | 【可选】查询引擎升级         | 2024.12 |
| x.x.x | 【社区功能】支持GraphAr    | 2024.12 |' metadata={'Header 1': '技术规划', 'Header 2': '3. 2024年功能更新'}","page_content='技术规划

4. 期望社区共创的功能

目前团队研发精力并不能实现我们对TuGraph-DB的全部期望，在功能的梳理中，我们发现有一系列值得挖掘的想法，
团队也有一些初步的探索，期望下面功能能够在社区中共同研发。  
| 版本号   | 功能                      | 计划时间   |
|-------|-------------------------|--------|
| x.x.x | 图算法库丰富                  | 2024.x |
| x.x.x | 属性默认值支持                 | 2024.x |
| x.x.x | Embedded TuGraph-DB最佳实践 | 2024.x |
| x.x.x | Bolt显式事务支持              | 2024.x |
| x.x.x | List、Map和Decimal等数据类型扩展 | 2024.x |
| x.x.x | 探索多存储引擎                 | 2024.x |  
一些更加简单的功能，我们会在github的issue中打上 good first issue 的标签，欢迎对图数据库感兴趣的技术爱好者共同研讨。' metadata={'Header 1': '技术规划', 'Header 2': '4. 期望社区共创的功能'}","page_content='运维监控

3.未来计划

目前可视化监控只支持单机监控，能监控服务所在机器的cpu，磁盘，网络io，请求qps等性能指标，未来将会实现监控ha集群的功能，也会将更多有意义的指标纳入监控范围' metadata={'Header 1': '运维监控', 'Header 2': '3.未来计划'}"
"调用 ""CallGql"" 接口时，如何指定要查询的图的名称？","page_content='C++客户端

2.使用示例

2.4.调用GQL

```C++
std::string str;
bool ret = client.CallGql(str,
""CALL db.createVertexLabel('actor', 'name', 'name', string, false, 'age', int8, true)"");
```
```
bool CallGql(std::string& result, const std::string& gql,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0, const std::string& url = """");
@param [out] result      The result.
@param [in]  gql         inquire statement.
@param [in]  graph       (Optional) the graph to query.
@param [in]  json_format (Optional) Returns the format， true is json，Otherwise, binary
format.
@param [in]  timeout     (Optional) Maximum execution time, overruns will be interrupted.
@param [in]  url         (Optional) Node address of calling gql.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.4.调用GQL'}","page_content='Java客户端

2.使用示例

2.4.调用GQL

```java
String res = client.callGql(""CALL db.edgeLabels()"", ""default"", 10);
log.info(""db.edgeLabels() : "" + res);
```
```
@param gql: inquire statement.
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@param url: (Optional) Node address of calling GQL
@return: the result of GQL query execution
public String callGql(String gql, String graph, double timeout, String url)
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。
注：JAVA不支持默认参数，因此，JAVA中的默认参数是使用重载函数实现的。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.4.调用GQL'}","page_content='Python客户端

3.RPC Client

3.4.调用GQL

```python
ret, res = client.callGql(""CALL db.edgeLabels()"", ""default"", 10)
```
```
callGql(self: liblgraph_client_python.client, gql: str, graph: str, json_format: bool, timeout: float, url: str) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.4.调用GQL'}"
图中能把属性值展示出来吗？,"page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}","page_content='技术规划

4. 期望社区共创的功能

目前团队研发精力并不能实现我们对TuGraph-DB的全部期望，在功能的梳理中，我们发现有一系列值得挖掘的想法，
团队也有一些初步的探索，期望下面功能能够在社区中共同研发。  
| 版本号   | 功能                      | 计划时间   |
|-------|-------------------------|--------|
| x.x.x | 图算法库丰富                  | 2024.x |
| x.x.x | 属性默认值支持                 | 2024.x |
| x.x.x | Embedded TuGraph-DB最佳实践 | 2024.x |
| x.x.x | Bolt显式事务支持              | 2024.x |
| x.x.x | List、Map和Decimal等数据类型扩展 | 2024.x |
| x.x.x | 探索多存储引擎                 | 2024.x |  
一些更加简单的功能，我们会在github的issue中打上 good first issue 的标签，欢迎对图数据库感兴趣的技术爱好者共同研讨。' metadata={'Header 1': '技术规划', 'Header 2': '4. 期望社区共创的功能'}","page_content='🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！

仅需 5 步，即可呈现 🎊

1. 启动 GeaFlow 流图作业和 Socket 服务

参考 [快速开始](https://github.com/TuGraph-family/tugraph-analytics/blob/master/docs/docs-cn/quick_start.md)  
⚠️ 注意在 `启动SocketServer` 步骤使用下列命令代替  
```bash
bin/socket.sh 9003 GI
```  
输出下列内容时，即表示 Tugraph Analytics 准备好建立连接  
<img width=""610"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/a25ed6ba-4fb9-4db1-9325-ee2f26a4337f"">  
> 如启动服务过程中遇到问题，可见 https://github.com/TuGraph-family/tugraph-analytics/issues/1' metadata={'Header 1': '🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！', 'Header 2': '仅需 5 步，即可呈现 🎊', 'Header 3': '1. 启动 GeaFlow 流图作业和 Socket 服务'}"
tugraph-db如何与neo4j驱动连接？,"page_content='业务开发指南

连接tugraph-db

驱动连接

tugraph-db兼容neo4j的通讯协议，因此可以使用neo4j的驱动连接tugraph-db的server。  
[bolt driver 使用介绍](./7.client-tools/5.bolt-client.md)  
[bolt driver 使用例子](https://github.com/TuGraph-family/tugraph-db/tree/master/demo/Bolt)' metadata={'Header 1': '业务开发指南', 'Header 2': '连接tugraph-db', 'Header 3': '驱动连接'}","page_content='图数据库智能化建设与探索

**02\. 技术分享｜TuGraph-DB兼容Neo4j客户端：Bolt协议设计与实现**

“兼容Neo4j客户端的最大优势在于生态支持。以客户端为例，Neo4j官方自身支持五种编程语言的客户端，社区又贡献了两种，共计七种语言的客户端得以直接使用。此外，还有一系列与上下游生态相接的组件，如与Apache Spark或Apache Kafka的连接，都有现成的代码可供利用。在编程框架方面，特别是Java，例如OGM（Object-Graph Mapping，对象图映射）以及一些业务开发框架，如Spring，这些所需的相关代码都已现成，无需重新编写。这种做法极大地节约了研发资源，我们可以将这些资源重新投入到提升数据库本身能力上。”' metadata={'Header 1': '图数据库智能化建设与探索', 'Header 2': '**02\\. 技术分享｜TuGraph-DB兼容Neo4j客户端：Bolt协议设计与实现**'}","page_content='QA汇总

数据导入QA

数据导出到csv

Q：怎么把存储于tugraph的某些指定的点/边类型的全量数据，导出到csv文件中？
A：使用neo4j driver 连接tugraph，直接发送cypher 语句 ""match (n) return n"" 就可以了。结果是流式返回的，不管多少数据都可以读出来，不会引发内存oom' metadata={'Header 1': 'QA汇总', 'Header 2': '数据导入QA', 'Header 3': '数据导出到csv'}"
图模型中某些边设置了属性，这些有属性的边在导入数据之后进行查询，发现查不到这些边数据,"page_content='性能优先

4.数据编码

对于属性图模型而言，除了图拓扑编码外，属性数据也会很大程度影响功能和性能，我们先讨论属性数据如何与拓扑数据共存的编码格式。从目前的调研来看，属性编码有两种方式，我们称之为基于指针索引将属性数据单独存储的离散编码，和将属性数据和拓扑数据打包在一起的紧凑编码。离散编码根据程度的不同，可以每个属性都单独存储，或者每条边的属性打包后各自存储，下面的讨论对两种情况都适用。  
点查询。属性编码主要针对边，不涉及点查询。  
单边查询。离散编码通过指针定位边，紧凑编码则需要二分查找定位边的位置，离散编码有略微的优势。  
边遍历。离散编码在边遍历过程需要不断地进行指针跳转进行随机数据访问，而紧凑编码提前把数据排列在一起，顺序访问的特性使得效率大大提升。 由规律三知对边的遍历操作很普遍，紧凑编码在边遍历的优势明显。  
单边更新。离散编码对边的更新仅需找到对应的指针位置，插入数据后修改前后指针指向。紧凑编码则需要对紧凑排列的数据进行重编码，对整个边值进行重新写入，开销显著大于离散编码的情形。  
批量边更新。批量更新可以在内存中预先构建点的所有边属性，一次性编码写入，离散编码和紧凑编码相当。但紧凑编码不需要存储指针变量，更少的存储空间效率也会更高。  
以上离散编码和紧凑编码在某一类的查询的性能问题，可以通过优化的来缓解。整体上说，由于图负载读写 20:1 的特性，读性能在整体性能中占比更高。以及规律三所揭示的对属性访问的特征，TuGraph 更倾向于采用紧凑编码来保证读性能。其主要弱势为单边更新时重编码的开销，可以用自适应映射的技术来解决。' metadata={'Header 1': '性能优先', 'Header 2': '4.数据编码'}","page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属性不会存在相同的值。
由于底层存储设计，组合索引key需要保存属性的长度，因此，
组合唯一索引k' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}"
"在""TuGraph-DataX""项目中如何通过job配置文件将""actors.csv""导入到TuGraph？","page_content='TuGraph-DataX

3. 导入TuGraph

3.1.文本数据通过DataX导入TuGraph

我们以 TuGraph 手册中导入工具 lgraph_import 章节举的数据为例子，有三个 csv 数据文件，如下：
`actors.csv`  
```
nm015950,Stephen Chow
nm0628806,Man-Tat Ng
nm0156444,Cecilia Cheung
nm2514879,Yuqi Zhang
```  
`movies.csv`  
```
tt0188766,King of Comedy,1999,7.3
tt0286112,Shaolin Soccer,2001,7.3
tt4701660,The Mermaid,2016,6.3
```  
`roles.csv`  
```
nm015950,Tianchou Yin,tt0188766
nm015950,Steel Leg,tt0286112
nm0628806,,tt0188766
nm0628806,coach,tt0286112
nm0156444,PiaoPiao Liu,tt0188766
nm2514879,Ruolan Li,tt4701660
```  
然后建三个 DataX 的 job 配置文件：
`job_actors.json`  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"": 1
}
},
""content"": [
{
""reader"": {
""name"": ""txtfilereader"",
""parameter"": {
""path"": [""actors.csv""],
""encoding"": ""UTF-8"",
""column"": [
{
""index"": 0,
""type"": ""string""
},
{
""index"": 1,
""type"": ""string""
}
],
""fieldDelimiter"": "",""
}
},
""writer"": {
""name"": ""tugraphwriter"",
""parameter"": {
""url"": ""bolt://127.0.0.1:27687"",
""username"": ""admin"",
""password"": ""73@TuGraph"",
""graphName"": ""default"",
""labelType"": ""VERTEX"",
""labelName"": ""actor"",
""batchNum"": 1000,
""properties"": [""aid"", ""name""]
}
}
}
]
}
}
```  
`job_movies.json`  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"": 1
}
},
""content"": [
{
""reader"": {
""name"": ""txtfilereader"",
""parameter"": {
""path"": [""movies.csv""],
""encoding"": ""UTF-8"",
""column"": [
{
""index"": 0,
""type"": ""string""
},
{
""index"": 1,
""type"": ""string""
},
{
""index"": 2,
""type"": ""string""
},
{
""index"": 3,
""type"": ""string""
}
],
""fieldDelimiter"": "",""
}
},
""writer"": {
""name"": ""tugraphwriter"",
""parameter"": {
""url"": ""bolt://127.0.0.1:27687"",
""username"": ""admin"",
""password"": ""73@TuGraph"",
""graphName"": ""default"",
""labelType"": ""VERTEX"",
""labelName"": ""movie"",
""batchNum"": 1000,
""properties"": [""mid"", ""name"", ""year"", ""rate""]
}
}
}
]
}
}
```  
`job_roles.json`  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"": 1
}
},
""content"": [
{
""reader"": {
""name"": ""txtfilereader"",
""parameter"": {
""path"": [""roles.csv""],
""encoding"": ""UTF-8"",
""column"": [
{
""index"": 0,
""type"": ""string""
},
{
""index"": 1,
""t' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '3. 导入TuGraph', 'Header 3': '3.1.文本数据通过DataX导入TuGraph'}","page_content='TuGraph-DataX

4.导出TuGraph

4.1.配置样例

TuGraph支持使用DataX导出数据，使用如下配置即可将数据导出到文本数据中  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"":1
}
},
""content"": [
{
""reader"": {
""name"": ""tugraphreader"",
""parameter"": {
""username"": ""admin"",
""password"": ""73@TuGraph"",
""graphName"": ""Movie_8C5C"",
""queryCypher"": ""match (n:person) return n.id,n.name,n.born;"",
""url"": ""bolt://127.0.0.1:27687""
}
},
""writer"": {
""name"": ""txtfilewriter"",
""parameter"": {
""path"": ""./result"",
""fileName"": ""luohw"",
""writeMode"": ""truncate""
}
}
}
]
}
}
```  
使用这个配置文件，可以把TuGraph Movie_8C5C子图中person节点的id,name和born属性全部导出出来，
导出到当前目录下的result目录中，文件名称为luohw+随机后缀。' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '4.导出TuGraph', 'Header 3': '4.1.配置样例'}","page_content='数据导入

1.简介

在图数据库服务安装成功后，您可以使用`lgraph_import`批量导入工具将现有数据导入 TuGraph。`lgraph_import`支持从 CSV 文件和 JSON 数据源导入数据。  
> CSV 格式  
```
[movies.csv]
id, name, year, rating
tt0188766,King of Comedy,1999,7.3
tt0286112,Shaolin Soccer,2001,7.3
tt4701660,The Mermaid,2016,6.3
```  
> jsonline 格式  
```json
[""tt0188766"",""King of Comedy"",1999,7.3]
[""tt0286112"",""Shaolin Soccer"",2001,7.3]
[""tt4701660"",""The Mermaid"",2016,6.3]
```  
TuGraph 支持两种导入模式：  
- _离线模式_：读取数据并将其导入指定服务器的数据文件，应仅在服务器离线时完成。
- _在线模式_：读取数据并将其发送到工作中的服务器，然后将数据导入其数据库。' metadata={'Header 1': '数据导入', 'Header 2': '1.简介'}"
创建新子图时需要哪些参数？,"page_content='Cypher API

5.附录2. 内置procedures列表

* dbms.graph.createGraph(graph_name, description, max_size_GB)

create a new subgraph in this graph database .  
**Parameters:**  
| parameter   | parameter type | description              |
| ----------- | -------------- | -------------------------------- |
| graph_name  | string     | the name of new subgraph     |
| description | string     | description of new subgraph      |
| max_size_GB | integer    | Upper limit of subgraph capacity |  
**Output:**  
if successful , it will return true.  
**Example input:**  
```
CALL dbms.graph.createGraph('graph1', 'description', 2045)
```  
**Example output:**  
| success |
| ------- |
| true    |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* dbms.graph.createGraph(graph_name, description, max_size_GB)'}","page_content='RESTful API Legacy

6.Deprecated

6.5.子图管理

TuGraph 支持多子图，子图之间完全独立，不同的子图可以对不同用户开放不同权限。管理员可以添加和删除子图。  
#### 6.5.1.创建新子图  
- **URI**: `/db`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | 子图名 | 字符串 |
| config | 配置 | 字典，格式为 { {列名 1}:{列值 1},... } |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""name"":""graph1"",
""config"" : {
""max_size_GB"":2048,
""description"": ""description of graph1""
}
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.5.2.删除子图  
- **URI**: `/db/{graph_name}`
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• DELETE http://localhost:7070/db/graph1
```  
**Example response.**  
```
• 200: OK
```  
#### 6.5.3.列出所有子图  
- **URI**: `/db`
- **METHOD**: GET
- **RESPONSE**: 子图列表  
**Example request.**  
```
• GET http://localhost:7070/db
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""graph1"": {
""max_size_GB"":1024,
""description"":""description of graph1""
}
}
```  
#### 6.5.4.获取子图信息  
- **URI**: `/db/{graph_name}`
- **METHOD**: GET
- **RESPONSE**: 子图列表  
**Example request.**  
```
• GET http://localhost:7070/db/graph1
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""max_size_GB"":1024,
""description"":""description of graph1""
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.5.子图管理'}","page_content='可视化操作手册（旧版）

操作详情

3.工作台

#### 3.1 快速上手  
- 首次登录，系统会默认创建 default 空图  
![alt 快速上手](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/2.tugraph-browser-quickstart-01.png)  
- 用户点击帮助选项，并选择快速上手  
![alt 帮助](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/3.tugraph-browser-quickstart-02.png)  
- 然后点击“一键创建模型”——>""一键创建数据""，就可以完成内置的 Movie 数据图谱的构建  
#### 3.2 创建子图和示例  
##### 3.2.1 创建子图  
- 点击新建子图
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/4.tugraph-browser-create-subgraph-01.png)
- 填写表单信息
![alt 填写表单](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/5.tugraph-browser-create-subgraph-02.png)
- 子图名称
- 子图描述
- 配置信息
- 点击确认，提示创建成功
- 切换子图
![alt 切换子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/6.tugraph-browser-use-graph-01.png)  
- 点击新建示例
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/create-scene-01.png)
- 选择示例并点击创建
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/select-scene.png)  
#### 3.3 查询  
![alt 查询](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/7.tugraph-browser-query-01.png)  
##### 3.3.1 页面组成  
- cypher 输入框
- 结果集展示区域  
##### 3.3.2 结果集展示区域功能详情  
- 结果集标签展示及功能
![alt 结果集标签](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/tugraph-browser-result.png)
- 这里展示了结果集的所有类型统计
- 点击不同的“label（标签）”，可以进行以下修改操作
- 修改展示颜色
- 修改节点大小或边的粗细
- 修改默认展示属性或系统属性
- 布局修改
- 力导布局
- 网格布局
- 树形布局
- 环境布局
- 边聚合
- 相同类型，方向的边可以进行合并
- 创建节点
- 点击创建节点按钮
- 选择节点类型
- 添写节点内容
- 创建关系
- 在画布中选择起点和终点
- 选择可以匹配的类型
- 填写节点信息
- 停止布局
- 当数据量过大，导致浏览器页面卡顿时候，可以点击这个停止布局的按钮，能够提高体验的流畅度
- 鼠标悬停
- 开启此功能，可以高亮显示鼠标悬停节点的一度邻居节点
- 结果集导出
- 可以将结果集导出为 png，json，csv 三种不同的文件形式
- 刷新
- 点击刷新按钮，会重新执行当前页面的初始 cypher 语句，并刷新结果集
- 最大化
- 点击最大化，结果集展示区域将全屏展示
- 结果集展示形式切换
- 支持图谱、表格、文本三种形式  
##### 3.3.3 建模  
- 点边模型
![alt 建模](https://tugraph-w' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '3.工作台'}"
在test_export_default函数中，如何验证导出后再次导入的数据是否与原始数据一致？,"page_content='数据导出

2.导出命令

该工具的命令示例如下：  
```bash
$ lgraph_export -d {database_dir} -e {export_destination_dir} -g {graph_to_use} -u {username} -p {password} -f {output_format}
```  
其中：  
- `-d {database_dir}` 指定需要进行数据导出的数据库所在目录，默认值为 `./testdb`。
- `-e {export_destination_dir}` 指定导出文件存放的目录，默认值为 `./exportdir`。
- `-g {graph_to_use}` 指定图数据库的种类，默认为 `default` 。
- `-u {username}` 指定进行该导出操作的用户的用户名。
- `-p {password}` 指定进行该导出操作的用户的用户密码。
- `-s {field_separator}` 指定导出文件的分隔符，默认为逗号。
- `-f {output_format}` 指定导出数据的格式，`json`或者`csv`，默认为`csv`。
- `-h` 除上述指定参数外，也可以使用该参数查看该工具的使用帮助。' metadata={'Header 1': '数据导出', 'Header 2': '2.导出命令'}","page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

#### 2.3.1.rest  
样例代码中在test_get_info函数执行之前先启动server，server启动后启动了rest client，进入test_get_info函数后获取server的一些信息，并通过assert判断是否有获取到cpu的信息。  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7073 --rpc_port 9093"",
""cleanup_dir"":[""./testdb""]}
RESTTOPT = {""port"":""7073"", ""user"":""admin"", ""password"":""73@TuGraph""}
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""rest"", [RESTTOPT], indirect=True)
def test_get_info(self, server, rest):
res = rest.get_server_info()
log.info(""res : %s"", res)
assert('cpu' in res)
```  
#### 2.3.2.client  
样例代码中在test_flushdb函数执行之前先执行了数据离线导入逻辑，并启动server后，通过client创建链接，进入test_flushdb函数后，通过查询点的个数判断导入是否成功，导入成功后执行flushDB操作，再次通过assert判断是否能正常清空db  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}

CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}

IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}

@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_flushdb(self, importor, server, client):
ret = client.callCypher(""MATCH (n) RETURN n LIMIT 100"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert len(res) == 21
ret = client.callCypher(""CALL db.flushDB()"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}","page_content='业务开发指南

导出数据

本地导出整个图的所有数据

[lgraph_export 使用介绍](./6.utility-tools/2.data-export.md)  
CSV 格式
```
lgraph_export -d your_db_path -e export_data -g default -f json -u admin -p 73@TuGraph
```
JSON 格式
```
lgraph_export -d your_db_path -e export_data -g default -f json -u admin -p 73@TuGraph
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导出数据', 'Header 3': '本地导出整个图的所有数据'}"
Work函数在处理节点vi时，返回值代表什么？,"page_content='OlapBase API

7. 图类OlapBase

7.4 批处理操作

TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程。分别是：  
```c++
/*
函数名称:ReducedSum ProcessVertexInRange(std::function<ReducedSum(size_t)> work, size_t lower, size_t upper,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考include/lgraph/olap_base.h中具体代码

使用示例:统计数组parent数组中有出边的点个数
*/

auto vertex_num = graph.ProcessVertexInRange<size_t>(
[&](size_t i) {
if (graph.OutDegree(parent[i]) > 0) {
return 1;
}
},
0, parent.Size()
);
printf(""the number is %lu\n"",vertex_num);
```  
其中graph为图类OlapBase的实例化对象  
```C++
/*
函数名称:ReducedSum ProcessVertexActive(std::function<ReducedSum(size_t)> work, ParallelBitset &active_vertices,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对active_vertices中对应为1的节点执行work函数，第三个参数表示累加的基数，默认为0；
第四个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考/include/lgraph/olap_base.h中具体代码

使用示例:输出Graph中节点1，2，3的所有出度邻居，并统计这三个节点的总出度
*/

auto active_in = graph.AllocVertexSubset();
active_in.Add(1);
active_in.Add(2);
active_in.Add(3);
auto total_outdegree = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t local_outdegree = 0;
for (auto & edge : graph.OutEdges(vi)) {
size_t dst = edge.neighbour;
printf(""node %lu has neighbour %lu\n"",vi,dst);
local_outdegree += 1;
}
return local_outdegree;
},
active_in
);
printf(""total outdegree of node1,2,3 is %lu\n"",total_outdegree);
```' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.4 批处理操作'}","page_content='OlapOnDB API

3. 算法举例

3.1 主函数

主函数输入有三个参数，`TuGraph`数据库参数`db`，从网页端获取的请求`request`，给网页端的返回值`response`，整体流程可以分为一下几步：  
1. 相关参数的获取
2. 快照类的创建
3. PageRank算法主流程
4. 网页端返回值的获取和发送  
```C++
extern ""C"" bool Process(GraphDB & db, const std::string & request, std::string & response) {

// 从网页端请求中获取迭代次数（num_iterations），
int num_iterations = 20;
try {
json input = json::parse(request);
num_iterations = input[""num_iterations""].get<int>();
} catch (std::exception & e) {
throw std::runtime_error(""json parse error"");
return false;
}

// 读事务的创建以及快照类的创建
auto txn = db.CreateReadTxn();
OlapOnDB<Empty> olapondb(
db,
txn,
SNAPSHOT_PARALLEL
);

// 创建pr数组用于存储每个节点的pr值
ParallelVector<double> pr = olapondb.AllocVertexArray<double>();
// pagerank算法主流程，获取每个节点的pagerank值
PageRankCore(olapondb, num_iterations, pr);

auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
/*
函数用途：从所有节点中获取pagerank值最大的节点编号

函数流程描述：该函数对点集合all_vertices中所有为1的位对应的节点vi（又称为活跃点）执行Func A，再将Func A的返回值作为Func B的第二个输入参数，得到局部最大值（因为第一个输入参数为0，因此实际上返回值就是每个节点的pagerank值），最后再将所有线程的返回值汇总，再次 执行Func B得到全局返回值，并存入max_pr_vi变量中
*/
size_t max_pr_vi = olapondb.ProcessVertexActive<size_t>(

//Func A
[&](size_t vi) {
return vi;
},
all_vertices,
0,

//Func B
[&](size_t a, size_t b) {
return pr[a] > pr[b] ? a : b;
}
);

// 网页端返回值的获取和发送
json output;
output[""max_pr_vid""] = olapondb.OriginalVid(max_pr_vi);
output[""max_pr_val""] = pr[max_pr_vi];
response = output.dump();
return true;
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.1 主函数'}","page_content='OlapOnDB API

4. 其他常用函数功能描述

4.10 活跃点的描述

活跃点指的是在批处理函数中需要处理的点，在本例子中只是输出了活跃点的编号，并且汇总活跃点的数量：  
```C++
ParallelBitset temp = 000111;//当前活跃点为3，4，5号点

size_t delta = ForEachActiveVertex<double>(
//void c
[&](size_t vi) {
printf(""active_vertexId = %lu\n"",vi);
return 1;
},
all_vertices
);
```  
函数的运行结果显而易见，因为多线程的关系，一下输出顺序可能有所变化：  
```
active_vertexId = 3
active_vertexId = 4
active_vertexId = 5
```  
局部返回值均为1，该函数会在保证线程安全的情况下将所有的局部返回值累加得到最终的返回值，并存储在`delta`变量中，该值最终为3' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.10 活跃点的描述'}"
TuGraph Explorer 的功能现在在哪里可以找到？,"page_content='功能概览

6.生态工具

6.2.可视化交互

TuGraph Browser 是面向图数据库直接使用者的可视化交互界面，功能上覆盖了 TuGraph 的绝大部分能力，包括数据导入、图模型建立、数据增删查改、监控运维等操作链路。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.2.可视化交互'}","page_content='功能概览

6.生态工具

6.1.TuGraph DataX

![导入导出](../../../images/tugraph-datax.png)  
TuGraph 核心支持 CSV 和 JSON 合适的导入导出，提供空库导入和增量导入的模式。实际中会存在 MySQL、Kafka、Hive 等多数据源导入的需求，TuGraph 通过 DataX 做多数据源的对接。由于关系模型和图模型存在的差异，数据清洗的流程可以使用 SparkSQL 快速处理，TuGraph 本身仅关注 CSV 和 JSON 的简单场景导入可靠性和性能。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.1.TuGraph DataX'}","page_content='可视化操作手册（旧版）

作用

TuGraph Browser 的主要功能是为使用图数据库的开发人员，提供可视化的图数据开发，图数据管理和维护等功能。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '作用'}"
在批量创建点的操作中，如果请求成功，TuGraph 会返回什么？,"page_content='RESTful API Legacy

2.请求与数据格式

2.3.返回值

TuGraph 返回的 HTTP 状态码包含以下四种：  
- 200 OK: 操作成功
- 307 Temporary Redirect: 操作被重定向，一般用于高可用模式下，把操作重定向到 master 上
- 400 Bad Request: 输入有误，例如 URI 错误，或者请求中的 JSON 参数错误
- 500 Internal Server Error: 服务器端错误  
当操作成功时，返回的 JSON 中包含操作的返回值。当操作重定向时，返回的 HTTP 报头中的 `location` 域包含重定向目的地址。
当发生输入错误或者服务器错误时，返回的 JSON 中包含 `error_message` 域，其内容是错误提示。  
在高可用模式下，服务器还会在报头中设置 `server_version`，以告知客户端当前服务器的数据版本号。当客户端在不同的服务器之间切换时，该数据版本号可以保证客户端不会读到错误的历史数据。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '2.请求与数据格式', 'Header 3': '2.3.返回值'}","page_content='TuGraph-Restful-Server

5.返回值

通用返回格式  
|  body参数  | 参数说明  |  参数类型  |  是否必填  |
|:--------:|:-----:|:------:| :-----: |
| errorCode |  状态码  |  字符串  |  是  |
| errorMessage | 错误信息  |  字符串  |  是  |
| data | 返回的数据 |  字符串  |  是  |  
TuGraph 返回的 HTTP 状态码包含以下四种：  
- 200 OK: 操作成功
- 400 Bad Request: 输入有误，例如 URI 错误，或者请求中的 JSON 参数错误
- 401 Unauthorized: 未通过鉴权认证，例如用户名密码错误，token超过有效期等
- 500 Internal Server Error: 服务器端错误
当操作成功时，返回的 data 中包含操作的返回值。
当发生输入错误或者服务器错误时，返回的 errorMessage 中包含错误提示。' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '5.返回值'}","page_content='TuGraph-Restful-Server

7.接口

7.7 批量创建schema请求

用户通过此类请求批量创建schema，请求报文在http body 中将创建schema的目标子图和schema信息发送给server，如果拿到返回errorCode为200的响应报文即为正常创建
#### 7.7.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_schema
#### 7.7.2 REQUEST
|  body参数  |    参数说明    |  参数类型  |  是否必填  |
|:--------:|:----------:|:------:| :-----: |
| graph |   创建目标子图   |  字符串  |  是  |
| schema | schema描述信息 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.7 批量创建schema请求'}"
tugraph能否支持混合检索 vector+知识图谱？,"page_content='QA汇总

内核引擎QA

边支持索引

Q: TuGraph 的边是否支持索引？
A: TuGraph 在引擎层支持边索引，可通过存储过程使用。Cypher的边索引功能正在开发支持中。' metadata={'Header 1': 'QA汇总', 'Header 2': '内核引擎QA', 'Header 3': '边支持索引'}","page_content='图算法介绍

2\. 流图推理简介

TuGraph计算引擎（TuGraph Analytics\[1\]）是蚂蚁集团开源的大规模分布式实时图计算引擎（流图引擎），实现了流批一体的图计算模型，支持了丰富的图计算算法。TuGraph Analytics的流图计算能力，能处理连续输入的数据流，并支持增量的计算模式，极大得提高了数据的计算效率和实时性。TuGraph Analytics解决了业界大规模数据关联分析的实时计算问题，已广泛应用于数仓加速、金融风控、知识图谱以及社交推荐等场景。  
随着业务场景中问题复杂度的提升，基于传统的迭代图算法已无法满足业务的实际需求。例如在反洗钱场景中，利用图神经网络算法处理复杂的交易关系，能够捕获到节点的局部图结构信息。通过聚合邻接节点的特征信息，每个交易节点都可以感知到周边图网络结构的信息。类似的图神经网络等AI模型的推理逻辑，是无法基于传统的图迭代计算模式直接高效地表达的。  
受上述问题启发，我们思考是否可以将TuGraph Analytics的流图计算能力与图神经网络等深度学习模型相结合，开发一套基于流图计算的模型推理系统。最终期望的推理系统具备如下能力：  
-   对于图算法工程师，在图迭代计算过程中，能够方便地使用机器学习模型的推理能力。  
-   对于AI算法工程师，可以通过TuGraph Analytics分布式流式计算的能力实现实时的模型推理。  
众所周知，在深度学习为代表的数据科学领域，Python已经成为数据分析、模型训练和推理框架的主流开发语言，并提供了丰富的开发库和框架生态。而以Hadoop全家桶为代表的大数据计算引擎领域，基于Java语言开发的系统仍占据一席之地，当然TuGraph Analytics也在其中。这种语言差异带来的“互操作性”成本，使得相当一部分大数据和AI生态组件无法轻松地融合，这也是TuGraph Analytics支持图推理需要亟待解决的问题。' metadata={'Header 1': '图算法介绍', 'Header 2': '2\\. 流图推理简介'}","page_content='试用体验：TuGraph — 简单高效的图数据库

支持RESTful API

除了支持Cypher查询语言，TuGraph还提供了RESTful API接口。这使得我可以通过编程方式与图数据库进行交互，更好地将TuGraph集成到我的应用程序中。API设计合理，易于使用，为我提供了灵活性和自由度。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持RESTful API'}"
TuGraph 数据预热的主要目的是什么？,"page_content='数据预热

1.简介

TuGraph 是基于磁盘的数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '数据预热', 'Header 2': '1.简介'}","page_content='功能概览

4.核心功能

4.5 数据预热

TuGraph 是基于磁盘的图数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.5 数据预热'}","page_content='数据预热

1.数据预热命令

数据预热可以通过工具 `lgraph_warmup` 来进行。它的使用示例如下：  
```bash
$ lgraph_warmup -d {directory} -g {graph_list}
```  
其中：  
- `-d {db_dir}` 选项指定了 TuGraph 服务器的数据目录  
- `-g {graph_list}` 选项指定需要进行数据预热的图名称，用逗号分隔  
根据数据大小和所使用的磁盘类型不同，预热过程运行时间也不同。机械磁盘上预热一个大数据库可能耗时较长，请耐心等待。' metadata={'Header 1': '数据预热', 'Header 2': '1.数据预热命令'}"
InEdgeIterator 类的 GetSrc 方法返回什么信息？,"page_content='OlapOnDB API

4. 其他常用函数功能描述

4.7 获取入边集合

```C++
AdjList<EdgeData> InEdges(size_t vid)

// 使用示例：输出节点vid的所有入度邻居
for (auto & edge : olapondb.InEdges(vid)) {
size_t dst = edge.neighbour;
printf(""src = %lu,dst = %lu\n"",vid,dst);
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.7 获取入边集合'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/relationship/{euid}
```  
与 Nodes 功能类似，Relationships 提供边（edge）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。每一条边都可以由一个唯一 ID（euid）来标识。这个 ID 可以从在插入边时获得，或者在 [列出所有边](#%E5%88%97%E5%87%BA%E6%89%80%E6%9C%89%E8%BE%B9) 操作中得到。  
#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| fields | 数据列名 | 列表 |
| edge | 边数据 | 列表 |  
其中 edge 是一个数据列表，其中每个元素都是一条边，其定义如下：  
| 域名        | 说明     | 类型                                                   |
| ----------- | -------- | ------------------------------------------------------ |
| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}","page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.3.对结果进行格式转换

```python
src = EdgeInfo[0].astype('int64')
dst = EdgeInfo[1].astype('int64')
nodes_idx = NodeInfo[0].astype('int64')
remap(src, dst, nodes_idx)
features = NodeInfo[1].astype('float32')
labels = NodeInfo[2].astype('int64')
g = dgl.graph((src, dst))
g.ndata['feat'] = torch.tensor(features)
g.ndata['label'] = torch.tensor(labels)
return g
```
对结果进行格式转换，使之符合训练格式' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.3.对结果进行格式转换'}"
可选匹配子句OPTIONAL MATCH在查询中有什么作用？,"page_content='ISO GQL

2.Clauses

2.2.OPTIONAL MATCH

`OPTIONAL MATCH`匹配图模式，如果未命中，则返回`null`。  
#### 查询命中  
```
OPTIONAL MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
#### 查询未命中  
```
OPTIONAL MATCH (n:Person{name:'Redgrave Michael'})
RETURN n.birthyear
```  
返回结果  
```JSON
[{""n.birthyear"":null}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.2.OPTIONAL MATCH'}","page_content='ISO GQL

2.Clauses

2.1.MATCH

`MATCH`子句式是GQL最基础的子句，几乎所有查询都是通过 `MATCH`展开。  
`MATCH`子句用于指定在图中搜索的匹配模式，用来匹配满足一定条件的点或者路径。  
#### 点查询  
##### 查询所有点  
```
MATCH (n)
RETURN n
```  
##### 查询特定标签的点  
```
MATCH (n:Person)
RETURN n
```  
##### 通过属性匹配点  
```
MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
##### 通过过滤条件匹配点  
```
MATCH (n:Person WHERE n.birthyear > 1910)
RETURN n.name LIMIT 2
```  
返回结果
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```  
#### 边查询  
##### 出边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1970)-[e]->(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""BORN_IN"",""m.name"":""London"",""n.name"":""Christopher Nolan""},{""label(e)"":""DIRECTED"",""m.name"":null,""n.name"":""Christopher Nolan""}]
```  
##### 入边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1939)<-[e]-(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""HAS_CHILD"",""m.name"":""Rachel Kempson"",""n.name"":""Corin Redgrave""},{""label(e)"":""HAS_CHILD"",""m.name"":""Michael Redgrave"",""n.name"":""Corin Redgrave""}]
```  
##### 带过滤条件的边匹配  
```
MATCH (n:Person)-[e:BORN_IN WHERE e.weight > 20]->(m)
RETURN n.name, e.weight, m.name
```  
返回结果
```JSON
[{""e.weight"":20.549999237060547,""m.name"":""New York"",""n.name"":""John Williams""},{""e.weight"":20.6200008392334,""m.name"":""New York"",""n.name"":""Lindsay Lohan""}]
```  
#### 路径匹配  
##### 不定跳查询  
```
MATCH (n:Person)-[e]->{2,3}(m:Person)
RETURN m.name LIMIT 2
```  
返回结果
```JSON
[{""m.name"":""Liam Neeson""},{""m.name"":""Natasha Richardson""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.1.MATCH'}","page_content='Cypher API

2.Clauses

2.3.RETURN

- ✓ Return nodes  
```
MATCH (n {name: 'Carrie-Anne Moss'}) RETURN n
```  
- ✓ Return relationships  
```
MATCH (n {name: 'Carrie-Anne Moss'})-[r:acted_in]->(c)
RETURN r
```  
- ✓ Return property  
```
MATCH (n {name: 'Carrie-Anne Moss'}) RETURN n.born
```  
- ❏ Return all elements  
```
MATCH p = (a {name: 'A'})-[r]->(b)
RETURN *
```  
- ❏ Variable with uncommon characters  
```
MATCH (`This isn\'t a common variable`)
WHERE `This isn\'t a common variable`.name = 'A'
RETURN `This isn\'t a common variable`.happy
```  
- ✓ Aliasing a field  
```
MATCH (a {name: 'Carrie-Anne Moss'})
RETURN a.born AS SomethingTotallyDifferent
```  
- ✓ Optional properties  
```
MATCH (n)
RETURN n.age
```  
- ❏ Other expressions  
```
MATCH (a {name: 'Carrie-Anne Moss'})
RETURN a.born > 1900, ""I'm a literal"", (a)-[]->()
```  
`(a)-[]->()` not supported.  
- ✓ Unique results  
```
MATCH (a {name: 'Carrie-Anne Moss'})-[]->(b)
RETURN DISTINCT b
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.3.RETURN'}"
GraphDB 实例无法使用的情况是什么？,"page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

一、高可用架构介绍

2.高可用性代表系统的可用性程度，是进行系统设计时的准则之一

怎样去衡量系统的可用性和不可用性呢？这就引出了高可用性的概念。高可用性代表系统的可用性程度，是进行系统设计的准则之一。高可用性，是系统的一个非常重要的能力，通常是通过提高系统的容错能力来实现的。可用性的一个度量方式是根据系统损毁无法提供服务的时间和系统正常运行时间的比值来得到的。下图右侧表格展示了衡量一个系统可用性和不可用性的等级。  
TuGraph-DB 对于可用性的要求，至少是 4 个 9 级别，也就是一年之内宕机时间不能超过 53 分钟。我们在开源之前服务的一个银行用户就已经达到了一个极高可用的等级，也就是 5 个 9 的等级。' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '一、高可用架构介绍', 'Header 3': '2.高可用性代表系统的可用性程度，是进行系统设计时的准则之一'}","page_content='Java客户端

2.使用示例

2.1.实例化client对象

添加maven依赖  
```xml
<dependency>
<groupId>com.antgroup.tugraph</groupId>
<artifactId>tugraph-db-java-rpc-client</artifactId>
<version>1.4.1</version>
</dependency>
```  
引入依赖
```java
import com.antgroup.tugraph.TuGraphDbRpcClient;
```  
#### 2.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
```java
TuGraphDbRpcClient client = new TuGraphDbRpcClient(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(String url, String user, String pass)
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```  
#### 2.1.2.实例化HA集群直连连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化。
```java
TuGraphDbRpcClient client = new TuGraphDbRpcClient(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(String url, String user, String pass)
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 2.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化
```java
List<String> urls = new ArrayList<>();
urls.add(""189.33.97.23:9091"");
urls.add(""189.33.97.24:9091"");
urls.add(""189.33.97.25:9091"");
TuGraphDbRpcClient client = new TuGraphDbRpcClient(urls, ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(List<String> urls, String user, String password)
@param urls: tugraph host list
@param user: login user name
@param password: login password
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.1.实例化client对象'}","page_content='Bolt客户端

使用示例

添加Maven依赖  
```xml
<dependency>
<groupId>org.neo4j.driver</groupId>
<artifactId>neo4j-java-driver</artifactId>
<version>4.4.2</version>
</dependency>
```
Client按照如下格式进行实例化:  
```java
Driver driver = GraphDatabase.driver(""bolt://ip:port"", AuthTokens.basic(""admin"", ""73@TuGraph""));
```  
常用语句  
```java
//通过 driver 对象创建一个 Session，设置会话连接到特定的数据库，用于执行Cypher语句
Session session = driver.session(SessionConfig.forDatabase(""default""));
//清空图项目，请不要轻易尝试，它会清空你选中的图项目的模型以及数据
session.run(""CALL db.dropDB()"");
//创建点模型
session.run(""CALL db.createVertexLabel('person', 'id' , 'id' ,INT32, false, 'name' ,STRING, false)"");
//创建边模型
session.run(""CALL db.createEdgeLabel('is_friend','[[\""person\"",\""person\""]]')"");
//创建索引
session.run(""CALL db.addIndex(\""person\"", \""name\"", false)"");
//插入点数据
session.run(""create (n1:person {name:'jack',id:1}), (n2:person {name:'lucy',id:2})"");
//插入边数据
session.run(""match (n1:person {id:1}), (n2:person {id:2}) create (n1)-[r:is_friend]->(n2)"");
//查询点和边
Result res = session.run(""match (n)-[r]->(m) return n,r,m"");
//Parameterized Query
String cypherQuery = ""MATCH (n1:person {id:$id})-[r]-(n2:person {name:$name}) RETURN n1, r, n2"";
Result result1 = session.run(cypherQuery, parameters(""id"", 1, ""name"", ""lucy""));
while (result1.hasNext()) {
Record record = result1.next();
System.out.println(""n1: "" + record.get(""n1"").asMap());
System.out.println(""r: "" + record.get(""r"").asMap());
System.out.println(""n2: "" + record.get(""n2"").asMap());
}
//删除点数据
session.run(""match (n1:person {id:1}) delete n1"");
//删除边数据
session.run(""match (n1:person {id:1})-[r]-(n2:person{id:2}) delete r"");
//删除边模型
session.run(""CALL db.deleteLabel('edge', 'is_friend')"");
//删除点模型
session.run(""CALL db.deleteLabel('vertex', 'person')"");
```  
详细Cypher和存储过程的使用可见[Cypher](../../8.query/1.cypher.md)' metadata={'Header 1': 'Bolt客户端', 'Header 2': '使用示例'}"
TuGraph 运行需要保证哪个库文件的位置在环境变量 LD_LIBRARY_PATH 中？,"page_content='数据库运行

1.前置条件

TuGraph 运行的前置条件为 TuGraph 正确安装，参考[安装流程](1.environment.md)。  
TuGraph 运行需要保证库文件 liblgraph.so 的文件位置在环境变量 LD_LIBRARY_PATH。  
运行 TuGraph 进程的用户不需要超级权限，但需要对配置文件（一般为lgraph.json）及文件中涉及的文件有读权限，并且对数据文件夹、日志文件夹等有写权限。' metadata={'Header 1': '数据库运行', 'Header 2': '1.前置条件'}","page_content='环境分类

2.依赖系统库

针对三种环境，除去TuGraph的运行包，所需要的系统库如下：
* 编译环境，包括gcc、python、java等编译器，也包含antlr4、pybind11等，具体参见tugraph-db源码目录 ci/images/tugraph-compile-*-Dockerfile。
* 运行环境，主要由存储过程引入，包括gcc、boost、cmake等，具体参见tugraph-db源码目录 ci/images/tugraph-runtime-*-Dockerfile。
* 精简运行环境，无，可以参见tugraph-db源码目录 ci/images/ tugraph-mini-runtime-*-Dockerfile。' metadata={'Header 1': '环境分类', 'Header 2': '2.依赖系统库'}","page_content='环境分类

1.分类

根据环境所承载功能的不同，区分为编译环境，运行环境，以及精简运行环境。
* 编译环境，具备TuGraph编译的所有依赖库，包含运行环境的所有依赖，并且能够编译TuGraph源码，但不包含预编译好的TuGraph可执行文件和库文件，供开发者编译源码使用。
* 运行环境，具备GCC/Java/Python环境，能够运行TuGraph的所有功能，并且能承载全文索引，java client，c++源码上传为plugin，以及python plugin的完整功能，内置TuGraph预编译好的可执行文件和库文件，供客户直接安装使用，无需编译源码。
* 精简运行环境，约等于裸系统加预编译TuGraph，仅能运行TuGraph的基本功能，无C++ plugin编译运行，仅so上传，无全文索引，无python plugin，供快速搭建试用。  
TuGraph编译后，会把所有的依赖库以.a的形式打包在一起，因此原则上运行不需要的其他的依赖库。但TuGraph支持存储过程，即在服务端编译C++代码，因此在环境中依然需要涉及的编译器。' metadata={'Header 1': '环境分类', 'Header 2': '1.分类'}"
GetNumOutEdges函数如何在达到限制时响应？,"page_content='Python Olap API

4. Olap API

图类OlapBase

- `NumVertices()-> size_t`：获取点数
- `NumEdges()-> size_t`：获取边数
- `OutDegree(size_t vid)-> size_t`：点vid的出度
- `InDegree(size_t vid)-> size_t`：点vid的入度  
- `AllocVertexArray[VertexData]() ->ParallelVector[VertexData]`：分配一个类型为VertexData的数组，大小为点个数
- `AllocVertexSubset()-> ParallelBitset`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `OutEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有出边集合
- `InEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有入边集合
- `Transpose()-> cython.void`：对有向图进行图反转
- `LoadFromArray(edge_array: cython.p_char, input_vertices: size_t, input_edges: size_t, edge_direction_policy: EdgeDirectionPolicy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。  
- `AcquireVertexLock(vid: size_t)-> cython.void`：对点vid加锁，禁止其它线程对该锁对应的点数据进行访存
- `void ReleaseVertexLock(vid: size_t)-> cython.void`：对点vid解锁，所有线程均可访存该锁对应的点数据  
TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程，在Python中与C++使用方法稍有不同。  
```python
# 函数名称:ProcessVertexInRange[ReducedSum, Algorithm](
#           work: (algo: Algorithm, vi: size_t)-> ReducedSum,
#           lower: size_t, upper: size_t,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#     函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
#     第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
#     具体实现请参考include/lgraph/olap_base.h中具体代码
#
#     使用示例:统计数组parent数组中有出边的点个数

import cython
from cython.cimports.olap_base import *


@cython.cclass
class CountCore:
graph: cython. pointer(OlapBase[Empty])
parent: ParallelVector[size_t]

@cython.cfunc
@cython.nogil
def Work(self, vi: size_t) -> size_t:
if self.graph.OutDegree(self.parent[vi]) > 0:
return 1
return 0

def run(self, pointer_g: cython. pointer(OlapBase[Empty])):
self.graph = pointe' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}","page_content='OlapOnDB API

4. 其他常用函数功能描述

4.6 获取出边集合

```C++
/*
函数名称：AdjList<EdgeData> OutEdges(size_t vid)
数据结构:
AdjList 可以理解为类型为AdjUnit结构体的数组
AdjUnit 有两个成员变量： 1. size_t neighbour 2. edge_data，其中neighbour表示该出边指向的目标节点编号，如果为有权图，则edge_data数据类型和输入文件中边的权重值相同，否则数据类型为Empty

使用示例：输出节点vid的所有出度邻居
*/
for (auto & edge : olapondb.OutEdges(vid)) {
size_t dst = edge.neighbour;
printf(""src = %lu,dst = %lu\n"",vid,dst);
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.6 获取出边集合'}","page_content='OlapBase API

7. 图类OlapBase

7.1 基本信息

- `size_t NumVertices()`：获取点数
- `size_t NumEdges()`：获取边数
- `size_t OutDegree(size_t vid)`：点vid的出度
- `size_t InDegree(size_t vid)`：点vid的入度' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.1 基本信息'}"
文本中的 BFS 算法在每次迭代中怎样更新活跃顶点数量？,"page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

`bfs`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关定义、数据结构的初始化
2. 使用批处理函数对每个节点进行循环计算，每一轮找到与当前节点相邻的全部节点，并在该轮次终止时进行交换。
3. 直到找到全部节点，返回节点个数discovered_vertices。  
```C++
size_t BFSCore(Graph<Empty>& graph, size_t root_vid, ParallelVector<size_t>& parent){

size_t root = root_vid;
auto active_in = graph.AllocVertexSubset();   //分配数组，active_in用于存放上一循环阶段已找到的节点
active_in.Add(root);            //把跟节点加入数组中
auto active_out = graph.AllocVertexSubset();  //分配数组active_out用于存放当前循环阶段找到的节点
parent.Fill((size_t)-1);               //将parent数组中的节点赋值为-1，-1表示未被找到
parent[root] = root;
size_t num_activations = 1;       //表示当前循环阶段找到的节点个数
size_t discovered_vertices = 0;    //表示当前循环阶段找到节点的总个数

for (int ii = 0; num_activations != 0; ii++) {       //num_activations表示当前循环阶段找到的节点个数
printf(""activates(%d) <= %lu\n"", ii, num_activations);
discovered_vertices += num_activations;         //discovered_vertices表示当前循环阶段找到节点的总个数
active_out.Clear();
num_activations = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t num_activations = 0;
for (auto& edge : graph.OutEdges(vi)) {   //每一次循环从根节点出发，查找邻近的相邻节点，对其parent值改变，并num_activations+1操作
size_t dst = edge.neighbour;
if (parent[dst] == (size_t)-1) {
auto lock = graph.GuardVertexLock(dst);
if (parent[dst] == (size_t)-1) {
parent[dst] = vi;
num_activations += 1;
active_out.Add(dst);       //存放当前循环阶段找到的节点
}
}
}
return num_activations;
},
active_in);
active_in.Swap(active_out);
}
// 返回全部节点数
return discovered_vertices;
}
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}","page_content='OLAP API

4. Standalone 编译与运行

该文件主要用于在终端处直接加载图数据，并运行打印输出结果。使用方法如下：
在tugraph-db/build目录下执行`make bfs_standalone` (需要在g++默认include路径中包含boost/sort/sort.hpp)即可得到bfs_standalone文件,该文件生成于tugraph-db/build/output/algo文件夹下。
运行方式：在tugraph-db/build目录下执行`./output/algo/bfs_standalone -–type [type] –-input_dir [input_dir] --id_mapping [id_mapping] -–vertices [vertices] --root [root] –-output_dir [output_dir]`即可运行。  
- `[type]`：表示输入图文件的类型来源，包含text文本文件、BINARY_FILE二进制文件和ODPS源。
- `[input_dir]`：表示输入图文件的文件夹路径，文件夹下可包含一个或多个输入文件。TuGraph在读取输入文件时会读取[input_dir]下的所有文件，要求[input_dir]下只能包含输入文件，不能包含其它文件。参数不可省略。
- `[id_mapping]`：当读入边表时，是否对输入数据做id映射，使达到符合算法运行的形式。1为需要做id映射，0为不需要做。该过程会消耗一定时间。参数可省略，默认值为0。
- `[vertices]`：表示图的点个数，为0时表示用户希望系统自动识别点数量；为非零值时表示用户希望自定义点个数，要求用户自定义点个数需大于最大的点ID。参数可省略，默认值为0。
- `[root]`：表示进行bfs的起始点id。参数不可省略。
- `[output_dir]`：表示输出数据保存的文件夹路径，将输出内容保存至该文件中，参数不可省略。  
示例：' metadata={'Header 1': 'OLAP API', 'Header 2': '4. Standalone 编译与运行'}","page_content='OlapOnDisk API

1. 简介

TuGraph的Standalone模式可用于加载图数据文件，其中图数据文件来源可包含text文本文件、BINARY_FILE二进制文件和ODPS源。在该模式下，TuGraph可实现多数据来源快速加载成图，然后在该图上运行如BFS、WCC、SSSP等迭代式算法，并输出最终结果至终端。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph内置了大量的常见图分析算法和丰富的辅助接口，因此用户几乎不需要自己实现具体的图计算过程，只需要在实现自己的存储过程的时候将相应算法库的头文件(.h)包含到自己的程序中，并在编译阶段链接自己的动态库文件即可。  
该文档主要介绍了Standalone的常用接口，使用到的辅助函数主要包含在OlapOnDB类。同时为帮助用户理解方便，对BFS算法进行举例说明。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '1. 简介'}"
角色名的允许的最大长度是多少字节？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLm' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.1.用户管理

系统默认创建一个管理员，管理员用户名为 _admin_，密码为 _73@TuGraph_。为了安全起见，请用户在第一次启动服务器后更改密码。  
#### 6.1.1.添加用户  
添加一个新的用户，并为其设置初始密码。只有管理员有权限进行此操作。其中用户名只能由字母，数字以及下划线构成，密码则可以包含任意字符。用户名和密码长度不能超过 64 字节。添加用户时还可以为用户增加一个描述，用户描述可以包含任意字符，最长不超过 512 字节。  
新用户默认拥有同名的角色，不具备任何图的权限。  
- **URI**: `/user`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |
| description | 用户描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""user"": ""USER1"",
""password"": ""AN_INITIAL_PASSWORD"",
""description"": ""This is a user""
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.1.2.列出所有用户  
列出数据库的所有用户。只有管理员拥有该操作权限。  
- **URI**: `/user/`
- **METHOD**: GET
- **RESPONSE**: 所有用户及其信息。  
**Example request.**  
```
• GET http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
Output:
{
""admin"": {
""disabled"": false,
""description"": ""Builtin admin user"",
""roles"": [""admin""]
},
""guest1"": {
""disabled"": true,
""description"": """",
""roles"": [""guest1"", ""some_other_role""]
}
}
```  
#### 6.1.3.获取用户信息  
列出给定用户的信息。  
- **URI**: `/user/{user_name}`
- **METHOD**: GET
- **RESPONSE**: 用户信息。  
**Example request.**  
```
• GET http://localhost:7070/user/guest1
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_z' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.1.用户管理'}","page_content='TuGraph图模型说明

2. 图项目、点、边、属性命名规则和建议

2.1 命名规则

图项目、点、边和属性是识别符。该节描述了在TuGraph中识别符的允许的语法。
下面的表描述了每类识别符的最大长度和允许的字符。  
|**识别符** |**长度** |**允许的字符**|
|---------  |---------  |---------  |
|用户、角色、图项目|1-64字符|允许中文、字母、数字、下划线，且首字符不为数字|
|点类型、边类型、属性|1~256字符|允许中文、字母、数字、下划线，且首字符不为数字|' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '2. 图项目、点、边、属性命名规则和建议', 'Header 3': '2.1 命名规则'}"
URIs 用于修改和启用角色的 HTTP 方法是什么？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLm' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='用户权限

4.常用权限操作

4.4.角色赋权

- 修改角色对指定图的访问权限  
```cypher
CALL dbms.security.modRoleAccessLevel(role::STRING,access_level::MAP)
```  
示例  
```cypher
CALL dbms.security.modRoleAccessLevel(""test_role"", {test_graph1:""FULL"", test_graph2:""NONE""})
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.4.角色赋权'}","page_content='用户权限

4.常用权限操作

4.2.角色操作

- 创建角色  
```cypher
CALL dbms.security.createRole(role_name::STRING,desc::STRING)
```  
- 删除角色  
```cypher
CALL dbms.security.deleteRole(role_name::STRING
```  
- 列出所有角色  
```cypher
CALL dbms.security.listRoles()
```  
- 禁用/启用角色  
```cypher
CALL dbms.security.disableRole(role::STRING,disable::BOOLEAN)
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.2.角色操作'}"
