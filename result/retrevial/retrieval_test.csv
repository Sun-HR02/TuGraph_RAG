Q,K1,K2,K3
在添加边时，如果指定的值不包含在value_dict中将如何处理？,"page_content='可视化操作手册

2.操作指南

2.4.图项目

- 编辑点：可以增加点的属性和修改已有属性的数据类型，新增或删除索引。需要对每个新增或修改的属性点击`保存`按钮才可以生效。
_注：主键字段的属性创建后无修改_  
![图构建-编辑点](../../../images/browser/graphbuild-editvertex.png)  
###### c.添加边  
在`模型定义`界面点击`添加边`按钮，在右侧滑动窗口中添加边类型。  
![图构建-添加边按钮](../../../images/browser/graphbuild-addedge-button.png)  
用户需要输入边类型名称、属性、选择起点类型和终点类型，点击`完成`按钮完成边类型的创建。
- 边类型名称：边的名称，也是该边的唯一标识。
- 属性：边的属性，边上可以没有属性。
- 数据类型：属性字段的数据类型，支持INT、STRING、DOUBLE、DATE、DATETIME、BLOB、BOOL等类型。
- 选填：该属性是否可以为空值。
- 删除：在创建边时可以任意删除属性。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='业务开发指南

边类型操作

边类型添加字段

>该操作会同步变更所有该类型边的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于边类型`edge1`，一次添加了两个字段: `field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是`0`.
```
CALL db.alterLabelAddFields('edge', 'edge1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型添加字段'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

用户需要输入边类型名称、属性、选择起点类型和终点类型，点击`完成`按钮完成边类型的创建。
- 边类型名称：边的名称，也是该边的唯一标识。
- 属性：边的属性，边上可以没有属性。
- 数据类型：属性字段的数据类型，支持INT、STRING、DOUBLE、DATE、DATETIME、BLOB、BOOL等类型。
- 选填：该属性是否可以为空值。
- 删除：在创建边时可以任意删除属性。
- 选择起点类型和终点类型：设置边的起点点类型和终点点类型，支持多个起点类型和终点类型。
- 起点：选择起点的点类型。
- 终点：选择终点的点类型。
- 需要提前创建至少一个点类型才能设置边的起点类型和终点。
- 如果不选择则表示起点和终点可以为任意点类型，同时画布上不展示对应的边，需要在左侧列表查看边类型。  
![图构建-添加边](../../../images/browser/graphbuild-addedge.png)  
- 编辑边：可以增加边的属性和修改已有属性的数据类型。需要对每个新增或修改的属性点击`保存`按钮才可以生效。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}"
在使用LIMIT子句时，如果查询数据库中前两个人的名字，返回的名字是什么？,"page_content='ISO GQL

2.Clauses

2.8.LIMIT

`LIMIT`限制结果行数。  
#### 使用LIMIT  
```
MATCH (n:Person)
RETURN n.name LIMIT 2;
```  
返回结果
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.8.LIMIT'}","page_content='Cypher API

2.Clauses

2.6.LIMIT

- ✓ Return a subset of the records  
```
MATCH (n:person)
RETURN n.name
LIMIT 3
```  
- ❏ Using an expression with LIMIT to return a subset of the records  
```
MATCH (n:person)
RETURN n.name
LIMIT toInteger(3 * rand())+ 1
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.6.LIMIT'}","page_content='Cypher API

2.Clauses

2.5.SKIP

- ✓ Skip first three records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 3
```  
- ✓ Return middle two records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 1
LIMIT 2
```  
- ❏ Using an expression with SKIP to return a subset of the records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP toInteger(3*rand())+ 1
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.5.SKIP'}"
如何查询数据库中现有角色及其相关信息？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

列出数据库的所有角色。只有管理员拥有该操作权限。  
- **URI**: `/role/`
- **METHOD**: GET
- **RESPONSE**: 所有角色及其信息。  
**Example request.**  
```
• GET http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
Output:
{
""admin"": {' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='可视化操作手册

2.操作指南

2.5.控制台

`控制台`提供可视化的的账户管理和数据库信息查看功能，它为用户提供了全面的账户和角色管理功能，包括账户的增删改查以及禁用，角色的增删改查以及禁用。此外，它也为用户提供了便捷的数据库信息查看功能，让用户可以轻松地查看图数据库的基础信息和配置信息。其中，基础信息主要包括版本号、运行时间、CPP编译版本号等，而数据库配置信息则包括端口号、系统功能参数配置等。  
#### 2.5.1.账户管理  
##### 2.5.1.1.账户管理  
###### a.添加账户  
在`账户管理`界面点击`添加`按钮创建新的账户，用户需要输入账户名称、账户描述、账户密码以及相关角色。  
![账户管理-添加账户按钮](../../../images/browser/account-add-button.png)  
- 账户名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 相关角色：新建账户时必须要选择一个角色，在账户添加成功后，系统会自动生成一个与账户名称一样的角色。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.5.控制台'}","page_content='部署高可用模式

9.查看服务器状态

备份组的当前状态可以在 TuGraph 可视化工具、REST API 以及 Cypher 查询中获取。  
在 TuGraph 可视化工具中，可以在 DBInfo 部分中找到备份组中的服务器及其角色列表。  
使用 REST API 时，可以使用`GET /info/peers` 请求获取信息。  
在 Cypher 中，使用`CALL dbms.listServers()`语句来查询当前备份组的状态信息。' metadata={'Header 1': '部署高可用模式', 'Header 2': '9.查看服务器状态'}"
tugraph可以最多创建多少点边和点边上最多创建多少属性？,"page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='TuGraph图模型说明

2. 图项目、点、边、属性命名规则和建议

2.2 使用限制

|**描述**|**最大个数**|
|-------- |--------- |
|用户数、角色数|65536|
|图项目的个数|4096|
|每个图项目的点和边类型数量之和|4096|
|每个点或边类型的属性数量|1024|  
注：
1、特殊字符和关键字说明：使用特殊字符或非保留关键字时，需要使用反单引号/backquote（``）进行引用；  
示例： ```match (`match`:match) return `match`.id limit 1```  
2、大小写敏感性：TuGraph大小写敏感；  
3、图项目、点/边、属性名称之间可以重复使用，同一点或边下的属性名称不可以重复；  
4、属性名字保留关键字：SRC_ID / DST_ID / SKIP' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '2. 图项目、点、边、属性命名规则和建议', 'Header 3': '2.2 使用限制'}"
我下载了4.3.2镜像，启动成功了，进入容器后没有 setup.sh 脚本是改变目录了吗？,"page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}","page_content='安装指南

启动容器

```  
容器默认以本地模式（local）启动，默认拉起本地的MySQL、Redis、InfluxDB。
```properties
# /opt/geaflow/config/application.properties
geaflow.deploy.mode=local
geaflow.host=127.0.0.1
geaflow.gateway.port=8888
geaflow.gateway.url=http://${geaflow.host}:${geaflow.gateway.port}' metadata={'Header 1': '安装指南', 'Header 2': '启动容器'}","page_content='快速上手

2.安装

2.1.通过docker快速体验

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
**方式二**  
```shell
docker run -dt -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.1.通过docker快速体验'}"
lgraph_server -d start的方式启动，不是会在pwd路径下生成pid文件吗？这个pid文件有参数能控制路径吗？,"page_content='数据库运行

3.服务操作

3.1.启动服务

TuGraph 需要通过 `lgraph_server -d start` 命令行启动，启动命令示例如下：  
```bash
$ ./lgraph_server -d start -c lgraph.json
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.1.启动服务'}","page_content='数据库运行

2.运行模式

2.2.运行进程守护模式

启动命令：  
```shell
$ ./lgraph_server -d start -c lgraph.json
```  
守护模式的运行输出示例：  
```shell
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '2.运行模式', 'Header 3': '2.2.运行进程守护模式'}","page_content='数据迁移

3. 升级迁移

3.3. 启动新服务

使用如下命令启动新服务
```bash
lgraph_server -c /usr/local/etc/lgraph.json --directory db.export -d start
```' metadata={'Header 1': '数据迁移', 'Header 2': '3. 升级迁移', 'Header 3': '3.3. 启动新服务'}"
如果在使用ARM机器（如M1芯片的Mac）编译TuGraph，应该如何修改cmake命令？,"page_content='从源码编译

2.编译介绍

以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`，如果在arm机器编译（如M1芯片的Mac中，需要加上` -DENABLE_BUILD_ON_AARCH64=ON`）
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build' metadata={'Header 1': '从源码编译', 'Header 2': '2.编译介绍'}","page_content='demo/TuGraph-Demo.md/ # TuGraph 示例

## 1 简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph是TuGraph的曾用名。

主要功能特征包括：

- 支持属性图模型
- 原生图存储及处理
- 完全的ACID事务支持
- 支持OpenCypher图查询语言
- 支持原生的Core API和Traversal API
- 支持REST和RPC接口
- 支持CSV、JSON、MySQL等多数据源导入导出
- 支持可视化图交互
- 支持命令行交互
- 内置用户权限控制、操作审计
- 支持任务和日志的监控管理
- 原生适配PandaGraph图分析引擎
- 集成DGL图神经网络系统

性能及可扩展性特征包括：

- 支持TB级大容量
- 吞吐率高达千万顶点每秒
- 面向读优化的存储引擎
- 支持高可用模式
- 支持离线备份恢复
- 在线热备份
- 高性能批量导入导出

## 2 快速上手

见QuickStart文档。

## 3 基本功能

### 3.1 RPC Client
#### 3.1.1 概述
RPC Client是对cpp语言rpc客户端的简单封装，每次执行时会创建一条到lgraph_server的链接用于发送请求数据以及接收响应结果，执行完毕后进程退出前会断开链接
#### 3.1.2 编译
在代码目录demo/CppRpcClientDemo目录下,执行下列命令 ,成功后将会看到可执行文件clientdemo
```bash
mkdir build && cd build && cmake ../ && make
```
#### 3.1.3 运行
先启动lgraph_server，确保rpc端口处于打开状态。

clientdemo程序接收参数如下：
        -h             show this usage
        -i --ip        ip for graph server
        -p --port      port for graph server
        -g --graph     graph name
        -u --user      user name
        --password     user password
        -c --cypher    cypher to query
举例如下
```bash
./clientdemo -i 127.0.0.1 -p 9090 -u admin --password 73@TuGraph -g default -c ""MATCH (n) RETURN n LIMIT 100""
```
### 3.2 Python RPC Client
#### 3.2.1 概述
Python RPC Client是对python语言rpc客户端的简单封装，每次执行时会创建一条到lgraph_server的链接用于发送请求数据以及接收响应结果，执行完毕后进程退出前会断开链接
#### 3.2.2 运行
需要依赖编译生成的python_client.so库，将python_client.so与client_python.py放在同一目录下
先启动lgraph_server，确保rpc端口处于打开状态。

clientdemo程序接收参数如下：
-h             show this usage
-i --ip        ip for graph server
-p --port      port for graph server
-g --graph     graph name
-u --user      user name
--password     user password
-c --cypher    cypher to query
举例如下
```bash
python3 client_python.py -i 127.0.0.1 -p 9090 -u admin --password 73@TuGraph -g default -c ""MATCH (n) RETURN n LIMIT 100""
```
## 4 集成工具

### 4.1 DataX 导入导出工具
#### 4.1.1 概述
DataX 支持 TuGraph 和 MySQL、SQL Server、Oracle、PostgreSQL、HDFS、Hive、HBase、OTS、ODPS、Kafka 等各种异构数据源的数据导入导出。
#### 4.' metadata={'file_name': 'TuGraph-Demo.md', 'file_path': 'demo/TuGraph-Demo.md', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/TuGraph-Demo.md'}","page_content='TuGraph-db

3. 从源代码编译

建议在Linux系统中构建TuGraph，Docker环境是个不错的选择。如果您想设置一个新的环境，请参考[Dockerfile]  
以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build' metadata={'Header 1': 'TuGraph-db', 'Header 2': '3. 从源代码编译'}"
启动参数中cleanup_dir指定的目录用于执行什么操作？,"page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

```  
##### 2.2.6.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制备份不同的db，函数开始执行前会拷贝db到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""backup_copy_dir"", [BACKUPOPT], indirect=True)
def test_backup_copy_dir(self, backup_copy_dir):
pass
```  
#### 2.2.7.build_so  
##### 2.2.7.1.启动参数
采用python字典传入
+ cmd是启动命令，采用python列表传入，可以一次编译多个so
+ so_name是执行完成后需要清理的so，可以是多个，通过python列表传入  
```python' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}","page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

##### 2.2.5.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制备份不同的binlog，函数开始执行前会拷贝binlog到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""backup_binlog"", [BINLOGOPT], indirect=True)
def test_backup_binlog(self, backup_binlog):
pass
```  
#### 2.2.6.backup_copy_dir  
##### 2.2.6.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
BACKUPOPT = {""cmd"" : ""./lgraph_backup --src ./testdb -dst ./testdb1"",
""cleanup_dir"":[]}
```' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}","page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}"
使用什么命令来启动 TuGraph？,"page_content='数据库运行

3.服务操作

3.1.启动服务

TuGraph 需要通过 `lgraph_server -d start` 命令行启动，启动命令示例如下：  
```bash
$ ./lgraph_server -d start -c lgraph.json
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.1.启动服务'}","page_content='TuGraph Management

使用

TuGraph Management使用Maven进行管理，请运行如下命令启动TuGraph Management  
`mvn spring-boot:run`  
TuGraph Management 使用了sofastack框架，并使用brpc与TuGraph进行通信，sofastack默认端口为`6071`，brpc默认端口为`6091`，如需修改服务端口，请修改`./src/main/resources/application.properties`文件中的对应配置项。' metadata={'Header 1': 'TuGraph Management', 'Header 2': '使用'}","page_content='部署高可用模式

3.启动初始备份组

安装好TuGraph之后，可以使用`lgraph_server`命令在不同的机器上启动高可用集群。本节主要讲解高可用集群的启动方式，启动之后的集群状态管理参见[lgraph_peer工具](../6.utility-tools/5.ha-cluster-management.md)' metadata={'Header 1': '部署高可用模式', 'Header 2': '3.启动初始备份组'}"
TuGraph团队为了提高解析速度所进行的优化包括了哪些主要手段？,"page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

TuGraph做了哪些工作

（i）保证修改后程序的正确性/稳定性  
（ii）保证方案的有效性（低成本）  
反复推演后，我们选择了提交给社区的优化方案，即通过改变关键数据的 ownership 接触对锁的依赖。针对上述两个难点的分析如下：  
经过源码分析并与开源社区讨论，我们确认关键数据结构的初始化构建是非常耗时的，但可以通过“只调用一次”（`call_once`）手段将成本均摊，而后续的增量构建相对开销较低，并且也可均摊。因此该优化方案的低时间成本是可以保证的。  
关于程序正确性的保证，我们通过双重验证来保证。首先在设计之初我们已经从源代码角度，推断出共享数据仍然是安全的，其次我们也设计了实验对此进行了验证，验证结果与我们的分析一致' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': 'TuGraph做了哪些工作'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

TuGraph做了哪些工作

进一步地，我们通过分析程序中的并发访问情况，找到了可能引发数据竞争的所有代码段和共享变量（主要为 DFA、ATN 等结构），拼接出了数据竞争的完整链路。  
（4）破解数据竞争问题  
数据竞争问题是多线程程序中常见而又复杂的问题，可以考虑通过破解多种竞争条件来解决。就本文问题来说，也存在多种破解方案选择，如何制定最优的解决方案是一项极具挑战的工作，主要难点有两个：  
（i）保证修改后程序的正确性/稳定性  
（ii）保证方案的有效性（低成本）  
反复推演后，我们选择了提交给社区的优化方案，即通过改变关键数据的 ownership 接触对锁的依赖。针对上述两个难点的分析如下：  
经过源码分析并与开源社区讨论，我们确认关键数据结构的初始化构建是非常耗时的，但可以通过“只调用一次”（`call_once`）手段将成本均摊，而后续的增量构建相对开销较低，并且也可均摊。因此该优化方案的低时间成本是可以保证的。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': 'TuGraph做了哪些工作'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

贡献和成果

对Antlr4的优化的效果十分显著，32 线程的并发性能提升超过 18 倍 。考虑到实际生产服务器性能远高于测试机型，实际的性能提升效果将比测试结果更高， 优化后 GQL 解析能力已能完全满足企业业务的需要。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '贡献和成果'}"
当中止一个正在执行的任务时，应该使用哪种HTTP请求方法？,"page_content='RESTful API Legacy

6.Deprecated

6.4.任务管理

""time_elapsed"" : 30.887,
""task_id"" : ""2_6""
}
]
}
```  
#### 6.4.2.中止任务  
- **URI**: `/task/{task_id}`
其中 `{task_id}` 是 `GET /task` 返回结果中的 `task_id`。
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• DELETE http://localhost:7070/task/3_10
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.4.任务管理'}","page_content='RESTful API Legacy

6.Deprecated

6.4.任务管理

```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""description"" : ""[CPP_PLUGIN] scan_graph"",
""time_elapsed"" : 13.987,
""task_id"" : ""3_10""
},
{
""description"" : ""[CYPHER] MATCH(n) return n"",
""time_elapsed"" : 30.887,
""task_id"" : ""2_6""
}
]
}
```  
#### 6.4.2.中止任务  
- **URI**: `/task/{task_id}`
其中 `{task_id}` 是 `GET /task` 返回结果中的 `task_id`。
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.4.任务管理'}","page_content='RESTful API Legacy

6.Deprecated

6.4.任务管理

TuGraph 提供长任务的跟踪和中止功能。用户可以通过 REST API 来查询当前正在运行的在 Cypher 和存储过程查询，并选择中止正在执行的查询。  
任务管理对应的 URI 格式为  
```
http://{host}:{port}/task/{thread_id}/{task_id}
```  
#### 6.4.1.查询正在执行的任务  
- **URI**: `/task`
- **METHOD**: GET
- **RESPONSE**:  
返回的 JSON 为一个数组，其中每一个元素格式如下：  
| 域名         | 说明                         | 类型   |
| ------------ | ---------------------------- | ------ |
| description  | 任务描述                     | 字符串 |
| time_elapsed | 任务已经执行的时间，单位为秒 | 浮点   |' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.4.任务管理'}"
AllocVertexSubset函数用来做什么？,"page_content='OlapOnDB API

3. 算法举例

3.1 主函数

auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
/*
函数用途：从所有节点中获取pagerank值最大的节点编号

函数流程描述：该函数对点集合all_vertices中所有为1的位对应的节点vi（又称为活跃点）执行Func A，再将Func A的返回值作为Func B的第二个输入参数，得到局部最大值（因为第一个输入参数为0，因此实际上返回值就是每个节点的pagerank值），最后再将所有线程的返回值汇总，再次 执行Func B得到全局返回值，并存入max_pr_vi变量中
*/
size_t max_pr_vi = olapondb.ProcessVertexActive<size_t>(

//Func A
[&](size_t vi) {
return vi;
},
all_vertices,
0,

//Func B
[&](size_t a, size_t b) {
return pr[a] > pr[b] ? a : b;
}
);' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.1 主函数'}","page_content='OlapOnDB API

3. 算法举例

3.1 主函数

// 读事务的创建以及快照类的创建
auto txn = db.CreateReadTxn();
OlapOnDB<Empty> olapondb(
db,
txn,
SNAPSHOT_PARALLEL
);

// 创建pr数组用于存储每个节点的pr值
ParallelVector<double> pr = olapondb.AllocVertexArray<double>();
// pagerank算法主流程，获取每个节点的pagerank值
PageRankCore(olapondb, num_iterations, pr);

auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
/*
函数用途：从所有节点中获取pagerank值最大的节点编号' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.1 主函数'}","page_content='OlapBase API

7. 图类OlapBase

7.2 点集和边集及其相关操作

- `ParallelVector<VertexData> AllocVertexArray<VertexData>()`：分配一个类型为VertexData的数组，大小为点个数
- `void fill_vertex_array<V>(V * array, V value)`：将数组array中的所有元素赋值为value
- `ParallelBitset AllocVertexSubset()`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `AdjList<EdgeData> OutEdges(size_t vid)`：获取点v的所有出边集合
- `AdjList<EdgeData> InEdges(size_t vid)`：获取点v的所有入边集合
- `void Transpose()`：对有向图进行图反转' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.2 点集和边集及其相关操作'}"
web端导入10G数据报错,"page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}","page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}","page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

#### 6.10.1.指定文件内容导入  
- **URI**: `/db/{graph_name}/import/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |
| data | 要导入的文件内容（建议最大在 16MB 左右，最长不超过 17MB） | 字符串 / 数组 / 对象 |
| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}"
TuGraph支持的导出格式？,"page_content='TuGraph console client

在线数据导出

lgraph_cli 支持流式读取，导出数据只需要把lgraph_cli的输出重定向到文件中即可，导出格式支持csv和json。' metadata={'Header 1': 'TuGraph console client', 'Header 2': '在线数据导出'}","page_content='功能概览

4.核心功能

4.3.数据导入导出

尽管TuGraph本身支持数据的插入，但批量导入能够大幅提升的效率。导入的功能可以分为空库导入（离线导入）和增量导入，前者指子图是空的时候进行导入，额外的假设能够大幅提升导入的性能，在 TuGraph 中，空库导入和增量导入的吞吐率差了10 倍。在数据导出中，需要考虑导出数据的一致性，即是基于一个快照数据导出的。  
TuGraph 可以通过 命令行工具`lgraph_export` 来对已经存放在TuGraph的图数据进行数据导出，导出格式支持CSV和JSON。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.3.数据导入导出'}","page_content='功能概览

6.生态工具

6.1.TuGraph DataX

![导入导出](../../../images/tugraph-datax.png)  
TuGraph 核心支持 CSV 和 JSON 合适的导入导出，提供空库导入和增量导入的模式。实际中会存在 MySQL、Kafka、Hive 等多数据源导入的需求，TuGraph 通过 DataX 做多数据源的对接。由于关系模型和图模型存在的差异，数据清洗的流程可以使用 SparkSQL 快速处理，TuGraph 本身仅关注 CSV 和 JSON 的简单场景导入可靠性和性能。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.1.TuGraph DataX'}"
TuGraph的调优，除了语句前加EXPLAIN和PROFILE还有没有别的方式,"page_content='可视化操作手册

2.操作指南

2.4.图项目

在`语句查询`功能中，用户可以输入查询语句来查询图数据，并加载数据至画布区域进行展示。
- 语法说明：TuGraph的[查询语言及语法说明文档](../8.query/1.cypher.md)。
- 清空画布数据：未选择此按钮，每次执行查询的结果会追加至画布区域；选择此按钮，每次执行查询前会先清空画布。  
![图分析-语句查询](../../../images/browser/graphanalysis-queryfilter-query.png)  
##### 2.4.4.2.配置查询  
在`配置查询`功能中，用户可以选择节点类型和输入属性条件来查询图数据，并加载数据至画布区域进行展示。
- 清空画布数据：未选择此按钮，每次执行查询的结果会追加至画布区域；选择此按钮，每次执行查询前会先清空画布。  
![图分析-模板查询](../../../images/browser/graphanalysis-queryfilter-configurequery.png)  
##### 2.4.4.3.画布分析' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

TuGraph做了哪些工作

在调研讨论的过程中我们发现，多位开发者在论坛提出其耗时甚至多于 Java target 数倍之多。因此，我们决定从问题和开源代码出发，来定位、解决问题。  
这是一个典型的并发程序优化问题，根据以往的程序优化经验，我们分步推进该问题的解决：  
（1）识别问题  
通过对程序运行时的性能数据进行收集和分析，我们找到了程序运行瓶颈所在，通过调用分析，初步将问题定位为数据竞争导致的并发问题。  
（2）深入阅读 Antlr4 开源代码  
接下来，我们对 Antlr4 的源代码进行仔细的阅读和理解，掌握其内部的结构和核心逻辑，找出了核心的数据结构和关键的调用链路。为我们破解性能难题和分析修改的正确性做好了准备。  
（3）梳理数据竞争链路  
根据上述分析，我们判断问题的症结极大概率是数据竞争造成的。形成数据竞争至少有两个条件：一是线程之间共享内存数据，二是至少存在两个线程去读写某个共享内存。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': 'TuGraph做了哪些工作'}","page_content='环境分类

1.分类

根据环境所承载功能的不同，区分为编译环境，运行环境，以及精简运行环境。
* 编译环境，具备TuGraph编译的所有依赖库，包含运行环境的所有依赖，并且能够编译TuGraph源码，但不包含预编译好的TuGraph可执行文件和库文件，供开发者编译源码使用。
* 运行环境，具备GCC/Java/Python环境，能够运行TuGraph的所有功能，并且能承载全文索引，java client，c++源码上传为plugin，以及python plugin的完整功能，内置TuGraph预编译好的可执行文件和库文件，供客户直接安装使用，无需编译源码。
* 精简运行环境，约等于裸系统加预编译TuGraph，仅能运行TuGraph的基本功能，无C++ plugin编译运行，仅so上传，无全文索引，无python plugin，供快速搭建试用。  
TuGraph编译后，会把所有的依赖库以.a的形式打包在一起，因此原则上运行不需要的其他的依赖库。但TuGraph支持存储过程，即在服务端编译C++代码，因此在环境中依然需要涉及的编译器。' metadata={'Header 1': '环境分类', 'Header 2': '1.分类'}"
RpcSingleClient 构造函数需要哪些参数？,"page_content='RPC API

3.登录

登录请求信息包含以下参数：
- user: 必要参数，用户名
- pass: 必要参数，密码
以C++为例，用户使用构建好的服务存根发送登录请求：
```C++
auto* req = request.mutable_acl_request();
auto* auth = req->mutable_auth_request()->mutable_login();
auth->set_user(user);
auth->set_password(pass);
// send data
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req->set_client_version(server_version);
req->set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}","page_content='RPC API

2.请求

2.2.请求类型

| ImportRequest   | 数据导入请求     |
| GraphRequest    | 子图操作请求     |
| AclRequest      | 权限管理请求     |
| ConfigRequest   | 配置管理请求     |
| RestoreRequest  | 备份请求       |
| SchemaRequest   | schema管理请求 |  
用户发送请求时，需要传入以下参数：
- client_version: 可选参数，HA模式下可通过对比`client_version`和`server_version`防止响应过时的请求
- token: 必要参数，客户端登陆之后获得token，每次请求传入token以校验用户身份
- is_write_op: 可选参数，标志请求是否是写请求
- user: 可选参数，HA模式下主从之间同步请求时设置user，不需验证token  
服务处理完RPC请求之后发回响应，响应消息中除了包含每个请求的单独响应信息之外，还包含以下参数：' metadata={'Header 1': 'RPC API', 'Header 2': '2.请求', 'Header 3': '2.2.请求类型'}","page_content='Python客户端

3.RPC Client

result, const std::string& schema, const std::string& graph, bool json_format, double timeout)                                                                                                                                                    |' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client'}"
Cython是如何导入与Olap相关的模块和图数据库模块的？,"page_content='Python Olap API

5. lgraph_db API

见procedures/algo_cython/lgraph_db.pxd与lgraph_db_python.py文件。  
lgraph_db.pxd中接口用法与功能基本与C++接口相同，lgraph_db.pxd中声明的接口都由C++实现，在py文件中必须通过`from cython.cimports.olap_base import *`的方式导入，由Cython编译py文件后才能运行。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API'}","page_content='Python Olap API

4. Olap API

见procedures/algo_cython/olap_base.pxd文件，用法与功能基本与C++接口相同，olap_base.pxd中声明的接口都由C++实现，在py文件中必须通过`from cython.cimports.olap_base import *`的方式导入，由Cython编译py文件后才能运行。' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API'}","page_content='Python Olap API

3. Cython

Cython是一种高效的编程语言，是Python的超集。Cython能将py文件翻译为C/C++代码后编译为Python拓展类，在Python中通过import调用。在TuGraph中，所有的Python plugin都由Cython编译为Python拓展类后使用。  
Cython的Pure Python模式在保证Python语法的同时具有C/C++的性能，TuGraph Python接口均使用Cython实现。  
[Cython 文档](https://cython.readthedocs.io/en/latest/index.html)' metadata={'Header 1': 'Python Olap API', 'Header 2': '3. Cython'}"
在调用db.addEdgeIndex时，'unique'参数和'pair_unique'参数有何不同？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.addEdgeIndex(label_name, field_name, unique, pair_unique)

create an index on some field of one edge label .  
**Parameters:**  
| parameter | parameter type | description               |
| ---------- | -------------- | ------------------------------------- |
| label_name | string     | name of the label             |
| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |
| pair_unique | boolean    | Specifies whether the index is pair_unique |  
**Output:**' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addEdgeIndex(label_name, field_name, unique, pair_unique)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.addEdgeIndex(label_name, field_name, unique, pair_unique)

| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |
| pair_unique | boolean    | Specifies whether the index is pair_unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.addEdgeIndex('BornIn', 'id', true, false)
```  
**Example output:**  
```
Added index [BornIn:id]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addEdgeIndex(label_name, field_name, unique, pair_unique)'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}"
图数据库相比于关系型数据库有什么优势？,"page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.2. 兼容性

现实中，项目进程通常不断演变，数据的内容甚至数据格式也在不断变化。在关系型数据库中，这意味着表结构的变化或建立多个新表，对源数据的修改非常大。而在图数据库中，仅需添加新的点、边和属性，并将其设置为对应的类型即可。从本质上说，一个表代表一种类型的数据，一个点代表一个特定的数据。这意味着关系型数据库更关注数据类型，而图数据库更关注数据个体及其关联关系。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.2. 兼容性'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.1. 性能

在关联关系处理上，使用关系型数据库不可避免地要使用表的JOIN操作，这会对性能产生较大影响；而图数据库则直接跳转访问类指针，操作关联数据的效率更高，比关系型数据库提高2到4个数量级的性能。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.1. 性能'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.3. 直观性

使用图的方式表达现实世界的关系更直接和自然，在万物互联的时代尤为突出。如果使用关系型数据，先建立实体表，再建立关系表，最后映射数据，需要高度的抽象思维。在图数据上进行分析查询时，可以直观地通过点边连接的拓扑结构找到所需数据，无需任何专业知识。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.3. 直观性'}"
在创建节点的时候，报错：message: Vertex unique index value [xxx] is too long，是属性值太长了吗？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.addIndex(label_name, field_name, unique)

create an index on some field of one vertex label .  
**Parameters:**  
| parameter | parameter type | description               |
| ---------- | -------------- | ------------------------------------- |
| label_name | string     | name of the label             |
| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addIndex(label_name, field_name, unique)'}","page_content='业务开发指南

点类型操作

创建点类型

如下json定义了一个点类型，名字是`node1`。
```json
{
""label"": ""node1"",
""primary"": ""id"",
""type"": ""VERTEX"",
""detach_property"": true,
""properties"": [{
""name"": ""id"",
""type"": ""INT32"",
""optional"": false
}, {
""name"": ""name"",
""type"": ""STRING"",
""optional"": false,
""index"": true
}, {
""name"": ""num"",
""type"": ""INT32"",
""optional"": false,
""index"": true,
""unique"": true
}, {
""name"": ""desc"",
""type"": ""STRING"",
""optional"": true
}]
}' metadata={'Header 1': '业务开发指南', 'Header 2': '点类型操作', 'Header 3': '创建点类型'}","page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

| name | Label 名 | 字符串 |
| fields | 数据列定义 | 列表 |
| is_vertex | 是否是点 Label | 布尔值 |
| primary | 点的主键属性 | 字符串 |
| edge_constraints | 边的约束 | 列表 |  
`primary` 在 `is_vertex` 为 `true` 的时候设置，这个字段只有点才有, 创建点的时候必须设置。  
`edge_constraints` 在 `is_vertex` 为 `false` 的时候设置，这个字段只有边有。这个字段限制了该边的起点和终点只能是哪些点的组合，比如：`[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]`，限制了该边只能是从 `vertex_label1` 到 `vertex_label2` 和 从 `vertex_label3` 到 `vertex_label4`。如果不想有任何限制，不设置该字段即可。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}"
使用 GET 方法获取具体边属性时，如果边不存在该属性，会返回什么错误代码？,"page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

- **METHOD**: GET
- **RESPONSE**: 如果成功,返回代码 200,同时返回边的属性。如果失败,返回代码 400,同时返回 ""Illegal field.""。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/relationship/17_0_2_2/property/charactername
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""Henri Ducard""
}
```  
#### 6.8.10.更新边的属性  
- **URI**: `/db/{graph_name}/relationship/{euid}`
- **METHOD**: PUT
- **REQUEST**:' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
{
""weight"": 0.8,
""begin"": 20180922
}
}
```  
#### 6.8.9.获取边的属性  
- **URI**: `/db/{graph_name}/relationship/{euid}/property/{field}`
- **METHOD**: GET
- **RESPONSE**: 如果成功,返回代码 200,同时返回边的属性。如果失败,返回代码 400,同时返回 ""Illegal field.""。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/relationship/17_0_2_2/property/charactername' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• DELETE http://localhost:7070/db/graph1/relationship/14_0_1_0
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
```  
#### 6.8.8.获取边的所有属性  
- **URI**: `/db/{graph_name}/relationship/{euid}/property`
- **METHOD**: GET
- **RESPONSE**: 边属性字典  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/relationship/14_0_2_0/property
• Accept: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}"
TuGraph针对不同用户的需求提供了哪些类型的系统环境？,"page_content='环境和版本选择

1. 简介

TuGraph为不同需求的用户提供了差异化的系统环境和部署方式，来满足新手、系统开发者、生产运维人员、研究人员等不同用户的需求。' metadata={'Header 1': '环境和版本选择', 'Header 2': '1. 简介'}","page_content='环境分类

2.依赖系统库

针对三种环境，除去TuGraph的运行包，所需要的系统库如下：
* 编译环境，包括gcc、python、java等编译器，也包含antlr4、pybind11等，具体参见tugraph-db源码目录 ci/images/tugraph-compile-*-Dockerfile。
* 运行环境，主要由存储过程引入，包括gcc、boost、cmake等，具体参见tugraph-db源码目录 ci/images/tugraph-runtime-*-Dockerfile。
* 精简运行环境，无，可以参见tugraph-db源码目录 ci/images/ tugraph-mini-runtime-*-Dockerfile。' metadata={'Header 1': '环境分类', 'Header 2': '2.依赖系统库'}","page_content='环境分类

1.分类

根据环境所承载功能的不同，区分为编译环境，运行环境，以及精简运行环境。
* 编译环境，具备TuGraph编译的所有依赖库，包含运行环境的所有依赖，并且能够编译TuGraph源码，但不包含预编译好的TuGraph可执行文件和库文件，供开发者编译源码使用。
* 运行环境，具备GCC/Java/Python环境，能够运行TuGraph的所有功能，并且能承载全文索引，java client，c++源码上传为plugin，以及python plugin的完整功能，内置TuGraph预编译好的可执行文件和库文件，供客户直接安装使用，无需编译源码。
* 精简运行环境，约等于裸系统加预编译TuGraph，仅能运行TuGraph的基本功能，无C++ plugin编译运行，仅so上传，无全文索引，无python plugin，供快速搭建试用。  
TuGraph编译后，会把所有的依赖库以.a的形式打包在一起，因此原则上运行不需要的其他的依赖库。但TuGraph支持存储过程，即在服务端编译C++代码，因此在环境中依然需要涉及的编译器。' metadata={'Header 1': '环境分类', 'Header 2': '1.分类'}"
TuGraph-DB新增支持的空间数据类型有哪些？,"page_content='空间数据类型在TuGraph-DB中的实现

定义空间数据类型

TuGraph-DB当前已经支持Point、Linestring与Polygon三种类型  
-   • Point：点，创建方式例如POINT(2.0, 2.0, 7203)  
-   • Linestring：折线，创建方式例如LINESTRING(0 2,1 1,2 0)  
-   • Polygon：多边形，创建方式例如POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '定义空间数据类型'}","page_content='空间数据类型在TuGraph-DB中的实现

需求分析

结合上述案例，我们可以分析总结出对空间数据类型的需求:  
-   •支持不同坐标系下（包括地球地理坐标系，平面几何坐标系等）不同空间数据类型（包括Point、LineString,、Polygon）的存储与创建  
-   •支持不同坐标系下的常见空间查询操作, 包括Distance、BoundingBox、Disjoint（判断两个数据是否相交）的查询等  
-   •支持空间数据索引（R-Tree）  
-   •支持常见空间数据格式的导入（ESRI Shapefile data / OpenStreetMap）  
-   •支持空间数据的可视化' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '需求分析'}","page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

OGC(Open Geospatial Consortium) 定义了空间数据的标准表示格式，分别为EWKT(extended well known text)与EWKB(extended well known binary)格式，用于在不同系统和平台之间交换和存储空间数据，现已被广泛采用。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现'}"
在CREATE LABEL命令中，如果要创建一个顶点标签，主要属性名称应该由哪个参数确定？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.createLabel(label_type, label_name, extra, field_spec...)

Create a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| extra      | string     | for edge, it means constraints; for vertex, it means primary property |
| field_spec | list       | specification of a field  |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createLabel(label_type, label_name, extra, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createEdgeLabel( label_name, field_spec...)

Create an edge label.  
**Parameters:**  
| parameter  | parameter type | description          |
| ---------- | -------------- | ------------------------ |
| label_name | string     | name of the label    |
| edge_constraints | string | edge constraints |
| field_spec | list       | specification of a field |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`, where optional is specified as true, only for  optional fields.' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createEdgeLabel( label_name, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createLabel(label_type, label_name, extra, field_spec...)

| label_name | string     | name of the label     |
| extra      | string     | for edge, it means constraints; for vertex, it means primary property |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createLabel(label_type, label_name, extra, field_spec...)'}"
在HA模式下，client可以向谁发送导入点边数据请求？,"page_content='C++客户端

2.使用示例

2.14.从文件中导入点边数据

binary format.
@param [in]  timeout             (Optional) Maximum execution time, overruns will be
interrupted.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.14.从文件中导入点边数据'}","page_content='Java客户端

2.使用示例

2.14.从文件中导入点边数据

@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromFile(String confFile, String delimiter, boolean continueOnError, int threadNums,
int skipPackages, String graph, double timeout) throws IOException, UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.14.从文件中导入点边数据'}","page_content='C++客户端

2.使用示例

2.12.从字节流中导入点边数据

binary format.
@param [in]  timeout             (Optional) Maximum execution time, overruns will be
interrupted.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}"
在只读事务中调用 SetFields 方法会抛出什么异常？,"page_content='Java客户端

2.使用示例

2.8.加载存储过程

@param procedureDescription: procedure description
@param readOnly: procedure is read only or not
@param version: The version of procedure
@param graph: the graph to query.
@return: the result of procedure execution
public boolean loadProcedure(String sourceFile, String procedureType, String procedureName, String codeType,
String procedureDescription, boolean readOnly, String version, String graph) throws Exception
```' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.8.加载存储过程'}","page_content='src/cypher/execution_plan/clause_read_only_decider.h/ /**
 * Copyright 2023 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"") {}
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include ""cypher/utils/ast_node_visitor_impl.h""
#include ""procedure/procedure.h""

namespace cypher {

class ClauseReadOnlyDecider : public cypher::AstNodeVisitorImpl {
 public:
    ClauseReadOnlyDecider() {}

    virtual ~ClauseReadOnlyDecider() = default;

    bool IsReadOnly() {
        return read_only_;
    }

    geax::frontend::GEAXErrorCode Build(geax::frontend::AstNode* root) {
        return std::any_cast<geax::frontend::GEAXErrorCode>(root->accept(*this));
    }

 private:
    std::any visit(geax::frontend::AmbientLinearQueryStatement* node) override {
        read_only_ = true;
        ACCEPT_AND_CHECK_WITH_ERROR_MSG(node->resultStatement());
        for (auto query_statement : node->queryStatements()) {
            ACCEPT_AND_CHECK_WITH_ERROR_MSG(query_statement);
        }
        return geax::frontend::GEAXErrorCode::GEAX_SUCCEED;
    }

    std::any visit(geax::frontend::LinearDataModifyingStatement* node) override {
        read_only_ = false;
        for (auto query_statement : node->queryStatements()) {
            ACCEPT_AND_CHECK_WITH_ERROR_MSG(query_statement);
        }
        for (auto modify_statement : node->modifyStatements()) {
            ACCEPT_AND_CHECK_WITH_ERROR_MSG(modify_statement);
        }
        if (node->resultStatement().has_value()) {
            ACCEPT_AND_CHECK_WITH_ERROR_MSG(node->resultStatement().value());
        }
        return geax::frontend::GEAXErrorCode::GEAX_SUCCEED;
    }

    std::any visit(geax::front' metadata={'file_name': 'clause_read_only_decider.h', 'file_path': 'src/cypher/execution_plan/clause_read_only_decider.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/execution_plan/clause_read_only_decider.h'}","page_content='src/cypher/cypher_exception.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <exception>
#include <string>
#include ""core/data_type.h""
#include ""fma-common/string_formatter.h""

namespace lgraph {

#ifndef NDEBUG
#define CYPHER_TODO_FILE_NAME std::string(__FILE__)
#else
#define CYPHER_TODO_FILE_NAME """"
#endif

#define CYPHER_TODO()                                                                        \
    do {                                                                                     \
        throw lgraph::CypherException(                                                       \
            fma_common::StringFormatter::Format(""Function not implemented yet: {} at {}:{}"", \
                                                __func__, CYPHER_TODO_FILE_NAME, __LINE__)); \
    } while (0)

#define CYPHER_INTL_ERR()                                                               \
    do {                                                                                \
        throw lgraph::CypherException(fma_common::StringFormatter::Format(              \
            ""Internal error: {} at {}:{}"", __func__, CYPHER_TODO_FILE_NAME, __LINE__)); \
    } while (0)

#define CYPHER_THROW_ASSERT(pred)       \
    do {                                \
        if (!(pred)) CYPHER_INTL_ERR(); \
    } while (0)

#define CYPHER_PARSER_CHECK(pred, msg)                               \
    if (!(pred)) {                                                   \
        throw lgraph::ParserException(""error around '"" + msg + ""'""); \
    }
#define CYPHER_ARGUMENT_ERROR()  ' metadata={'file_name': 'cypher_exception.h', 'file_path': 'src/cypher/cypher_exception.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/cypher_exception.h'}"
GetVertexIndexIterator函数在liblgraph_python_api.Transaction中用于获取什么类型的迭代器？,"page_content='Python Olap API

5. lgraph_db API

Transaction：

```
GetVertexIndexIterator(
label: std::string,
field: std::string,
key_start: std::string,
key_end: std::string)-> VertexIndexIterator
```
获取索引迭代器。迭代器的field值为 [key_start, key_end]。所以在key_start=key_end=v时，返回指向field值为v的点的迭代器  
lgraph_db_python.py是lgraph_db.pxd中C++类 Galaxy与GraphDB的包装，将C++类包装为Python类，将lgraph_db_python.py编译为Python拓展后，可以直接在Python文件或Python命令行中`import lgraph_db_python`访问lgraph_db_python.PyGraphDB与PyGraphDB.PyGalaxy。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Transaction：'}","page_content='Python Olap API

6. 算法插件示例

root_id.encode('utf-8'), root_id.encode('utf-8')
).GetVid()
# 通过 GetVertexIndexIterator 根据root节点label名和filed名与filed值（root_id）
# 获取root节点的迭代器，通过迭代器获取vid，在无ID_MAPPING时，该vid与OlapOnDB中的id相同
cost = time.time() - cost
printf(""prepare_cost = %lf s\n"", cython.cast(cython.double, cost))
a = BFSCore()
cost = time.time()
count = a.run(cython.address(olapondb), root_vid)
cost = time.time() - cost
printf(""core_cost = %lf s\n"", cython.cast(cython.double, cost))' metadata={'Header 1': 'Python Olap API', 'Header 2': '6. 算法插件示例'}","page_content='Python Olap API

6. 算法插件示例

txn = db.CreateReadTxn()
olapondb = OlapOnDB[Empty](db[0], txn, SNAPSHOT_PARALLEL)
# 并行创建OlapOnDB
# Cython不支持如 *db 的解引用操作，通过db[0]来解引用
root_vid = txn.GetVertexIndexIterator(
label.encode('utf-8'), field.encode('utf-8'),
root_id.encode('utf-8'), root_id.encode('utf-8')
).GetVid()
# 通过 GetVertexIndexIterator 根据root节点label名和filed名与filed值（root_id）
# 获取root节点的迭代器，通过迭代器获取vid，在无ID_MAPPING时，该vid与OlapOnDB中的id相同
cost = time.time() - cost' metadata={'Header 1': 'Python Olap API', 'Header 2': '6. 算法插件示例'}"
db.importor.dataImportor 函数在导入数据时是否可以指定错误继续执行和线程数？,"page_content='Cypher API

5.附录2. 内置procedures列表

5.2.内置procedures完整列表

| db.importor.dataImportor              | 导入点或边数据                               | db.importor.dataImportor(description::STRING,content::STRING,continue_on_error::BOOLEAN,thread_nums::INTEGER,delimiter::STRING) :: (::VOID)                                             |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '5.2.内置procedures完整列表'}","page_content='Java客户端

2.使用示例

2.12.从字节流中导入点边数据

@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromContent(String desc, String data, String delimiter, boolean continueOnError,
int threadNums, String graph, double timeout) throws UnsupportedEncodingException
```' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='Java客户端

2.使用示例

2.14.从文件中导入点边数据

@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param skipPackages: skip packages number
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromFile(String confFile, String delimiter, boolean continueOnError, int threadNums,' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.14.从文件中导入点边数据'}"
在尝试读取一个已完成索引构建的顶点时，应该使用哪个函数？,"page_content='demo/ProcedureDemo/cpp/khop_kth.cpp/ /*
 * 根据给定顶点，返回第k层的顶点个数
 */
#include ""lgraph/lgraph.h""
#include ""lgraph/olap_on_db.h""
#include ""lgraph/lgraph_traversal.h""

#include ""json.hpp""

#include <iostream>
#include <vector>
#include <unordered_set>
using json = nlohmann::json;

using namespace lgraph_api;

class UnorderedParallelBitset {
 public:
    size_t size_;
    size_t parallel_bitset_size_;
    size_t threshold_size_;
    bool use_unordered_set_;
    std::shared_ptr<olap::ParallelBitset> parallel_bitset_visited_;
    std::unordered_set<int64_t> unordered_set_visited_;

    UnorderedParallelBitset(size_t parallel_bitset_size, size_t threshold_size) {
        size_ = 0;
        parallel_bitset_size_ = parallel_bitset_size;
        threshold_size_ = threshold_size;
        use_unordered_set_ = true;
    }

    ~UnorderedParallelBitset() {}

    bool Has(int64_t vid) {
        if (use_unordered_set_) {
            return unordered_set_visited_.find(vid) != unordered_set_visited_.end();
        } else {
            return parallel_bitset_visited_->Has(vid);
        }
    }

    bool Add(int64_t vid) {
        if (use_unordered_set_ && size_ >= threshold_size_) {
            use_unordered_set_ = false;
            std::shared_ptr<olap::ParallelBitset> ptr_(new olap::ParallelBitset(parallel_bitset_size_));
            parallel_bitset_visited_ = ptr_;
            for(auto iter = unordered_set_visited_.begin(); iter != unordered_set_visited_.end(); ++iter) {
                parallel_bitset_visited_->Add(*iter);
            }
        }
        if (use_unordered_set_) {
            unordered_set_visited_.emplace(vid);
        } else {
            parallel_bitset_visited_->Add(vid);
        }
        size_ += 1;
        return true;
    }

    void Clear() {
        if (use_unordered_set_) {
            unordered_set_visited_.clear();
        } else {
            parallel_bitset_visited_->Clear();
        }
        size_ = 0;
    }
};

extern ""C"" bool Process(GraphDB & db, const std::string & request, std::string & respon' metadata={'file_name': 'khop_kth.cpp', 'file_path': 'demo/ProcedureDemo/cpp/khop_kth.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/ProcedureDemo/cpp/khop_kth.cpp'}","page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.2.构建采样器

训练过程中，首先使用GetDB算子从数据库中获取图数据并转换成所需数据结构，具体代码如下：
```python
GetDB.Process(db_: lgraph_db_python.PyGraphDB, olapondb: lgraph_db_python.PyOlapOnDB, feature_num: size_t, NodeInfo: list, EdgeInfo: list)
```
如代码所示，结果存储在NodeInfo和EdgeInfo中。NodeInfo和EdgeInfo是python list结果，其存储的信息结果如下：  
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |  
然后构建采样器
```python
batch_size = 5
count = 2708' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.2.构建采样器'}","page_content='src/core/index_manager.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <atomic>
#include <mutex>
#include <map>

#include ""fma-common/binary_buffer.h""
#include ""fma-common/binary_read_write_helper.h""

#include ""core/data_type.h""
#include ""core/defs.h""
#include ""core/vertex_index.h""
#include ""core/edge_index.h""
#include ""core/kv_store.h""
#include ""core/lightning_graph.h""
#include ""core/schema.h""
#include ""core/schema_manager.h""
#include ""core/transaction.h""

namespace lgraph {
namespace _detail {
struct IndexEntry {
    IndexEntry() {}
    IndexEntry(IndexEntry&& rhs)
        : label(std::move(rhs.label)),
          field(std::move(rhs.field)),
          table_name(std::move(rhs.table_name)),
          type(rhs.type) {}

    std::string label;
    std::string field;
    std::string table_name;
    IndexType type;

    template <typename StreamT>
    size_t Serialize(StreamT& buf) const {
        return BinaryWrite(buf, label) + BinaryWrite(buf, field) + BinaryWrite(buf, table_name) +
               BinaryWrite(buf, type);
    }

    template <typename StreamT>
    size_t Deserialize(StreamT& buf) {
        return BinaryRead(buf, label) + BinaryRead(buf, field) + BinaryRead(buf, table_name) +
               BinaryRead(buf, type);
    }
};

struct CompositeIndexEntry {
    CompositeIndexEntry() {}
    CompositeIndexEntry(CompositeIndexEntry&& rhs)
        : label(std::move(rhs.label)),
          n(rhs.n),
          field_names(std::move(rhs.field_names)),
          field_types(std::move(rhs.field_types)),
          table_name(std::move(rhs.table_name)' metadata={'file_name': 'index_manager.h', 'file_path': 'src/core/index_manager.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/index_manager.h'}"
在调用函数DeleteGraph时，如果操作未被授权会抛出什么异常？,"page_content='Java客户端

2.使用示例

2.10.删除存储过程

```java
String result = client.deleteProcedure(""CPP"", ""sortstr"", ""default"");
log.info(""loadProcedure : "" + result);
```
```
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param graph: the graph to query.
@return: the result of procedure execution
public boolean deleteProcedure(String procedureType, String procedureName, String graph) throws Exception
```' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.10.删除存储过程'}","page_content='demo/MultithreadClient/delete_plugin.cpp/ 
#include ""delete_plugin.h""
#include ""tools/json.hpp""
#include <sstream>
#include <fstream>
#include <boost/algorithm/string/trim_all.hpp>

namespace multithread_client {

    void DeletePlugin::process() {
        std::fstream ifs(config.input, std::fstream::in);
        std::fstream ofs(config.output, std::fstream::out);
        std::string line;
        while (std::getline(ifs, line)) {
            if (line.empty()) continue;
            size_t idx = 0;
            if ((idx = line.find(""##""), idx != std::string::npos)) {
                if (idx == 0) continue;
                line = line.substr(0, idx);
            }
            std::string cypher;
            std::string plugin;
            std::string graph;
            if (!parse_line(line, cypher, plugin, graph)) {
                ofs << ""configuration file missing field"" << ""\n"";
                if (!config.continue_on_error) {
                    return;
                }
            }
            std::string res;
            bool success = channel->CallCypher(res, cypher, graph);
            if (!success) {
                ofs << ""failure delete "" << plugin <<  "" from "" << graph << "" because "" << res << ""\n"";
                if (!config.continue_on_error) {
                    return;
                }
            } else {
                ofs << ""success delete "" << plugin << "" from "" << graph << ""\n"";
            }
        }
    }

    bool DeletePlugin::parse_line(std::string& line, std::string& cypher, std::string& plugin, std::string& graph) {
        boost::trim_all(line);
        nlohmann::json obj = nlohmann::json::parse(line);
        if (!obj.contains(""PluginType"") || !obj.contains(""PluginName"") || !obj.contains(""Graph"")) {
            return false;
        }
        std::stringstream ss;
        ss << ""CALL db.plugin.deletePlugin('"";
        ss << obj[""PluginType""].get<std::string>();
        ss << ""','"";
        ss << obj[""PluginName""].get<std::string>();
        ss << ""')"";
        cypher = ss.str();' metadata={'file_name': 'delete_plugin.cpp', 'file_path': 'demo/MultithreadClient/delete_plugin.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/MultithreadClient/delete_plugin.cpp'}","page_content='src/cypher/cypher_exception.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <exception>
#include <string>
#include ""core/data_type.h""
#include ""fma-common/string_formatter.h""

namespace lgraph {

#ifndef NDEBUG
#define CYPHER_TODO_FILE_NAME std::string(__FILE__)
#else
#define CYPHER_TODO_FILE_NAME """"
#endif

#define CYPHER_TODO()                                                                        \
    do {                                                                                     \
        throw lgraph::CypherException(                                                       \
            fma_common::StringFormatter::Format(""Function not implemented yet: {} at {}:{}"", \
                                                __func__, CYPHER_TODO_FILE_NAME, __LINE__)); \
    } while (0)

#define CYPHER_INTL_ERR()                                                               \
    do {                                                                                \
        throw lgraph::CypherException(fma_common::StringFormatter::Format(              \
            ""Internal error: {} at {}:{}"", __func__, CYPHER_TODO_FILE_NAME, __LINE__)); \
    } while (0)

#define CYPHER_THROW_ASSERT(pred)       \
    do {                                \
        if (!(pred)) CYPHER_INTL_ERR(); \
    } while (0)

#define CYPHER_PARSER_CHECK(pred, msg)                               \
    if (!(pred)) {                                                   \
        throw lgraph::ParserException(""error around '"" + msg + ""'""); \
    }
#define CYPHER_ARGUMENT_ERROR()  ' metadata={'file_name': 'cypher_exception.h', 'file_path': 'src/cypher/cypher_exception.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/cypher_exception.h'}"
在初始化每个节点的pagerank值时，当节点的出度大于0，pagerank值是如何计算的？,"page_content='OlapOnDB API

3. 算法举例

3.2 PageRank算法流程

// 每个节点pagerank值的初始化，和该节点的出度成反比
double delta = graph.ProcessVertexActive<double>(
[&](size_t vi) {
curr[vi] = one_over_n;
if (olapondb.OutDegree(vi) > 0) {
curr[vi] /= olapondb.OutDegree(vi);
}
return one_over_n;
},
all_vertices);

// 总迭代过程
double d = (double)0.85;
for (int ii = 0;ii < num_iterations;ii ++) {
printf(""delta(%d)=%lf\n"", ii, delta);
next.Fill((double)0);

/*
函数用途：计算所有节点的pagerank值' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.2 PageRank算法流程'}","page_content='OlapOnDB API

3. 算法举例

3.2 PageRank算法流程

`pagerank`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关数据结构的初始化
1. 每个节点pagerank值的初始化
1. 每个节点pagerank值的计算，活跃点为所有点（意味着所有点都需要计算pagerank值）
1. 得到每个节点经过`num_iterations`次迭代后的pagerank值  
```C++
void PageRankCore(OlapBase<Empty>& graph, int num_iterations, ParallelVector<double>& curr) {' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.2 PageRank算法流程'}","page_content='内置算法

基础算法包

网页排序

网页排序程序实现了常用的Pagerank算法。该算法根据图中边和边权值计算所有点的重要性排名，PageRank值越高，表示该点在图中的重要性越高。计算时以点数量的倒数为各点初始Rank值，然后将点的Rank值按照出边平均传递到相邻点，重复该传递过程直到满足给定的收敛阈值或达到给定迭代轮数。每轮传递结束后，所有点的Rank值会有一定的的比例随机传递到任意点上。算法内容请参考 [https://en.wikipedia.org/wiki/PageRank](https://en.wikipedia.org/wiki/PageRank ""pagerank wiki"")。' metadata={'Header 1': '内置算法', 'Header 2': '基础算法包', 'Header 3': '网页排序'}"
TuGraph 支持哪些数据导出格式？,"page_content='TuGraph console client

在线数据导出

lgraph_cli 支持流式读取，导出数据只需要把lgraph_cli的输出重定向到文件中即可，导出格式支持csv和json。' metadata={'Header 1': 'TuGraph console client', 'Header 2': '在线数据导出'}","page_content='功能概览

6.生态工具

6.1.TuGraph DataX

![导入导出](../../../images/tugraph-datax.png)  
TuGraph 核心支持 CSV 和 JSON 合适的导入导出，提供空库导入和增量导入的模式。实际中会存在 MySQL、Kafka、Hive 等多数据源导入的需求，TuGraph 通过 DataX 做多数据源的对接。由于关系模型和图模型存在的差异，数据清洗的流程可以使用 SparkSQL 快速处理，TuGraph 本身仅关注 CSV 和 JSON 的简单场景导入可靠性和性能。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.1.TuGraph DataX'}","page_content='功能概览

4.核心功能

4.3.数据导入导出

尽管TuGraph本身支持数据的插入，但批量导入能够大幅提升的效率。导入的功能可以分为空库导入（离线导入）和增量导入，前者指子图是空的时候进行导入，额外的假设能够大幅提升导入的性能，在 TuGraph 中，空库导入和增量导入的吞吐率差了10 倍。在数据导出中，需要考虑导出数据的一致性，即是基于一个快照数据导出的。  
TuGraph 可以通过 命令行工具`lgraph_export` 来对已经存放在TuGraph的图数据进行数据导出，导出格式支持CSV和JSON。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.3.数据导入导出'}"
"启动TuGraph的时候报这个错误：0x00007f7e5f272900 FATAL include/fma-common/binary_buffer.h:289] CHECK(gpos_ + size <= ppos_)      failedreading beyond the array: required size=4, actual size=2","page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

1. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7:${VERSION}
```  
2. 启动docker  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}","page_content='TuGraph Java Client

用例

OGM 用例

executive(""mkdir ha3 && cp -r ../../src/server/lgraph_ha.json ./lgraph_server ./resource ha3 && cd ha3 && ./lgraph_server --host "" + host + "" --port 27074 --enable_rpc true --enable_ha true --ha_node_offline_ms 5000 --ha_node_remove_ms 10000 --rpc_port 29094 --directory ./db --log_dir ./log  --ha_conf "" + host + "":29092,"" + host + "":29093,"" + host + "":29094 -c lgraph_ha.json -d start"");
Thread.sleep(3000);

Driver driver = startHaClient(""29092"");
try {' metadata={'Header 1': 'TuGraph Java Client', 'Header 2': '用例', 'Header 3': 'OGM 用例'}","page_content='TuGraph-Restful-Server

2.启动 TuGraph-Restful-Server

需要在启动Tugraph时设置enable_rpc参数为true的方式，正常启动TuGraph' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '2.启动 TuGraph-Restful-Server'}"
如果在FrontierTraversal中开启了TRAVERSAL_PARALLEL标志，事务必须是怎样的？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}"
使用 CSV 文件导入数据时，文件中的栏位与配置文件中的 columns 如何对应？,"page_content='数据导入

3.配置文件

3.2.配置文件示例

""format"": ""CSV"",
""label"": ""movie"",
""columns"": [""mid"", ""name"", ""year"", ""rate""]
},
{
""path"": ""roles.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""play_in"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
对于上述配置文件，定义了三个 label：两个点类型`actor`和`movie`，一个边类型`role`。每个 label 都描述了：label 的名字、类型（点还是边）、属性字段有哪些以及每个字段的类型。对于点，另外定义了 primary 字段是哪个；对于边，另外定义了 constraints 字段，用来限制边的起点和终点只能是哪些组合。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.2.配置文件示例'}","page_content='数据导入

3.配置文件

3.2.配置文件示例

""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
对于上述配置文件，定义了三个 label：两个点类型`actor`和`movie`，一个边类型`role`。每个 label 都描述了：label 的名字、类型（点还是边）、属性字段有哪些以及每个字段的类型。对于点，另外定义了 primary 字段是哪个；对于边，另外定义了 constraints 字段，用来限制边的起点和终点只能是哪些组合。  
还描述了三个数据文件，两个点的数据文件`actors.csv`和`movies.csv`，一个边的数据文件`roles.csv`。每个部分都描述了：文件的路径（path）、数据类型（format）、信息头占开头几行（header）、是哪个 label 的数据（label）、文件中每行数据中的每个列对应的字段是哪个。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.2.配置文件示例'}","page_content='数据导入

3.配置文件

3.2.配置文件示例

""constraints"": [[""actor"", ""movie""]]
}
],
""files"": [
{
""path"": ""actors.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""actor"",
""columns"": [""aid"", ""name""]
},
{
""path"": ""movies.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""movie"",
""columns"": [""mid"", ""name"", ""year"", ""rate""]
},
{
""path"": ""roles.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""play_in"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.2.配置文件示例'}"
在创建一个顶点标签时，需要指定哪些参数？,"page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

其中{type}可以是 node 或者 relationship。  
#### 6.6.1.创建Label  
创建 Label 的过程同时也是定义其数据类型的过程。只有创建了 Label 才能在图中插入相应类型的点或者边。  
- **URI**: `/db/{graph_name}/label`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | Label 名 | 字符串 |
| fields | 数据列定义 | 列表 |
| is_vertex | 是否是点 Label | 布尔值 |
| primary | 点的主键属性 | 字符串 |
| edge_constraints | 边的约束 | 列表 |  
`primary` 在 `is_vertex` 为 `true` 的时候设置，这个字段只有点才有, 创建点的时候必须设置。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}","page_content='src/core/edge_index.cpp/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#include ""core/edge_index.h""
#include ""core/transaction.h""

namespace lgraph {

namespace _detail {

/**
 * Patch the key with the specified vid.
 *
 * \param           key     The key.
 * \param           src_vid     The src_vid.
 * \param           src_vid     The dst_vid.
 * \param           lid         The label id.
 * \param           tid         The temporal id.
 * \param           eid     The eid.
 * \return  The patched key.
 */
static Value PatchNonuniqueIndexKey(const Value& key, VertexId src_vid, VertexId end_vid,
                                    LabelId lid, TemporalId tid, EdgeId eid) {
    Value key_euid(key.Size() + EUID_SIZE);
    memcpy(key_euid.Data(), key.Data(), key.Size());
    WriteVid(key_euid.Data() + key.Size(), src_vid);
    WriteVid(key_euid.Data() + key.Size() + VID_SIZE, end_vid);
    WriteLabelId(key_euid.Data() + key.Size() + LID_BEGIN, lid);
    WriteTemporalId(key_euid.Data() + key.Size() + TID_BEGIN, tid);
    WriteEid(key_euid.Data() + key.Size() + EID_BEGIN, eid);
    return key_euid;
}

static Value PatchPairUniqueIndexKey(const Value& key, VertexId src_vid, VertexId end_vid) {
    Value key_euid(key.Size() + VID_SIZE * 2);
    memcpy(key_euid.Data(), key.Data(), key.Size());
    WriteVid(key_euid.Data() + key.Size(), src_vid);
    WriteVid(key_euid.Data() + key.Size() + VID_SIZE, end_vid);
    return key_euid;
}

std::unique_ptr<KvIterator> InitEdgeIndexIterator(KvTransaction& txn, KvTable& table,
                                                  const Value& key' metadata={'file_name': 'edge_index.cpp', 'file_path': 'src/core/edge_index.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/edge_index.cpp'}","page_content='业务开发指南

点类型操作

创建点类型

```
把上面这个json序列化成字符串，作为参数传入，建议使用驱动的参数化特性，避免自己拼接语句。
```
CALL db.createVertexLabelByJson($json_data)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '点类型操作', 'Header 3': '创建点类型'}"
TuGraph Browser 的默认端口号是什么？,"page_content='快速上手

2.安装

2.1.通过docker快速体验

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
5. 前端访问  
访问tugraph-db-browser: `http://x.x.x.x:7070`，数据库地址格式为 `bolt://ip:bolt_port`（老版本不用填），默认用户名为 `admin`，密码为 `73@TuGraph`。
首次登录会默认跳转修改密码页面，请尽快修改默认密码避免安全风险。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.1.通过docker快速体验'}","page_content='可视化操作手册

2.操作指南

2.1.访问

当用户完成图数据库的安装后，可以通过浏览器访问Browser。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7070。  
- 例如：127.0.0.1:7070。
- 推荐使用Chrome。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.1.访问'}","page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}"
在配置中，用于计算图表中显示的值的方法是什么？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='典型示例

PageRank动态图计算示例介绍

实例代码

// graphview 名称
final String graphName = ""graph_view_name"";
// 创建增量图 graphview
GraphViewDesc graphViewDesc = GraphViewBuilder
.createGraphView(graphName)
// 设置 graphview 分片数, 可从配置中指定
.withShardNum(envConfig.getInteger(ExampleConfigKeys.ITERATOR_PARALLELISM))
// 设置 graphview backend 类型
.withBackend(BackendType.RocksDB)
// 指定 graphview 点边以及属性等schema信息
.withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class, Integer.class, ValueEdge.class, IntegerType.class))' metadata={'Header 1': '典型示例', 'Header 2': 'PageRank动态图计算示例介绍', 'Header 3': '实例代码'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

##### 2.4.4.2.配置查询  
在`配置查询`功能中，用户可以选择节点类型和输入属性条件来查询图数据，并加载数据至画布区域进行展示。
- 清空画布数据：未选择此按钮，每次执行查询的结果会追加至画布区域；选择此按钮，每次执行查询前会先清空画布。  
![图分析-模板查询](../../../images/browser/graphanalysis-queryfilter-configurequery.png)  
##### 2.4.4.3.画布分析  
在`画布分析`功能中，用户可以对画布中的节点或边数据进行操作和分析，主要包括：选中节点进行扩展查询、收起/展开节点、固定节点，清空画布，套索，点/边检索，画布图例等。画布上的最基础操作是拖拽点数据，鼠标左键选住一个节点并移动鼠标，可以完成点数据位置的移动。  
###### a.扩展查询  
在`画布`区域右键点击一个节点数据，弹出操作悬窗，鼠标移至`扩展查询`处弹出二级悬窗，点击对应的扩展度数进行查询。
- 一度查询：双向扩展一度关系。
- 二度查询：双向扩展二度关系。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}"
TuGraph是由哪个团队开发的？,"page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}","page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}"
图学习系统是解决什么问题的？,"page_content='名词解释

2.图产品

> __图计算系统__：一般包括图数据库、图分析系统、图学习系统，有时也特指图分析系统。  
> __图数据库__：侧重于对图数据的增删改查、事务性操作等，如TuGraph DB、Neo4j、JanusGraph等。  
> __图分析系统__：解决图分析问题，可以细分为流水图分析、离线图分析，如TuGraph Analytics、GraphX等。  
> __图学习系统__：解决图学习问题，比如TuGraph Learn、DGL等。' metadata={'Header 1': '名词解释', 'Header 2': '2.图产品'}","page_content='TuGraph在图计算系统建设中的作用

TuGraph 技术优势

蚂蚁自己开发了一套图计算系统 TuGraph，既能解决图数据的存储问题，也能解决流式计算、离线计算和图学习的问题。目前，超过 100 个业务线和 300 多个场景都在使用这套系统。这套系统在 2021 年获得了世界互联网大会领先科技成果奖。  
在 TuGraph 中，性能是一个重要的因素，因为图数据集的体积很大，如果性能不佳就会浪费机器资源，导致许多情况下无法完成任务。比如，希望业务的查询能在几十毫秒内返回结果，但是如果做的性能不好，几秒钟才能返回结果，就无法作为在线查询使用。因此，我们是非常对性能是很重视的，其中在 LDBC-SNB 标准测试中（类似于数据库领域性能标准测试 TPC-C），TuGraph 仍然是世界纪录的保持者。' metadata={'Header 1': 'TuGraph在图计算系统建设中的作用', 'Header 2': 'TuGraph 技术优势'}","page_content='图算法介绍

1\. 图算法概述

图迭代算法解决了经典的图计算问题，但随着业务需求的复杂度提升，基于迭代的图算法存在着表达能力不足、自适应性能力差、异质图处理难度大等缺点。近年来随着深度学习的研究和应用的发展，以图神经网络（Graph Neural Networks，GNNs）为代表的一类神经网络算法，被设计用来捕获图中实体（节点）和关系（边）间的复杂模式。图神经网络能够结合节点特征和图的结构来学习节点和边的表示，相比之下，传统的迭代图算法通常不会直接从原始特征中学习，而更多地专注于结构特征。依赖于深度学习的天然优势，GNNs具有更强的表示学习能力，可以自动从数据中学习复杂的模式，这使得 GNNs 能够更好地处理多任务学习和迁移学习等问题。在社交网络分析、知识图谱、生物分子网络、推荐系统以及交通网络等领域，得到广泛应用。' metadata={'Header 1': '图算法介绍', 'Header 2': '1\\. 图算法概述'}"
VertexIterator GetVertexByUniqueCompositeIndex函数需要哪些参数？,"page_content='src/core/graph_vertex_iterator.cpp/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#include ""core/kv_store.h""
#include ""core/graph_vertex_iterator.h""
#include ""core/transaction.h""

namespace lgraph {
namespace graph {
VertexIterator::VertexIterator(::lgraph::Transaction* txn, KvTable& tbl, VertexId vid, bool closest)
    : IteratorBase(txn), it_(tbl.GetIterator(txn_->GetTxn())), impl_(*it_) {
    impl_.Goto(vid, closest);
}

VertexIterator::VertexIterator(KvTransaction* txn, KvTable& tbl, VertexId vid, bool closest)
    : IteratorBase(nullptr), it_(tbl.GetIterator(*txn)), impl_(*it_) {
    impl_.Goto(vid, closest);
}

VertexIterator::VertexIterator(VertexIterator&& rhs)
    : IteratorBase(std::move(rhs)), it_(std::move(rhs.it_)), impl_(std::move(rhs.impl_)) {
    impl_.SetItPtr(it_.get());
}

void VertexIterator::CloseImpl() { impl_.Close(); }
}  // namespace graph
}  // namespace lgraph
' metadata={'file_name': 'graph_vertex_iterator.cpp', 'file_path': 'src/core/graph_vertex_iterator.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/graph_vertex_iterator.cpp'}","page_content='Python Olap API

6. 算法插件示例

txn = db.CreateReadTxn()
olapondb = OlapOnDB[Empty](db[0], txn, SNAPSHOT_PARALLEL)
# 并行创建OlapOnDB
# Cython不支持如 *db 的解引用操作，通过db[0]来解引用
root_vid = txn.GetVertexIndexIterator(
label.encode('utf-8'), field.encode('utf-8'),
root_id.encode('utf-8'), root_id.encode('utf-8')
).GetVid()
# 通过 GetVertexIndexIterator 根据root节点label名和filed名与filed值（root_id）
# 获取root节点的迭代器，通过迭代器获取vid，在无ID_MAPPING时，该vid与OlapOnDB中的id相同
cost = time.time() - cost' metadata={'Header 1': 'Python Olap API', 'Header 2': '6. 算法插件示例'}","page_content='src/lgraph_api/lgraph_vertex_composite_index_iterator.cpp/ /**
* Copyright 2022 AntGroup CO., Ltd.
*
* Licensed under the Apache License, Version 2.0 (the ""License"");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
* http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an ""AS IS"" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*/

#include ""core/transaction.h""

#include ""lgraph/lgraph_vertex_composite_index_iterator.h""

namespace lgraph_api {
#define ThrowIfInvalid()                                                        \
    do {                                                                        \
        if (!txn_->IsValid()) throw std::runtime_error(""Invalid transaction.""); \
        if (!it_->IsValid()) throw std::runtime_error(""Invalid iterator."");     \
    } while (0)

VertexCompositeIndexIterator::VertexCompositeIndexIterator(lgraph::CompositeIndexIterator&& it,
                                        const std::shared_ptr<lgraph::Transaction>& txn)
    : it_(new lgraph::CompositeIndexIterator(std::move(it))), txn_(txn) {}

VertexCompositeIndexIterator::VertexCompositeIndexIterator(VertexCompositeIndexIterator&& rhs)
    : it_(std::move(rhs.it_)), txn_(std::move(rhs.txn_)) {}

VertexCompositeIndexIterator& VertexCompositeIndexIterator::operator=(
    VertexCompositeIndexIterator&& rhs) {
    it_ = std::move(rhs.it_);
    txn_ = std::move(rhs.txn_);
    return *this;
}

VertexCompositeIndexIterator::~VertexCompositeIndexIterator() {}

void VertexCompositeIndexIterator::Close() { it_->Close(); }

bool VertexCompositeIndexIterator::IsValid() const { return it_->IsValid(); }

bool VertexCompositeIndexIterator::Next() {
    ThrowIfInvalid();
    return it_->Next();
}

std::vector<FieldData> VertexCompositeIndexIterator::GetIndexValue() const {
    ThrowIfInvalid();
    return it_->GetKeyData();
}

st' metadata={'file_name': 'lgraph_vertex_composite_index_iterator.cpp', 'file_path': 'src/lgraph_api/lgraph_vertex_composite_index_iterator.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/lgraph_api/lgraph_vertex_composite_index_iterator.cpp'}"
rpc port怎么配置？,"page_content='数据库运行

4.服务配置

4.1.配置参数

| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='数据库运行

4.服务配置

4.1.配置参数

| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客户端端口。默认端口为 7687。                                                                                                                                                            |' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='数据库运行

4.服务配置

4.1.配置参数

| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}"
图数据库在处理关联关系时相比关系型数据库有什么优势？,"page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.1. 性能

在关联关系处理上，使用关系型数据库不可避免地要使用表的JOIN操作，这会对性能产生较大影响；而图数据库则直接跳转访问类指针，操作关联数据的效率更高，比关系型数据库提高2到4个数量级的性能。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.1. 性能'}","page_content='什么是图数据库

3. 图数据库与关系型数据库对比

| 分类         | 模型   | 优势                                   | 劣势                                     | 举例           |
| ------------ | ------ | -------------------------------------- | ---------------------------------------- | -------------- |
| 关系型数据库 | 表结构 | 数据高度结构化，一致性强，软件成熟度高 | 面向多跳的关联关系查询低效或不支持       | MySQL、Oracle  |
| 图数据库     | 图结构 | 针对关联关系的建模建模和操作效率非常高 | 高度结构化的数据处理能力不及关系型数据库 | Neo4j、TuGraph |' metadata={'Header 1': '什么是图数据库', 'Header 2': '3. 图数据库与关系型数据库对比'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.2. 兼容性

现实中，项目进程通常不断演变，数据的内容甚至数据格式也在不断变化。在关系型数据库中，这意味着表结构的变化或建立多个新表，对源数据的修改非常大。而在图数据库中，仅需添加新的点、边和属性，并将其设置为对应的类型即可。从本质上说，一个表代表一种类型的数据，一个点代表一个特定的数据。这意味着关系型数据库更关注数据类型，而图数据库更关注数据个体及其关联关系。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.2. 兼容性'}"
使用TuGraph Browser时，默认的登录密码是什么？,"page_content='可视化操作手册

2.操作指南

2.2.登录

![login](../../../images/browser/login.png)  
- 浏览器成功访问Browser后，首先进入的是登录页面（如上图所示），用户需要填写账号和密码进行登录。
- 数据库地址格式为：ip:bolt_port。
- 默认账号：admin。
- 默认密码：73@TuGraph。
- 用户首次登录后，会跳转至修改密码页面，密码修改成功后，使用新密码重新登录即可使用。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.2.登录'}","page_content='可视化操作手册（旧版）

操作详情

2.登录数据库

![alt 登录](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/1.tugraph-browser-lpgin.png)  
- 页面打开成功会，首先进图的是登录页面，用户需要填写账号和密码进行登录。
- 默认账号：admin
- 默认密码：73@TuGraph
- 建议用户登录后，及时修改初始化的密码' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '2.登录数据库'}","page_content='快速上手

2.安装

2.1.通过docker快速体验

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
5. 前端访问  
访问tugraph-db-browser: `http://x.x.x.x:7070`，数据库地址格式为 `bolt://ip:bolt_port`（老版本不用填），默认用户名为 `admin`，密码为 `73@TuGraph`。
首次登录会默认跳转修改密码页面，请尽快修改默认密码避免安全风险。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.1.通过docker快速体验'}"
SetFields函数的第一个版本中，field_value_strings参数的数据类型是什么？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

in which each `field_value_spec` is a list of string in the form of `[field_name, field_type, field_value, optional]`, where: `field_value` is the default value of the field.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelAddFields(
'vertex',
'new_label',' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

| ---------------- | -------------- | ------------------------- |
| label_type       | string     | either 'vertex' or 'edge' |
| label_name       | string     | name of the label     |
| field_value_spec | list       | specification of a field  |  
in which each `field_value_spec` is a list of string in the form of `[field_name, field_type, field_value, optional]`, where: `field_value` is the default value of the field.  
**Output:**' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

Adds specified fields to the label.  
**Parameters:**  
| parameter    | parameter type | description           |
| ---------------- | -------------- | ------------------------- |
| label_type       | string     | either 'vertex' or 'edge' |
| label_name       | string     | name of the label     |
| field_value_spec | list       | specification of a field  |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}"
DB和tuGraph Analytics是独立运行吗？,"page_content='数据库运行

1.前置条件

TuGraph 运行的前置条件为 TuGraph 正确安装，参考[安装流程](1.environment.md)。  
TuGraph 运行需要保证库文件 liblgraph.so 的文件位置在环境变量 LD_LIBRARY_PATH。  
运行 TuGraph 进程的用户不需要超级权限，但需要对配置文件（一般为lgraph.json）及文件中涉及的文件有读权限，并且对数据文件夹、日志文件夹等有写权限。' metadata={'Header 1': '数据库运行', 'Header 2': '1.前置条件'}","page_content='数据库运行

2.运行模式

TuGraph 可以作为前台普通进程启动，也可以作为后台守护进程启动。
当作为普通进程运行时，TuGraph 可以直接将日志打印到终端，这在调试服务器配置时非常方便。但是，由于前台进程在终端退出后被终止，因此用户须确保在 TuGraph 服务器处于运行状态时，终端保持打开状态。另一方面，在守护进程模式下，即使启动它的终端退出，TuGraph 服务器也可以继续运行。因此，在长时间运行的服务器下推荐以守护进程模式启动 TuGraph 服务器。' metadata={'Header 1': '数据库运行', 'Header 2': '2.运行模式'}","page_content='图算法介绍

3\. 系统设计

| 动态代理 | 部署分发难度大 |
| 支持复杂类型 | 版本难兼容 |
| API使用简易 | 运行时环境依赖复杂 |  
4.Web服务化  
Web服务化是一种将机器学习模型部署成网络服务，调用者通过相应的api获取模型推理结果。  
| **优点** | **缺点** |
| --- | --- |
| 扩展性好 | 性能差 |
| 简易且轻量 | 不适合计算密集型场景 |
| 社区支持 | 无状态管理 |
| 机器学习类库易集成 | 并发连接有限 |  
在TuGraph Analytics模型推理系统的架构设计中，核心部分是通过C++原生语言建立起来的一座桥梁，实现Python环境和Java虚拟机之间高效的数据交互和操作指令的传递。通过使用C++作为媒介语言，我们不仅能够利用其接近硬件的执行效率，确保数据交互的性能，还能够保证在两个虚拟环境之间数据交换的计算精度和稳定性。基于共享内存的设计允许Python和JVM进程各自独立运行，既保证了运行环境的安全隔离，又能实现数据的高效共享。' metadata={'Header 1': '图算法介绍', 'Header 2': '3\\. 系统设计'}"
RpcClient 构造函数需要什么参数用于用户登录？,"page_content='RPC API

3.登录

登录请求信息包含以下参数：
- user: 必要参数，用户名
- pass: 必要参数，密码
以C++为例，用户使用构建好的服务存根发送登录请求：
```C++
auto* req = request.mutable_acl_request();
auto* auth = req->mutable_auth_request()->mutable_login();
auth->set_user(user);
auth->set_password(pass);
// send data
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req->set_client_version(server_version);
req->set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}","page_content='RPC API

3.登录

if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
token = res.acl_response().auth_response().token();
```
登录响应信息包含以下参数：
- token: 必要参数，登录成功会收到带有签名的令牌，即 Json Web Token，客户端储存该令牌，并且用于以后的每次发送请求。
如果登录失败会收到“Authentication failed”错误。' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}","page_content='C++客户端

2.使用示例

2.1.实例化client对象

```
```
RpcClient(std::vector<std::string>& urls, std::string user, std::string password)
@param urls: tugraph host list
@param user: login user name
@param password: login password
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.1.实例化client对象'}"
如何使用lgraph_cypher工具在命令行中以单命令模式提交一条Cypher查询并保存结果？,"page_content='命令行工具

1.单命令模式

在单命令模式下，`lgraph_cypher`可用于提交单个 Cypher 查询并将结果直接打印到终端，打印结果也可以容易地重定向写入指定文件。当用户需要从服务器获取大量结果并将其保存在文件中时，这非常便利。
在此模式下，`lgraph_cypher`工具具有以下选项：' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式'}","page_content='命令行工具

1.单命令模式

1.2.命令示例:

**cypher 命令文件查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -f /home/usr/cypher.json
```  
**cypher 命令单句查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -s ""MATCH (n) RETURN n""
```' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式', 'Header 3': '1.2.命令示例:'}","page_content='命令行工具

2.交互模式

2.3.cypher 查询命令:

在交互模式下，用户也可直接输入单句 cypher 命令进行查询，以""`;`""结束。输入命令不区分大小写。例子如下：  
```
login success
>MATCH (n) RETURN n, n.name;
+---+---+-------------+
|   | n |n.name       |
+---+---+-------------+
| 0 | 0 |david        |
| 1 | 1 |Ann          |
| 2 | 2 |first movie  |
| 3 | 3 |Andres       |
+---+---+-------------+
time spent: 0.000520706176758
size of query: 4
>
```  
`lgraph_cypher`输入命令时支持多行输入，用户可使用`ENTER`键将长查询语句分多行输入。多行输入情况下命令行开头会从`>`变为`=>`，然后用户可以继续输入查询的其余部分。  
例子如下：  
```
login success' metadata={'Header 1': '命令行工具', 'Header 2': '2.交互模式', 'Header 3': '2.3.cypher 查询命令:'}"
数据和日志目录的持久化位置在哪里？,"page_content='快速上手

2.安装

2.1.通过docker快速体验

# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
**方式二**  
```shell
docker run -dt -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION} /bin/bash' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.1.通过docker快速体验'}","page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}","page_content='快速上手

2.安装

2.1.通过docker快速体验

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
**方式二**  
```shell
docker run -dt -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.1.通过docker快速体验'}"
TuGraph 的 Traversal API 当中对于遍历的起始点设置有哪三种方式？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
```  
上述为 FrontierTraversal 的三种遍历方式，即从当前的点集合出发，对集合中的每个点，依次访问每条出边/入边/出边和入边，若满足用户自定义的过滤条件（其中，edge_filter 为面向边的过滤函数，neighbour_filter 则为面向邻居点的过滤函数），则将邻居点加入新的点集合。  
```c' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}"
方法 `SetField` 的目的是什么？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}"
TuGraph-DB图数据库是由哪个团队开发的？,"page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}","page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}"
TuGraph 的精简运行环境需要哪些系统库？,"page_content='环境分类

2.依赖系统库

针对三种环境，除去TuGraph的运行包，所需要的系统库如下：
* 编译环境，包括gcc、python、java等编译器，也包含antlr4、pybind11等，具体参见tugraph-db源码目录 ci/images/tugraph-compile-*-Dockerfile。
* 运行环境，主要由存储过程引入，包括gcc、boost、cmake等，具体参见tugraph-db源码目录 ci/images/tugraph-runtime-*-Dockerfile。
* 精简运行环境，无，可以参见tugraph-db源码目录 ci/images/ tugraph-mini-runtime-*-Dockerfile。' metadata={'Header 1': '环境分类', 'Header 2': '2.依赖系统库'}","page_content='环境分类

1.分类

根据环境所承载功能的不同，区分为编译环境，运行环境，以及精简运行环境。
* 编译环境，具备TuGraph编译的所有依赖库，包含运行环境的所有依赖，并且能够编译TuGraph源码，但不包含预编译好的TuGraph可执行文件和库文件，供开发者编译源码使用。
* 运行环境，具备GCC/Java/Python环境，能够运行TuGraph的所有功能，并且能承载全文索引，java client，c++源码上传为plugin，以及python plugin的完整功能，内置TuGraph预编译好的可执行文件和库文件，供客户直接安装使用，无需编译源码。
* 精简运行环境，约等于裸系统加预编译TuGraph，仅能运行TuGraph的基本功能，无C++ plugin编译运行，仅so上传，无全文索引，无python plugin，供快速搭建试用。  
TuGraph编译后，会把所有的依赖库以.a的形式打包在一起，因此原则上运行不需要的其他的依赖库。但TuGraph支持存储过程，即在服务端编译C++代码，因此在环境中依然需要涉及的编译器。' metadata={'Header 1': '环境分类', 'Header 2': '1.分类'}","page_content='环境和版本选择

2. 环境能力选择

用户可以根据实际使用场景，来选择不同的环境。编译环境的能力最完备，所需的第三方软件也越多。与其相对应的，精简运行环境几乎不需要安装任何依赖库，能运行TuGraph除存储过程外的基础功能。  
| 环境     | 用途             | 备注        |
|--------|----------------|-----------|
| 编译环境   | 从源码编译TuGraph   | 适用于开发人员   |
| 运行环境   | 运行TuGraph安装包   | 适用于大部分用户  |
| 精简运行环境 | 运行精简TuGraph安装包 | 对系运行统依赖较小 |  
不同环境的具体介绍参见 [链接](../5.installation&running/2.environment-mode.md)。' metadata={'Header 1': '环境和版本选择', 'Header 2': '2. 环境能力选择'}"
函数 SetFrontier(std::function<bool(VertexIterator&)> root_vertex_filter) 是如何利用参数 root_vertex_filter 的？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}"
rpm包中包含新版前端页面资源吗？,"page_content='src/BuildClients.cmake/ # brpc
set(BRPC_LIB libbrpc.a)

if (ENABLE_FULLTEXT_INDEX)
    # jni
    find_package(JNI REQUIRED)
endif ()

# protbuf
include(cmake/GenerateProtobuf.cmake)
GenerateProtobufCpp(${CMAKE_CURRENT_LIST_DIR}/protobuf
        PROTO_SRCS PROTO_HEADERS
        ${CMAKE_CURRENT_LIST_DIR}/protobuf/ha.proto)

# leveldb
find_path(LEVELDB_INCLUDE_PATH NAMES leveldb/db.h)
find_library(LEVELDB_LIB NAMES leveldb)
if ((NOT LEVELDB_INCLUDE_PATH) OR (NOT LEVELDB_LIB))
    message(FATAL_ERROR ""Fail to find leveldb"")
endif ()

find_library(SNAPPY NAMES snappy)

find_package(PythonInterp 3)
find_package(PythonLibs ${PYTHON_VERSION_MAJOR}.${PYTHON_VERSION_MINOR} EXACT REQUIRED)

############### liblgraph_client_cpp_rpc ######################

set(TARGET_CLIENT_CPP_RPC lgraph_client_cpp_rpc)

add_library(${TARGET_CLIENT_CPP_RPC} SHARED
        client/cpp/rpc/lgraph_rpc_client.cpp
        lgraph_api/lgraph_exceptions.cpp
        ${PROTO_SRCS})

target_include_directories(${TARGET_CLIENT_CPP_RPC} PRIVATE
        ${DEPS_INCLUDE_DIR}
        ${CMAKE_CURRENT_LIST_DIR}
        ${CMAKE_CURRENT_LIST_DIR}/cypher    # for FieldDataConvert
        ${LGRAPH_INCLUDE_DIR}
        ${JNI_INCLUDE_DIRS})

if (NOT (CMAKE_SYSTEM_NAME STREQUAL ""Darwin""))
    target_link_libraries(${TARGET_CLIENT_CPP_RPC}
            PUBLIC
            ${Boost_LIBRARIES}
            # begin static linking
            -Wl,-Bstatic
            ${BRPC_LIB}
            ${GFLAGS_LIBRARY}
            ${LEVELDB_LIB}
            -Wl,--whole-archive
            ${PROTOBUF_LIBRARY}
            -Wl,--no-whole-archive
            gflags
            snappy
            -Wl,-Bstatic
            -static-libstdc++
            -static-libgcc
            libstdc++fs.a
            OpenSSL::ssl
            OpenSSL::crypto
            -Wl,-Bdynamic
            rt
            dl
            z
            )
else ()
    target_link_libraries(${TARGET_CLIENT_CPP_RPC}
            PUBLIC
            lgraph
            lgraph_cypher_lib
            ${BRPC_LIB}
            ${LEVEL' metadata={'file_name': 'BuildClients.cmake', 'file_path': 'src/BuildClients.cmake', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/BuildClients.cmake'}","page_content='技术规划

2. 已完成功能

| 3.3.1 | 图分析引擎重构，多模式支持                    | 2022.10.14 |
| 3.3.2 | OGM支持，UT覆盖率提升                    | 2022.11.21 |
| 3.3.3 | 链接认证机制迭代，加入英文文档                  | 2022.12.23 |
| 3.3.4 | 支持上云，梳理LDBC SNB Audit流程          | 2023.1.28  |
| 3.4.0 | 支持OLAP Python API, 离线导入升级        | 2023.3.11  |
| 3.5.0 | 支持POG，前端升级，文档梳理                  | 2023.6.5   |
| 3.5.1 | 图学习引擎，Procedure Rust API，存储属性分离  | 2023.7.14  |
| 3.6.0 | 高可用开源，日志系统升级                     | 2023.8.11  |' metadata={'Header 1': '技术规划', 'Header 2': '2. 已完成功能'}","page_content='RPC API

2.请求

2.2.请求类型

- client_version: 可选参数，HA模式下可通过对比`client_version`和`server_version`防止响应过时的请求
- token: 必要参数，客户端登陆之后获得token，每次请求传入token以校验用户身份
- is_write_op: 可选参数，标志请求是否是写请求
- user: 可选参数，HA模式下主从之间同步请求时设置user，不需验证token  
服务处理完RPC请求之后发回响应，响应消息中除了包含每个请求的单独响应信息之外，还包含以下参数：
- error_code: 必要参数，标志请求处理状态
- redirect: 可选参数，HA模式下向follower发送写请求时处理失败，设置redirect为请求转发地址，即leader地址
- error: 可选参数，请求错误信息
- server_version: 可选参数，HA模式的请求响应中设置`server_version`以避免client读取数据时发生反向时间旅行问题' metadata={'Header 1': 'RPC API', 'Header 2': '2.请求', 'Header 3': '2.2.请求类型'}"
请问一下镜像 tugraph-runtime-centos7启动大概需要多少资源,"page_content='快速上手

2.安装

2.1.通过docker快速体验

1. 本地安装 docker 环境  
参考 docker 官方文档：https://docs.docker.com/get-started/  
2. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7
```  
3. 启动docker  
启动 TuGraph 服务可以通过两种方式来实现。第一种方式将镜像拉取与服务启动整合在一起，用户只需执行运行容器的操作，即可同时启动 TuGraph 服务。第二种方式则是在创建 TuGraph 容器后，手动进入容器内部以触发服务启动。尽管这种方法初期步骤稍显繁琐，但在如忘记密码的情况下，它提供了更灵活的密码重置选项。  
**方式一**  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.1.通过docker快速体验'}","page_content='部署高可用模式

8.docker部署高可用集群

8.1.安装镜像

使用如下命令下载TuGraph的编译docker镜像环境
```shell
docker pull tugraph/tugraph-compile-centos7
```
然后拉取TuGraph源码并编译安装' metadata={'Header 1': '部署高可用模式', 'Header 2': '8.docker部署高可用集群', 'Header 3': '8.1.安装镜像'}","page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

1. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7:${VERSION}
```  
2. 启动docker  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}"
当创建组合索引时，需要提供哪些参数？,"page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属性不会存在相同的值。
由于底层存储设计，组合索引key需要保存属性的长度，因此，' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属性不会存在相同的值。
由于底层存储设计，组合索引key需要保存属性的长度，因此，
组合唯一索引key的最大长度是480-2*(属性个数-1) bytes，**超过的属性不能建立唯一索引**。  
##### 1.3.2.2 非唯一索引  
和点的普通非唯一索引类似，点的非唯一索引指的是非全局唯一的索引，即若一组属性设置了非唯一索引，
在同一个图中，相同label的点的该组属性可以存在相同的值。
由于非唯一索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}"
函数 `SetField` 抛出的异常之一是什么？,"page_content='src/core/field_extractor.cpp/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#include ""core/field_extractor.h""

namespace lgraph {
namespace _detail {
/**
 * Parse string data as type and set the field
 *
 * \tparam  T   Type into which the data will be parsed.
 * \param [in,out]  record  The record.
 * \param           data    The string representation of the data. If it is
 * NBytes or String, then the data is stored as-is.
 *
 * \return  ErrorCode::OK if succeeds
 *          FIELD_PARSE_FAILED.
 */
template <FieldType FT>
void FieldExtractor::_ParseStringAndSet(Value& record, const std::string& data) const {
    typedef typename field_data_helper::FieldType2CType<FT>::type CT;
    typedef typename field_data_helper::FieldType2StorageType<FT>::type ST;
    CT s{};
    size_t tmp = fma_common::TextParserUtils::ParseT<CT>(data.data(), data.data() + data.size(), s);
    if (_F_UNLIKELY(tmp != data.size())) throw ParseStringException(Name(), data, FT);
    return SetFixedSizeValue(record, static_cast<ST>(s));
}

template <>
void FieldExtractor::_ParseStringAndSet<FieldType::STRING>(Value& record,
                                                           const std::string& data) const {
    return _SetVariableLengthValue(record, Value::ConstRef(data));
}

template <>
void FieldExtractor::_ParseStringAndSet<FieldType::POINT>(Value& record,
                                                          const std::string& data) const {
    FMA_DBG_ASSERT(!is_vfield_);
    // check whether the point data is valid;
    if (!::lgraph_api::TryDecodeEWKB(data, ::lgraph_api::SpatialType::' metadata={'file_name': 'field_extractor.cpp', 'file_path': 'src/core/field_extractor.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/field_extractor.cpp'}","page_content='典型示例

KeyAgg流计算示例介绍

实例代码

return pipeline.execute();
}

public static void validateResult() throws IOException {
ResultValidator.validateMapResult(REF_FILE_PATH, RESULT_FILE_PATH, String::compareTo);
}


public static class AggFunc implements
AggregateFunction<Tuple<Long, Long>, Tuple<Long, Long>, Tuple<Long, Long>> {

// 定义累加器实现
@Override
public Tuple<Long, Long> createAccumulator() {
return Tuple.of(0L, 0L);
}' metadata={'Header 1': '典型示例', 'Header 2': 'KeyAgg流计算示例介绍', 'Header 3': '实例代码'}","page_content='src/core/task_tracker.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <atomic>
#include <chrono>
#include <exception>
#include <mutex>
#include <stdexcept>
#include <string>
#include <type_traits>
#include <vector>

#include ""fma-common/string_formatter.h""
#include ""fma-common/text_parser.h""
#include ""fma-common/timed_task.h""
#include ""fma-common/utils.h""

#include ""core/data_type.h""
#include ""core/cache_aligned_vector.h""
#include ""core/thread_id.h""

#include ""lgraph/lgraph_exceptions.h""

namespace lgraph {

class TaskTracker {
    typedef std::chrono::system_clock::time_point TimePoint;
    typedef std::chrono::system_clock SystemClock;

 public:
    // interface, statistics
    struct Stats {
        double qps;
        double tps;
        double failure_rate;
        size_t n_running;
    };

    enum ErrorCode { SUCCESS = 0, NOTFOUND = 1, FAIL_TO_KILL = 2 };

    // interface, identifies a task
    struct TaskId {
        TaskId() : thread_id(-1), task_id(-1) {}
        TaskId(int thr, int64_t tsk) : thread_id(thr), task_id(tsk) {}

        std::string ToString() const {
            return fma_common::StringFormatter::Format(""{}_{}"", thread_id, task_id);
        }

        bool FromString(const std::string& str) {
            const char* b = str.data();
            const char* e = str.data() + str.size();
            size_t s1 = fma_common::TextParserUtils::ParseT(b, e, thread_id);
            b += s1;
            if (s1 == 0 || b >= e || *b != '_') return false;
            b++;
            size_t s2 = fma_common::TextParserUtils::ParseT(b, e,' metadata={'file_name': 'task_tracker.h', 'file_path': 'src/core/task_tracker.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/task_tracker.h'}"
TuGraphClient是什么？,"page_content='TuGraph Java Client

特性

- Java中的RPC客户端
- OGM，即对象图映射，支持将图中的实体和关系映射到Java对象，从而加速Java开发过程。' metadata={'Header 1': 'TuGraph Java Client', 'Header 2': '特性'}","page_content='demo/TuGraph-Demo.md/ # TuGraph 示例

## 1 简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph是TuGraph的曾用名。

主要功能特征包括：

- 支持属性图模型
- 原生图存储及处理
- 完全的ACID事务支持
- 支持OpenCypher图查询语言
- 支持原生的Core API和Traversal API
- 支持REST和RPC接口
- 支持CSV、JSON、MySQL等多数据源导入导出
- 支持可视化图交互
- 支持命令行交互
- 内置用户权限控制、操作审计
- 支持任务和日志的监控管理
- 原生适配PandaGraph图分析引擎
- 集成DGL图神经网络系统

性能及可扩展性特征包括：

- 支持TB级大容量
- 吞吐率高达千万顶点每秒
- 面向读优化的存储引擎
- 支持高可用模式
- 支持离线备份恢复
- 在线热备份
- 高性能批量导入导出

## 2 快速上手

见QuickStart文档。

## 3 基本功能

### 3.1 RPC Client
#### 3.1.1 概述
RPC Client是对cpp语言rpc客户端的简单封装，每次执行时会创建一条到lgraph_server的链接用于发送请求数据以及接收响应结果，执行完毕后进程退出前会断开链接
#### 3.1.2 编译
在代码目录demo/CppRpcClientDemo目录下,执行下列命令 ,成功后将会看到可执行文件clientdemo
```bash
mkdir build && cd build && cmake ../ && make
```
#### 3.1.3 运行
先启动lgraph_server，确保rpc端口处于打开状态。

clientdemo程序接收参数如下：
        -h             show this usage
        -i --ip        ip for graph server
        -p --port      port for graph server
        -g --graph     graph name
        -u --user      user name
        --password     user password
        -c --cypher    cypher to query
举例如下
```bash
./clientdemo -i 127.0.0.1 -p 9090 -u admin --password 73@TuGraph -g default -c ""MATCH (n) RETURN n LIMIT 100""
```
### 3.2 Python RPC Client
#### 3.2.1 概述
Python RPC Client是对python语言rpc客户端的简单封装，每次执行时会创建一条到lgraph_server的链接用于发送请求数据以及接收响应结果，执行完毕后进程退出前会断开链接
#### 3.2.2 运行
需要依赖编译生成的python_client.so库，将python_client.so与client_python.py放在同一目录下
先启动lgraph_server，确保rpc端口处于打开状态。

clientdemo程序接收参数如下：
-h             show this usage
-i --ip        ip for graph server
-p --port      port for graph server
-g --graph     graph name
-u --user      user name
--password     user password
-c --cypher    cypher to query
举例如下
```bash
python3 client_python.py -i 127.0.0.1 -p 9090 -u admin --password 73@TuGraph -g default -c ""MATCH (n) RETURN n LIMIT 100""
```
## 4 集成工具

### 4.1 DataX 导入导出工具
#### 4.1.1 概述
DataX 支持 TuGraph 和 MySQL、SQL Server、Oracle、PostgreSQL、HDFS、Hive、HBase、OTS、ODPS、Kafka 等各种异构数据源的数据导入导出。
#### 4.' metadata={'file_name': 'TuGraph-Demo.md', 'file_path': 'demo/TuGraph-Demo.md', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/TuGraph-Demo.md'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}"
TuGraph 支持哪些类型的硬件平台？,"page_content='环境准备

1.硬件环境

1.1. CPU

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的硬件平台，测试认证过的硬件平台包括 Intel、AMD、Kunpeng、Hygon、飞腾等。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.1. CPU'}","page_content='快速上手

1.简介

1.1.支持的平台

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的的平台。' metadata={'Header 1': '快速上手', 'Header 2': '1.简介', 'Header 3': '1.1.支持的平台'}","page_content='环境准备

2.软件环境

2.1. 操作系统

TuGraph 能够兼容主流操作系统，包括Ubuntu、CentOS、SUSE、银河麒麟、 中标麒麟、UOS等，均通过测试认证。  
其中最稳定使用的系统版本是 Ubuntu 18.04、CentOS 7、CentOS 8。' metadata={'Header 1': '环境准备', 'Header 2': '2.软件环境', 'Header 3': '2.1. 操作系统'}"
"我想问一下字节流导入点边数据的api：boolean ret = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000);前两个参数的格式，是不是和执行导入脚本一样","page_content='Python客户端

3.RPC Client

3.12.从字节流中导入点边数据

```python
ret, res = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000)
```
```
importDataFromContent(self: liblgraph_client_python.client, desc: str, data: str, delimiter: str, continue_on_error: bool, thread_nums: int, graph: str, json_format: bool, timeout: float) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.12.从字节流中导入点边数据'}","page_content='C++客户端

2.使用示例

2.12.从字节流中导入点边数据

binary format.
@param [in]  timeout             (Optional) Maximum execution time, overruns will be
interrupted.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='Java客户端

2.使用示例

2.12.从字节流中导入点边数据

@return: the result of import data
public boolean importDataFromContent(String desc, String data, String delimiter, boolean continueOnError,
int threadNums, String graph, double timeout) throws UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}"
什么标签和属性用于表示OGM中类的映射为一个边类型？,"page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

0 映射原理

TuGraph-OGM 将 JAVA 对象映射为图的对象，类映射为点，类的属性映射为图中的属性，类中的方法映射为操作 TuGraph 的查询语句。  
以电影场景为例，对演员、电影、导演之间的关系进行数据化，就形成了非常典型的图数据。举一个简单的示例，演员Alice在1990年和2019年分别出演了两部电影《Jokes》和《Speed》，其中《Jokes》的导演是Frank Darabont。  
以图的思维来看，演员、导演、电影可以被映射为三种不同的节点，而出演、执导可以被映射为两种边，映射结果如上图所示，将数据存入图数据库后，相关的开发人员就可以使用各类图查询语言对数据进行查询。  
但对非图数据库相关的开发人员来说，这个例子中的演员、导演、电影作为实体，同样可以映射为类中的对象，而与实体相关联的对象可以通过集合存储，这是大多数开发人员熟悉的领域。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '0 映射原理'}","page_content='TuGraph-OGM

1.简介

> TuGraph-OGM 项目在其他仓库开源。  
TuGraph-OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。同时 TuGraph-OGM 兼容 Neo4j-OGM，Neo4j 生态用户可以无缝迁移到 TuGraph 数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '1.简介'}","page_content='TuGraph-OGM

简介

TuGraph-OGM(Object Graph Mapping), 源自 `Neo4j-OGM` 项目，TuGraph-OGM
支持将JAVA对象（POJO）映射到TuGraph中，JAVA中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此JAVA开发人员可以在熟悉的生态中轻松地使用TuGraph数据库。同时TuGraph-OGM兼容Neo4j-OGM，Neo4j生态用户可以无缝迁移到TuGraph数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '简介'}"
如果在对 DateTime 对象使用 operator+= 或 operator-= 运算时发生溢出，会如何处理？,"page_content='C++客户端

2.使用示例

2.6.调用存储过程

double procedure_time_out = 0.0, bool in_process = false,
const std::string& graph = ""default"", bool json_format = true,
const std::string& url = """");
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}","page_content='src/cypher/parser/generated/LcypherParser.cpp/ 
// Generated from src/cypher/grammar/Lcypher.g4 by ANTLR 4.13.0


#include ""LcypherVisitor.h""

#include ""LcypherParser.h""


using namespace antlrcpp;
using namespace parser;

using namespace antlr4;

namespace {

struct LcypherParserStaticData final {
  LcypherParserStaticData(std::vector<std::string> ruleNames,
                        std::vector<std::string> literalNames,
                        std::vector<std::string> symbolicNames)
      : ruleNames(std::move(ruleNames)), literalNames(std::move(literalNames)),
        symbolicNames(std::move(symbolicNames)),
        vocabulary(this->literalNames, this->symbolicNames) {}

  LcypherParserStaticData(const LcypherParserStaticData&) = delete;
  LcypherParserStaticData(LcypherParserStaticData&&) = delete;
  LcypherParserStaticData& operator=(const LcypherParserStaticData&) = delete;
  LcypherParserStaticData& operator=(LcypherParserStaticData&&) = delete;

  std::vector<antlr4::dfa::DFA> decisionToDFA;
  antlr4::atn::PredictionContextCache sharedContextCache;
  const std::vector<std::string> ruleNames;
  const std::vector<std::string> literalNames;
  const std::vector<std::string> symbolicNames;
  const antlr4::dfa::Vocabulary vocabulary;
  antlr4::atn::SerializedATNView serializedATN;
  std::unique_ptr<antlr4::atn::ATN> atn;
};

::antlr4::internal::OnceFlag lcypherParserOnceFlag;
#if ANTLR4_USE_THREAD_LOCAL_CACHE
static thread_local
#endif
LcypherParserStaticData *lcypherParserStaticData = nullptr;

void lcypherParserInitialize() {
#if ANTLR4_USE_THREAD_LOCAL_CACHE
  if (lcypherParserStaticData != nullptr) {
    return;
  }
#else
  assert(lcypherParserStaticData == nullptr);
#endif
  auto staticData = std::make_unique<LcypherParserStaticData>(
    std::vector<std::string>{
      ""oC_Cypher"", ""oC_Statement"", ""oC_Query"", ""oC_RegularQuery"", ""oC_Union"", 
      ""oC_SingleQuery"", ""oC_SinglePartQuery"", ""oC_MultiPartQuery"", ""oC_UpdatingClause"", 
      ""oC_ReadingClause"", ""oC_Match"", ""oC_Unwind"", ""oC_Merge"", ""oC_MergeAction""' metadata={'file_name': 'LcypherParser.cpp', 'file_path': 'src/cypher/parser/generated/LcypherParser.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/parser/generated/LcypherParser.cpp'}","page_content='C++客户端

2.使用示例

2.7.向leader调用存储过程

@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.7.向leader调用存储过程'}"
AlterEdgeLabelAddFields函数成功执行的条件是什么？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

in which each `field_value_spec` is a list of string in the form of `[field_name, field_type, field_value, optional]`, where: `field_value` is the default value of the field.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelAddFields(
'vertex',
'new_label',' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

Adds specified fields to the label.  
**Parameters:**  
| parameter    | parameter type | description           |
| ---------------- | -------------- | ------------------------- |
| label_type       | string     | either 'vertex' or 'edge' |
| label_name       | string     | name of the label     |
| field_value_spec | list       | specification of a field  |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelAddFields(
'vertex',
'new_label',
['birth_date', DATE, '', true],
['img', BLOB, '', true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}"
带权图的边权重是什么类型的数值？,"page_content='OlapOnDisk API

2. 算法举例

2.2 配置类MyConfig

MyConfig配置类函数用于提供算法逻辑计算时所需的配置信息，继承于ConfigBase<EdgeData>,其中EdgeDate可根据加载图类型不同选择Empty（无权图）、int（带权图权重为整数）或者double（带权图权重为double）类型。  
MyConfig配置类一般根据算法不同，需要额外配置信息如下：  
1.算法所需参数
2.算法名称
3.配置类内Print函数
其余公用成员继承与ConfigBase，可参考src/olap/olap_config.h查阅。  
```C++
class MyConfig : public ConfigBase<Empty> {
public:' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.2 配置类MyConfig'}","page_content='Python Olap API

4. Olap API

自定义数据结构

- `neighbour: size_t`：边的邻居点
- `edge_data: EdgeData`：边的权值
- `AdjList[EdgeData]`：权值类型为EdgeData的点的邻接表，常用于表示点的入边和出边集合，包含两个成员变量：
- `begin()-> cython.pointer(AdjUnit[T])`：列表的起始指针
- `end()-> cython.pointer(AdjUnit[T])`：列表的结束指针。
- `operator[](i: size_t)-> AdjUnit[EdgeData]`: 下标为i的数据' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '自定义数据结构'}","page_content='Traversal API

2. 接口说明

2.1. Snapshot

C++ OLAP API 中的 Snapshot 模版类用于表示抽取出来的静态子图，其中 EdgeData 用来表示该子图上每条边所用权值的数据类型（如果边不需要权值，使用 Empty 作为 EdgeData 即可）。  
抽取的子图通过 Snapshot 类的构造函数来描述：  
```c
Snapshot::Snapshot(
GraphDB & db,
Transaction & txn,
size_t flags = 0,
std::function<bool(VertexIterator &)> vertex_filter = nullptr,
std::function<bool(OutEdgeIterator &, EdgeData &)> out_edge_filter = nullptr
);
```' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.1. Snapshot'}"
RPC 是一种如何工作的通信协议？,"page_content='RPC API

1.简介

TuGraph 提供丰富的 RPC API，以供开发者通过 RPC 请求远程调用 TuGraph 提供的服务。  
RPC（远程过程调用）是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。
相比REST，RPC 面向方法，主要用于函数方法的调用，可以适合更复杂通信需求的场景，且性能更高。
brpc是用c++语言编写的工业级RPC框架，基于brpc，TuGraph 提供了丰富的RPC API，本文档描述
TuGraph 的 RPC API 使用方式。' metadata={'Header 1': 'RPC API', 'Header 2': '1.简介'}","page_content='C++客户端

1.概述

C++ Client 能够使用 RPC 连接lgraph_server，进行数据导入、执行存储过程、调用Cypher等操作。' metadata={'Header 1': 'C++客户端', 'Header 2': '1.概述'}","page_content='src/server/db_management_client.cpp/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#include ""client/cpp/rpc/rpc_exception.h""
#include ""server/db_management_client.h""

namespace lgraph {

DEFINE_string(mgr_protocol, ""baidu_std"", ""Protocol type. Defined in src/brpc/options.proto"");
DEFINE_string(mgr_connection_type, """", ""Connection type. Available values: single, pooled, short"");
DEFINE_int32(mgr_timeout_ms, 60 * 60 * 1000, ""RPC timeout in milliseconds"");
DEFINE_int32(mgr_max_retry, 3, ""Max retries(not including the first RPC)"");
DEFINE_string(mgr_load_balancer, """", ""The algorithm for load balancing"");
// DEFINE_bool(usercode_in_pthread);

DBManagementClient::DBManagementClient()
    : exit_(false),
      connected_(false),
      heartbeat_count_(0),
      heartbeat_interval_(10),
      channel_(std::make_shared<brpc::Channel>()) {}

void DBManagementClient::Init(const std::string& hostname, const uint16_t port,
                              const std::string& url) {
    host_ = hostname;
    port_ = std::to_string(port);

    // Initialize brpc channel to DbManagement
    brpc::ChannelOptions options;
    options.protocol = FLAGS_mgr_protocol;
    options.connection_type = FLAGS_mgr_connection_type;
    options.timeout_ms = FLAGS_mgr_timeout_ms;
    options.max_retry = FLAGS_mgr_max_retry;
    if (channel_->Init(url.c_str(), FLAGS_mgr_load_balancer.c_str(), &options) != 0) {
        throw RpcException(""failed to initialize channel."");
    }
}

void DBManagementClient::DetectHeartbeat() {
    DbMgr::JobManagementService_Stub stub(channel_.get());
    static const uint64_t MA' metadata={'file_name': 'db_management_client.cpp', 'file_path': 'src/server/db_management_client.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/server/db_management_client.cpp'}"
TuGraph中主键的作用是什么？,"page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.3 通过OGM进行增操作**

OGM支持对TuGraph的实体执行CRUD 操作，同时支持发送任意TuGraph支持的Cypher语句，包括通过CALL调用存储过程。  
**CREATE**  
在完成图对象的构建后，即可通过类的实例化创建节点，当两个节点互相存储在对方的集合（该集合在构建时被标注为边）中，就形成了一条边，最后使用session.save方法将数据存入数据库。  
注意：TuGraph数据库为强schema类型数据库，在创建实体前需要该数据的label已经存在，且新建过程中需要提供唯一的主键。  
```
Movie jokes = new Movie（""Jokes""，1990）； // 新建Movie节点jokes session.save(jokes); // 将jokes存储在TuGraph中

Movie speed = new Movie(""Speed"", 2019);

Actor alice = new Actor(""Alice Neeves"");

alice.actsIn(speed);

session.save(speed);' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.3 通过OGM进行增操作**'}"
RpcException是什么类型的异常？,"page_content='RPC API

2.请求

2.1.建立连接

options->protocol = ""baidu_std"";
options->connection_type = """";
options->timeout_ms = 60 * 60 * 1000 /*milliseconds*/;
options->max_retry = 3;
std::string load_balancer = """";
std::shared_ptr<lgraph_rpc::m_channel> channel = std::make_shared<lgraph_rpc::m_channel>();
if (channel->Init(url.c_str(), load_balancer, options.get()) != 0)
throw RpcException(""Fail to initialize channel"");
LGraphRPCService_Stub stub(channel.get());
```' metadata={'Header 1': 'RPC API', 'Header 2': '2.请求', 'Header 3': '2.1.建立连接'}","page_content='src/client/cpp/rpc/rpc_exception.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <exception>
#include <string>

#include ""core/data_type.h""

namespace lgraph {
class RpcException : public std::exception {
    std::string err_;

 public:
    explicit RpcException(const std::string& err) : err_(""rpc exception: "" + err) {}

    const char* what() const noexcept override { return err_.c_str(); }
};

class RpcStatusException : public RpcException {
 public:
    explicit RpcStatusException(const std::string& code)
        : RpcException(""Server returned error: "" + code) {}
};

class RpcConnectionException : public RpcException {
 public:
    explicit RpcConnectionException(const std::string& msg)
        : RpcException(""Connection failed: "" + msg) {}
};
}  // namespace lgraph
' metadata={'file_name': 'rpc_exception.h', 'file_path': 'src/client/cpp/rpc/rpc_exception.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/client/cpp/rpc/rpc_exception.h'}","page_content='RPC API

5.存储过程

5.1.加载存储过程

LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
加载存储过程的响应不包含参数，如果加载失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.1.加载存储过程'}"
match语句中是否支持set多个属性,"page_content='Cypher API

2.Clauses

2.7.CREATE

```  
- ✓ Create a relationship and set properties  
```
MATCH (n:person), (m:movie)
WHERE n.name = 'Jada Pinkett Smith' AND m.title = 'The Matrix'
CREATE (n)-[r:acted_in{role: 'Trinity'}]->(m)
```  
- ❏ Create a full path  
```
CREATE p = (andres:person {id: 2005, name:'Andres'})-[:acted_in {role: 'Trinity'}]->
(m:movie {id: 2006})<-[:acted_in {role: 'Trinity'}]-(michael {id: 2006, name:'Michael'})
RETURN p
```  
- Use parameters with CREATE' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.7.CREATE'}","page_content='Cypher API

2.Clauses

2.2.MATCH

```
- Get node or relationship by id  
- ✓ Node by id  
```
MATCH (n)
WHERE id(n)= 0
RETURN n
```  
- ✓ Relationship by id  
```
MATCH ()-[r]->()
WHERE euid(r) = ""0_3937_0_0_0""
RETURN r
```  
- ✓ Multiple nodes by id  
```
MATCH (n)
WHERE id(n) IN [0, 3, 5]
RETURN n
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.2.MATCH'}","page_content='ISO GQL

2.Clauses

2.4.NEXT

`NEXT`子句用于连接多个子句。  
#### 连接MATCH  
```
MATCH (n:Person) WHERE n.birthyear = 1970
RETURN n
NEXT
MATCH (m:Person) WHERE m.birthyear < 1968
RETURN n.name, n.birthyear, m.name LIMIT 2
```  
返回结果
```JSON
[{""m.name"":""Rachel Kempson"",""n.birthyear"":1970,""n.name"":""Christopher Nolan""},{""m.name"":""Michael Redgrave"",""n.birthyear"":1970,""n.name"":""Christopher Nolan""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.4.NEXT'}"
TuGraph DB关于Antlr4改进了哪些性能方面的内容？,"page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

关于 Antlr4

Antlr4 是一款备受欢迎的开源解析器生成器，能够根据语法规则快速生成自定义解析器。其支持 LL(\*)解析，拥有更强大的错误处理能力和更快的解析速度。不仅如此，Antlr4 还支持 Java、Python、C++、JavaScript、Go 等 10 种目标语言，广泛应用于多种开发语言生态中。简单易用的 API 和文档使得开发人员能够快速上手。无论是编程语言、数据格式、编译器还是解释器等领域，Antlr4 都发挥着重要作用。  
著名的开源项目如 Apache Spark、Eclipse IDE 和 MongoDB 等都选择了 Antlr4。 对于语言工具开发者而言，Antlr4 是不可或缺的工具，能大幅提高开发效率和代码质量。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '关于 Antlr4'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

贡献和成果

对Antlr4的优化的效果十分显著，32 线程的并发性能提升超过 18 倍 。考虑到实际生产服务器性能远高于测试机型，实际的性能提升效果将比测试结果更高， 优化后 GQL 解析能力已能完全满足企业业务的需要。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '贡献和成果'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

当 TuGraph 遇见 Antlr4

ISO GQL（ISO/IEC 39075）是一种标准化的图数据库查询语言，蚂蚁集团是其主要贡献者之一。因此，Antlr4 作为一种强大的解析器生成器，成为了蚂蚁图数据库 TuGraph 生成 GQL 解释器的理想选择。Antlr4 能够帮助团队更快、更准确地构建图数据库的查询语言，从而提高产品性能和用户体验。  
然而，当我们从开发场景来到生产场景，超高的并发量带来一个严重问题：Antlr4 C++ target 的并发性能不足以支持所需的超高并发 GQL 请求。经过调研并与 Antlr 开源社区讨论，我们发现\*\*并发性能这个问题普遍存在，并且在过去 5 年中持续困扰着 C++生态的开发者。\*\*我们决定解决这个问题。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '当 TuGraph 遇见 Antlr4'}"
TuGraph 和 OpenCypher 在处理节点和关系的标签数量上有什么不同？,"page_content='Cypher API

4.附录1. 语法扩充及不同

TuGraph查询语言与OpenCypher的不同点如下：  
- Label数量
- TuGraph: Each node/relationship must have one and only one label. So error occurs when there is no label, and the 1st label will be picked as the label if there are more than one label.
- OpenCypher: One node/relationship may have 0 to many labels.
- Schema.
- TuGraph: TuGraph has strong schema
- OpenCypher: schema-less' metadata={'Header 1': 'Cypher API', 'Header 2': '4.附录1. 语法扩充及不同'}","page_content='Cypher API

3.Functions

3.6.Mathematical functions

TuGraph 查询语言与 OpenCypher 的不同点如下：  
- Label 数量
- TuGraph: Each node/relationship must have one and only one label. So error occurs when there is no label, and the 1st label will be picked as the label if there are more than one label.
- OpenCypher: One node/relationship may have 0 to many labels.
- Schema.
- TuGraph: TuGraph has strong schema
- OpenCypher: schema-less' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.6.Mathematical functions'}","page_content='Cypher API

3.Functions

3.6.Mathematical functions

**Scope:** whole instance.
**Example input:**  
```
RETURN sign(-17), sign(0.1)
```  
**Example output:**  
| sign(-17) | sign(0.1) |
| --------- | --------- |
| -1        | 1         |  
TuGraph 查询语言与 OpenCypher 的不同点如下：  
- Label 数量
- TuGraph: Each node/relationship must have one and only one label. So error occurs when there is no label, and the 1st label will be picked as the label if there are more than one label.' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.6.Mathematical functions'}"
函数DeleteVertexIndex成功执行时返回什么值？,"page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

""name"": ""Natasha Richardson""
},
""label"": ""Person""
}
```  
#### 6.7.5.删除点  
- **URI**: `/db/{graph_name}/node/{vertex_id}`
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| in | 被删掉的点的入边数量 | 整数值 |
| out | 被删掉的点的出边数量 | 整数值 |  
**Example request.**  
```
• DELETE http://localhost:7070/db/{graph_name}/node/4
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}","page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

```
• GET http://localhost:7070/db/{graph_name}/node/5
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""property"": {
""birthyear"": 1963,
""name"": ""Natasha Richardson""
},
""label"": ""Person""
}
```  
#### 6.7.5.删除点  
- **URI**: `/db/{graph_name}/node/{vertex_id}`
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| in | 被删掉的点的入边数量 | 整数值 |' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}","page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

| --- | --- | --- |
| in | 被删掉的点的入边数量 | 整数值 |
| out | 被删掉的点的出边数量 | 整数值 |  
**Example request.**  
```
• DELETE http://localhost:7070/db/{graph_name}/node/4
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""in"": 0,
""out"": 0
}
```  
#### 6.7.6.获取点所有属性  
- **URI**: `/db/{graph_name}/node/{vertex_id}/property`
- **METHOD**: GET
- **RESPONSE**: Node 所有属性（字典）  
**Example request.**  
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}"
现在tugraph-analytics是不支持窗口函数吗？,"page_content='🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！

仅需 5 步，即可呈现 🎊

4. 演示

<img width=""332"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/7ca76607-41a1-4afe-9427-cf7599de6889"">  
同样的，Tugraph Analytics 终端也会实时输出操作信息，并自动启动计算任务。  
<img width=""611"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/d8d0d73a-4c07-4ecd-bcac-4633a742933a"">' metadata={'Header 1': '🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！', 'Header 2': '仅需 5 步，即可呈现 🎊', 'Header 3': '4. 演示'}","page_content='🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！

仅需 5 步，即可呈现 🎊

1. 启动 GeaFlow 流图作业和 Socket 服务

参考 [快速开始](https://github.com/TuGraph-family/tugraph-analytics/blob/master/docs/docs-cn/quick_start.md)  
⚠️ 注意在 `启动SocketServer` 步骤使用下列命令代替  
```bash
bin/socket.sh 9003 GI
```  
输出下列内容时，即表示 Tugraph Analytics 准备好建立连接  
<img width=""610"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/a25ed6ba-4fb9-4db1-9325-ee2f26a4337f"">  
> 如启动服务过程中遇到问题，可见 https://github.com/TuGraph-family/tugraph-analytics/issues/1' metadata={'Header 1': '🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！', 'Header 2': '仅需 5 步，即可呈现 🎊', 'Header 3': '1. 启动 GeaFlow 流图作业和 Socket 服务'}","page_content='QA汇总

内核引擎QA

边支持索引

Q: TuGraph 的边是否支持索引？
A: TuGraph 在引擎层支持边索引，可通过存储过程使用。Cypher的边索引功能正在开发支持中。' metadata={'Header 1': 'QA汇总', 'Header 2': '内核引擎QA', 'Header 3': '边支持索引'}"
当调用CallProcedure函数时，如果设置json_format参数为false，返回的结果格式是什么？,"page_content='C++客户端

2.使用示例

2.6.调用存储过程

binary format.
@param [in]  url                 (Optional) Node address of calling procedure.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}","page_content='C++客户端

2.使用示例

2.6.调用存储过程

interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  url                 (Optional) Node address of calling procedure.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}","page_content='Python客户端

3.RPC Client

3.6.调用存储过程

```python
ret, res = client.callProcedure(""CPP"", ""test_plugin1"", ""bcefg"", 1000, False, ""default"")
```
```
callProcedure(self: liblgraph_client_python.client, procedure_type: str, procedure_name: str, param: str, procedure_time_out: float, in_process: bool, graph: str, json_format: bool, url: str) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.6.调用存储过程'}"
在 PathTraversal 类中，通过调用哪个函数来通过传入的过滤器设置初始边界？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

std::function<bool(InEdgeIterator &, Path &, IteratorHelper &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &, Path &, IteratorHelper &)> out_neighbour_filter = nullptr,
std::function<bool(VertexIterator &, Path &, IteratorHelper &)> in_neighbour_filter = nullptr
);
```  
PathTraversal 的三种遍历方式与 FrontierTraversal 类似，只是用户自定义的过滤函数中增加了两个参数，其中：Path 包含了到新扩展的这条边之前的路径，IteratorHelper 可用于将路径中的点/边转为数据库中对应的迭代器，相关文档可参考对应的 C++ API 文档。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}"
GeaBase的主要部署方式需要多长时间？,"page_content='运维监控

2.部署方案

2.4.第四步

""for"": ""5m"",
""frequency"": ""1m"",
""handler"": 1,
""message"": ""【生产图数据库Grafana】\n  QPS超过1000"",
""name"": ""请求统计 alert"",
""noDataState"": ""no_data"",
""notifications"": []
},
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""axisLabel"": """",
""axisPlacement"": ""auto"",
""barAlignment"": 0,
""drawStyle"": ""line"",
""fillOpacity"": 7,
""gradientMode"": ""none"",
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
},' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}","page_content='Console平台介绍

部署架构

GeaFlow支持多种异构环境执行，以常见的K8S部署环境为例，GeaFlow物理部署架构如下：  
![deploy_arch](../../static/img/deploy_arch.png)  
在GeaFlow作业的全生命周期过程中，涉及的关键数据流程有：  
* **研发阶段**：Console平台提供了实例下所有的研发资源的管理，用户可以在创建任务前，提前准备所需的研发资源信息，并存储在Catalog。
* **构建阶段**：任务创建完成后，通过发布动作触发构建流水线，用户的JAR包、任务的ZIP包等会上传到RemoteFileStore。' metadata={'Header 1': 'Console平台介绍', 'Header 2': '部署架构'}","page_content='部署高可用模式

5.横向扩展其他服务器

启动初始备份组后，如果想对备份组进行横向扩展，要将新服务器添加到备份组，
应使用`--ha_conf HOST：PORT`选项，其中`HOST`可以是该备份组中已有的任何服务器的 IP 地址，
而`PORT`是其 RPC 端口。例如：  
```bash
./lgraph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090
```  
此命令将启动一台高可用模式的 TuGraph 服务器，并尝试将其添加到包含服务器`172.22.224.15:9090`的备份组中。
请注意，加入备份组需要服务器将其数据与备份组的`leader`服务器同步，此过程可能需要相当长的时间，具体取决于数据的大小。' metadata={'Header 1': '部署高可用模式', 'Header 2': '5.横向扩展其他服务器'}"
在图论中，图的基本元素包括哪些？,"page_content='图相关DDL

Create Graph

**Syntax**
一个图至少包含一对点边，点表必须包含一个id字段作为主键，边表必须包含srcId和targetId作为主键，边表还可以有一个时间戳字段标识时间。  
```
CREATE GRAPH <graph name>
(
<graph vertex>
[ { , <graph vertex> } ... ]
, <graph edge>
[ { , <graph edge> } ... ]
) WITH （
storeType = <graph store type>
[ { , <config key> = <config value> } ... ]
);

<graph vertex>  ::=
VERTEX <vertex name>
(
<column name> <data type> ID
[ {, <column name> <data type> } ... ]
)' metadata={'Header 1': '图相关DDL', 'Header 2': 'Create Graph'}","page_content='图算法介绍

5.2 图迭代推理

if (vertex != null) {
List<IEdge<Integer, Integer>> newEs = temporaryGraph.getEdges();
List<IEdge<Integer, Integer>> oldEs = historicalGraph.getSnapShot(lastVersionId)
.edges().getOutEdges();
if (newEs != null) {
for (IEdge<Integer, Integer> edge : newEs) {
graphContext.sendMessage(edge.getTargetId(), vertexId);
}
}
if (oldEs != null) {
for (IEdge<Integer, Integer> edge : oldEs) {
graphContext.sendMessage(edge.getTargetId(), vertexId);
}
}
}

}' metadata={'Header 1': '图算法介绍', 'Header 2': '5.2 图迭代推理'}","page_content='图算法介绍

1\. 图算法概述

在计算机科学中，图是一种表示实体（节点或顶点）以及实体之间关系（边）的数据结构。图模型可以天然地描述网络结构，能更清晰地表达复杂的数据关系和依赖，简化关联数据的理解和分析。在不同的场景下，图中点边具备不同的语义信息。比如在资金交易场景下，每个人可以抽象成一个点表示，人与人之间的转账关系可以抽象成一条边表示。通过图数据模型反映出各个实体之间的资金往来关系，让数据的关联分析更加直观和高效。  
在图数据模型上可以执行多种图算法，如社区检测，最短路径匹配，环路检测算法等。通过点边上的迭代计算，探索图模型中各个实体之间的关系。探索过程不依赖于数据的线性结构，从而便于识别隐藏的模式和关联关系。在主流迭代图算法中，节点通过消息传递的方式进行通信。每次迭代，节点可以接收来自它们邻居的消息，处理这些消息，然后决定是否发送新的消息给其他节点。迭代算法中，每个节点有一个状态，每次迭代它们都有可能更新这个状态直至收敛。例如，在PageRank算法中，每个节点的状态是其PageRank值，这个值在迭代过程中会随着邻居的值的更新而更新。' metadata={'Header 1': '图算法介绍', 'Header 2': '1\\. 图算法概述'}"
TuGraph支持哪些编程语言？,"page_content='Procedure API

3.存储过程语言支持

在 TuGraph 中，用户可以动态的加载，更新和删除存储过程。TuGraph 支持 C++ 语言、 Python 语言和 Rust 语言编写存储过程。在性能上 C++ 语言支持的最完整，性能最优。  
注意存储过程是在服务端编译执行的逻辑，和客户端的语言支持无关。' metadata={'Header 1': 'Procedure API', 'Header 2': '3.存储过程语言支持'}","page_content='RPC API

5.存储过程

为满足用户较为复杂的查询/更新逻辑，TuGraph支持 C 语言和 Python 语言编写的存储过程。
用户可以使用RPC请求对存储过程进行增删改查操作。' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程'}","page_content='功能概览

4.核心功能

4.2.存储过程

当用户需要表达的查询/更新逻辑较为复杂（例如 Cypher 无法描述，或是对性能要求较高）时，相比调用多个 REST 请求并在客户端完成整个
处理流程的方式，TuGraph 提供的存储过程（Procedure）是更简洁和高效的选择。  
从 3.5 版本开始，TuGraph 重新设计了新的存储过程编程范式，支持定义标准的签名和结果，支持POG编程。  
TuGraph 支持 POG (Procedres on Graph Query Languages) 编程和 POG 库，其中“Graph Query Languages”包含 Cypher 以及
制定中的 ISO GQL 等图查询语言。POG 库提供在查询语言中对用户定义的存储过程的访问，打破了查询语言和存储过程之间的界限，扩展了查询
语言的使用范围。  
> 这个文档描述了 [新的 Procedure 编程范式以及 POG](../9.olap&procedure/1.procedure/1.procedure.md)。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.2.存储过程'}"
在这段代码中，如何获取存储过程响应的列表？,"page_content='RESTful API Legacy

5.存储过程

5.2.列出所有存储过程

- **URI**: `/db/{graph_name}/cpp_plugin|python_plugin`
- **METHOD**: GET
- **RESPONSE**: 存储过程列表，其中每个元素是一个 plugin 的描述，其格式为：
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | 存储过程名 | 字符串 |
| description | 存储过程描述 | 字符串 |
| read_only | 存储过程是否只读 | 布尔值 |  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/cpp_plugin
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
Output:
{
[
{
""description"":""adds a vertex label to the db"",' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程', 'Header 3': '5.2.列出所有存储过程'}","page_content='Procedure API

4.2.如何使用存储过程

4.2.2.列出已加载的存储过程

在服务器运行过程中，用户可以随时获取存储过程列表。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin')
>>> r.status_code
200
>>> r.text
'{""plugins"":[{""description"":""Custom Page Rank Procedure"", ""name"":""age_10"", ""read_only"":true}]}'
```' metadata={'Header 1': 'Procedure API', 'Header 2': '4.2.如何使用存储过程', 'Header 3': '4.2.2.列出已加载的存储过程'}","page_content='Procedure API

5.Procedure v2接口

5.2.加载存储过程

#### 5.2.1.列出已加载的存储过程  
在服务器运行过程中，用户可以随时获取存储过程列表。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin')
>>> r.status_code
200
>>> r.text
'{""plugins"":[{""description"":""Custom Page Rank Procedure"", ""name"":""custom_pagerank"", ""read_only"":true}]}'
```  
#### 5.2.2.获取存储过程详情  
在服务器运行过程中，用户可以随时获取单个存储过程的详情，包括代码。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin/custom_pagerank')
>>> r.status_code
200
>>> r.text' metadata={'Header 1': 'Procedure API', 'Header 2': '5.Procedure v2接口', 'Header 3': '5.2.加载存储过程'}"
什么是RPC接口？,"page_content='RPC API

1.简介

TuGraph 提供丰富的 RPC API，以供开发者通过 RPC 请求远程调用 TuGraph 提供的服务。  
RPC（远程过程调用）是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。
相比REST，RPC 面向方法，主要用于函数方法的调用，可以适合更复杂通信需求的场景，且性能更高。
brpc是用c++语言编写的工业级RPC框架，基于brpc，TuGraph 提供了丰富的RPC API，本文档描述
TuGraph 的 RPC API 使用方式。' metadata={'Header 1': 'RPC API', 'Header 2': '1.简介'}","page_content='Python客户端

3.RPC Client

Python的TuGraph Rpc Client是使用pybind11包装的CPP Client SDK，下表列出了Python和CPP Client SDK的对应关系。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client'}","page_content='demo/TuGraph-Demo.md/ # TuGraph 示例

## 1 简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph是TuGraph的曾用名。

主要功能特征包括：

- 支持属性图模型
- 原生图存储及处理
- 完全的ACID事务支持
- 支持OpenCypher图查询语言
- 支持原生的Core API和Traversal API
- 支持REST和RPC接口
- 支持CSV、JSON、MySQL等多数据源导入导出
- 支持可视化图交互
- 支持命令行交互
- 内置用户权限控制、操作审计
- 支持任务和日志的监控管理
- 原生适配PandaGraph图分析引擎
- 集成DGL图神经网络系统

性能及可扩展性特征包括：

- 支持TB级大容量
- 吞吐率高达千万顶点每秒
- 面向读优化的存储引擎
- 支持高可用模式
- 支持离线备份恢复
- 在线热备份
- 高性能批量导入导出

## 2 快速上手

见QuickStart文档。

## 3 基本功能

### 3.1 RPC Client
#### 3.1.1 概述
RPC Client是对cpp语言rpc客户端的简单封装，每次执行时会创建一条到lgraph_server的链接用于发送请求数据以及接收响应结果，执行完毕后进程退出前会断开链接
#### 3.1.2 编译
在代码目录demo/CppRpcClientDemo目录下,执行下列命令 ,成功后将会看到可执行文件clientdemo
```bash
mkdir build && cd build && cmake ../ && make
```
#### 3.1.3 运行
先启动lgraph_server，确保rpc端口处于打开状态。

clientdemo程序接收参数如下：
        -h             show this usage
        -i --ip        ip for graph server
        -p --port      port for graph server
        -g --graph     graph name
        -u --user      user name
        --password     user password
        -c --cypher    cypher to query
举例如下
```bash
./clientdemo -i 127.0.0.1 -p 9090 -u admin --password 73@TuGraph -g default -c ""MATCH (n) RETURN n LIMIT 100""
```
### 3.2 Python RPC Client
#### 3.2.1 概述
Python RPC Client是对python语言rpc客户端的简单封装，每次执行时会创建一条到lgraph_server的链接用于发送请求数据以及接收响应结果，执行完毕后进程退出前会断开链接
#### 3.2.2 运行
需要依赖编译生成的python_client.so库，将python_client.so与client_python.py放在同一目录下
先启动lgraph_server，确保rpc端口处于打开状态。

clientdemo程序接收参数如下：
-h             show this usage
-i --ip        ip for graph server
-p --port      port for graph server
-g --graph     graph name
-u --user      user name
--password     user password
-c --cypher    cypher to query
举例如下
```bash
python3 client_python.py -i 127.0.0.1 -p 9090 -u admin --password 73@TuGraph -g default -c ""MATCH (n) RETURN n LIMIT 100""
```
## 4 集成工具

### 4.1 DataX 导入导出工具
#### 4.1.1 概述
DataX 支持 TuGraph 和 MySQL、SQL Server、Oracle、PostgreSQL、HDFS、Hive、HBase、OTS、ODPS、Kafka 等各种异构数据源的数据导入导出。
#### 4.' metadata={'file_name': 'TuGraph-Demo.md', 'file_path': 'demo/TuGraph-Demo.md', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/TuGraph-Demo.md'}"
在文本中，The Matrix参与了哪几种类型的关系？,"page_content='Cypher API

2.Clauses

2.2.MATCH

```
MATCH (matrix:movie {title: 'The Matrix'})<-[:acted_in]-(actor)
RETURN actor.name
```  
- ✓ Match on multiple relationship types  
```
MATCH (matrix {title: 'The Matrix'})<-[:acted_in|:directed]-(person)
RETURN person.name
```  
- ✓ Match on relationship type and use a variable  
```
MATCH (matrix {title: 'The Matrix'})<-[r:acted_in]-(actor)
RETURN r.role
```
- Relationships in depth  
- ❏ Relationship types with uncommon characters  
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.2.MATCH'}","page_content='Cypher API

2.Clauses

2.2.MATCH

RETURN person.name
```  
- ✓ Match on relationship type and use a variable  
```
MATCH (matrix {title: 'The Matrix'})<-[r:acted_in]-(actor)
RETURN r.role
```
- Relationships in depth  
- ❏ Relationship types with uncommon characters  
```
MATCH (n {name: 'Rob Reiner'})-[r:`TYPE WITH SPACE`]->()
RETURN type(r)
```  
- ✓ Multiple relationships  
```
MATCH (laurence {name: 'Laurence Fishburne'})-[:acted_in]->(movie)<-[:directed]-(director)
RETURN movie.title, director.name' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.2.MATCH'}","page_content='Cypher API

2.Clauses

2.2.MATCH

```
MATCH (:person {name: 'Laurence Fishburne'})-[]->(movie)
RETURN movie.title
```  
- ✓ Directed relationships and variable  
```
MATCH (:person {name: 'Laurence Fishburne'})-[r]->(movie)
RETURN type(r)
```  
- ✓ Match on relationship type  
```
MATCH (matrix:movie {title: 'The Matrix'})<-[:acted_in]-(actor)
RETURN actor.name
```  
- ✓ Match on multiple relationship types  
```
MATCH (matrix {title: 'The Matrix'})<-[:acted_in|:directed]-(person)
RETURN person.name
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.2.MATCH'}"
使用什么命令启动 TuGraph 服务器？,"page_content='数据库运行

3.服务操作

3.1.启动服务

TuGraph 需要通过 `lgraph_server -d start` 命令行启动，启动命令示例如下：  
```bash
$ ./lgraph_server -d start -c lgraph.json
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.1.启动服务'}","page_content='数据库运行

2.运行模式

2.2.运行进程守护模式

启动命令：  
```shell
$ ./lgraph_server -d start -c lgraph.json
```  
守护模式的运行输出示例：  
```shell
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '2.运行模式', 'Header 3': '2.2.运行进程守护模式'}","page_content='TuGraph Management

使用

TuGraph Management使用Maven进行管理，请运行如下命令启动TuGraph Management  
`mvn spring-boot:run`  
TuGraph Management 使用了sofastack框架，并使用brpc与TuGraph进行通信，sofastack默认端口为`6071`，brpc默认端口为`6091`，如需修改服务端口，请修改`./src/main/resources/application.properties`文件中的对应配置项。' metadata={'Header 1': 'TuGraph Management', 'Header 2': '使用'}"
如果在添加顶点时存在相同的unique_id，将会发生什么？,"page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.addEdgeIndex(label_name, field_name, unique, pair_unique)

| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |
| pair_unique | boolean    | Specifies whether the index is pair_unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.addEdgeIndex('BornIn', 'id', true, false)
```  
**Example output:**  
```
Added index [BornIn:id]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addEdgeIndex(label_name, field_name, unique, pair_unique)'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}"
TuGraph 支持哪些硬件架构？,"page_content='环境准备

1.硬件环境

1.1. CPU

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的硬件平台，测试认证过的硬件平台包括 Intel、AMD、Kunpeng、Hygon、飞腾等。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.1. CPU'}","page_content='快速上手

1.简介

1.1.支持的平台

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的的平台。' metadata={'Header 1': '快速上手', 'Header 2': '1.简介', 'Header 3': '1.1.支持的平台'}","page_content='TuGraph与ARM架构

摘要：

- TuGraph适配国产ARM架构处理器，又双叒叕打破了LDBC SNB世界纪录，较之前纪录提升31%，云端机器开销降低了40%，大大提升了资源能效。  
- 验证了TuGraph对于ARM架构的兼容性，成为对X86和ARM架构均完整适配的图数据库，也使得TuGraph继麒麟、鲲鹏、海光等国产操作系统和处理器之后，**实现了对国产软硬件的全面支持，为用户的机器选型提供更多选择**。  
- 我们还测试了数据量大于内存的情况，结果显示，性能只下降了20%左右，显示了TuGraph在大规模数据下的适用性。  
TuGraph图数据库GitHub仓库：https://github.com/tugraph-family/tugraph-db' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '摘要：'}"
TuGraph-OGM项目如何面向TuGraph数据库支持JAVA开发人员进行图对象映射？,"page_content='TuGraph-OGM

1.简介

> TuGraph-OGM 项目在其他仓库开源。  
TuGraph-OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。同时 TuGraph-OGM 兼容 Neo4j-OGM，Neo4j 生态用户可以无缝迁移到 TuGraph 数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '1.简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

0 映射原理

TuGraph-OGM 将 JAVA 对象映射为图的对象，类映射为点，类的属性映射为图中的属性，类中的方法映射为操作 TuGraph 的查询语句。  
以电影场景为例，对演员、电影、导演之间的关系进行数据化，就形成了非常典型的图数据。举一个简单的示例，演员Alice在1990年和2019年分别出演了两部电影《Jokes》和《Speed》，其中《Jokes》的导演是Frank Darabont。  
以图的思维来看，演员、导演、电影可以被映射为三种不同的节点，而出演、执导可以被映射为两种边，映射结果如上图所示，将数据存入图数据库后，相关的开发人员就可以使用各类图查询语言对数据进行查询。  
但对非图数据库相关的开发人员来说，这个例子中的演员、导演、电影作为实体，同样可以映射为类中的对象，而与实体相关联的对象可以通过集合存储，这是大多数开发人员熟悉的领域。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '0 映射原理'}","page_content='TuGraph-OGM

简介

TuGraph-OGM(Object Graph Mapping), 源自 `Neo4j-OGM` 项目，TuGraph-OGM
支持将JAVA对象（POJO）映射到TuGraph中，JAVA中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此JAVA开发人员可以在熟悉的生态中轻松地使用TuGraph数据库。同时TuGraph-OGM兼容Neo4j-OGM，Neo4j生态用户可以无缝迁移到TuGraph数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '简介'}"
OPTIONAL MATCH在GQL中有什么作用？,"page_content='ISO GQL

2.Clauses

2.2.OPTIONAL MATCH

`OPTIONAL MATCH`匹配图模式，如果未命中，则返回`null`。  
#### 查询命中  
```
OPTIONAL MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
#### 查询未命中  
```
OPTIONAL MATCH (n:Person{name:'Redgrave Michael'})
RETURN n.birthyear
```  
返回结果  
```JSON
[{""n.birthyear"":null}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.2.OPTIONAL MATCH'}","page_content='ISO GQL

2.Clauses

2.1.MATCH

`MATCH`子句式是GQL最基础的子句，几乎所有查询都是通过 `MATCH`展开。  
`MATCH`子句用于指定在图中搜索的匹配模式，用来匹配满足一定条件的点或者路径。  
#### 点查询  
##### 查询所有点  
```
MATCH (n)
RETURN n
```  
##### 查询特定标签的点  
```
MATCH (n:Person)
RETURN n
```  
##### 通过属性匹配点  
```
MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
##### 通过过滤条件匹配点  
```
MATCH (n:Person WHERE n.birthyear > 1910)
RETURN n.name LIMIT 2
```  
返回结果
```JSON' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.1.MATCH'}","page_content='ISO GQL

2.Clauses

| 类别                | 子句           |
| ------------------- | -------------- |
| Reading clauses     | MATCH          |
|                     | OPTIONAL MATCH |
| Projecting clauses  | RETURN         |
|                     | NEXT           |
| Reading sub-clauses | WHERE          |
|                     | ORDER BY       |
|                     | SKIP           |
|                     | LIMIT          |' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses'}"
loadProcedure方法中，如何通过参数控制存储过程是否为只读？,"page_content='Java客户端

2.使用示例

2.8.加载存储过程

@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param codeType: code type, currently supported PY, SO, CPP, ZIP
@param procedureDescription: procedure description
@param readOnly: procedure is read only or not
@param version: The version of procedure
@param graph: the graph to query.
@return: the result of procedure execution' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.8.加载存储过程'}","page_content='C++客户端

2.使用示例

2.8.加载存储过程

@param [in]  procedure_name          procedure name.
@param [in]  code_type               code type, currently supported PY, SO, CPP, ZIP.
@param [in]  procedure_description   procedure description.
@param [in]  read_only               procedure is read only or not.
@param [in]  version                 (Optional) the version of procedure.
@param [in]  graph                   (Optional) the graph to query.
@returns True if it succeeds, false if it fails.
```' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.8.加载存储过程'}","page_content='Java客户端

2.使用示例

2.8.加载存储过程

@param procedureDescription: procedure description
@param readOnly: procedure is read only or not
@param version: The version of procedure
@param graph: the graph to query.
@return: the result of procedure execution
public boolean loadProcedure(String sourceFile, String procedureType, String procedureName, String codeType,
String procedureDescription, boolean readOnly, String version, String graph) throws Exception
```' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.8.加载存储过程'}"
在RPC调用中，如果回应的错误码不是成功，则抛出的异常类型是什么？,"page_content='RPC API

5.存储过程

5.3.删除存储过程

if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
删除存储过程的响应不包含参数，如果删除失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.3.删除存储过程'}","page_content='RPC API

5.存储过程

5.1.加载存储过程

LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
加载存储过程的响应不包含参数，如果加载失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.1.加载存储过程'}","page_content='RPC API

3.登录

if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
token = res.acl_response().auth_response().token();
```
登录响应信息包含以下参数：
- token: 必要参数，登录成功会收到带有签名的令牌，即 Json Web Token，客户端储存该令牌，并且用于以后的每次发送请求。
如果登录失败会收到“Authentication failed”错误。' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}"
Transform操作中的swap_id函数是用来做什么的？,"page_content='RESTful API

2.请求与响应格式

2.2请求类型

| taskId   | 任务id，用于重启出错的任务 | 字符串类型 | 否 |
| flag   | 标记位，flag为1时导入成功将删除数据文件 | 可以转成int类型的字符串 | 否 |
| other   | 其他参数 | 可以转成int类型的字符串 | 否  |  
- **RESPONSE**:
如果成功，返回的响应信息中success为00  
| body参数  | 参数说明 | 参数类型   | 是否必填       |
| ------- |------|--------|------------|
| taskId   | 任务编号 | 字符串类型 | 是          |  
**Example request.**  
```
{
""graph"": ""default"",         //导入的子图名称
""delimiter"": "","",//数据分隔符
""continueOnError"": true,//遇到错误时是否跳过错误数据并继续导入
""skipPackages"": “0”,//跳过的包个数' metadata={'Header 1': 'RESTful API', 'Header 2': '2.请求与响应格式', 'Header 3': '2.2请求类型'}","page_content='OlapOnDB API

3. 算法举例

3.2 PageRank算法流程

// 相关中间变量统计
if (olapondb.OutDegree(vi) > 0) {
next[vi] /= olapondb.OutDegree(vi);
return fabs(next[vi] - curr[vi]) * olapondb.OutDegree(vi);
} else {
return fabs(next[vi] - curr[vi]);
}
}
},
all_vertices
);

// 将本轮迭代得到的pagerank值输出作为下一轮迭代的输入
curr.Swap(next);
}
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.2 PageRank算法流程'}","page_content='src/cypher/execution_plan/ops/op_relationship_count.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

//
// Created by wt on 19-11-28.
//
#pragma once

#include ""cypher/execution_plan/ops/op.h""

namespace cypher {

class RelationshipCount : public OpBase {
    lgraph::Transaction *txn_;
    cypher::Node *start_;
    cypher::Node *neighbor_;
    cypher::Relationship *relp_;
    unsigned int pattern_type_ = 0;

    inline bool GetLabelIds(lgraph::LabelId &start_lid, lgraph::LabelId &nbr_lid,
                            std::vector<lgraph::LabelId> &relp_lids) {
        try {
            if (!start_->Label().empty()) start_lid = txn_->GetLabelId(true, start_->Label());
            if (!neighbor_->Label().empty()) nbr_lid = txn_->GetLabelId(true, neighbor_->Label());
        } catch (std::exception &) {
            return false;
        }
        for (auto &t : relp_->Types()) {
            lgraph::LabelId rl;
            try {
                rl = txn_->GetLabelId(false, t);
            } catch (std::exception &) {
                continue;
            }
            relp_lids.emplace_back(rl);
        }
        return true;
    }

    inline size_t CountAllOutEdges() const {
        size_t n = 0;
        for (auto vit = txn_->GetVertexIterator(); vit.IsValid(); vit.Next()) {
            n += vit.GetNumOutEdges();
        }
        return n;
    }

    inline size_t CountOutEdgesWithStartLabel(lgraph::LabelId start_lid) const {
        size_t n = 0;
        for (auto vit = txn_->GetVertexIterator(); vit.IsValid(); vit.Next()) {
            if (txn_->GetVertexLabelId(vit) != st' metadata={'file_name': 'op_relationship_count.h', 'file_path': 'src/cypher/execution_plan/ops/op_relationship_count.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/execution_plan/ops/op_relationship_count.h'}"
在影视场景Demo中，如何通过Cypher语言查询影片'Forrest Gump'的所有演员以及他们扮演的角色？,"page_content='场景：影视

2.查询示例

2.2.示例二

查询影片 'Forrest Gump' 的所有演员，列出演员在影片中扮演的角色。  
```
MATCH (m:movie {title: 'Forrest Gump'})<-[r:acted_in]-(a:person) RETURN a.name,r.role
```' metadata={'Header 1': '场景：影视', 'Header 2': '2.查询示例', 'Header 3': '2.2.示例二'}","page_content='场景：影视

2.查询示例

2.1.示例一

查询影片 'Forrest Gump' 的所有演员，返回影片和演员构成的子图。  
```
MATCH (m:movie {title: 'Forrest Gump'})<-[:acted_in]-(a:person) RETURN a, m
```' metadata={'Header 1': '场景：影视', 'Header 2': '2.查询示例', 'Header 3': '2.1.示例一'}","page_content='demo/movie/query/e2.cypher/ MATCH (m:movie {title: 'Forrest Gump'})<-[r:acted_in]-(a:person) RETURN a.name,r.role;
' metadata={'file_name': 'e2.cypher', 'file_path': 'demo/movie/query/e2.cypher', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/movie/query/e2.cypher'}"
TuGraph-DB图数据库社区版内置了多少种基础算法？,"page_content='内置算法

简介

TuGraph目前包含以下6个基础算法28种扩展算法，共34个图算法：' metadata={'Header 1': '内置算法', 'Header 2': '简介'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}"
TuGraph-DB支持的三种空间数据类型是什么？,"page_content='空间数据类型在TuGraph-DB中的实现

定义空间数据类型

TuGraph-DB当前已经支持Point、Linestring与Polygon三种类型  
-   • Point：点，创建方式例如POINT(2.0, 2.0, 7203)  
-   • Linestring：折线，创建方式例如LINESTRING(0 2,1 1,2 0)  
-   • Polygon：多边形，创建方式例如POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '定义空间数据类型'}","page_content='地理空间数据类型使用示例

3. 数据类型

目前在TuGraph中，我们已经支持了Point, Linestring与Polygon三种类型:  
- Point：点    point(2.0, 2.0, 7203)
- Linestring：折线 LINESTRING(0 2,1 1,2 0)
- Polygon：多边形  POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型，创建图模型和插入数据示例如下：  
**创建标记美食位置的点模型**  
```
CALL db.createVertexLabel('food', 'id', 'id', int64, false, 'name', string, true,'pointTest',point,true)
```  
![image.png](../../../images/spatail/createVertexLabel.png)  
**插入标记美食点的数据**  
```' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '3. 数据类型'}","page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的表示

空间数据类型可以用不同的坐标系来表示，EPSG<sup>[1]</sup>是一个标准化的地理空间参考系统标识符集合， 用于标识不同的地理空间参考系统，包括坐标系统、地理坐标系、投影坐标系等。通常使用EPSG编码表示数据的坐标系。行业内一般采用  
-   •WGS84坐标系（没错，就是GPS系统的坐标系），标识符为EPSG 4326  
-   •Cartesian（笛卡尔）坐标系（没错，就是你高中数学学的直角坐标系），标识符为EPSG 7203  
WGS84是全球定位系统(GPS)的基础，允许全球的GPS接收器确定精确位置。几乎所有现代GPS设备都是基于WGS84坐标系来提供位置信息。在地图制作和GIS（地图制作和地理信息系统）领域，WGS84被广泛用于定义地球上的位置。这包括各种类型的地图创建、空间数据分析和管理等。  
Cartesian（笛卡尔）坐标系，又称直角坐标系，是一种最基本、最广泛应用的坐标系统。它通过两条数轴定义一个平面，三条数轴定义一个空间，这些轴互相垂直，在数学、物理、工程、天文和许多其他领域中有着广泛的应用。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的表示'}"
产品是否支持麒麟操作系统？只有企业版支持么？,"page_content='QA汇总

安装部署QA

麒麟操作系统支持

Q：产品是否支持麒麟操作系统？只有企业版支持么？
A：开源和企业版都支持' metadata={'Header 1': 'QA汇总', 'Header 2': '安装部署QA', 'Header 3': '麒麟操作系统支持'}","page_content='TuGraph与ARM架构

摘要：

- TuGraph适配国产ARM架构处理器，又双叒叕打破了LDBC SNB世界纪录，较之前纪录提升31%，云端机器开销降低了40%，大大提升了资源能效。  
- 验证了TuGraph对于ARM架构的兼容性，成为对X86和ARM架构均完整适配的图数据库，也使得TuGraph继麒麟、鲲鹏、海光等国产操作系统和处理器之后，**实现了对国产软硬件的全面支持，为用户的机器选型提供更多选择**。  
- 我们还测试了数据量大于内存的情况，结果显示，性能只下降了20%左右，显示了TuGraph在大规模数据下的适用性。  
TuGraph图数据库GitHub仓库：https://github.com/tugraph-family/tugraph-db' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '摘要：'}","page_content='环境准备

2.软件环境

2.1. 操作系统

TuGraph 能够兼容主流操作系统，包括Ubuntu、CentOS、SUSE、银河麒麟、 中标麒麟、UOS等，均通过测试认证。  
其中最稳定使用的系统版本是 Ubuntu 18.04、CentOS 7、CentOS 8。' metadata={'Header 1': '环境准备', 'Header 2': '2.软件环境', 'Header 3': '2.1. 操作系统'}"
TuGraph-DB中存储Point类型数据的格式是什么？,"page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

EWKB

EWKB格式数据如下  
-   •第0-1位: 表示编码方式 00表示大端法，01表示小端法  
-   •第2 - 5位: 空间数据类型  
-   •0100: point  
-   •0200: linestring  
-   •0300: polygon  
-   •第6 - 9位: 数据维度  
-   •0020: 二维  
-   •0030: 三维  
-   •第10 - 17位: 坐标系的EPSG编码  
-   •第18 - n位: double类型的坐标对的16进制表示  
**注:**对于POINT类型，其EWKB格式为定长存储，固定长度为50，而对于其他类型，则为不定长。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现', 'Header 3': 'EWKB'}","page_content='TuGraph图模型说明

1. 数据模型

1.2. 数据类型

| BLOB         |                     |                     | 二进制数据（在输入输出时使用Base64编码） |
| POINT        |                     |                     | EWKB格式数据，表示点              |
| LINESTRING   |                     |                     | EWKB格式数据，表示线              |
| POLYGON      |                     |                     | EWKB格式数据，表示面(多边形)       |
| FLOAT_VECTOR |                     |                     | 包含32位浮点数的动态向量               |' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.2. 数据类型'}","page_content='空间数据类型在TuGraph-DB中的实现

定义空间数据类型

TuGraph-DB当前已经支持Point、Linestring与Polygon三种类型  
-   • Point：点，创建方式例如POINT(2.0, 2.0, 7203)  
-   • Linestring：折线，创建方式例如LINESTRING(0 2,1 1,2 0)  
-   • Polygon：多边形，创建方式例如POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '定义空间数据类型'}"
TuGraph嵌入模式的API允许用户执行哪些操作？,"page_content='Procedure API

1.简介

当用户需要表达的查询/更新逻辑较为复杂（例如 Cypher 无法描述，或是对性能要求较高）时，相比调用多个请求并在客户端完成整个处理流程的方式，TuGraph 提供的存储过程是更简洁和高效的选择。  
与传统数据库类似，TuGraph 的存储过程运行在服务器端，用户通过将处理逻辑（即多个操作）封装到一个过程单次调用，并且可以在实现时通过并行处理的方式（例如使用相关的 C++ OLAP 接口以及基于其实现的内置算法）进一步提升性能。  
存储过程中有一类特殊的API来进行数据的并行操作，我们叫 Traversal API，见[文档](2.traversal.md)。' metadata={'Header 1': 'Procedure API', 'Header 2': '1.简介'}","page_content='RPC API

5.存储过程

为满足用户较为复杂的查询/更新逻辑，TuGraph支持 C 语言和 Python 语言编写的存储过程。
用户可以使用RPC请求对存储过程进行增删改查操作。' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程'}","page_content='RESTful API

1.简介

TuGraph 提供遵从 REST 规范的 HTTP API，以供开发者通过 HTTP 请求远程调用 TuGraph 提供的服务。  
本文档描述 TuGraph 的 HTTP API 使用方式。' metadata={'Header 1': 'RESTful API', 'Header 2': '1.简介'}"
Date 类的默认构造函数设置的日期是什么？,"page_content='src/bolt/temporal.h/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Copyright (c) ""Neo4j""
 * Neo4j Sweden AB [https://neo4j.com]
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

/*
 * written by botu.wzy, inspired by Neo4j Go Driver
 */
#pragma once
#include <string>

namespace bolt {

struct Date {
    int64_t days;
};

struct Time {
    int64_t nanoseconds;
    int64_t tz_offset_seconds;
};

struct LocalTime {
    int64_t nanoseconds;
};

struct DateTime {
    int64_t seconds;
    int64_t nanoseconds;
    int64_t tz_offset_seconds;
};

struct DateTimeZoneId {
    int64_t seconds;
    int64_t nanoseconds;
    std::string tz_id;
};

struct LocalDateTime {
    int64_t seconds;
    int64_t nanoseconds;
};

struct LegacyDateTime {
    int64_t seconds;
    int64_t nanoseconds;
    int64_t tz_offset_seconds;
};

struct LegacyDateTimeZoneId {
    int64_t seconds;
    int64_t nanoseconds;
    std::string tz_id;
};

// Duration represents temporal amount containing months, days, seconds and nanoseconds.
// Supports longer durations than time.Duration
struct Duration {
    int64_t months;
    int64_t days;
    int64_t seconds;
    int64_t nanos;
};

}  // namespace bolt
' metadata={'file_name': 'temporal.h', 'file_path': 'src/bolt/temporal.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/bolt/temporal.h'}","page_content='GeaFlow支持以下日期函数：
* [from_unixtime](#from_unixtime)
* [from_unixtime_millis](#from_unixtime_millis)
* [unix_timestamp](#unix_timestamp)
* [unix_timestamp_millis](#unix_timestamp_millis)
* [isdate](#isdate)
* [now](#now)
* [day](#day)
* [weekday](#weekday)
* [lastday](#lastday)
* [day_of_month](#day_of_month)
* [week_of_year](#week_of_year)
* [date_add](#date_add)
* [date_sub](#date_sub)
* [date_diff](#date_diff)
* [add_months](#add_months)
* [date_format](#date_format)'","page_content='TuGraph图模型说明

1. 数据模型

1.2. 数据类型

| INT32        | - 2^31              | 2^31 - 1            | 32位整型                         |
| INT64        | - 2^63              | 2^63 - 1            | 64位整型                         |
| DATE         | 0000-00-00          | 9999-12-31          | ""YYYY-MM-DD"" 格式的日期             |
| DATETIME     | 0000-00-00 00:00:00.000000 | 9999-12-31 23:59:59.999999 | ""YYYY-MM-DD HH:mm:ss[.ffffff]"" 格式的日期时间 |' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.2. 数据类型'}"
在使用 bool DeleteVertexIndex 函数时，如果给定的 vertex_label 或 field 不存在会发生什么？,"page_content='src/core/schema.cpp/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#include ""fma-common/string_formatter.h""

#include ""core/vertex_index.h""
#include ""core/edge_index.h""
#include ""core/schema.h""
#include ""import/import_config_parser.h""
#include ""core/vector_index.h""

namespace lgraph {

void Schema::DeleteEdgeFullTextIndex(EdgeUid euid, std::vector<FTIndexEntry>& buffers) {
    if (fulltext_fields_.empty()) {
        return;
    }
    FTIndexEntry entry;
    entry.type = FTIndexEntryType::DELETE_EDGE;
    entry.vid1 = euid.src;
    entry.vid2 = euid.dst;
    entry.lid = euid.lid;
    entry.eid = euid.eid;
    buffers.emplace_back(std::move(entry));
}

void Schema::DeleteVertexFullTextIndex(VertexId vid, std::vector<FTIndexEntry>& buffers) {
    if (fulltext_fields_.empty()) {
        return;
    }
    FTIndexEntry entry;
    entry.type = FTIndexEntryType::DELETE_VERTEX;
    entry.vid1 = vid;
    buffers.emplace_back(std::move(entry));
}

void Schema::DeleteVertexIndex(KvTransaction& txn, VertexId vid, const Value& record) {
    for (auto& idx : indexed_fields_) {
        auto& fe = fields_[idx];
        if (fe.GetIsNull(record)) continue;
        if (fe.Type() != FieldType::FLOAT_VECTOR) {
            VertexIndex* index = fe.GetVertexIndex();
            FMA_ASSERT(index);
            // update field index
            if (!index->Delete(txn, fe.GetConstRef(record), vid)) {
                THROW_CODE(InputError, ""Failed to un-index vertex [{}] with field ""
                                                    ""value [{}:{}]: index value does not exist."",
                      ' metadata={'file_name': 'schema.cpp', 'file_path': 'src/core/schema.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/schema.cpp'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.deleteLabel(label_type, label_name)

Delete a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |  
**Output:**  
| field_name | field_type | description              |
| ---------- | ---------- | -------------------------------- |
| affected   | integer    | number of vertexes/edges deleted |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.deleteLabel(label_type, label_name)'}","page_content='Cypher API

5.附录2. 内置procedures列表

5.2.内置procedures完整列表

| db.deleteFullTextIndex                | 删除全文索引                                | db.deleteFullTextIndex(is_vertex::BOOLEAN, label_name::STRING, field_name::STRING) :: (::VOID)                                                                                          |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '5.2.内置procedures完整列表'}"
在单命令模式下，如何使用 lgraph_cypher 通过命令行参数来执行一条 Cypher 查询并将结果显示为表格格式？,"page_content='命令行工具

1.单命令模式

在单命令模式下，`lgraph_cypher`可用于提交单个 Cypher 查询并将结果直接打印到终端，打印结果也可以容易地重定向写入指定文件。当用户需要从服务器获取大量结果并将其保存在文件中时，这非常便利。
在此模式下，`lgraph_cypher`工具具有以下选项：' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式'}","page_content='命令行工具

1.单命令模式

1.1.命令行参数:

| -P       | string | 数据库登录密码。                                                         |
| -f       | string | 包含单条 Cypher 查询单文本文件的路径。                                   |
| -s       | string | 单行 cypher 查询命令。以`""`开头结尾。                                    |
| -t       | int    | 进行 cypher 查询时服务器的超时阈值。默认值为`150`秒。 -format            | string | 查询结果显示模式。支持`plain`与`table`两种格式。`plain`格式会将查询结果单列打印。`table`格式会将查询结果以表格方式显示。默认值为`table`。 |' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式', 'Header 3': '1.1.命令行参数:'}","page_content='命令行工具

1.单命令模式

1.2.命令示例:

**cypher 命令文件查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -f /home/usr/cypher.json
```  
**cypher 命令单句查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -s ""MATCH (n) RETURN n""
```' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式', 'Header 3': '1.2.命令示例:'}"
reduce_plus函数是如何处理它的两个参数的？,"page_content='OlapBase API

7. 图类OlapBase

7.4 批处理操作

TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程。分别是：  
```c++
/*
函数名称:ReducedSum ProcessVertexInRange(std::function<ReducedSum(size_t)> work, size_t lower, size_t upper,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考include/lgraph/olap_base.h中具体代码

使用示例:统计数组parent数组中有出边的点个数
*/' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.4 批处理操作'}","page_content='Python Olap API

4. Olap API

图类OlapBase

#           active: ParallelBitset,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#   函数用途:对active_vertices中对应为1的节点执行work函数，第三个参数表示累加的基数，默认为0；
#   第四个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
#   具体实现请参考/include/lgraph/olap_base.h中具体代码
#
# 使用示例:输出Graph中节点1，2，3的所有出度邻居，并统计这三个节点的总出度' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}","page_content='Python Olap API

4. Olap API

图类OlapBase

#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#     函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
#     第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
#     具体实现请参考include/lgraph/olap_base.h中具体代码
#
#     使用示例:统计数组parent数组中有出边的点个数' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}"
是否支持无向边,"page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='OlapBase API

7. 图类OlapBase

7.2 点集和边集及其相关操作

- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.2 点集和边集及其相关操作'}"
FieldData类中提供哪些构造函数来初始化不同类型的数据？,"page_content='src/cypher/cypher_types.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

//
// Created by wt on 19-11-20.
//
#pragma once

#include <unordered_map>
#include ""core/data_type.h""
#include ""cypher/cypher_exception.h""

namespace cypher {

struct FieldData {
    typedef std::unordered_map<std::string, cypher::FieldData> CYPHER_FIELD_DATA_MAP;
    typedef std::vector<cypher::FieldData> CYPHER_FIELD_DATA_LIST;
    // TODO(lingsu) : a default state should be added
    enum FieldType { SCALAR, ARRAY, MAP } type;

    lgraph::FieldData scalar;
    CYPHER_FIELD_DATA_LIST* array = nullptr;
    CYPHER_FIELD_DATA_MAP* map = nullptr;

    FieldData() : type(SCALAR) {}

    explicit FieldData(bool rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(int8_t rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(int16_t rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(int32_t rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(int64_t rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(float rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(double rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(const lgraph::Date& rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(const lgraph::DateTime& rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(const std::string& rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(std::string&& rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(const char* rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(const char* rhs, size_t s) : type(SCALAR), scalar(rhs, ' metadata={'file_name': 'cypher_types.h', 'file_path': 'src/cypher/cypher_types.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/cypher_types.h'}","page_content='src/cypher/resultset/record.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

//
// Created by wt on 6/14/18.
//
#pragma once

#include <utility>
#include ""core/data_type.h""  // lgraph::FieldData
#include ""cypher/cypher_types.h""
#include ""parser/data_typedef.h""
#include ""graph/node.h""
#include ""graph/relationship.h""

namespace cypher {

struct SymbolTable;
class RTContext;

struct Entry {
    cypher::FieldData constant;
    union {
        Node *node = nullptr;
        Relationship *relationship;
    };

    enum RecordEntryType {
        UNKNOWN = 0,
        CONSTANT,
        NODE,
        RELATIONSHIP,
        VAR_LEN_RELP,
        HEADER,  // TODO(anyone) useless?
        NODE_SNAPSHOT,
        RELP_SNAPSHOT,
    } type;

    Entry() = default;

    explicit Entry(const cypher::FieldData &v) : constant(v), type(CONSTANT) {}

    explicit Entry(cypher::FieldData &&v) : constant(std::move(v)), type(CONSTANT) {}

    explicit Entry(const lgraph::FieldData &v) : constant(v), type(CONSTANT) {}

    explicit Entry(lgraph::FieldData &&v) : constant(std::move(v)), type(CONSTANT) {}

    explicit Entry(Node *v) : node(v), type(NODE) {}

    explicit Entry(Relationship *v)
        : relationship(v), type(v->VarLen() ? VAR_LEN_RELP : RELATIONSHIP) {}

    Entry(const Entry &rhs) = default;

    Entry(Entry &&rhs) = default;

    Entry &operator=(const Entry &rhs) = default;

    Entry &operator=(Entry &&rhs) = default;

    bool EqualNull() const {
        switch (type) {
        case CONSTANT:
            return constant.EqualNull();
        case NODE:
            return !node ||' metadata={'file_name': 'record.h', 'file_path': 'src/cypher/resultset/record.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/resultset/record.h'}","page_content='src/server/proto_convert.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

/**
 * This file contains the code to convert between ProtoBuf data structures and
 *LGraph data structures.
 **/

#include ""core/data_type.h""
#include ""core/field_data_helper.h""
#include ""db/acl.h""
#include ""lgraph/lgraph_types.h""
#include ""protobuf/ha.pb.h""

#include ""lgraph_api/result_element.h""

#ifndef _WIN32
#include ""cypher/resultset/record.h""
#endif

namespace lgraph {
struct FieldDataConvert {
    static inline FieldData ToLGraphT(ProtoFieldData&& fd) {
        switch (fd.Data_case()) {
        case ProtoFieldData::DATA_NOT_SET:
            return FieldData();
        case ProtoFieldData::kBoolean:
            return FieldData::Bool(fd.boolean());
        case ProtoFieldData::kInt8:
            return FieldData::Int8(fd.int8_());
        case ProtoFieldData::kInt16:
            return FieldData::Int16(fd.int16_());
        case ProtoFieldData::kInt32:
            return FieldData::Int32(fd.int32_());
        case ProtoFieldData::kInt64:
            return FieldData::Int64(fd.int64_());
        case ProtoFieldData::kSp:
            return FieldData::Float(fd.sp());
        case ProtoFieldData::kDp:
            return FieldData::Double(fd.dp());
        case ProtoFieldData::kDate:
            return FieldData::Date(Date(fd.date()));
        case ProtoFieldData::kDatetime:
            return FieldData::DateTime(DateTime(fd.datetime()));
        case ProtoFieldData::kStr:
            return FieldData::String(std::move(*fd.release_str()));
        case ProtoFieldData::kBlob:
      ' metadata={'file_name': 'proto_convert.h', 'file_path': 'src/server/proto_convert.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/server/proto_convert.h'}"
TuGraph-DB是如何帮助解决旅行时选择路线的烦恼的？,"page_content='Round The World Demo

示例

查询示例

在左下角的城市列表中选择不超过8个城市，点击查询可返回推荐的航班规划，在满足前后航班间隔在2-6小时的要求下，返回费用最低和飞行时间最短的10条路径规划。  
![data](../../../../images/round-the-world/search_example.jpg)  
详细使用说明见 [Round The World Demo](https://github.com/TuGraph-family/tugraph-db-demo/tree/main/round_the_world) 文档。' metadata={'Header 1': 'Round The World Demo', 'Header 2': '示例', 'Header 3': '查询示例'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

一、高可用架构介绍

4.TuGraph-DB高可用架构—Raft 共识算法

-   有了一致性的保证后，安全性也就有了保证，当超过半数的节点达成一致之后，才应用日志，这样就能解决网络分区延迟、丢包、冗余和乱序的错误。
-   基于一致性和安全性，它的可用性也就得到了保证，只要少于半数的节点宕机，即使主机宕机，也可以快速恢复应用，通过一次选举的时间就可以重新选出一个leader对外提供服务。  
国标对于高可用系统的指标评估，RTO 和 RPO 分别是恢复时间指标和恢复点目标，有 6 个等级，TuGraph-DB 已经达到了最高等级。当少量节点故障时，RPO 是 0，也就是没有数据损失，数据恢复时间点指标是小于 15 秒。即使是在部署的时候，无论是在同城的两中心、三中心，还是多地的多中心，都可以达成 RTO 小于 15 秒的标准。  
Raft算法优点:  
• 易用性：状态简单，强Leader  
• 一致性：日志逐个复制，超过半数节点达成一致才提交，不存在日志空洞  
• 安全性：超半数节点达成一致才应用日志，能解决网络延迟、分区、丢包、冗余和乱序等错误' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '一、高可用架构介绍', 'Header 3': '4.TuGraph-DB高可用架构—Raft 共识算法'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}"
exists()函数用于检查什么？,"page_content='Cypher API

3.Functions

3.2.Predicate functions

- exists()
judge it whether a vertex or edge has the field .
**Scope:** whole instance.
**Example input:**  
```
MATCH (n)
WHERE exists(n.born)
RETURN n.name, n.born
```  
**Example output:**  
| exists(name) |
| ------------ |
| true         |' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.2.Predicate functions'}","page_content='数据导入

6.在线全量导入

6.1 从原数据导入

exists. Default=0.
--parse_block_size  Block size per parse. Default=8388608.
--parse_block_threads
How many threads to parse the data block. Default=5.
--parse_file_threadsHow many threads to parse the files. Default=5.
--generate_sst_threads
How many threads to generate sst files. Default=15.
--read_rocksdb_threads
How many threads to read rocksdb in the final stage.
Default=15.
--vid_num_per_reading
How many vertex data to read each time. Default=10000.' metadata={'Header 1': '数据导入', 'Header 2': '6.在线全量导入', 'Header 3': '6.1 从原数据导入'}","page_content='Cypher API

3.Functions

3.1.Whole List Of Functions

| 种类                   | 功能               | 备注                      |
| ---------------------- |------------------| ------------------------- |
| Predicate functions    | exists()         |                           |
|                        | all()            | 不支持                    |
|                        | any()            | 不支持                    |
|                        | single()         | 不支持                    |' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.1.Whole List Of Functions'}"
安装部署TuGraph硬件的最低和建议CPU配置分别是多少个核心？,"page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='环境准备

1.硬件环境

1.3. 外存

我们强烈建议用户使用 NVMe SSD 作为外存，数据库有大量的写操作需要同步的外存，通常为随机写，外存的读写性能很容易成为整体数据库运行的性能瓶颈。因此，高IOPS、低延迟的 NVMe SSD 是最优的选择。  
如果现实条件只能使用 SATA接口的SSD，或者云上的网盘，性能虽然会受到影响，但 TuGraph 依然能正确的运行。  
外存大小建议为实际数据大小的4倍，比如数据为1TB，则准备4TB的硬盘会比较稳妥。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.3. 外存'}","page_content='云部署

2.实例说明

TuGraph部署的为社区开源版本，源码参考Github Repo，目前可以选择的实例规格如下：  
| 规格族         | vCPU与内存                 | 系统盘              | 公网带宽      |
|----------------|-------------------------|-------------------|-----------|
| ecs.r7a.xlarge | AMD 内存型 r7a，4vCPU 32GiB | ESSD云盘 200GiB PL0 | 固定带宽1Mbps |
| ecs.r6.xlarge  | 内存型r6，4vCPU 32GiB       | ESSD云盘 200GiB PL0 | 固定带宽1Mbps |  
预估费用在创建实例时可实时看到（目前为免费）。 如需更多规格、其他服务（如集群高可用性要求、企业级支持服务等），请联系我们 tugraph@service.alipay.com。' metadata={'Header 1': '云部署', 'Header 2': '2.实例说明'}"
MappedVid 函数是用于什么目的？,"page_content='OlapOnDB API

4. 其他常用函数功能描述

4.9 获取OlapOnDB中节点对应TuGraph的节点编号

```C++
size_t MappedVid(size_t original_vid)
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.9 获取OlapOnDB中节点对应TuGraph的节点编号'}","page_content='OlapOnDisk API

2. 算法举例

2.3 主函数

// core
start_time = get_time();
// 创建数组用于统计某节点是否遍历过
auto parent = graph.AllocVertexArray<size_t>();
// 宽度优先搜索算法，返回图内root_vid根结点连接的节点个数
size_t count = BFSCore(graph, root_vid, parent);
memUsage.print();
memUsage.reset();
auto core_cost = get_time() - start_time;
printf(""core_cost = %.2lf(s)\n"", core_cost);' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.3 主函数'}","page_content='demo/ProcedureDemo/cpp/khop_kth.cpp/ /*
 * 根据给定顶点，返回第k层的顶点个数
 */
#include ""lgraph/lgraph.h""
#include ""lgraph/olap_on_db.h""
#include ""lgraph/lgraph_traversal.h""

#include ""json.hpp""

#include <iostream>
#include <vector>
#include <unordered_set>
using json = nlohmann::json;

using namespace lgraph_api;

class UnorderedParallelBitset {
 public:
    size_t size_;
    size_t parallel_bitset_size_;
    size_t threshold_size_;
    bool use_unordered_set_;
    std::shared_ptr<olap::ParallelBitset> parallel_bitset_visited_;
    std::unordered_set<int64_t> unordered_set_visited_;

    UnorderedParallelBitset(size_t parallel_bitset_size, size_t threshold_size) {
        size_ = 0;
        parallel_bitset_size_ = parallel_bitset_size;
        threshold_size_ = threshold_size;
        use_unordered_set_ = true;
    }

    ~UnorderedParallelBitset() {}

    bool Has(int64_t vid) {
        if (use_unordered_set_) {
            return unordered_set_visited_.find(vid) != unordered_set_visited_.end();
        } else {
            return parallel_bitset_visited_->Has(vid);
        }
    }

    bool Add(int64_t vid) {
        if (use_unordered_set_ && size_ >= threshold_size_) {
            use_unordered_set_ = false;
            std::shared_ptr<olap::ParallelBitset> ptr_(new olap::ParallelBitset(parallel_bitset_size_));
            parallel_bitset_visited_ = ptr_;
            for(auto iter = unordered_set_visited_.begin(); iter != unordered_set_visited_.end(); ++iter) {
                parallel_bitset_visited_->Add(*iter);
            }
        }
        if (use_unordered_set_) {
            unordered_set_visited_.emplace(vid);
        } else {
            parallel_bitset_visited_->Add(vid);
        }
        size_ += 1;
        return true;
    }

    void Clear() {
        if (use_unordered_set_) {
            unordered_set_visited_.clear();
        } else {
            parallel_bitset_visited_->Clear();
        }
        size_ = 0;
    }
};

extern ""C"" bool Process(GraphDB & db, const std::string & request, std::string & respon' metadata={'file_name': 'khop_kth.cpp', 'file_path': 'demo/ProcedureDemo/cpp/khop_kth.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/ProcedureDemo/cpp/khop_kth.cpp'}"
当尝试更新一个存在的边但标签与指定的不符时，会发生什么？,"page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

- **METHOD**: GET
- **RESPONSE**: 如果成功,返回代码 200,同时返回边的属性。如果失败,返回代码 400,同时返回 ""Illegal field.""。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/relationship/17_0_2_2/property/charactername
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""Henri Ducard""
}
```  
#### 6.8.10.更新边的属性  
- **URI**: `/db/{graph_name}/relationship/{euid}`
- **METHOD**: PUT
- **REQUEST**:' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""Henri Ducard""
}
```  
#### 6.8.10.更新边的属性  
- **URI**: `/db/{graph_name}/relationship/{euid}`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• PUT http://localhost:7070/db/graph1/relationship/17_0_2_2
• Accept: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}"
"批量在线导入是通过”CREATE (n), (m)“吗？","page_content='数据导入

5.在线增量导入

-h, --help          Print this help message. Default=0.
```  
文件的相关配置在配置文件中指定，其格式与`离线模式`完全相同。但是，我们现在不是将数据导入本地数据库，而是将数据发送到正在运行的 TuGraph 实例中，该实例通常运行在与运行导入工具的客户端计算机不同的计算机上。因此，我们需要指定远程计算机的 HTTP 地址的URL、DB用户和密码。  
如果用户和密码有效，并且指定的图存在，导入工具将将数据发送到服务器，服务器随后解析数据并将其写入指定的图。数据将以大约 16MB 大小的包发送，在最近的换行符处中断。每个包都是以原子方式导入的，这意味着如果成功导入包，则成功导入所有数据，否则，任何数据都不会进入数据库。如果指定了`--continue_on_error true`，则忽略数据完整性错误，并忽略违规行。否则，导入将在第一个错误包处停止，并打印出已导入的包数。在这种情况下，用户可以修改数据以消除错误，然后使用`--skip_packages N`重做导入以跳过已导入的包。' metadata={'Header 1': '数据导入', 'Header 2': '5.在线增量导入'}","page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}","page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}"
lgraph_backup工具的主要功能是什么？,"page_content='备份恢复

1.数据备份

TuGraph 可以通过 `lgraph_backup` 工具来进行数据备份。
`lgraph_backup` 工具可以将一个 TuGraph 数据库中的数据备份到另一个目录下，它的用法如下：  
```bash
$ lgraph_backup -s {source_dir} -d {destination_dir} -c {true/false}
```  
其中：  
- `-s {source_dir}` 指定需要备份的数据库（源数据库）所在目录。
- `-d {destination_dir}` 指定备份文件（目标数据库）所在目录。
如果目标数据库不为空，`lgraph_backup` 会提示是否覆盖该数据库。
- `-c {true/false}` 指明是否在备份过程中进行 compaction。
compaction 能使产生的备份文件更紧凑，但备份时间也会变长。该选项默认为 `true`。' metadata={'Header 1': '备份恢复', 'Header 2': '1.数据备份'}","page_content='备份恢复

2.数据恢复

使用`lgraph_backup` 工具得到的目标数据库`{destination_dir}`备份了源数据库
`{source_dir}`的所有子图，但不包含HA集群的raft信息，从而保证服务和集群能
以备份数据库成功重启并与源数据库的数据一致。使用如下命令可以用备份数据库重启服务，
在服务启动时会恢复所有子图的存储过程，保证备份服务和原服务完全一致。  
```bash
$ lgraph_server -c lgraph.json --directory {destination_dir} -d start
```  
其中：  
- `-d {destination_dir}` 指定备份文件（目标数据库）所在目录。' metadata={'Header 1': '备份恢复', 'Header 2': '2.数据恢复'}","page_content='数据迁移

2. 兼容迁移

兼容迁移指的是在系统环境不变，且TuGraph软件版本兼容时，原服务的数据和存储过程可以在新服务中使用，所以可以直接迁移。
用户可以先使用`lgraph_backup`工具备份数据，然后将数据传输到新机器中并重启服务。具体迁移步骤如下：' metadata={'Header 1': '数据迁移', 'Header 2': '2. 兼容迁移'}"
在获取某个节点的所有属性时，通过什么方法和URI可以实现？,"page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

| --- | --- | --- |
| in | 被删掉的点的入边数量 | 整数值 |
| out | 被删掉的点的出边数量 | 整数值 |  
**Example request.**  
```
• DELETE http://localhost:7070/db/{graph_name}/node/4
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""in"": 0,
""out"": 0
}
```  
#### 6.7.6.获取点所有属性  
- **URI**: `/db/{graph_name}/node/{vertex_id}/property`
- **METHOD**: GET
- **RESPONSE**: Node 所有属性（字典）  
**Example request.**  
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}","page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""in"": 0,
""out"": 0
}
```  
#### 6.7.6.获取点所有属性  
- **URI**: `/db/{graph_name}/node/{vertex_id}/property`
- **METHOD**: GET
- **RESPONSE**: Node 所有属性（字典）  
**Example request.**  
```
• GET http://localhost:7070/db/{graph_name}/node/5/property
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""birthyear"": 1963,' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}","page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

**Example request.**  
```
• GET http://localhost:7070/db/{graph_name}/node/5/property
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""birthyear"": 1963,
""name"": ""Natasha Richardson""
}
```  
#### 6.7.7.获取点属性  
- **URI**: `/db/{graph_name}/node/{vertex_id}/property/{field}`
- **METHOD**: GET
- **RESPONSE**: Node 某一属性  
**Example request.**  
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}"
知识图谱的基本元素包括哪些？,"page_content='图数据库智能化建设与探索

**03.技术分享｜知识图谱语义框架SPG及图谱推理**

“当前，我们正处于图谱技术发展的第三阶段，这一阶段的核心是将图谱与大型模型相结合。目标转向了知识的标准化、跨领域数据的联通与复用。随着这个阶段的深入，简单地在推理过程中融入文本概念和信息，或者是加入交易与社交的实体关系，已经不能明显提升推理效果了。关键的做法应当是结合实体信息的多元素特征进行深度协作，从而更精准地关联相关性，揭示那些稀疏的实体间关系，并实现意义解释的密集化。”' metadata={'Header 1': '图数据库智能化建设与探索', 'Header 2': '**03.技术分享｜知识图谱语义框架SPG及图谱推理**'}","page_content='src/core/kv_table_comparators.h/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include ""core/data_type.h""

namespace lgraph {

typedef int (*KeySortFunc)(const MDB_val*, const MDB_val*);

struct ComparatorDesc {
    enum Type {
        BYTE_SEQ = 0,
        SINGLE_TYPE = 1,
        TYPE_AND_VID = 2,
        TYPE_AND_EUID = 3,
        GRAPH_KEY = 4,
        BOTH_SIDE_VID = 5,
        COMPOSITE_KEY = 6,
        COMPOSITE_KEY_AND_VID = 7,
        INVALID_TYPE = 255
    };

    Type comp_type = Type::BYTE_SEQ;
    FieldType data_type;
    std::vector<FieldType> data_types;

    static ComparatorDesc SingleDataComp(FieldType ft) {
        ComparatorDesc desc{Type::SINGLE_TYPE, ft};
        return desc;
    }

    static ComparatorDesc CompositeDataComp(std::vector<FieldType> fts) {
        ComparatorDesc desc{.comp_type = Type::COMPOSITE_KEY,
                            .data_types = std::move(fts)};
        return desc;
    }

    static const ComparatorDesc& DefaultComparator() {
        static ComparatorDesc desc{Type::BYTE_SEQ, FieldType::NUL};
        return desc;
    }
};

KeySortFunc GetKeyComparator(const ComparatorDesc& desc);
}  // namespace lgraph
' metadata={'file_name': 'kv_table_comparators.h', 'file_path': 'src/core/kv_table_comparators.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/kv_table_comparators.h'}","page_content='src/cypher/graph/graph.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

//
// Created by wt on 6/12/18.
//
#pragma once

#include ""fma-common/type_traits.h""

#include ""cypher/graph/node.h""
#include ""cypher/graph/relationship.h""
#include ""parser/data_typedef.h""
#include ""parser/symbol_table.h""

namespace cypher {

// triple: <start_node, relationship, neighbor_node>
typedef std::vector<std::tuple<NodeID, RelpID, NodeID>> EXPAND_STEPS;

class PatternGraph {
    std::vector<Node> _nodes;
    std::vector<Relationship> _relationships;
    NodeID _next_nid;
    RelpID _next_rid;
    std::unordered_map<std::string, NodeID> _node_map;
    std::unordered_map<std::string, RelpID> _relp_map;
    // for relationship uniqueness
    lgraph::EuidHashSet _visited_edges;

    bool _IsHanging(NodeID id, bool ignore_created) const {
        const auto &node = GetNode(id);
        for (auto rr : node.RhsRelps()) {
            auto &r = GetRelationship(rr);
            // TODO(anyone) think about this again
            if (!ignore_created || (r.derivation_ != Relationship::CREATED &&
                                    GetNode(r.Rhs()).derivation_ != Node::CREATED &&
                                    r.derivation_ != Relationship::MERGED &&
                                    GetNode(r.Rhs()).derivation_ != Node::MERGED)) {
                return false;
            }
        }
        for (auto lr : node.LhsRelps()) {
            auto &r = GetRelationship(lr);
            if (!ignore_created || (r.derivation_ != Relationship::CREATED &&
                                    GetNode(r.Lhs()).d' metadata={'file_name': 'graph.h', 'file_path': 'src/cypher/graph/graph.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/graph/graph.h'}"
TuGraph-DB是否支持存储过程？支持哪些编程语言的存储过程？,"page_content='RPC API

5.存储过程

为满足用户较为复杂的查询/更新逻辑，TuGraph支持 C 语言和 Python 语言编写的存储过程。
用户可以使用RPC请求对存储过程进行增删改查操作。' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程'}","page_content='Procedure API

3.存储过程语言支持

在 TuGraph 中，用户可以动态的加载，更新和删除存储过程。TuGraph 支持 C++ 语言、 Python 语言和 Rust 语言编写存储过程。在性能上 C++ 语言支持的最完整，性能最优。  
注意存储过程是在服务端编译执行的逻辑，和客户端的语言支持无关。' metadata={'Header 1': 'Procedure API', 'Header 2': '3.存储过程语言支持'}","page_content='功能概览

4.核心功能

4.2.存储过程

当用户需要表达的查询/更新逻辑较为复杂（例如 Cypher 无法描述，或是对性能要求较高）时，相比调用多个 REST 请求并在客户端完成整个
处理流程的方式，TuGraph 提供的存储过程（Procedure）是更简洁和高效的选择。  
从 3.5 版本开始，TuGraph 重新设计了新的存储过程编程范式，支持定义标准的签名和结果，支持POG编程。  
TuGraph 支持 POG (Procedres on Graph Query Languages) 编程和 POG 库，其中“Graph Query Languages”包含 Cypher 以及
制定中的 ISO GQL 等图查询语言。POG 库提供在查询语言中对用户定义的存储过程的访问，打破了查询语言和存储过程之间的界限，扩展了查询
语言的使用范围。  
> 这个文档描述了 [新的 Procedure 编程范式以及 POG](../9.olap&procedure/1.procedure/1.procedure.md)。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.2.存储过程'}"
GetEdgeProp操作的目的是什么？,"page_content='动态图

接口

}

interface TemporaryGraph<K, VV, EV> {
/** 从增量图中获取vertex */
IVertex<K, VV> getVertex();

/** 从增量图中获取edges */
List<IEdge<K, EV>> getEdges();

/** 更新vertex value */
void updateVertexValue(VV value);

}

interface HistoricalGraph<K, VV, EV> {
/** 获取图数据最新版本id */
Long getLatestVersionId();

/** 获取图数据所有版本 */
List<Long> getAllVersionIds();

/** 获取图数据所有vertex */
Map<Long, IVertex<K, VV>> getAllVertex();' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='动态图

接口

/** 获取图数据指定版本的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions);

/** 获取图数据指定版本并满足过滤条件的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions, IVertexFilter<K, VV> vertexFilter);

/** 获取图数据指定版本的快照 */
GraphSnapShot<K, VV, EV> getSnapShot(long version);

}

interface GraphSnapShot<K, VV, EV> {
/** 获取当前版本id */
long getVersion();
/** 获取vertex */
VertexQuery<K, VV> vertex();
/** 获取edges */
EdgeQuery<K, EV> edges();

}' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='Cypher API

5.附录2. 内置procedures列表

5.2.内置procedures完整列表

| db.getEdgeSchema                      | 列出边的 schema                           | db.getEdgeSchema(label::STRING) :: (schema::MAP)                                                                                                                                        |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '5.2.内置procedures完整列表'}"
TuGraph-DB的主要功能是什么？,"page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='可视化操作手册（旧版）

作用

TuGraph Browser 的主要功能是为使用图数据库的开发人员，提供可视化的图数据开发，图数据管理和维护等功能。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '作用'}"
当Cypher请求的响应不包含正确的结果时，会抛出什么异常？,"page_content='RPC API

4.查询

stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
server_version = std::max(server_version, res.server_version());
CypherResponse cypher_res = res.cypher_response();
```
Cypher请求响应为以下两个参数之一：
- json_result: JSON格式的cypher查询结果
- binary_result: CypherResult格式的cypher查询结果' metadata={'Header 1': 'RPC API', 'Header 2': '4.查询'}","page_content='src/cypher/parser/cypher_base_visitor_v2.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

// Generated from Lcypher.g4 by ANTLR 4.9.2

#pragma once

#include ""antlr4-runtime/antlr4-runtime.h""
#include ""parser/generated/LcypherVisitor.h""
#include ""cypher/cypher_exception.h""
#include ""geax-front-end/common/ObjectAllocator.h""
#include ""geax-front-end/ast/Ast.h""
#include ""cypher/parser/data_typedef.h""
#include ""execution_plan/runtime_context.h""

#if __APPLE__
#ifdef TRUE
#undef TRUE
#endif
#ifdef FALSE
#undef FALSE
#endif
#endif  // #if __APPLE__

namespace parser {

enum class VisitType {
    kReadingClause,
    kUpdatingClause,
    kMergeClause,
    kMergeOnMatch,
    kMergeOnCreate,
    kReadingPattern,
    kUpdatingPattern,
    kMatchPattern,
    kSetVariable,
    kSetLabel,
    kSetNull,
    kDeleteVariable,
    kWithClause,
    kStandaloneCall,
    kInQueryCall,
    kSinglePartQuery,
    kUnionClause
};

class VisitGuard {
    VisitType type_;
    std::unordered_set<VisitType>& cur_types_;
 public:
    VisitGuard(VisitType type, std::unordered_set<VisitType>& cur_types)
        : type_(type), cur_types_(cur_types) {
        cur_types.emplace(type_);
    }

    ~VisitGuard() { cur_types_.erase(type_); }

    static bool InClause(VisitType type, const std::unordered_set<VisitType>& cur_types) {
        return cur_types.find(type) != cur_types.end();
    }
};

/**
 * This class provides an empty implementation of LcypherVisitor, which can be
 * extended to create a visitor which only needs to handle a subset of the available methods.
 */
class CypherBaseVisitorV2 : public ' metadata={'file_name': 'cypher_base_visitor_v2.h', 'file_path': 'src/cypher/parser/cypher_base_visitor_v2.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/parser/cypher_base_visitor_v2.h'}","page_content='src/cypher/cypher_exception.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <exception>
#include <string>
#include ""core/data_type.h""
#include ""fma-common/string_formatter.h""

namespace lgraph {

#ifndef NDEBUG
#define CYPHER_TODO_FILE_NAME std::string(__FILE__)
#else
#define CYPHER_TODO_FILE_NAME """"
#endif

#define CYPHER_TODO()                                                                        \
    do {                                                                                     \
        throw lgraph::CypherException(                                                       \
            fma_common::StringFormatter::Format(""Function not implemented yet: {} at {}:{}"", \
                                                __func__, CYPHER_TODO_FILE_NAME, __LINE__)); \
    } while (0)

#define CYPHER_INTL_ERR()                                                               \
    do {                                                                                \
        throw lgraph::CypherException(fma_common::StringFormatter::Format(              \
            ""Internal error: {} at {}:{}"", __func__, CYPHER_TODO_FILE_NAME, __LINE__)); \
    } while (0)

#define CYPHER_THROW_ASSERT(pred)       \
    do {                                \
        if (!(pred)) CYPHER_INTL_ERR(); \
    } while (0)

#define CYPHER_PARSER_CHECK(pred, msg)                               \
    if (!(pred)) {                                                   \
        throw lgraph::ParserException(""error around '"" + msg + ""'""); \
    }
#define CYPHER_ARGUMENT_ERROR()  ' metadata={'file_name': 'cypher_exception.h', 'file_path': 'src/cypher/cypher_exception.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/cypher_exception.h'}"
2024年度功能更新预计何时推出HA支持Witness角色和管理工具？,"page_content='技术规划

3. 2024年功能更新

在2024年度，我们计划的功能更新包括：  
| 版本号   | 功能                 | 计划时间    |
|-------|--------------------|---------|
| 4.2.x | HA支持Witness角色和管理工具 | 2024.3  |
| 4.2.x | Bolt支持流处理和参数化查询    | 2024.3  |
| x.x.x | GeaX支持Cypher       | 2024.6  |
| x.x.x | 支持组合索引             | 2024.6  |
| x.x.x | 数据导入功能优化           | 2024.6  |
| x.x.x | 【社区功能】支持地理数据类型使用   | 2024.6  |
| x.x.x | Cypher能力提升         | 2024.9  |
| x.x.x | 支持Schema快速变更       | 2024.9  |
| x.x.x | 向量化支持              | 2024.12 |' metadata={'Header 1': '技术规划', 'Header 2': '3. 2024年功能更新'}","page_content='部署高可用模式

1.原理

例如，当只有2台机器的情况下，可以在一台机器上部署`replica`节点，在另一台机器上部署`replica`节点和`witness`节点，不仅节省资源，而且不需要把日志应用到状态机上，
也不需要生成和安装快照，因此响应请求的速度很快，可以在集群崩溃或网络分区时协助快速选举出新的`leader`，这就是TuGraph HA集群的简约部署模式。
尽管`witness`节点有诸多好处，但是由于没有数据，集群实际上增加了一个不能成为`leader`的节点，因此可用性会略有降低。为提高集群的可用性，
可通过指定`ha_enable_witness_to_leader`参数为`true`，允许`witness`节点临时当主。`witness`节点在把新日志同步到其他节点之后，
会将leader角色主动切换到有最新日志的节点。  
v3.6及以上版本支持此功能。' metadata={'Header 1': '部署高可用模式', 'Header 2': '1.原理'}","page_content='技术规划

3. 2024年功能更新

| x.x.x | 支持组合索引             | 2024.6  |
| x.x.x | 数据导入功能优化           | 2024.6  |
| x.x.x | 【社区功能】支持地理数据类型使用   | 2024.6  |
| x.x.x | Cypher能力提升         | 2024.9  |
| x.x.x | 支持Schema快速变更       | 2024.9  |
| x.x.x | 向量化支持              | 2024.12 |
| x.x.x | RPQ支持              | 2024.12 |
| x.x.x | 【可选】查询引擎升级         | 2024.12 |
| x.x.x | 【社区功能】支持GraphAr    | 2024.12 |' metadata={'Header 1': '技术规划', 'Header 2': '3. 2024年功能更新'}"
TuGraph-DB使用CMake作为编译工具，支持的C++标准为C++17,"page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='TuGraph-db

3. 从源代码编译

建议在Linux系统中构建TuGraph，Docker环境是个不错的选择。如果您想设置一个新的环境，请参考[Dockerfile]  
以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build' metadata={'Header 1': 'TuGraph-db', 'Header 2': '3. 从源代码编译'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}"
Cython.cimports.libcpp.unordered_map是什么？,"page_content='Python Olap API

6. 算法插件示例

import json

import cython
from cython.cimports.olap_base import *
from cython.cimports.lgraph_db import *
# 从procedures/algo_cython/ 中cimportolap_base.pxd与lgraph_db.pxd, 类似C++中#include ""xxx.h""

from cython.cimports.libc.stdio import printf
# 类似C++中#include <stdio.h>
# 其他常见的还有cython.cimports.libcpp.unordered_map等

import time' metadata={'Header 1': 'Python Olap API', 'Header 2': '6. 算法插件示例'}","page_content='demo/MultithreadClient/client.cpp/ 
#include ""client.h""
#include ""load_plugin.h""
#include ""cypher_sender.h""
#include ""plugin_sender.h""
#include ""delete_plugin.h""
#include <functional>
#include <unordered_map>

static const std::unordered_map<std::string, std::function<void(multithread_client::Client*)>> sRouter = {
        {""callcypher"", std::bind(&multithread_client::Client::call_cypher, std::placeholders::_1)},
        {""loadplugin"", std::bind(&multithread_client::Client::load_plugin, std::placeholders::_1)},
        {""callplugin"", std::bind(&multithread_client::Client::call_plugin, std::placeholders::_1)},
        {""deleteplugin"", std::bind(&multithread_client::Client::delete_plugin, std::placeholders::_1)},
};

namespace multithread_client {

    void Client::call_cypher() {
        std::shared_ptr<CypherSender> cs = std::make_shared<CypherSender>(config);
        cs->process();
    }

    void Client::load_plugin() {
        std::shared_ptr<LoadPlugin> lp = std::make_shared<LoadPlugin>(config);
        lp->process();
    }

    void Client::call_plugin() {
        std::shared_ptr<PluginSender> ps = std::make_shared<PluginSender>(config);
        ps->process();
    }

    void Client::delete_plugin() {
        std::shared_ptr<DeletePlugin> ds = std::make_shared<DeletePlugin>(config);
        ds->process();
    }

    void Client::process() {
        auto it = sRouter.find(config.mode);
        if (it == sRouter.end()) return;
        auto func = it->second;
        func(this);
    }

} // end of namespace multithread_client' metadata={'file_name': 'client.cpp', 'file_path': 'demo/MultithreadClient/client.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/MultithreadClient/client.cpp'}","page_content='RPC API

5.存储过程

5.1.加载存储过程

pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
pluginRequest->set_version(version);
lgraph::LoadPluginRequest* loadPluginRequest = pluginRequest->mutable_load_plugin_request();
loadPluginRequest->set_code_type([](const std::string& type) {
std::unordered_map<std::string, lgraph::LoadPluginRequest_CodeType> um{
{""SO"", lgraph::LoadPluginRequest::SO},
{""PY"", lgraph::LoadPluginRequest::PY},' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.1.加载存储过程'}"
TuGraph 数据预热命令需要指定哪两个选项？,"page_content='数据预热

1.数据预热命令

数据预热可以通过工具 `lgraph_warmup` 来进行。它的使用示例如下：  
```bash
$ lgraph_warmup -d {directory} -g {graph_list}
```  
其中：  
- `-d {db_dir}` 选项指定了 TuGraph 服务器的数据目录  
- `-g {graph_list}` 选项指定需要进行数据预热的图名称，用逗号分隔  
根据数据大小和所使用的磁盘类型不同，预热过程运行时间也不同。机械磁盘上预热一个大数据库可能耗时较长，请耐心等待。' metadata={'Header 1': '数据预热', 'Header 2': '1.数据预热命令'}","page_content='数据库运行

4.服务配置

TuGraph 服务器在启动时从配置文件和命令行选项加载配置，如果在配置文件和命令行中同一选项指定了不同的值，将优先使用命令行中指定的值。' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置'}","page_content='数据导入

4.离线全量导入

离线模式只能在离线状态的服务器使用。离线导入会创建一张新图，因此更适合新安装的 TuGraph 服务器上的第一次数据导入。
要在离线模式下使用`lgraph_import`工具，可以指定`lgraph_import --online false`选项。要了解可用的命令行选项，请使用`lgraph_import --online false --help`：  
```shell
$ ./lgraph_import --online false -help
Available command line options:
--log               Log file to use, empty means stderr. Default="""".
-v, --verbose       Verbose level to use, higher means more verbose.
Default=1.
...
-h, --help          Print this help message. Default=0.
```' metadata={'Header 1': '数据导入', 'Header 2': '4.离线全量导入'}"
是否支持GQL语句？,"page_content='ISO GQL

1.GQL简介

Graph Query Language(GQL, 图查询语言)是一种国际标准语言，用于属性图查询，该语言建立在SQL的基础上，并整合了现有的[openCypher、PGQL、GSQL和G-CORE](https://gql.today/comparing-cypher-pgql-and-g-core/)语言的成熟思想。目前该标准仍然处于草稿阶段。  
TuGraph基于[ISO GQL (ISO/IEC 39075) Antlr4 语法文件](https://github.com/TuGraph-family/gql-grammar)实现了GQL，并做了一些扩展与改造。目前并未完全支持所有的GQL语法，我们会在未来逐步完善。' metadata={'Header 1': 'ISO GQL', 'Header 2': '1.GQL简介'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

###### a.语句查询窗口  
用户在`语句查询窗口`输入图查询语句，点击`执行`按钮可以运行对应语句，并在`执行结果页签`展示结果。  
- 切换查询语言：提供不同图查询语言模式的切换。_当前只支持Cypher语法_  
![图查询-切换语言](../../../images/browser/query-selectgql.png)  
- 语句查询窗口：提供当前查询语言的语法提示。  
![图查询-语法提示](../../../images/browser/query-gqltips.png)  
- 执行：点击`执行`按钮，发送输入的查询语句至后台运行。  
![图查询-执行按钮](../../../images/browser/query-execute-button.png)  
- 收藏：点击`收藏`按钮，将当前语句查询窗口的内容保存成模板，以便下次使用。  
![图查询-收藏按钮](../../../images/browser/query-bookmark-button.png)' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

当 TuGraph 遇见 Antlr4

ISO GQL（ISO/IEC 39075）是一种标准化的图数据库查询语言，蚂蚁集团是其主要贡献者之一。因此，Antlr4 作为一种强大的解析器生成器，成为了蚂蚁图数据库 TuGraph 生成 GQL 解释器的理想选择。Antlr4 能够帮助团队更快、更准确地构建图数据库的查询语言，从而提高产品性能和用户体验。  
然而，当我们从开发场景来到生产场景，超高的并发量带来一个严重问题：Antlr4 C++ target 的并发性能不足以支持所需的超高并发 GQL 请求。经过调研并与 Antlr 开源社区讨论，我们发现\*\*并发性能这个问题普遍存在，并且在过去 5 年中持续困扰着 C++生态的开发者。\*\*我们决定解决这个问题。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '当 TuGraph 遇见 Antlr4'}"
在配置中提到的“log4j-core”和“guava”的版本号分别是多少？,"page_content='src/bolt/hydrator.cpp/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Copyright (c) ""Neo4j""
 * Neo4j Sweden AB [https://neo4j.com]
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

/*
 * written by botu.wzy, inspired by Neo4j Go Driver
 */
#include ""tools/lgraph_log.h""
#include ""bolt/hydrator.h""
#include ""bolt/messages.h""
#include ""bolt/graph.h""
#include ""bolt/path.h""
#include ""bolt/spatial.h""
#include ""bolt/temporal.h""
#include ""fma-common/string_formatter.h""
#include ""lgraph/lgraph_exceptions.h""

namespace bolt {
const char* containsSystemUpdatesKey = ""contains-system-updates"";
const char* containsUpdatesKey = ""contains-updates"";

std::unordered_map<std::string, int>  ExtractIntCounters(
    std::unordered_map<std::string, std::any> counters) {
    std::unordered_map<std::string, int> result;
    for (auto& pair : counters) {
        if (pair.first != containsSystemUpdatesKey && pair.first != containsUpdatesKey) {
            result[pair.first] = std::any_cast<int>(pair.second);
        }
    }
    return result;
}
std::optional<bool> ExtractBoolPointer(std::unordered_map<std::string, std::any> counters,
                                       const std::string& key) {
    auto iter = counters.find(key);
    if (iter == counters.end()) {
        return std::nullopt;
    }
    return std::any_cast<std::optional<bool>>(iter->second);
}

void Hydrator::SetErr(const std::string& err) {
    if (!err_) {
        err_ = err;
    }
}

void Hydrator::ClearErr() {
    err_.reset();
}

void Hydrator::UseUtc(bool use) {
    useUtc_ = use;
}

const std::optional<std::string>& Hydrator::GetErr() {
    if (unp_->Err()) {
        r' metadata={'file_name': 'hydrator.cpp', 'file_path': 'src/bolt/hydrator.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/bolt/hydrator.cpp'}","page_content='src/bolt/pack_stream.h/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Copyright (c) ""Neo4j""
 * Neo4j Sweden AB [https://neo4j.com]
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

/*
 * written by botu.wzy, inspired by Neo4j Go Driver
 */
#pragma once
#include <iostream>
#include <any>
#include ""tools/lgraph_log.h""
#include ""fma-common/string_formatter.h""
#include ""bolt/pack.h""
#include ""bolt/messages.h""
#include ""bolt/graph.h""
#include ""bolt/path.h""
#include ""bolt/temporal.h""

namespace bolt {

struct Chunker {
    std::string buf;
    // std::vector<int> sizes;
    int offset = 0;
    void BeginMessage() {
        // Space for length of next message
        buf.append(2, 0);
        offset = buf.size();
    }
    void EndMessage() {
        auto size = buf.size() - offset;
        // optimize
        while (size > 0xffff) {
            auto p = (uint16_t *) (buf.data() + offset - 2);
            *p = 0xffff;
            buf.insert(offset + 0xffff, 2, 0);
            offset += 0xffff + 2;
            size -= 0xffff;
        }
        auto p = (uint16_t *) (buf.data() + offset - 2);
        *p = size;
        boost::endian::native_to_big_inplace(*p);

        // Add zero chunk to mark End of message
        buf.append(2, 0);
    }
};

class PackStream {
 public:
    void Reset() {
        chunker_.buf.clear();
        chunker_.offset = 0;
        packer_.Reset();
    }
    void Begin() {
        chunker_.BeginMessage();
        packer_.Begin(&chunker_.buf);
    }
    void End() {
        const auto& err = packer_.Err();
        if (err) {
            LOG_FATAL() << FMA_FMT(""packer meet error {}"", err.value());
    ' metadata={'file_name': 'pack_stream.h', 'file_path': 'src/bolt/pack_stream.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/bolt/pack_stream.h'}","page_content='TuGraph Java Client

版本选择

| Client Version | TuGraph Version |
|----------------|-----------------|
| 1.1.1          | 3.3.3           |
| 1.2.1, 1.2.2   | 3.4.x, 3.5.0    |
| 1.3.0          | 3.6.0           |
| 1.4.0, 1.4.1   | 4.0.0, 4.0.1    |  
**注意**:  
- 3.3.0~3.3.2 版本的 TuGraph Server 是在 java-client 重构前的遗留版本，本仓库不支持这些版本。
- 1.1.0 和 1.2.0 因 pom 文件中的 ${revision} 变量引入的无法使用的问题而不可用[1]。' metadata={'Header 1': 'TuGraph Java Client', 'Header 2': '版本选择'}"
类liblgraph_python_api.Galaxy的方法SetUserGraphAccess主要用于什么？,"page_content='Python Olap API

5. lgraph_db API

Galaxy

- `Galaxy(dir_path: std::string)`: 构造函数，dir_path为db路径
- `SetCurrentUser(user: std::string, password: std::string)-> cython.void`: 设置用户
- `SetUser(user: std::string)-> cython.void`: 设置用户
- `OpenGraph(graph: std::string, read_only: bint)-> GraphDB`: 创建GraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Galaxy'}","page_content='Python Olap API

5. lgraph_db API

PyGalaxy:

- `PyGalaxy(self, dir_path: str)`: 构造函数，dir_path为db路径
- `SetCurrentUser(self, user: str password: str)-> void`: 设置用户
- `SetUser(self, user: std::string)-> void`: 设置用户
- `OpenGraph(self, graph: str, read_only: bool)-> PyGraphDB`: 创建PyGraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'PyGalaxy:'}","page_content='demo/ProcedureDemo/embed_main.py/ from liblgraph_python_api import GraphDB, Galaxy
import json

# --- add python plugin ---
import python.scan_graph as python_plugin
# --- add python plugin ---

if __name__ == ""__main__"":
    galaxy = Galaxy(""lgraph_db"")
    galaxy.SetCurrentUser(""admin"", ""73@TuGraph"")
    db = galaxy.OpenGraph(""default"", False)
    res = python_plugin.Process(db, ""{\""scan_edges\"": true}"")
    print(res)
    db.Close()
    galaxy.Close()

' metadata={'file_name': 'embed_main.py', 'file_path': 'demo/ProcedureDemo/embed_main.py', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/ProcedureDemo/embed_main.py'}"
TuGraph-DB如何在运行单元测试的过程中输出日志？,"page_content='数据库运行

2.运行模式

2.1.运行普通进程

`lgraph_server -d run`命令可以将 TuGraph 作为普通进程运行。普通进程依赖命令行终端，因此终端结束时，TuGraph 进程也会自动终止。普通进程模式配合`--log_dir """"`可以将进程日志直接输出到终端，因此更方便调试。注：当不使用`-d run`命令时，将默认运行普通进程。  
lgraph_server的默认路径为：/usr/local/bin/lgraph_server 。  
lgraph.json的默认路径为：/usr/local/etc/lgraph.json 。  
启动命令：  
```shell
$ ./lgraph_server -d run -c lgraph.json --log_dir """"
```
或者：
```shell
$ ./lgraph_server -c lgraph.json --log_dir """"
```  
普通模式的运行输出示例：  
```shell' metadata={'Header 1': '数据库运行', 'Header 2': '2.运行模式', 'Header 3': '2.1.运行普通进程'}","page_content='日志信息

2.服务器日志

2.3.存储过程日志

extern ""C"" bool Process(GraphDB& db, const std::string& request, std::string& response) {
response = ""TuGraph log demo"";
LogExample();
return true;
}
```
将以上示例代码作为存储过程插入数据库并运行后，可以在日志文件中看到相应的日志条目。  
#### 2.3.1.python存储过程
请使用python自带的print输出调试信息，调试信息会在存储过程运行结束后合并为一条WARN等级的日志条目输出至日志文件中。' metadata={'Header 1': '日志信息', 'Header 2': '2.服务器日志', 'Header 3': '2.3.存储过程日志'}","page_content='日志信息

3.审计日志

审核日志记录每个请求和响应，以及发送请求的用户以及收到请求的时间。审核日志只能是打开或关闭状态。可以使用 TuGraph 可视化工具和 REST API 查询结果。  
开启审计日志需要在配置文件中将`enable_audit_log`参数设置为`true`。配置文件和配置参数说明详见：[数据库运行/服务配置](../../5.installation&running/7.tugraph-running.md)。' metadata={'Header 1': '日志信息', 'Header 2': '3.审计日志'}"
"GeaBase 查询中使用 ""Nav"" 语句的一种情况是什么?","page_content='地理空间数据类型使用示例

5. 美食探索

5.3 构建美食探索查询

能够根据用户的当前位置，寻找距离2.5以内的美食,根据距离进行升序排列。返回距离和评分让用户得倒更好的体验。  
**查询语句**  
```
match (n:person{id:1}),(m:food) with n.pointTest as p1,m.pointTest as p2,m.name as food,m.mark as mark
CALL spatial.distance(p1,p2) YIELD distance
WHERE distance<2.5
RETURN food,distance,mark ORDER by distance
```  
![image.png](../../../images/spatail/querryFood.png)' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '5. 美食探索', 'Header 3': '5.3 构建美食探索查询'}","page_content='地理空间数据类型使用示例

5. 美食探索

5.2 数据模型设计

CREATE (n:food {id:10007, name: 'Lao Sze Chuan',pointTest:point(4.0,3.0,7203),mark:4.7}) RETURN n
```  
- Person（人物）节点：代表应用的用户，属性包含用户名、当前位置等。用户的当前位置同样通过地理坐标表示，便于后续的地理空间查询。  
```
CALL db.createVertexLabel('person', 'id', 'id', int64, false, 'name', string, true,'pointTest',point,true)
```  
准备数据：  
```
CREATE (n:person {id:1, name: 'Tom',pointTest:point(3.0,3.0,7203)}) RETURN n
```' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '5. 美食探索', 'Header 3': '5.2 数据模型设计'}","page_content='RESTful API Legacy

6.Deprecated

6.3.服务器状态

```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""failure_rate"": 2.3,
""requests/second"": 122.3,
""running_tasks"": 10,
""writes/second"": 12.4
}
```  
#### 6.3.11.审计日志信息  
- **URI**: `/info/log/?begin_time={begin_time}&end_time={end_time}&user={user}&num_log={num_log}&descending_order={descending_order}`
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| begin_time | 查询日志的起始时间(必填，格式为 YYYY-mm-dd HH:MM:SS) | 时间戳 |' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.3.服务器状态'}"
我要快速定位到2个顶点间的某条关系边，通过pair unique索引查找关系边的接口有么，需求是根据pair_unique的值更新对应的边数据么,"page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}"
TuGraph Explorer 的功能现在在哪里可以找到？,"page_content='功能概览

6.生态工具

6.2.可视化交互

TuGraph Browser 是面向图数据库直接使用者的可视化交互界面，功能上覆盖了 TuGraph 的绝大部分能力，包括数据导入、图模型建立、数据增删查改、监控运维等操作链路。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.2.可视化交互'}","page_content='可视化操作手册（旧版）

作用

TuGraph Browser 的主要功能是为使用图数据库的开发人员，提供可视化的图数据开发，图数据管理和维护等功能。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '作用'}","page_content='可视化操作手册（旧版）

操作详情

3.工作台

##### 3.3.6 帮助  
- 其中记录了 TuGraph-browser 的使用方式
![alt 查询](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/16.TuGraph-browser-help.png)  
#### 3.4 控制台  
##### 3.4.1 数据库基础信息  
- 展示数据库相关的基础配置信息
![alt 查询](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/17.tugraph-browser-config.png)  
##### 3.4.2 权限管理  
- 用来创建用户和角色的功能模块，用户可以在这里进行权限的管理操作' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '3.工作台'}"
SybilRank算法的执行过程中主要采用什么方式来进行计算？,"page_content='内置算法

扩展算法包

Sybil检测算法

Sybil检测算法实现了Sybil Rank算法。SybilRank算法从非Sybil节点开始进行提前终止的随机游走。算法内容请参考论文：“Aiding the Detection of Fake Accounts in Large Scale Social Online Services”。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': 'Sybil检测算法'}","page_content='内置算法

基础算法包

网页排序

网页排序程序实现了常用的Pagerank算法。该算法根据图中边和边权值计算所有点的重要性排名，PageRank值越高，表示该点在图中的重要性越高。计算时以点数量的倒数为各点初始Rank值，然后将点的Rank值按照出边平均传递到相邻点，重复该传递过程直到满足给定的收敛阈值或达到给定迭代轮数。每轮传递结束后，所有点的Rank值会有一定的的比例随机传递到任意点上。算法内容请参考 [https://en.wikipedia.org/wiki/PageRank](https://en.wikipedia.org/wiki/PageRank ""pagerank wiki"")。' metadata={'Header 1': '内置算法', 'Header 2': '基础算法包', 'Header 3': '网页排序'}","page_content='典型示例

PageRank动态图计算示例介绍

实例代码

// 获取作业执行map算子的并发数
int mapParallelism = pipelineTaskCxt.getConfig().getInteger(ExampleConfigKeys.MAP_PARALLELISM);
// 获取作业执行sink算子的并发数
int sinkParallelism = pipelineTaskCxt.getConfig().getInteger(ExampleConfigKeys.SINK_PARALLELISM);
// 创建sink方法
SinkFunction<String> sink = ExampleSinkFunctionFactory.getSinkFunction(conf);
// 基于图算法，执行动态图计算
incGraphView.incrementalCompute(new IncGraphAlgorithms(3))
// 获取结果点数据并作map操作
.getVertices()' metadata={'Header 1': '典型示例', 'Header 2': 'PageRank动态图计算示例介绍', 'Header 3': '实例代码'}"
节点和边的属性在知识图谱中有什么作用？,"page_content='Heterogeneous Graph

1. 异质图简介

异质图（Heterogeneous Graph）是指由不同类型的节点和边构成的图结构。在异质图中，节点和边可以具有多样化的属性和关系，代表了不同实体以及它们之间的复杂关联。  
在异质图中，节点类型可以代表不同的实体，如用户、商品、话题等，而边类型表示不同实体之间的关系，如用户之间的关注关系、用户与商品之间的购买关系等。节点和边可以具有不同的属性。  
异质图提供了一种强大的图模型，能够更好地表达和分析具有多种类型实体和复杂关系的现实世界系统。在不同领域的数据分析和应用中，异质图具有广泛的应用前景和研究价值。' metadata={'Header 1': 'Heterogeneous Graph', 'Header 2': '1. 异质图简介'}","page_content='Match

Syntax

Edge

匹配图上的边，类似Node节点可以指定边的类型以及对边的过滤条件。和Node不同的是,边需要指定方向，边的方向包括入边、出边和双向边。' metadata={'Header 1': 'Match', 'Header 2': 'Syntax', 'Header 3': 'Edge'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}"
在TuGraph项目中，为什么在提交代码前要先提交一个issue？,"page_content='如何贡献

4. 贡献代码流程

4.1. 提交issue

不论您是修复 TuGraph 的 bug 还是新增 TuGraph 的功能，在您提交代码之前，请在 TuGraph 的 GitHub 上提交一个 issue，描述您要修复的问题或者要增加的功能。这么做有几个好处:  
- 不会与其它开发者或是他们对这个项目的计划发生冲突，产生重复工作。
- TuGraph 的维护人员会对您提的 bug 或者新增功能进行相关讨论，确定该修改是不是必要，有没有提升的空间或更好的办法。
- 在达成一致后再开发，并提交代码，减少双方沟通成本，也减少 pull request 被拒绝的情况。' metadata={'Header 1': '如何贡献', 'Header 2': '4. 贡献代码流程', 'Header 3': '4.1. 提交issue'}","page_content='如何贡献

4. 贡献代码流程

4.2. 获取源码

要修改或新增功能，在提交 issue 后，fork一份 TuGraph  Master代码到您的代码仓库。' metadata={'Header 1': '如何贡献', 'Header 2': '4. 贡献代码流程', 'Header 3': '4.2. 获取源码'}","page_content='如何贡献

3. 准备工作

3.3. 许可协议

在贡献代码之前，请您稍微花一些时间了解为TuGraph贡献代码的流程，并阅读 [个人贡献者许可协议](3.individual-cla.md) 或 [公司贡献者许可协议](4.corporate-cla.md)，参与贡献则视为同意上述协议。' metadata={'Header 1': '如何贡献', 'Header 2': '3. 准备工作', 'Header 3': '3.3. 许可协议'}"
请问社区版本和企业版本，之间的差距在哪,"page_content='什么是TuGraph

4. TuGraph企业版

企业版对商业化功能支持更加完善，包括分布式集群架构，覆盖探索、研发、服务、运维管理全生命周期的一站式图平台，在线、近线、离线的图计算引擎，支持流式、大数据类数据源，多地多中心的部署形态，以及专家支持服务等。企业版是商业化解决方案的理想选择。  
如需商业支持，请联系我们：  
- 电话：400-903-0809
- 邮件：tugraph@service.alipay.com
- 官网：https://tugraph.antgroup.com' metadata={'Header 1': '什么是TuGraph', 'Header 2': '4. TuGraph企业版'}","page_content='云部署

2.实例说明

TuGraph部署的为社区开源版本，源码参考Github Repo，目前可以选择的实例规格如下：  
| 规格族         | vCPU与内存                 | 系统盘              | 公网带宽      |
|----------------|-------------------------|-------------------|-----------|
| ecs.r7a.xlarge | AMD 内存型 r7a，4vCPU 32GiB | ESSD云盘 200GiB PL0 | 固定带宽1Mbps |
| ecs.r6.xlarge  | 内存型r6，4vCPU 32GiB       | ESSD云盘 200GiB PL0 | 固定带宽1Mbps |  
预估费用在创建实例时可实时看到（目前为免费）。 如需更多规格、其他服务（如集群高可用性要求、企业级支持服务等），请联系我们 tugraph@service.alipay.com。' metadata={'Header 1': '云部署', 'Header 2': '2.实例说明'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}"
bfs_standalone程序的输出结果是什么？,"page_content='OLAP API

4. Standalone 编译与运行

C++:

在tugraph-db/build编译standalone算法程序  
```bash
make bfs_standalone
```  
在tugraph-db/build/output目录下运行text源文件  
```bash
./output/algo/bfs_standalone --type text --input_dir ../test/integration/data/algo/fb_unweighted --root 0
```  
得到运行结果：  
```text
prepare_cost = 0.10(s)
core_cost = 0.02(s)
found_vertices = 3829
output_cost = 0.00(s)
total_cost = 0.11(s)
DONE.
```  
结果参数解释同上。  
对于新的算法，运行时不了解该算法的所需参数时，可通过`./output/algo/bfs_standalone -h`进行查阅对应参数。' metadata={'Header 1': 'OLAP API', 'Header 2': '4. Standalone 编译与运行', 'Header 3': 'C++:'}","page_content='OLAP API

4. Standalone 编译与运行

该文件主要用于在终端处直接加载图数据，并运行打印输出结果。使用方法如下：
在tugraph-db/build目录下执行`make bfs_standalone` (需要在g++默认include路径中包含boost/sort/sort.hpp)即可得到bfs_standalone文件,该文件生成于tugraph-db/build/output/algo文件夹下。
运行方式：在tugraph-db/build目录下执行`./output/algo/bfs_standalone -–type [type] –-input_dir [input_dir] --id_mapping [id_mapping] -–vertices [vertices] --root [root] –-output_dir [output_dir]`即可运行。  
- `[type]`：表示输入图文件的类型来源，包含text文本文件、BINARY_FILE二进制文件和ODPS源。' metadata={'Header 1': 'OLAP API', 'Header 2': '4. Standalone 编译与运行'}","page_content='OlapOnDisk API

1. 简介

TuGraph的Standalone模式可用于加载图数据文件，其中图数据文件来源可包含text文本文件、BINARY_FILE二进制文件和ODPS源。在该模式下，TuGraph可实现多数据来源快速加载成图，然后在该图上运行如BFS、WCC、SSSP等迭代式算法，并输出最终结果至终端。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph内置了大量的常见图分析算法和丰富的辅助接口，因此用户几乎不需要自己实现具体的图计算过程，只需要在实现自己的存储过程的时候将相应算法库的头文件(.h)包含到自己的程序中，并在编译阶段链接自己的动态库文件即可。  
该文档主要介绍了Standalone的常用接口，使用到的辅助函数主要包含在OlapOnDB类。同时为帮助用户理解方便，对BFS算法进行举例说明。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '1. 简介'}"
Key_start和key_end相等于v时，VertexIndexIterator是如何工作的？,"page_content='src/core/vertex_index.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <atomic>
#include <exception>
#include <unordered_map>

#include ""core/field_data_helper.h""
#include ""core/data_type.h""
#include ""core/iterator_base.h""
#include ""core/kv_store.h""
#include ""core/kv_table_comparators.h""
#include ""core/type_convert.h""
#include ""core/value.h""

int TestVertexIndexImpl();
int CURDVertexWithTooLongKey();
int TestVRefreshContentIfKvIteratorModified();

namespace lgraph {
class Transaction;
class VertexIndex;
class VertexIndexIterator;
class Schema;
class CompositeIndex;
class CompositeIndexIterator;

/**
 * An VertexIndexValue packs multiple vids into a single value.
 */
class VertexIndexValue {
    /**
     * uint8_t count
     * [5 bytes vid] * count
     */

    friend class VertexIndex;
    friend class VertexIndexIterator;
    friend class CompositeIndex;
    friend class CompositeIndexIterator;

    Value v_;

    VertexIndexValue();

    explicit VertexIndexValue(const Value& v);

    explicit VertexIndexValue(Value&& v);

    template <typename IT>
    VertexIndexValue(const IT& beg, const IT& end) {
        size_t n = end - beg;
        FMA_DBG_ASSERT(n < std::numeric_limits<uint8_t>::max());
        v_.Resize(1 + _detail::VID_SIZE * n);
        char* p = v_.Data();
        *(uint8_t*)p = (uint8_t)n;
        p++;
        for (auto it = beg; it < end; it++) {
            _detail::WriteVid(p, *it);
            p += _detail::VID_SIZE;
        }
    }

    int GetVidCount() const { return static_cast<int>(*(uint8_t*)v_.Data()); }

    int64_t GetNth' metadata={'file_name': 'vertex_index.h', 'file_path': 'src/core/vertex_index.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/vertex_index.h'}","page_content='静态图

接口

| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |  
- 详细接口  
```java
public interface VertexCentricTraversalFunction<K, VV, EV, M, R> extends VertexCentricFunction<K, VV
, EV, M> {' metadata={'Header 1': '静态图', 'Header 2': '接口'}","page_content='动态图

接口

| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
应该如何写入图数据库中的顶点数据？,"page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.2.构建采样器

训练过程中，首先使用GetDB算子从数据库中获取图数据并转换成所需数据结构，具体代码如下：
```python
GetDB.Process(db_: lgraph_db_python.PyGraphDB, olapondb: lgraph_db_python.PyOlapOnDB, feature_num: size_t, NodeInfo: list, EdgeInfo: list)
```
如代码所示，结果存储在NodeInfo和EdgeInfo中。NodeInfo和EdgeInfo是python list结果，其存储的信息结果如下：  
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |  
然后构建采样器
```python
batch_size = 5
count = 2708' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.2.构建采样器'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

三、TuGraph-DB高可用集群部署与应用

3\. Client连接应用

urls-add (""172.22.224. 15:9090"");

urls. add (""172.22.224. 16:9090"");

urls.add (""172.22.224.17:9090"");

TuGraphDbRpcClient client = new TuGraphDbRpcClient(urls, ""admin"", ""73@TuGraph"");
```  
:执行请求  
• 从字节流中导入点边数据，先写到leader，再同步到follower  
```
boolean ret = client. importDataFromContent (personDesc, person, "" log. info(""importDataFromContent : "" + ret); , true, 16, ""default"" , 1000);

log.info(""importDataFromContent :"" + ret);
```' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '三、TuGraph-DB高可用集群部署与应用', 'Header 3': '3\\. Client连接应用'}","page_content='demo/ProcedureDemo/cpp/khop_kth.cpp/ /*
 * 根据给定顶点，返回第k层的顶点个数
 */
#include ""lgraph/lgraph.h""
#include ""lgraph/olap_on_db.h""
#include ""lgraph/lgraph_traversal.h""

#include ""json.hpp""

#include <iostream>
#include <vector>
#include <unordered_set>
using json = nlohmann::json;

using namespace lgraph_api;

class UnorderedParallelBitset {
 public:
    size_t size_;
    size_t parallel_bitset_size_;
    size_t threshold_size_;
    bool use_unordered_set_;
    std::shared_ptr<olap::ParallelBitset> parallel_bitset_visited_;
    std::unordered_set<int64_t> unordered_set_visited_;

    UnorderedParallelBitset(size_t parallel_bitset_size, size_t threshold_size) {
        size_ = 0;
        parallel_bitset_size_ = parallel_bitset_size;
        threshold_size_ = threshold_size;
        use_unordered_set_ = true;
    }

    ~UnorderedParallelBitset() {}

    bool Has(int64_t vid) {
        if (use_unordered_set_) {
            return unordered_set_visited_.find(vid) != unordered_set_visited_.end();
        } else {
            return parallel_bitset_visited_->Has(vid);
        }
    }

    bool Add(int64_t vid) {
        if (use_unordered_set_ && size_ >= threshold_size_) {
            use_unordered_set_ = false;
            std::shared_ptr<olap::ParallelBitset> ptr_(new olap::ParallelBitset(parallel_bitset_size_));
            parallel_bitset_visited_ = ptr_;
            for(auto iter = unordered_set_visited_.begin(); iter != unordered_set_visited_.end(); ++iter) {
                parallel_bitset_visited_->Add(*iter);
            }
        }
        if (use_unordered_set_) {
            unordered_set_visited_.emplace(vid);
        } else {
            parallel_bitset_visited_->Add(vid);
        }
        size_ += 1;
        return true;
    }

    void Clear() {
        if (use_unordered_set_) {
            unordered_set_visited_.clear();
        } else {
            parallel_bitset_visited_->Clear();
        }
        size_ = 0;
    }
};

extern ""C"" bool Process(GraphDB & db, const std::string & request, std::string & respon' metadata={'file_name': 'khop_kth.cpp', 'file_path': 'demo/ProcedureDemo/cpp/khop_kth.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/ProcedureDemo/cpp/khop_kth.cpp'}"
lgraph_api::Transaction的作用是什么？,"page_content='Python Olap API

5. lgraph_db API

GraphDB：

- `CreateReadTxn()-> Transaction`: 创建只读事务
- `CreateWriteTxn()-> Transaction`: 创建写事务
- `ForkTxn(txn: Transaction)-> Transaction`: 复制事务，只能复制读事务' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'GraphDB：'}","page_content='Python Olap API

5. lgraph_db API

Transaction：

```
GetVertexIndexIterator(
label: std::string,
field: std::string,
key_start: std::string,
key_end: std::string)-> VertexIndexIterator
```
获取索引迭代器。迭代器的field值为 [key_start, key_end]。所以在key_start=key_end=v时，返回指向field值为v的点的迭代器  
lgraph_db_python.py是lgraph_db.pxd中C++类 Galaxy与GraphDB的包装，将C++类包装为Python类，将lgraph_db_python.py编译为Python拓展后，可以直接在Python文件或Python命令行中`import lgraph_db_python`访问lgraph_db_python.PyGraphDB与PyGraphDB.PyGalaxy。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Transaction：'}","page_content='src/lgraph_api/lgraph_traversal.cpp/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#include ""lgraph/lgraph_traversal.h""

namespace lgraph_api {

namespace traversal {

ParallelVector<size_t> FindVertices(GraphDB &db, Transaction &txn,
                                    std::function<bool(VertexIterator &)> filter, bool parallel) {
    auto task_ctx = GetThreadContext();
    GraphDB &db_ = db;
    Transaction &txn_ = txn;
    size_t num_vertices_ = txn.GetNumVertices();
    ParallelVector<size_t> frontier(num_vertices_);
    if (parallel && txn.IsReadOnly()) {
        auto worker = Worker::SharedWorker();
        worker->Delegate([&]() {
#pragma omp parallel
            {
                constexpr size_t LOCAL_BUFFER_SIZE = 1024;
                ParallelVector<size_t> local_frontier(LOCAL_BUFFER_SIZE);
                auto txn = db_.ForkTxn(txn_);
                int thread_id = omp_get_thread_num();
                int num_threads = omp_get_num_threads();
                size_t start = num_vertices_ / num_threads * thread_id;
                size_t end = num_vertices_ / num_threads * (thread_id + 1);
                if (thread_id == num_threads - 1) end = num_vertices_;
                auto vit = txn.GetVertexIterator(start, true);
                for (size_t i = 0; vit.IsValid(); vit.Next(), i++) {
                    if (i % 1024 == 0 && ShouldKillThisTask(task_ctx)) break;
                    size_t vid = vit.GetId();
                    if (vid >= end) break;
                    if (filter(vit)) {
                        local_frontier.Append(vid, false);
           ' metadata={'file_name': 'lgraph_traversal.cpp', 'file_path': 'src/lgraph_api/lgraph_traversal.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/lgraph_api/lgraph_traversal.cpp'}"
在执行`ProcessVertexActive`函数时，如果运行时出现错误，会引发什么异常？,"page_content='OlapBase API

7. 图类OlapBase

7.4 批处理操作

使用示例:统计数组parent数组中有出边的点个数
*/

auto vertex_num = graph.ProcessVertexInRange<size_t>(
[&](size_t i) {
if (graph.OutDegree(parent[i]) > 0) {
return 1;
}
},
0, parent.Size()
);
printf(""the number is %lu\n"",vertex_num);
```  
其中graph为图类OlapBase的实例化对象  
```C++
/*
函数名称:ReducedSum ProcessVertexActive(std::function<ReducedSum(size_t)> work, ParallelBitset &active_vertices,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.4 批处理操作'}","page_content='Python Olap API

4. Olap API

图类OlapBase

if __name__ == ""__main__"":
count_core = CountCore()
count_core.run(cython.address(g))
```
其中g为图类OlapBase的实例化对象  
```python
# 函数名称:ProcessVertexActive[ReducedSum, Algorithm](
#           work: (algo: Algorithm, vi: size_t)-> ReducedSum,
#           active: ParallelBitset,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}","page_content='Python Olap API

4. Olap API

图类OlapBase

if __name__ == ""__main__"":
neighbor_core = NeighborCore()
neighbor_core.run(cython.address(g))
```  
如上面两个例子所展示，在Python中ProcessVertexActive与ProcessVertexInRange比在C++中额外需要一个算法类指针参数，Work函数一般也作为该算法类的成员函数，满足Work函数访问成员变量的需求（如图graph，点数组parent），在调用批处理函数时将Work函数和算法类的self指针传入批处理函数。  
其中Work函数会在多线程中调用，因此加上修饰器`@cython.nogil`释放Python全局解释锁，在多线程执行的代码中（例如批处理函数中的Work函数，`cython.parallel.prange`中），不能包含Python对象，最好通过`dst: type`或者`dst = cython.declare(type)`的方式声明变量为C/C++类型。' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}"
如果在调用存储过程时，指定json_format参数为false，返回结果的格式是什么？,"page_content='C++客户端

2.使用示例

2.6.调用存储过程

binary format.
@param [in]  url                 (Optional) Node address of calling procedure.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}","page_content='C++客户端

2.使用示例

2.6.调用存储过程

interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  url                 (Optional) Node address of calling procedure.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}","page_content='C++客户端

2.使用示例

2.7.向leader调用存储过程

@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@returns True if it succeeds, false if it fails.
```
本接口支持在HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.7.向leader调用存储过程'}"
Prometheus的地址是什么？,"page_content='src/monitor/prometheus_monitor.h/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include ""prometheus/exposer.h""
#include ""prometheus/gauge.h""

namespace lgraph {
namespace monitor {

class ResourceMonitor {
 public:
    explicit ResourceMonitor(const std::string &host);

    void report_server_info(const std::string& info);

    void report_tugraph_info(const std::string& info);

 private:
    prometheus::Exposer exposer;
    std::shared_ptr<prometheus::Registry> registry;
    prometheus::Gauge *cpu_total;
    prometheus::Gauge *cpu_self;

    prometheus::Gauge *mem_total;
    prometheus::Gauge *mem_available;
    prometheus::Gauge *mem_self;

    prometheus::Gauge *disk_read_rate;
    prometheus::Gauge *disk_write_rate;

    prometheus::Gauge *disk_total;
    prometheus::Gauge *disk_available;
    prometheus::Gauge *disk_self;

    prometheus::Gauge *total_request;
    prometheus::Gauge *write_request;
};

}  // end of namespace monitor

}  // end of namespace lgraph
' metadata={'file_name': 'prometheus_monitor.h', 'file_path': 'src/monitor/prometheus_monitor.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/monitor/prometheus_monitor.h'}","page_content='src/monitor/prometheus_monitor.cpp/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#include ""monitor/prometheus_monitor.h""
#include ""prometheus/registry.h""
#include ""fma-common/hardware_info.h""
#include ""fma-common/file_system.h""
#include ""tools/json.hpp""

namespace lgraph {
namespace monitor {

ResourceMonitor::ResourceMonitor(const std::string& host)
    : exposer(host)
    , registry(std::make_shared<prometheus::Registry>()) {
    prometheus::Family<prometheus::Gauge>& gf = prometheus::BuildGauge().Name(""resources_report"")
            .Help(""tugraph resources monitor gauge"").Register(*registry);
    cpu_total = &gf.Add({{""resouces_type"", ""cpu""}, {""type"", ""total""}});
    cpu_total->SetToCurrentTime();

    cpu_self = &gf.Add({{""resouces_type"", ""cpu""}, {""type"", ""self""}});
    cpu_self->SetToCurrentTime();

    mem_total = &gf.Add({{""resouces_type"", ""memory""}, {""type"", ""total""}});
    mem_total->SetToCurrentTime();
    mem_available = &gf.Add({{""resouces_type"", ""memory""}, {""type"", ""available""}});
    mem_available->SetToCurrentTime();
    mem_self = &gf.Add({{""resouces_type"", ""memory""}, {""type"", ""self""}});
    mem_self->SetToCurrentTime();

    disk_read_rate = &gf.Add({{""resouces_type"", ""disk_rate""}, {""type"", ""read""}});
    disk_read_rate->SetToCurrentTime();
    disk_write_rate = &gf.Add({{""resouces_type"", ""disk_rate""}, {""type"", ""write""}});
    disk_write_rate->SetToCurrentTime();

    disk_total = &gf.Add({{""resouces_type"", ""disk""}, {""type"", ""total""}});
    disk_total->SetToCurrentTime();
    disk_available = &gf.Add({{""resouces_type"", ""disk""}, {""type"", ""available""}});
 ' metadata={'file_name': 'prometheus_monitor.cpp', 'file_path': 'src/monitor/prometheus_monitor.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/monitor/prometheus_monitor.cpp'}","page_content='RESTful API Legacy

6.Deprecated

6.3.服务器状态

**Example request.**  
```
• GET http://localhost:7070/info/peers
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""rest_address"":""192.168.1.22:17071"",
""rpc_address"":""192.168.1.22:19091"",
""state"":""MASTER""
},
{
""rest_address"":""192.168.1.22:17072"",
""rpc_address"":""192.168.1.22:19092"",
""state"":""SLAVE""
}
]
}
```  
#### 6.3.9.当前 Leader 信息  
_(仅在高可用模式下有效)_  
- **URI**: `/info/leader`' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.3.服务器状态'}"
TuGraph图分析引擎主要面向哪类任务？,"page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}","page_content='OLAP API

1. TuGraph 图分析引擎介绍

TuGraph的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助TuGraph的 C++ / Python 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如PageRank、LPA、WCC等迭代式图算法，最后根据运行结果做出相应的对策。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph图计算系统社区版内置6个算法，商业版内置了25种算法，用户几乎不需要自己实现具体的图计算过程。其详细介绍可参考algorithms.md。  
根据数据来源及实现不同，可分为Procedure、Embed和Standalone三种运行方式，均继承于OlapBase API，OlapBase API接口文档可参考olapbase-api.md。' metadata={'Header 1': 'OLAP API', 'Header 2': '1. TuGraph 图分析引擎介绍'}","page_content='图算法介绍

2\. 流图推理简介

TuGraph计算引擎（TuGraph Analytics\[1\]）是蚂蚁集团开源的大规模分布式实时图计算引擎（流图引擎），实现了流批一体的图计算模型，支持了丰富的图计算算法。TuGraph Analytics的流图计算能力，能处理连续输入的数据流，并支持增量的计算模式，极大得提高了数据的计算效率和实时性。TuGraph Analytics解决了业界大规模数据关联分析的实时计算问题，已广泛应用于数仓加速、金融风控、知识图谱以及社交推荐等场景。  
随着业务场景中问题复杂度的提升，基于传统的迭代图算法已无法满足业务的实际需求。例如在反洗钱场景中，利用图神经网络算法处理复杂的交易关系，能够捕获到节点的局部图结构信息。通过聚合邻接节点的特征信息，每个交易节点都可以感知到周边图网络结构的信息。类似的图神经网络等AI模型的推理逻辑，是无法基于传统的图迭代计算模式直接高效地表达的。' metadata={'Header 1': '图算法介绍', 'Header 2': '2\\. 流图推理简介'}"
在给定的XML配置中，如果表内属性字段名为id时，应该如何处理node_id字段以避免报错？,"page_content='src/cypher/graph/node.cpp/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

//
// Created by wt on 6/12/18.
//

#include ""cypher/graph/node.h""
#include ""execution_plan/runtime_context.h""

namespace cypher {

Node::Node() : id_(-1), derivation_(UNKNOWN) {}

Node::Node(cypher::NodeID id, const std::string &label, const std::string &alias,
           Derivation derivation)
    : id_(id), label_(label), alias_(alias), derivation_(derivation) {}

Node::Node(cypher::NodeID id, const std::string &label, const std::string &alias,
           const Property &prop, Derivation derivation)
    : Node(id, label, alias, derivation) {
    property_ = prop;
}

NodeID Node::ID() const { return id_; }

const std::string &Node::Label() const { return label_; }

const std::string &Node::Alias() const { return alias_; }

size_t Node::RhsDegree() const { return rhs_relps_.size(); }

size_t Node::LhsDegree() const { return lhs_relps_.size(); }

const std::vector<RelpID> &Node::RhsRelps() const { return rhs_relps_; }

const std::vector<RelpID> &Node::LhsRelps() const { return lhs_relps_; }

const Property &Node::Prop() const { return property_; }

lgraph::VIter *Node::ItRef() { return &it_; }

bool Node::Empty() const { return (id_ < 0); }

bool Node::AddRelp(cypher::RelpID rid, bool is_rhs_relp) {
    if (is_rhs_relp) {
        for (auto r : rhs_relps_) {
            if (r == rid) return false;
        }
        rhs_relps_.emplace_back(rid);
    } else {
        for (auto r : lhs_relps_) {
            if (r == rid) return false;
        }
        lhs_relps_.emplace_back(rid);
    }
    return true;' metadata={'file_name': 'node.cpp', 'file_path': 'src/cypher/graph/node.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/graph/node.cpp'}","page_content='src/cypher/graph/common.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

//
// Created by wt on 6/12/18.
//
#pragma once
#include <string>
#include <unordered_set>
#include ""cypher/cypher_types.h""
#include ""parser/expression.h""
namespace cypher {

typedef int64_t NodeID;
typedef int64_t RelpID;

struct Property {
    bool hasMapFieldName;
    std::string field;
    std::string value_alias;
    std::string map_field_name;
    lgraph::FieldData value;
    enum {
        NUL,        // empty
        PARAMETER,  // {name:$name}
        VALUE,      // {name:'Tom Hanks'}
        VARIABLE,   // UNWIND [1,2] AS mid MATCH (n {id:mid}) || WITH {a: 1, b: 2} as pair
    } type;

    Property() : type(NUL) {}
};

/* See also traversal::Path */
struct Path {
    std::vector<bool> dirs_;
    std::vector<uint16_t> lids_;
    std::vector<int64_t> ids_;

    Path() = default;

    bool Empty() const { return ids_.empty(); }

    size_t Length() const { return dirs_.size(); }

    void SetStart(int64_t start_id) {
        if (Length() != 0) throw std::runtime_error(""Cannot set start for path."");
        ids_.clear();
        ids_.emplace_back(start_id);
    }

    void Append(const lgraph::EdgeUid &edge) {
        if (ids_.back() == edge.src) {
            // forward
            dirs_.push_back(true);
            lids_.push_back(edge.lid);
            ids_.push_back(edge.eid);
            ids_.push_back(edge.dst);
        } else if (ids_.back() == edge.dst) {
            // backward
            dirs_.push_back(false);
            lids_.push_back(edge.lid);
            ids_.push_back(edge.ei' metadata={'file_name': 'common.h', 'file_path': 'src/cypher/graph/common.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/graph/common.h'}","page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""in"": 0,
""out"": 0
}
```  
#### 6.7.6.获取点所有属性  
- **URI**: `/db/{graph_name}/node/{vertex_id}/property`
- **METHOD**: GET
- **RESPONSE**: Node 所有属性（字典）  
**Example request.**  
```
• GET http://localhost:7070/db/{graph_name}/node/5/property
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""birthyear"": 1963,' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}"
"使用OGM进行创建节点和边的代码示例中，哪部分代码用于创建边标签""DIRECT""?","page_content='TuGraph-OGM

使用TuGraph-OGM

通过OGM进行增删改查

session.query(""CALL db.createVertexLabel('Director', 'name', 'name',"" +
""STRING, false, 'age', INT16, true)"", emptyMap());            // 创建节点Label Director
session.query(""CALL db.createEdgeLabel('DIRECT', '[]')"", emptyMap()); // 创建边Label DIRECT
Result createResult = session.query(
""CREATE (n:Movie{title:\""The Shawshank Redemption\"", released:1994})"" +
""<-[r:DIRECT]-"" +
""(n2:Director{name:\""Frank Darabont\"", age:63})"",
emptyMap());' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '使用TuGraph-OGM', 'Header 3': '通过OGM进行增删改查'}","page_content='TuGraph-OGM

3.使用 TuGraph-OGM

3.3.通过OGM进行增删改查

session.query(""CALL db.createVertexLabel('Director', 'name', 'name',"" +
""STRING, false, 'age', INT16, true)"", emptyMap());            // 创建节点Label Director
session.query(""CALL db.createEdgeLabel('DIRECT', '[]')"", emptyMap()); // 创建边Label DIRECT
Result createResult = session.query(
""CREATE (n:Movie{title:\""The Shawshank Redemption\"", released:1994})"" +
""<-[r:DIRECT]-"" +
""(n2:Director{name:\""Frank Darabont\"", age:63})"",
emptyMap());' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '3.使用 TuGraph-OGM', 'Header 3': '3.3.通过OGM进行增删改查'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.1 构建图对象**

首先需要通过注解标明图中的实体。  
@NodeEntity：该注解标明的类为节点类。  
@Relationship：用于标明边，同时@Relationship中可指定label与边的指向。  
@Id：用于标明identity，是OGM中数据的唯一标识。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.1 构建图对象**'}"
"return n 和 return p.name,p.age 的数据结构不一致。 能统一返回可视化页面的这种结构么？","page_content='src/cypher/parser/symbol_table.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

//
// Created by wt on 19-2-25.
//
#pragma once
#include ""geax-front-end/ast/expr/Ref.h""
#include ""cypher/parser/data_typedef.h""

namespace cypher {

struct SymbolNode {
    size_t id;  // index in record
    enum Type {
        CONSTANT = 0,
        NODE = 1,
        RELATIONSHIP = 2,
        PARAMETER = 3,
        NAMED_PATH = 4,
    } type;
    enum Scope {
        LOCAL,             // MATCH (n) RETURN n,1 AS num
        ARGUMENT,          // WITH a
        DERIVED_ARGUMENT,  // derived from argument, WITH a UNWIND a AS x
    } scope;

    SymbolNode(size_t i, Type t, Scope s) : id(i), type(t), scope(s) {}

    inline static std::string to_string(const SymbolNode::Type& t) {
        static std::unordered_map<SymbolNode::Type, std::string> type_map = {
            {SymbolNode::Type::CONSTANT, ""CONSTANT""},
            {SymbolNode::Type::NODE, ""NODE""},
            {SymbolNode::Type::RELATIONSHIP, ""RELATIONSHIP""},
            {SymbolNode::Type::PARAMETER, ""PARAMETER""},
            {SymbolNode::Type::NAMED_PATH, ""NAMED_PATH""},
        };
        auto it = type_map.find(t);
        if (it == type_map.end()) {
            throw std::runtime_error(""Unknown SymbolNode::Type"");
        }
        return it->second;
    }

    inline static std::string to_string(const SymbolNode::Scope& s) {
        static std::unordered_map<SymbolNode::Scope, std::string> scope_map = {
            {SymbolNode::Scope::LOCAL, ""LOCAL""},
            {SymbolNode::Scope::ARGUMENT, ""ARGUMENT""},
            {SymbolNode::Scop' metadata={'file_name': 'symbol_table.h', 'file_path': 'src/cypher/parser/symbol_table.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/parser/symbol_table.h'}","page_content='ISO GQL

2.Clauses

2.3.RETURN

```  
#### 可选属性  
```
MATCH (n:Person)
RETURN n.age LIMIT 2
```  
返回结果  
```JSON
[{""n.age"":null},{""n.age"":null}]
```  
#### 其它表达式  
```
MATCH (n:Person)
RETURN n.birthyear > 1970, ""I'm a literal"", 1 + 2, abs(-2)
LIMIT 2
```  
返回结果  
```JSON
[{""\""I'm a literal\"""":""I'm a literal"",""1 + 2"":3,""abs(-2)"":2,""n.birthyear > 1970"":false},{""\""I'm a literal\"""":""I'm a literal"",""1 + 2"":3,""abs(-2)"":2,""n.birthyear > 1970"":false}]
```  
#### 结果唯一性  
```
MATCH (n)' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.3.RETURN'}","page_content='ISO GQL

2.Clauses

2.3.RETURN

MATCH (n:Person)
RETURN n.name AS nname LIMIT 2
```  
返回结果  
```JSON
[{""nname"":""Christopher Nolan""},{""nname"":""Corin Redgrave""}]
```  
#### 可选属性  
```
MATCH (n:Person)
RETURN n.age LIMIT 2
```  
返回结果  
```JSON
[{""n.age"":null},{""n.age"":null}]
```  
#### 其它表达式  
```
MATCH (n:Person)
RETURN n.birthyear > 1970, ""I'm a literal"", 1 + 2, abs(-2)
LIMIT 2
```  
返回结果  
```JSON' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.3.RETURN'}"
编译TuGraph时如何为基于ARM的机器（如Mac M1）配置CMake？,"page_content='从源码编译

2.编译介绍

以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`，如果在arm机器编译（如M1芯片的Mac中，需要加上` -DENABLE_BUILD_ON_AARCH64=ON`）
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build' metadata={'Header 1': '从源码编译', 'Header 2': '2.编译介绍'}","page_content='TuGraph-db

3. 从源代码编译

建议在Linux系统中构建TuGraph，Docker环境是个不错的选择。如果您想设置一个新的环境，请参考[Dockerfile]  
以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build' metadata={'Header 1': 'TuGraph-db', 'Header 2': '3. 从源代码编译'}","page_content='demo/TuGraph-Demo.md/ # TuGraph 示例

## 1 简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph是TuGraph的曾用名。

主要功能特征包括：

- 支持属性图模型
- 原生图存储及处理
- 完全的ACID事务支持
- 支持OpenCypher图查询语言
- 支持原生的Core API和Traversal API
- 支持REST和RPC接口
- 支持CSV、JSON、MySQL等多数据源导入导出
- 支持可视化图交互
- 支持命令行交互
- 内置用户权限控制、操作审计
- 支持任务和日志的监控管理
- 原生适配PandaGraph图分析引擎
- 集成DGL图神经网络系统

性能及可扩展性特征包括：

- 支持TB级大容量
- 吞吐率高达千万顶点每秒
- 面向读优化的存储引擎
- 支持高可用模式
- 支持离线备份恢复
- 在线热备份
- 高性能批量导入导出

## 2 快速上手

见QuickStart文档。

## 3 基本功能

### 3.1 RPC Client
#### 3.1.1 概述
RPC Client是对cpp语言rpc客户端的简单封装，每次执行时会创建一条到lgraph_server的链接用于发送请求数据以及接收响应结果，执行完毕后进程退出前会断开链接
#### 3.1.2 编译
在代码目录demo/CppRpcClientDemo目录下,执行下列命令 ,成功后将会看到可执行文件clientdemo
```bash
mkdir build && cd build && cmake ../ && make
```
#### 3.1.3 运行
先启动lgraph_server，确保rpc端口处于打开状态。

clientdemo程序接收参数如下：
        -h             show this usage
        -i --ip        ip for graph server
        -p --port      port for graph server
        -g --graph     graph name
        -u --user      user name
        --password     user password
        -c --cypher    cypher to query
举例如下
```bash
./clientdemo -i 127.0.0.1 -p 9090 -u admin --password 73@TuGraph -g default -c ""MATCH (n) RETURN n LIMIT 100""
```
### 3.2 Python RPC Client
#### 3.2.1 概述
Python RPC Client是对python语言rpc客户端的简单封装，每次执行时会创建一条到lgraph_server的链接用于发送请求数据以及接收响应结果，执行完毕后进程退出前会断开链接
#### 3.2.2 运行
需要依赖编译生成的python_client.so库，将python_client.so与client_python.py放在同一目录下
先启动lgraph_server，确保rpc端口处于打开状态。

clientdemo程序接收参数如下：
-h             show this usage
-i --ip        ip for graph server
-p --port      port for graph server
-g --graph     graph name
-u --user      user name
--password     user password
-c --cypher    cypher to query
举例如下
```bash
python3 client_python.py -i 127.0.0.1 -p 9090 -u admin --password 73@TuGraph -g default -c ""MATCH (n) RETURN n LIMIT 100""
```
## 4 集成工具

### 4.1 DataX 导入导出工具
#### 4.1.1 概述
DataX 支持 TuGraph 和 MySQL、SQL Server、Oracle、PostgreSQL、HDFS、Hive、HBase、OTS、ODPS、Kafka 等各种异构数据源的数据导入导出。
#### 4.' metadata={'file_name': 'TuGraph-Demo.md', 'file_path': 'demo/TuGraph-Demo.md', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/TuGraph-Demo.md'}"
单机的配置大致是什么情况？,"page_content='环境准备

3.典型配置推荐

| 硬件      | 最低配置   | 建议配置                   |
| -------- | --------- | ------------------------ |
| CPU      | 4 Cores   | 64 Cores                 |
| 内存      | 4GB       | 512GB                    |
| 外存      | 100GB     | 2TB NVMe SSD             |
| OS       | Linux 4.9 | CentOS 7.3               |' metadata={'Header 1': '环境准备', 'Header 2': '3.典型配置推荐'}","page_content='快速上手

1.简介

1.2.硬件要求

_目前我们建议用户使用 NVMe SSD 配合较大的内存配置以获取最佳性能。_  
| 硬件   | 最低配置      | 建议配置                     |
|------|-----------|--------------------------|
| CPU  | X86_64    | Xeon E5 2670 v4          |
| 内存   | 4GB       | 256GB                    |
| 硬盘   | 100GB     | 1TB NVMe SSD             |
| 操作系统 | Linux 2.6 | Ubuntu 18.04, CentOS 7.3 |' metadata={'Header 1': '快速上手', 'Header 2': '1.简介', 'Header 3': '1.2.硬件要求'}","page_content='环境准备

1.硬件环境

1.2. 内存

我们建议内存容量不小于实际的数据大小。如果最求极致的性能，把所有的数据缓存到内存里是最理想的。在数据访问的局部性上，图数据库的局部性要比关系型数据库差，因此如果数据在内存中放不下，通常会频繁地换入换出。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.2. 内存'}"
如何查询两点间的一条通路？,"page_content='内置算法

扩展算法包

两点间最短路径

两点间最短路径程序实现了Bidirectional Breadth-First Search算法，在有向无权图上从起点沿着出边做正向宽度优先搜搜，从终点沿着入边做反向宽度优先搜索，通过起点和终点共同遍历到的点来确定从起点到终点的最短路径长度。算法内容请参考[https://en.wikipedia.org/wiki/Bidirectional_search](https://en.wikipedia.org/wiki/Bidirectional_search ""Bidirectional search"")。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': '两点间最短路径'}","page_content='QA汇总

Cypher QA

查询最短路径

Q：如何查询最短路径，shortestPath 函数如何使用？
A：使用示例如下（示例图谱：MovieDemo）  
```
MATCH (n1 {name:'Corin Redgrave'}),(n2 {name:'Liam Neeson'})
CALL algo.allShortestPaths(n1,n2) YIELD nodeIds,relationshipIds,cost
RETURN nodeIds,relationshipIds,cost
```  
详尽使用方案请参考官网文档https://www.tugraph.org/doc?version=V3.3.0&id=10000000000658658。' metadata={'Header 1': 'QA汇总', 'Header 2': 'Cypher QA', 'Header 3': '查询最短路径'}","page_content='快速上手(本地运行)

本地运行流图作业

3. 输入数据  
输入数据如下，数据前面的"".""代表一条点数据，""-""代表一条边数据(起点、终点和权重)。  
```
. 1,jim
. 2,kate
. 3,lily
. 4,lucy
. 5,brown
. 6,jack
. 7,jackson
- 1,2,0.2
- 2,3,0.3
- 3,4,0.2
- 4,1,0.1
- 4,5,0.1
- 5,1,0.2
- 5,6,0.1
- 6,7,0.1
```  
可以看到 socket 控制台上显示计算出来的环路数据：  
![ide_socket_server](../static/img/ide_socket_server.png)  
你也可以继续输入新的点边数据，查看最新计算结果，如输入一下数据：  
```
- 6,3,0.1
```  
可以看到新的环路 3-4-5-6-3 被检查出来：  
![ide_socket_server_more](../static/img/ide_socket_server_more.png)  
4. 访问可视化dashboard页面' metadata={'Header 1': '快速上手(本地运行)', 'Header 2': '本地运行流图作业'}"
tugraph 支持通过cypher 或者python的形式修改schema吗,"page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}","page_content='QA汇总

内核引擎QA

边支持索引

Q: TuGraph 的边是否支持索引？
A: TuGraph 在引擎层支持边索引，可通过存储过程使用。Cypher的边索引功能正在开发支持中。' metadata={'Header 1': 'QA汇总', 'Header 2': '内核引擎QA', 'Header 3': '边支持索引'}","page_content='RPC API

5.存储过程

为满足用户较为复杂的查询/更新逻辑，TuGraph支持 C 语言和 Python 语言编写的存储过程。
用户可以使用RPC请求对存储过程进行增删改查操作。' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程'}"
TuGraph-Restful-Server 使用哪种框架支持其HTTP协议，并提供了哪些主要功能？,"page_content='TuGraph-Restful-Server

1.TuGraph-Restful-Server 简介

TuGraph Restful Server 使用brpc框架支持的http协议，提供restful接口查询功能，在实现中，restful server 与rpc server 使用同一个端口。目前restful接口提供文件上传，数据导入，导入进度查询，cypher查询，文件删除等功能' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '1.TuGraph-Restful-Server 简介'}","page_content='功能概览

6.生态工具

6.3.运维监控

TuGraph 使用 Prometheus 加 Grafana 的监控框架，采用松耦合的方式。Prometheus 从 TuGraph 的监控接口获取监控信息，存储在本地时序数据库中，然后通过 Grafana 在网页端交互展示。  
TuGraph 提供的监控的状态包括图数据库的状态和服务器的状态，前者包括读写负载、点边数量等数据库端的状态，后者包括内存、CPU、硬盘等服务器的实时状态。如果某些监控状态超过了预期的阈值，就需要主动告警，通常需要对接其他运维管控系统，比如群消息、邮件告警等。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.3.运维监控'}","page_content='RESTful API Legacy

3.登录

TuGraph 提供基于 JWT 的用户认证方式，可以使用 HTTP 或 HTTPS 协议进行传输。系统默认使用 HTTP 协议，如果需要使用 HTTPS，需要在 lgraph.json 配置文件中将 ssl_auth 设为 1。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '3.登录'}"
禁用角色后，具有该角色的用户会如何受影响？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

```  
#### 6.2.6.禁用角色  
角色可以被禁用。角色被禁用后，具有该角色的用户将不再从该角色中获得任何权限。只有管理员可以执行此操作。  
- **URI**: `/role/{role_name}/disable`
- **METHOD**: POST
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/disable
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.6.禁用角色  
角色可以被禁用。角色被禁用后，具有该角色的用户将不再从该角色中获得任何权限。只有管理员可以执行此操作。  
- **URI**: `/role/{role_name}/disable`
- **METHOD**: POST
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/disable' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='可视化操作手册

2.操作指南

2.5.控制台

![角色管理-添加角色](../../../images/browser/role-add.png)  
###### b.编辑角色  
在`角色管理`界面点击`编辑`按钮编辑已有角色，用户可以编辑角色描述以及图权限。  
![角色管理-编辑角色](../../../images/browser/role-edit.png)  
###### c.禁用角色  
在`角色管理`界面点击`禁用`按钮禁止对应的角色，点击`启用`按钮开启对应的角色。禁用角色后，对应角色图访问权限失效。  
- 禁用角色：禁用之后，对应角色图访问权限失效。
- 当一个用户拥有两个角色对同一个图有操作权限时，当禁用其中一个角色时，另一个角色权限同样有效。  
![角色管理-禁用](../../../images/browser/role-disable.png)
![角色管理-启用](../../../images/browser/role-enable.png)  
###### d.删除角色  
在`角色管理`界面点击`删除`按钮删除对应的角色。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.5.控制台'}"
如果您作为公司员工提交贡献内容，应如何保证合法授权？,"page_content='src/protobuf/tugraph_db_management.proto/ // Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// ""License""); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

syntax=""proto2"";
package lgraph.management;

option cc_generic_services = true;
option java_outer_classname = ""TuGraphDBManagement"";

enum ResponseCode {
      SUCCESS = 0;
      FAILED = 1;
}

message Job {
      required int32 job_id = 1;
      required string task_name = 2;
      required string task_id = 3;
      required string db_id = 4;
      required int64 start_time = 5;
      required string period = 6;
      required string procedure_name = 7;
      required string procedure_type = 8;
      required string status = 9;
      required int64 runtime = 10;
      required string user = 11;
      required int64 create_time = 12;
}

message AlgoResult {
      required string task_id = 1;
      required string result = 2;
}

message CreateJobRequest {
      required string task_id = 1;
      required string task_name = 2;
      required string user = 3;
      required string procedure_name = 4;
      required string procedure_type = 5;
      required string period = 6;
      required int64 create_time = 7;
      required int64 start_time = 8;
}

message CreateJobResponse {
      required int32 job_id = 1;
}

message GetJobStatusRequest {
      optional string task_id = 1;
}

message' metadata={'file_name': 'tugraph_db_management.proto', 'file_path': 'src/protobuf/tugraph_db_management.proto', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/protobuf/tugraph_db_management.proto'}","page_content='src/server/db_management_client.h/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <condition_variable>
#include ""tools/lgraph_log.h""
#include ""fma-common/utils.h""
#include ""protobuf/tugraph_db_management.pb.h""
#include ""gflags/gflags.h""
#include ""brpc/channel.h""

namespace lgraph {
namespace DbMgr = lgraph::management;

class DBManagementClient {
 private:
    // DbMgr::JobManagementService_Stub stub_;
    bool exit_;
    bool connected_;
    uint64_t heartbeat_count_;
    int heartbeat_interval_;
    std::shared_ptr<brpc::Channel> channel_;
    std::condition_variable heartbeat_cond_;
    std::mutex heartbeat_mutex_;
    std::string host_;
    std::string port_;

 public:
    DBManagementClient();

    DISABLE_COPY(DBManagementClient);
    DISABLE_MOVE(DBManagementClient);

    static DBManagementClient& GetInstance() {
        // brpc::FLAGS_usercode_in_pthread = true;
        static DBManagementClient instance;
        return instance;
    }

    void Init(const std::string& hostname, const uint16_t port, const std::string& url);

    bool GetConnected() { return connected_; }

    void DetectHeartbeat();

    void StopHeartbeat();

    /**
     * @brief   create a job record in db management.
     * @param   start_time   start time of a job, echo time in ms, int64.
     * @param   period   job period type, PERIODIC, IMMEDIATE, DELAYED.
     * @param   name   name of this job.
     * @param   type   type of this job.
     * @param   user   user of db who create this job.
     *
     * @returns   unique job_id for created job record.
     */
    voi' metadata={'file_name': 'db_management_client.h', 'file_path': 'src/server/db_management_client.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/server/db_management_client.h'}","page_content='src/core/managed_object.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <atomic>
#include <mutex>

#include ""fma-common/pipeline.h""
#include ""fma-common/timed_task.h""
#include ""fma-common/type_traits.h""
#include ""fma-common/utils.h""

#include ""core/thread_id.h""

#define GC_DEBUG 0

#if GC_DEBUG
#define GC_DBG_REF(o) FMA_LOG() << ""Referencing "" << (o);
#define GC_DBG_DEREF(o) FMA_LOG() << ""Dereferencing "" << (o);
#define GC_DBG_DEL(o) FMA_LOG() << ""Deleting "" << (o);
#else
#define GC_DBG_REF(o)
#define GC_DBG_DEREF(o)
#define GC_DBG_DEL(o)
#endif

namespace lgraph {

namespace _detail {
// Reference counted object
// NOTE: References are kept in Thread-Local-Storage, so Reference(tid) and Dereference(tid)
// must be paired with the same tid.
// Do NOT use this class directly unless you are pretty sure about what
// you are doing. Use GabageCollectedObject and ScopedRef instead.
template <typename T>
class RefCountedObj {
    // number of managers currently referencing this object
    // two GabageCollectedObject can use the same RefCountedObj when one is copy constructed
    // When GabageCollectedObject is destructed, it will try to delete this object
    // only when manager_count_==1
    std::atomic<int64_t> manager_count_;
    T* obj_;
    std::vector<fma_common::PadForCacheLine<uint64_t>> references_;

 public:
    explicit RefCountedObj(T* obj, size_t max_threads = LGRAPH_MAX_THREADS)
        : manager_count_(1), obj_(obj),
            references_(max_threads, fma_common::PadForCacheLine<uint64_t>(0)) {}

    ~RefCountedObj() {
        FMA_ASS' metadata={'file_name': 'managed_object.h', 'file_path': 'src/core/managed_object.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/managed_object.h'}"
如何只清空数据，而保留schema？,"page_content='业务开发指南

子图操作

清空子图

#### 删除所有的点边数据和图schema
```
CALL db.dropDB()
```
#### 只删除所有点边数据, 保留图schema
```
CALL db.dropAllVertex()
```' metadata={'Header 1': '业务开发指南', 'Header 2': '子图操作', 'Header 3': '清空子图'}","page_content='src/core/schema.cpp/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#include ""fma-common/string_formatter.h""

#include ""core/vertex_index.h""
#include ""core/edge_index.h""
#include ""core/schema.h""
#include ""import/import_config_parser.h""
#include ""core/vector_index.h""

namespace lgraph {

void Schema::DeleteEdgeFullTextIndex(EdgeUid euid, std::vector<FTIndexEntry>& buffers) {
    if (fulltext_fields_.empty()) {
        return;
    }
    FTIndexEntry entry;
    entry.type = FTIndexEntryType::DELETE_EDGE;
    entry.vid1 = euid.src;
    entry.vid2 = euid.dst;
    entry.lid = euid.lid;
    entry.eid = euid.eid;
    buffers.emplace_back(std::move(entry));
}

void Schema::DeleteVertexFullTextIndex(VertexId vid, std::vector<FTIndexEntry>& buffers) {
    if (fulltext_fields_.empty()) {
        return;
    }
    FTIndexEntry entry;
    entry.type = FTIndexEntryType::DELETE_VERTEX;
    entry.vid1 = vid;
    buffers.emplace_back(std::move(entry));
}

void Schema::DeleteVertexIndex(KvTransaction& txn, VertexId vid, const Value& record) {
    for (auto& idx : indexed_fields_) {
        auto& fe = fields_[idx];
        if (fe.GetIsNull(record)) continue;
        if (fe.Type() != FieldType::FLOAT_VECTOR) {
            VertexIndex* index = fe.GetVertexIndex();
            FMA_ASSERT(index);
            // update field index
            if (!index->Delete(txn, fe.GetConstRef(record), vid)) {
                THROW_CODE(InputError, ""Failed to un-index vertex [{}] with field ""
                                                    ""value [{}:{}]: index value does not exist."",
                      ' metadata={'file_name': 'schema.cpp', 'file_path': 'src/core/schema.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/schema.cpp'}","page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

}
}
```  
#### 6.6.4.Schema 导入  
- **URI**: `/db/{graph_name}/schema/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
- **RESPONSE**:  
Schema 导入会根据 description 比较新的 Schema 和数据库中原有的 Schema 是否兼容，检查的粒度为 Label。如果不一致则出错，如果一致则添加原先 Schema 中不存在的 Label，返回 200。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/schema/text' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}"
OGM在哪些方面类似于MyBatis？,"page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

简介

TuGraph 图数据库提供了 JAVA、C++、Python 等多种语言的 SDK 支持，方便客户在各种场景下使用。用户使用 SDK 向TuGraph服务器发送Cypher请求，服务器则以 JSON形式返回数据。近日，TuGraph 推出了一款面向 JAVA 客户端用户的开发工具 TuGraph-OGM (Object Graph Mapping)，为用户提供了对象操作接口，相较 Cypher/JSON 接口应用起来更加便捷。  
OGM 类似于关系数据库中的 ORM（Object Relational Model），可以将数据库返回的数据自动映射成 JAVA 中的对象，方便用户读取，而用户对这些对象的更新操作也可以被自动翻译成 Cypher 语句发送给服务器。这样即便是完全不懂 Cypher 的用户，也可以通过操作对象与数据库进行交互，大大降低了图数据库的使用门槛。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

简介

OGM 类似于关系数据库中的 ORM（Object Relational Model），可以将数据库返回的数据自动映射成 JAVA 中的对象，方便用户读取，而用户对这些对象的更新操作也可以被自动翻译成 Cypher 语句发送给服务器。这样即便是完全不懂 Cypher 的用户，也可以通过操作对象与数据库进行交互，大大降低了图数据库的使用门槛。  
TuGraph-OGM 同时也兼容其他开源产品 OGM 工具如 Neo4j-OGM，方便用户将工程在不同数据库与 TuGraph数据库间无缝迁移。本文将对 TuGraph-OGM 进行全面的介绍。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '简介'}","page_content='功能概览

5.客户端工具

OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。  
命令行工具`lgraph_cypher`是查询客户端，可用于向 TuGraph 服务器提交 OpenCypher 请求。`lgraph_cypher`客户端有两种执行模式：单命令模式和交互式模式。' metadata={'Header 1': '功能概览', 'Header 2': '5.客户端工具'}"
BROWSER 有 docker 部署么？,"page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}","page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

1. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7:${VERSION}
```  
2. 启动docker  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}","page_content='Docker部署

2.现有Docker Image

2.2.命名规范

`tugraph/tugraph-runtime-[os name & version]:[tugraph-runtime version]`  
例如：`tugraph/tugraph-runtime-centos7:3.4.0`  
#### 2.2.3.TuGraph Mini Runtime Image  
提供二进制可运行环境，不包含TuGraph种Java、Python相关的功能，无C++ plugin编译运行，仅so上传。  
`tugraph/tugraph-mini-runtime-[os name & version]:[tugraph-runtime version]`  
例如： `tugraph/tugraph-mini-runtime-centos7:3.4.0`' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.2.命名规范'}"
TuGraph-DB是否有数据导入工具？相关代码在哪里？,"page_content='数据导入

1.简介

在图数据库服务安装成功后，您可以使用`lgraph_import`批量导入工具将现有数据导入 TuGraph。`lgraph_import`支持从 CSV 文件和 JSON 数据源导入数据。  
> CSV 格式  
```
[movies.csv]
id, name, year, rating
tt0188766,King of Comedy,1999,7.3
tt0286112,Shaolin Soccer,2001,7.3
tt4701660,The Mermaid,2016,6.3
```  
> jsonline 格式  
```json
[""tt0188766"",""King of Comedy"",1999,7.3]
[""tt0286112"",""Shaolin Soccer"",2001,7.3]
[""tt4701660"",""The Mermaid"",2016,6.3]
```  
TuGraph 支持两种导入模式：  
- _离线模式_：读取数据并将其导入指定服务器的数据文件，应仅在服务器离线时完成。' metadata={'Header 1': '数据导入', 'Header 2': '1.简介'}","page_content='数据导出

1.简介

TuGraph 可以通过 `lgraph_export` 工具来对已经存放在TuGraph的图数据进行数据导出。 `lgraph_export` 工具可以将指定 TuGraph 数据库的数据以 `csv` 或者 `json` 文件形式导出到指定目录，同时导出这些数据进行再导入时需要的配置文件 `import.config` ，详细描述可参见[配置文件](1.data-import.md)。' metadata={'Header 1': '数据导出', 'Header 2': '1.简介'}","page_content='功能概览

6.生态工具

6.1.TuGraph DataX

![导入导出](../../../images/tugraph-datax.png)  
TuGraph 核心支持 CSV 和 JSON 合适的导入导出，提供空库导入和增量导入的模式。实际中会存在 MySQL、Kafka、Hive 等多数据源导入的需求，TuGraph 通过 DataX 做多数据源的对接。由于关系模型和图模型存在的差异，数据清洗的流程可以使用 SparkSQL 快速处理，TuGraph 本身仅关注 CSV 和 JSON 的简单场景导入可靠性和性能。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.1.TuGraph DataX'}"
图数据库相比关系型数据库有哪些独特的优势？,"page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.2. 兼容性

现实中，项目进程通常不断演变，数据的内容甚至数据格式也在不断变化。在关系型数据库中，这意味着表结构的变化或建立多个新表，对源数据的修改非常大。而在图数据库中，仅需添加新的点、边和属性，并将其设置为对应的类型即可。从本质上说，一个表代表一种类型的数据，一个点代表一个特定的数据。这意味着关系型数据库更关注数据类型，而图数据库更关注数据个体及其关联关系。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.2. 兼容性'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.3. 直观性

使用图的方式表达现实世界的关系更直接和自然，在万物互联的时代尤为突出。如果使用关系型数据，先建立实体表，再建立关系表，最后映射数据，需要高度的抽象思维。在图数据上进行分析查询时，可以直观地通过点边连接的拓扑结构找到所需数据，无需任何专业知识。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.3. 直观性'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.1. 性能

在关联关系处理上，使用关系型数据库不可避免地要使用表的JOIN操作，这会对性能产生较大影响；而图数据库则直接跳转访问类指针，操作关联数据的效率更高，比关系型数据库提高2到4个数量级的性能。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.1. 性能'}"
TuGraph 产品架构中，客户端 SDK 支持哪些编程语言？,"page_content='TuGraph产品架构

1.简介

![产品架构](../../../images/architecture.png)  
上图从功能模块的角度，以 TuGraph 为例，给出了企业级图数据库的整体架构，自下而上包括：  
- 软硬件环境。涉及图数据库的开发和使用环境。TuGraph 主要基于底层的 C++语言开发，能够兼容市面上大部分操作系统和 CPU。
- 存储层，包括 KV 存储层和图存储层。存储层需要支持计算层所需的各个功能。
- 计算层。计算层应包括图事务引擎、图分析引擎和图神经网络引擎，也包含了服务端提供的多种编程接口，包括描述式查询语言 Cypher，存储过程等。
- 客户端。客户端 SDK 应支持 Java、Python、C++ 等多种语言，也支持命令行的交互方式。Browser 和 Explorer 通过网页端交互的方式，降低了图数据库的使用门槛。
- 在生态工具方面，覆盖了企业级图数据库的开发、运维、管理等链路，提升可用性。' metadata={'Header 1': 'TuGraph产品架构', 'Header 2': '1.简介'}","page_content='功能概览

5.客户端工具

客户端主要分为各种编程语言的SDK，OGM以及命令行工具。  
客户端 SDK 主要用于二次开发，可以通过 RPC 或 REST 协议链接服务端。RPC 基于长链接有较好的性能，数据需要通过 protobuf 统一序列化。TuGraph 使用brpc，支持 Java、Python、C++ 的 rpc 客户端。REST 的协议比较宽泛，能够简单适配更加多样的环境，不同的编程语言能够简单对接。TuGraph 给出了 Python 的REST 客户端实例，命令行的交互也是用 REST 实现。  
OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。' metadata={'Header 1': '功能概览', 'Header 2': '5.客户端工具'}","page_content='QA汇总

Client QA

支持语言

Q：client 目前有哪些编程语言，是否支持 node js？
A：目前主要支持的编程语言有 c++,python,java；目前不支持 node js。使用 node 作为主要开发语言的用户，可以使用 tugraph 提供的 restful api 来调用。建议使用 Cypher 来封装调用接口。后续版本 restful api 将不再进行更新维护，只会保留登录、登出、刷新 token、cypher 调用这几个常见的 api。' metadata={'Header 1': 'QA汇总', 'Header 2': 'Client QA', 'Header 3': '支持语言'}"
OGC定义了哪些空间数据的标准表示格式？,"page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

OGC(Open Geospatial Consortium) 定义了空间数据的标准表示格式，分别为EWKT(extended well known text)与EWKB(extended well known binary)格式，用于在不同系统和平台之间交换和存储空间数据，现已被广泛采用。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现'}","page_content='地理空间数据类型使用示例

2. 预备知识

2.3 数据存储格式

OGC(Open Geospatial Consortium) 定义了空间数据的标准表示格式，分别为WKT与WKB格式，用于在不同系统和平台之间交换和存储空间数据，现已被广泛采用。其中WKT(well-kown text)格式, 是一种文本标记语言,易于人类阅读和编写，而WKB(Well-Known Binary)格式采用一系列字节来编码空间数据，更适合在计算机中存储;  
**WKT:**  
```
POINT(<x> <y>)
LINESTRING(<x1> <y1>, <x2><y2>, ...)
```  
WKT格式的数据如上例所示，先指定空间数据类型，再在括号内指定具体的坐标，一个坐标对表示一个点，每个坐标对之间用逗号隔开。对于Polygon类型的数据，第一个坐标对需要与最后一个坐标对相同，形成闭合的面。  
**WKB:**  
![image.png](../../../images/spatail/WKB.png)  
针对EWKB格式的编码，说明如下:  
- 第0 - 1位: 编码方式;' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '2. 预备知识', 'Header 3': '2.3 数据存储格式'}","page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的表示

空间数据类型可以用不同的坐标系来表示，EPSG<sup>[1]</sup>是一个标准化的地理空间参考系统标识符集合， 用于标识不同的地理空间参考系统，包括坐标系统、地理坐标系、投影坐标系等。通常使用EPSG编码表示数据的坐标系。行业内一般采用  
-   •WGS84坐标系（没错，就是GPS系统的坐标系），标识符为EPSG 4326  
-   •Cartesian（笛卡尔）坐标系（没错，就是你高中数学学的直角坐标系），标识符为EPSG 7203  
WGS84是全球定位系统(GPS)的基础，允许全球的GPS接收器确定精确位置。几乎所有现代GPS设备都是基于WGS84坐标系来提供位置信息。在地图制作和GIS（地图制作和地理信息系统）领域，WGS84被广泛用于定义地球上的位置。这包括各种类型的地图创建、空间数据分析和管理等。  
Cartesian（笛卡尔）坐标系，又称直角坐标系，是一种最基本、最广泛应用的坐标系统。它通过两条数轴定义一个平面，三条数轴定义一个空间，这些轴互相垂直，在数学、物理、工程、天文和许多其他领域中有着广泛的应用。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的表示'}"
db.importor.dataImportor函数的目的是什么？,"page_content='Cypher API

5.附录2. 内置procedures列表

5.2.内置procedures完整列表

| db.importor.dataImportor              | 导入点或边数据                               | db.importor.dataImportor(description::STRING,content::STRING,continue_on_error::BOOLEAN,thread_nums::INTEGER,delimiter::STRING) :: (::VOID)                                             |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '5.2.内置procedures完整列表'}","page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb1 --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7073 --rpc_port 9093"",
""cleanup_dir"":[""./testdb1""]}' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}","page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

ret = client.callCypher(""MATCH (n) RETURN n LIMIT 100"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert len(res) == 21
ret = client.callCypher(""CALL db.flushDB()"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```python' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}"
TuGraph企业版是什么？,"page_content='什么是TuGraph

4. TuGraph企业版

企业版对商业化功能支持更加完善，包括分布式集群架构，覆盖探索、研发、服务、运维管理全生命周期的一站式图平台，在线、近线、离线的图计算引擎，支持流式、大数据类数据源，多地多中心的部署形态，以及专家支持服务等。企业版是商业化解决方案的理想选择。  
如需商业支持，请联系我们：  
- 电话：400-903-0809
- 邮件：tugraph@service.alipay.com
- 官网：https://tugraph.antgroup.com' metadata={'Header 1': '什么是TuGraph', 'Header 2': '4. TuGraph企业版'}","page_content='TuGraph在图计算系统建设中的作用

TuGraph 技术优势

TuGraph 企业版特色

除了开源版本，我们也继续提供商业版本。这个版本包含一个分布式图数据库，以及离线计算引擎和流式图计算功能。此外，我们还提供了 TuGraph Platform 一站式图平台，包括运维、可视化等功能。在这个平台上，用户可以在图数据库中执行流式计算，并在线写回数据库。这种方式通常用于实时查询结果，因为流式计算的时间可能比较长，但用户可以立即查询到较早的结果。这对于在线业务来说非常重要。  
商业化产品还提供私有化部署，也可以通过一体机的方式部署硬件，并将很快推出云上部署方案，这样大家就可以在云上体验我们的产品。' metadata={'Header 1': 'TuGraph在图计算系统建设中的作用', 'Header 2': 'TuGraph 技术优势', 'Header 3': 'TuGraph 企业版特色'}","page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}"
请求存储过程列表时，应该使用哪种HTTP方法和URI？,"page_content='RESTful API Legacy

5.存储过程

5.2.列出所有存储过程

- **URI**: `/db/{graph_name}/cpp_plugin|python_plugin`
- **METHOD**: GET
- **RESPONSE**: 存储过程列表，其中每个元素是一个 plugin 的描述，其格式为：
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | 存储过程名 | 字符串 |
| description | 存储过程描述 | 字符串 |
| read_only | 存储过程是否只读 | 布尔值 |  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/cpp_plugin
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
Output:
{
[
{
""description"":""adds a vertex label to the db"",' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程', 'Header 3': '5.2.列出所有存储过程'}","page_content='RPC API

5.存储过程

5.4.列举存储过程

列举存储过程请求不需要参数，以C++为例，用户列举存储过程的方式如下所示：
```C++
LGraphRequest req;
req.set_is_write_op(false);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
pluginRequest->mutable_list_plugin_request();
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.4.列举存储过程'}","page_content='Procedure API

4.2.如何使用存储过程

4.2.2.列出已加载的存储过程

在服务器运行过程中，用户可以随时获取存储过程列表。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin')
>>> r.status_code
200
>>> r.text
'{""plugins"":[{""description"":""Custom Page Rank Procedure"", ""name"":""age_10"", ""read_only"":true}]}'
```' metadata={'Header 1': 'Procedure API', 'Header 2': '4.2.如何使用存储过程', 'Header 3': '4.2.2.列出已加载的存储过程'}"
TuGraph基础算法包包含哪些算法？,"page_content='内置算法

简介

TuGraph目前包含以下6个基础算法28种扩展算法，共34个图算法：' metadata={'Header 1': '内置算法', 'Header 2': '简介'}","page_content='OlapOnDisk API

1. 简介

TuGraph的Standalone模式可用于加载图数据文件，其中图数据文件来源可包含text文本文件、BINARY_FILE二进制文件和ODPS源。在该模式下，TuGraph可实现多数据来源快速加载成图，然后在该图上运行如BFS、WCC、SSSP等迭代式算法，并输出最终结果至终端。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph内置了大量的常见图分析算法和丰富的辅助接口，因此用户几乎不需要自己实现具体的图计算过程，只需要在实现自己的存储过程的时候将相应算法库的头文件(.h)包含到自己的程序中，并在编译阶段链接自己的动态库文件即可。  
该文档主要介绍了Standalone的常用接口，使用到的辅助函数主要包含在OlapOnDB类。同时为帮助用户理解方便，对BFS算法进行举例说明。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '1. 简介'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}"
REST 服务器的默认端口号是多少？,"page_content='数据库运行

4.服务配置

4.1.配置参数

| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='数据库运行

4.服务配置

4.1.配置参数

| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='数据库运行

4.服务配置

4.1.配置参数

| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客户端端口。默认端口为 7687。                                                                                                                                                            |' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}"
如果需要对一个角色进行禁用，调用何种函数，并且该函数在何种情况下返回true？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

- **METHOD**: POST
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/disable
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.7.启用角色  
启用一个被禁用的角色。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.6.禁用角色  
角色可以被禁用。角色被禁用后，具有该角色的用户将不再从该角色中获得任何权限。只有管理员可以执行此操作。  
- **URI**: `/role/{role_name}/disable`
- **METHOD**: POST
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/disable' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

```  
#### 6.2.6.禁用角色  
角色可以被禁用。角色被禁用后，具有该角色的用户将不再从该角色中获得任何权限。只有管理员可以执行此操作。  
- **URI**: `/role/{role_name}/disable`
- **METHOD**: POST
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/disable
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}"
TuGraph更新之后，原库的数据会丢吗？,"page_content='数据迁移

1. 简介

数据迁移是指将数据从一个系统、存储介质或应用程序迁移到另一个系统、存储介质或应用程序的过程。当TuGraph要升级或者系统硬件环境发生变化时，
需要对原TuGraph服务中的数据进行迁移。以系统硬件环境和软件版本为依据进行划分，本文将数据迁移分为三种方案：
1. 兼容迁移：当迁移前后系统环境一致且TuGraph软件兼容时，可以直接使用备份恢复的方式迁移数据；
2. 升级迁移：当迁移前后系统环境不一致或TuGraph软件不兼容时，需要使用先导出数据再重新导入的方式迁移数据；
3. 在线迁移：当对高可用集群进行数据迁移且集群网络环境良好时，可以使用增删节点的的方式将原集群平滑切换到新集群。
接下来本文将详细介绍这三种方案。' metadata={'Header 1': '数据迁移', 'Header 2': '1. 简介'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

一、高可用架构介绍

4.TuGraph-DB高可用架构—Raft 共识算法

-   有了一致性的保证后，安全性也就有了保证，当超过半数的节点达成一致之后，才应用日志，这样就能解决网络分区延迟、丢包、冗余和乱序的错误。
-   基于一致性和安全性，它的可用性也就得到了保证，只要少于半数的节点宕机，即使主机宕机，也可以快速恢复应用，通过一次选举的时间就可以重新选出一个leader对外提供服务。  
国标对于高可用系统的指标评估，RTO 和 RPO 分别是恢复时间指标和恢复点目标，有 6 个等级，TuGraph-DB 已经达到了最高等级。当少量节点故障时，RPO 是 0，也就是没有数据损失，数据恢复时间点指标是小于 15 秒。即使是在部署的时候，无论是在同城的两中心、三中心，还是多地的多中心，都可以达成 RTO 小于 15 秒的标准。  
Raft算法优点:  
• 易用性：状态简单，强Leader  
• 一致性：日志逐个复制，超过半数节点达成一致才提交，不存在日志空洞  
• 安全性：超半数节点达成一致才应用日志，能解决网络延迟、分区、丢包、冗余和乱序等错误' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '一、高可用架构介绍', 'Header 3': '4.TuGraph-DB高可用架构—Raft 共识算法'}","page_content='数据迁移

2. 兼容迁移

兼容迁移指的是在系统环境不变，且TuGraph软件版本兼容时，原服务的数据和存储过程可以在新服务中使用，所以可以直接迁移。
用户可以先使用`lgraph_backup`工具备份数据，然后将数据传输到新机器中并重启服务。具体迁移步骤如下：' metadata={'Header 1': '数据迁移', 'Header 2': '2. 兼容迁移'}"
"如果节点中未包含属性""belt""，应该返回什么值？","page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

| type     | 列数据类型                               | 字符串，有以下类型： int8, int16, int32, int64, float, double, string, date, datetime, binary, bool |
| optional | 数据是否可以为空（可选，缺省值为 false） | 布尔值                                                                                              |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/label
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}","page_content='boolean IS NOT FALSE | 如果布尔变量为true，则返回true。如果布尔变量是UNKNOWN，则返回true。
boolean IS TRUE | 如果布尔变量为true，则返回true。如果布尔变量是UNKNOWN，则返回false。
boolean IS NOT TRUE | 如果布尔变量为false，则返回true。如果布尔变量是UNKNOWN，则返回true。
value1 = value2 | 如果value1等于value2，则返回true。
value1 <> value2 | 如果value1不等于value2，则返回true。
value1 > value2 | 如果value1大于value2，则返回true。
value1 >= value2 | 如果value1大于或等于value2，则返回true。
value1 < value2 | 如果value1小于value2，则返回true。
value1 <= value2 | 如果value1小于或等于value2，则返回true。'","page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

| -------- | ---------------- | ------ |
| optional | 该列值是否可为空 | 布尔值 |
| type     | 列值类型         | 字符串 |  
**Example request.**  
```
• GET http://localhost:7070/db/{graph_name}/label/node/person
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""age"":{
""optional"":false,
""type"":""int16""
},
""id"":{
""optional"":false,
""type"":""int8""
},
""name"":{
""optional"":false,
""type"":""string""
}
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}"
磁盘IO警报是在什么情况下触发的？,"page_content='运维监控

2.部署方案

2.4.第四步

""handler"": 1,
""message"": ""【生产图数据库Grafana】\n  磁盘IO超过10MB/S"",
""name"": ""磁盘IO alert"",
""noDataState"": ""no_data"",
""notifications"": []
},
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""axisLabel"": """",
""axisPlacement"": ""auto"",
""barAlignment"": 0,
""drawStyle"": ""line"",
""fillOpacity"": 7,
""gradientMode"": ""none"",
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
},
""lineInterpolation"": ""smooth"",' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}","page_content='运维监控

2.部署方案

2.4.第四步

""sort"": ""none""
}
},
""targets"": [
{
""datasource"": {
""type"": ""prometheus""
},
""editorMode"": ""builder"",
""expr"": ""resources_report{instance=\""localhost:7010\"",job=\""TuGraph\"",resouces_type=\""disk_rate\"",type=~\""read|write\""}"",
""hide"": false,
""legendFormat"": ""{ {type} }"",
""range"": true,
""refId"": ""A""
}
],
""thresholds"": [
{
""colorMode"": ""critical"",
""op"": ""gt"",
""value"": 10000,
""visible"": true
}
],
""title"": ""磁盘IO"",
""type"": ""timeseries""
}
],
""refresh"": """",
""schemaVersion"": 36,' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}","page_content='运维监控

2.部署方案

2.4.第四步

""hide"": false,
""legendFormat"": ""{ {type} }"",
""range"": true,
""refId"": ""A""
}
],
""thresholds"": [
{
""colorMode"": ""critical"",
""op"": ""gt"",
""value"": 10000,
""visible"": true
}
],
""title"": ""磁盘IO"",
""type"": ""timeseries""
}
],
""refresh"": """",
""schemaVersion"": 36,
""style"": ""dark"",
""tags"": [],
""templating"": {
""list"": []
},
""time"": {
""from"": ""now-24h"",
""to"": ""now""
},
""timepicker"": {
""hidden"": false,
""refresh_intervals"": [
""10s""
]
},
""timezone"": """",
""title"": ""TuGraph监控页面"",
""version"": 20,' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}"
调用 Close() 函数后 InEdgeIterator 的状态是怎样的？,"page_content='src/core/graph_edge_iterator.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include ""core/graph_data_pack.h""
#include ""core/iterator_base.h""
#include ""core/kv_store.h""
#include ""core/schema_manager.h""

int TestOutEdgeIterator(int, char**);
int TestInRefIterator(int, char**);
int TestPerfGraphNoncontinuous(bool track_incoming, bool durable);

namespace lgraph {
class Transaction;

namespace graph {
class OutEdgeIterator;
class InEdgeIterator;
class VertexIterator;
class VertexIteratorImpl;
class Graph;

namespace _detail {
inline void StorePackedNode(KvIterator& it, VertexId vid, const PackedDataValue& pdv) {
    bool r = it.AddKeyValue(pdv.CreateKey(vid), pdv.GetBuf());
    FMA_ASSERT(r);
}

inline void StoreVertexOnlyNode(KvIterator& it, VertexId vid, const VertexValue& vov) {
    bool r = it.AddKeyValue(KeyPacker::CreateVertexOnlyKey(vid), vov.GetBuf(), false);
    FMA_ASSERT(r);
}

inline void StoreEdgeNode(PackType pt, KvIterator& it, VertexId vid1, const EdgeValue& ev) {
    if (ev.GetEdgeCount() == 0) return;
    bool r = it.AddKeyValue(ev.CreateKey(pt, vid1), ev.GetBuf(), false);
    FMA_ASSERT(r);
}
}  // namespace _detail

template <PackType ET>
class EdgeIterator;

namespace _detail {
template <PackType PT>
inline EdgeValue GetEdgeValue(const PackedDataValue& pdv) {
    return EdgeValue();
}

template <>
inline EdgeValue GetEdgeValue<PackType::IN_EDGE>(const PackedDataValue& pdv) {
    return pdv.GetInEdge();
}

template <>
inline EdgeValue GetEdgeValue<PackType::OUT_EDGE>(const PackedDataValue& pdv) {
    return pdv.GetOutEdge();
}

template <P' metadata={'file_name': 'graph_edge_iterator.h', 'file_path': 'src/core/graph_edge_iterator.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/graph_edge_iterator.h'}","page_content='自定义Connector

TableSource

/**
* Fetch data for the partition from start offset. if the windowSize is -1, it represents an
* all-window which will read all the data from the source, else return widow size for data.
*/
<T> FetchData<T> fetch(Partition partition, Optional<Offset> startOffset, long windowSize) throws IOException;

/**
* The close callback for the job finish the execution.
*/
void close();
}

```' metadata={'Header 1': '自定义Connector', 'Header 2': 'TableSource'}","page_content='src/core/graph_vertex_iterator.cpp/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#include ""core/kv_store.h""
#include ""core/graph_vertex_iterator.h""
#include ""core/transaction.h""

namespace lgraph {
namespace graph {
VertexIterator::VertexIterator(::lgraph::Transaction* txn, KvTable& tbl, VertexId vid, bool closest)
    : IteratorBase(txn), it_(tbl.GetIterator(txn_->GetTxn())), impl_(*it_) {
    impl_.Goto(vid, closest);
}

VertexIterator::VertexIterator(KvTransaction* txn, KvTable& tbl, VertexId vid, bool closest)
    : IteratorBase(nullptr), it_(tbl.GetIterator(*txn)), impl_(*it_) {
    impl_.Goto(vid, closest);
}

VertexIterator::VertexIterator(VertexIterator&& rhs)
    : IteratorBase(std::move(rhs)), it_(std::move(rhs.it_)), impl_(std::move(rhs.impl_)) {
    impl_.SetItPtr(it_.get());
}

void VertexIterator::CloseImpl() { impl_.Close(); }
}  // namespace graph
}  // namespace lgraph
' metadata={'file_name': 'graph_vertex_iterator.cpp', 'file_path': 'src/core/graph_vertex_iterator.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/graph_vertex_iterator.cpp'}"
DUAL_DIRECTION表示什么？,"page_content='OlapOnDisk API

3. 其他常用函数功能描述

3.1 图加载

DUAL_DIRECTION : 输入文件为非对称图，加载图为非对称图。
MAKE_SYMMETRIC : 输入文件为非对称图，加载图为对称图。
INPUT_SYMMETRIC : 输入文件为对称图，加载图为对称图。
对应的详细介绍见lgraph文件夹下的olap_config.h文件的`enum EdgeDirectionPolicy`。  
- `void LoadVertexArrayTxt<V>(V * array, std::string path, std::function<size_t(const char *, const char *, VertexUnit<V> &)> parse_line)`：将文件中的点-数据对按照点id的顺序加载到数组中。各参数表示意义分别为：
- `array`：待读入数据的数组
- `path`：读取文件的路径，文件中每行表示一对点-数据对
- `parse_line`：用户自定义函数，告诉系统如何将一行文本数据解析为一个点-数据对。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '3. 其他常用函数功能描述', 'Header 3': '3.1 图加载'}","page_content='OlapOnDisk API

3. 其他常用函数功能描述

3.1 图加载

- `config`：需要加载的配置参数。该参数内保存了该图的一般信息（如数据来源，算法名称，数据输入、输出路径，点个数等）以及根据不同数据来源、不同算法所配置的不同信息参数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。其中DUAL_DIRECTION为默认的图加载方式。
DUAL_DIRECTION : 输入文件为非对称图，加载图为非对称图。
MAKE_SYMMETRIC : 输入文件为非对称图，加载图为对称图。
INPUT_SYMMETRIC : 输入文件为对称图，加载图为对称图。
对应的详细介绍见lgraph文件夹下的olap_config.h文件的`enum EdgeDirectionPolicy`。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '3. 其他常用函数功能描述', 'Header 3': '3.1 图加载'}","page_content='数据导入

2.CSV文件格式分隔符

| \\f    | form-feed，即 ASCII 码 0x0c                                      |
| \\t    | 水平制表符，即 ASCII 码 0x09                                     |
| \\v    | 垂直制表符，即 ASCII 码 0x0b                                     |
| \\xnn  | 两位十六进制数，表示一个字节，如\\x9A                            |
| \\nnn  | 三位八进制数，表示一个字节，如\\001, \\443，数值范围不能超过 255 |  
例：  
```bash
$ ./lgraph_import -c ./import.config --delimiter ""\001\002""
```' metadata={'Header 1': '数据导入', 'Header 2': '2.CSV文件格式分隔符'}"
当指定的顶点ID不存在，并且nearest参数为true时，Goto函数将如何处理？,"page_content='src/core/managed_object.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <atomic>
#include <mutex>

#include ""fma-common/pipeline.h""
#include ""fma-common/timed_task.h""
#include ""fma-common/type_traits.h""
#include ""fma-common/utils.h""

#include ""core/thread_id.h""

#define GC_DEBUG 0

#if GC_DEBUG
#define GC_DBG_REF(o) FMA_LOG() << ""Referencing "" << (o);
#define GC_DBG_DEREF(o) FMA_LOG() << ""Dereferencing "" << (o);
#define GC_DBG_DEL(o) FMA_LOG() << ""Deleting "" << (o);
#else
#define GC_DBG_REF(o)
#define GC_DBG_DEREF(o)
#define GC_DBG_DEL(o)
#endif

namespace lgraph {

namespace _detail {
// Reference counted object
// NOTE: References are kept in Thread-Local-Storage, so Reference(tid) and Dereference(tid)
// must be paired with the same tid.
// Do NOT use this class directly unless you are pretty sure about what
// you are doing. Use GabageCollectedObject and ScopedRef instead.
template <typename T>
class RefCountedObj {
    // number of managers currently referencing this object
    // two GabageCollectedObject can use the same RefCountedObj when one is copy constructed
    // When GabageCollectedObject is destructed, it will try to delete this object
    // only when manager_count_==1
    std::atomic<int64_t> manager_count_;
    T* obj_;
    std::vector<fma_common::PadForCacheLine<uint64_t>> references_;

 public:
    explicit RefCountedObj(T* obj, size_t max_threads = LGRAPH_MAX_THREADS)
        : manager_count_(1), obj_(obj),
            references_(max_threads, fma_common::PadForCacheLine<uint64_t>(0)) {}

    ~RefCountedObj() {
        FMA_ASS' metadata={'file_name': 'managed_object.h', 'file_path': 'src/core/managed_object.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/managed_object.h'}","page_content='demo/Bolt/go_example.go/ package main

import (
	""context""
	""fmt""
	""github.com/neo4j/neo4j-go-driver/v5/neo4j""
)

func main() {
	driver, err := neo4j.NewDriverWithContext(""bolt://localhost:7687"", neo4j.BasicAuth(""admin"", ""73@TuGraph"", """"))
	if err != nil {
		panic(err)
	}

	ctx := context.Background()
	defer driver.Close(ctx)

	session := driver.NewSession(ctx, neo4j.SessionConfig{DatabaseName: ""default""})
	defer session.Close(ctx)

	_, err = session.Run(ctx, ""CALL db.dropDB()"", nil)
	if err != nil {
		panic(err)
		return
	}
	_, err = session.Run(ctx, ""CALL db.createVertexLabel('person', 'id' , 'id' ,INT32, false, 'name' ,STRING, false)"", nil)
	if err != nil {
		panic(err)
		return
	}
	_, err = session.Run(ctx, ""CALL db.createEdgeLabel('is_friend','[[\""person\"",\""person\""]]')"", nil)
	if err != nil {
		panic(err)
		return
	}
	_, err = session.Run(ctx, ""create (n1:person {name:'jack',id:1}), (n2:person {name:'lucy',id:2})"", nil)
	if err != nil {
		panic(err)
		return
	}
	_, err = session.Run(ctx, ""match (n1:person {id:1}), (n2:person {id:2}) create (n1)-[r:is_friend]->(n2)"", nil)
	if err != nil {
		panic(err)
		return
	}
	res, err := session.Run(ctx, ""match (n)-[r]->(m) return n,r,m"", nil)
	if err != nil {
		panic(err)
		return
	}
	records, err := res.Collect(ctx)
	if err != nil {
		panic(err)
		return
	}
	for _, record := range records {
		fmt.Printf(""record = %#v\n"", record)
	}
}
' metadata={'file_name': 'go_example.go', 'file_path': 'demo/Bolt/go_example.go', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/Bolt/go_example.go'}","page_content='demo/ProcedureDemo/cpp/khop_kth.cpp/ /*
 * 根据给定顶点，返回第k层的顶点个数
 */
#include ""lgraph/lgraph.h""
#include ""lgraph/olap_on_db.h""
#include ""lgraph/lgraph_traversal.h""

#include ""json.hpp""

#include <iostream>
#include <vector>
#include <unordered_set>
using json = nlohmann::json;

using namespace lgraph_api;

class UnorderedParallelBitset {
 public:
    size_t size_;
    size_t parallel_bitset_size_;
    size_t threshold_size_;
    bool use_unordered_set_;
    std::shared_ptr<olap::ParallelBitset> parallel_bitset_visited_;
    std::unordered_set<int64_t> unordered_set_visited_;

    UnorderedParallelBitset(size_t parallel_bitset_size, size_t threshold_size) {
        size_ = 0;
        parallel_bitset_size_ = parallel_bitset_size;
        threshold_size_ = threshold_size;
        use_unordered_set_ = true;
    }

    ~UnorderedParallelBitset() {}

    bool Has(int64_t vid) {
        if (use_unordered_set_) {
            return unordered_set_visited_.find(vid) != unordered_set_visited_.end();
        } else {
            return parallel_bitset_visited_->Has(vid);
        }
    }

    bool Add(int64_t vid) {
        if (use_unordered_set_ && size_ >= threshold_size_) {
            use_unordered_set_ = false;
            std::shared_ptr<olap::ParallelBitset> ptr_(new olap::ParallelBitset(parallel_bitset_size_));
            parallel_bitset_visited_ = ptr_;
            for(auto iter = unordered_set_visited_.begin(); iter != unordered_set_visited_.end(); ++iter) {
                parallel_bitset_visited_->Add(*iter);
            }
        }
        if (use_unordered_set_) {
            unordered_set_visited_.emplace(vid);
        } else {
            parallel_bitset_visited_->Add(vid);
        }
        size_ += 1;
        return true;
    }

    void Clear() {
        if (use_unordered_set_) {
            unordered_set_visited_.clear();
        } else {
            parallel_bitset_visited_->Clear();
        }
        size_ = 0;
    }
};

extern ""C"" bool Process(GraphDB & db, const std::string & request, std::string & respon' metadata={'file_name': 'khop_kth.cpp', 'file_path': 'demo/ProcedureDemo/cpp/khop_kth.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/ProcedureDemo/cpp/khop_kth.cpp'}"
在BFS算法中，最终返回的结果是什么？,"page_content='内置算法

基础算法包

广度优先搜索

广度优先搜索实现了Breadth-first Search算法，从根点开始，沿着图的宽度遍历所有可访问点。返回结果为遍历点个数。算法内容请参考 [https://en.wikipedia.org/wiki/Breadth-first_search](https://en.wikipedia.org/wiki/Breadth-first_search ""bfs wiki"")。' metadata={'Header 1': '内置算法', 'Header 2': '基础算法包', 'Header 3': '广度优先搜索'}","page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

if (parent[dst] == (size_t)-1) {
auto lock = graph.GuardVertexLock(dst);
if (parent[dst] == (size_t)-1) {
parent[dst] = vi;
num_activations += 1;
active_out.Add(dst);       //存放当前循环阶段找到的节点
}
}
}
return num_activations;
},
active_in);
active_in.Swap(active_out);
}
// 返回全部节点数
return discovered_vertices;
}
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}","page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

`bfs`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关定义、数据结构的初始化
2. 使用批处理函数对每个节点进行循环计算，每一轮找到与当前节点相邻的全部节点，并在该轮次终止时进行交换。
3. 直到找到全部节点，返回节点个数discovered_vertices。  
```C++
size_t BFSCore(Graph<Empty>& graph, size_t root_vid, ParallelVector<size_t>& parent){' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}"
TuGraph“refresh_time”的默认设置是什么？,"page_content='TuGraph-DataX

4.导出TuGraph

4.2.参数说明

在使用DataX导出TuGraph数据时，需要将reader设置为tugraphreader并配置以下5个参数：  
* **url**
* 描述：TuGraph的bolt server地址 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **username**
* 描述：TuGraph的用户名 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **password**
* 描述：TuGraph的密码 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **graphName**
* 描述：所选取的需要同步的TuGraph子图 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **queryCypher**
* 描述：通过cypher语句读取TuGraph中的数据 <br />
* 必选：否 <br />
* 默认值：无 <br />' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '4.导出TuGraph', 'Header 3': '4.2.参数说明'}","page_content='功能概览

4.核心功能

4.5 数据预热

TuGraph 是基于磁盘的图数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.5 数据预热'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}"
GetEdgeProp命令中，如果要查找特定的时间戳的边属性，该如何指定timestamp字段？,"page_content='图相关DDL

Create Graph

**Syntax**
一个图至少包含一对点边，点表必须包含一个id字段作为主键，边表必须包含srcId和targetId作为主键，边表还可以有一个时间戳字段标识时间。  
```
CREATE GRAPH <graph name>
(
<graph vertex>
[ { , <graph vertex> } ... ]
, <graph edge>
[ { , <graph edge> } ... ]
) WITH （
storeType = <graph store type>
[ { , <config key> = <config value> } ... ]
);

<graph vertex>  ::=
VERTEX <vertex name>
(
<column name> <data type> ID
[ {, <column name> <data type> } ... ]
)' metadata={'Header 1': '图相关DDL', 'Header 2': 'Create Graph'}","page_content='图相关DDL

Create Graph

<graph vertex>  ::=
VERTEX <vertex name>
(
<column name> <data type> ID
[ {, <column name> <data type> } ... ]
)

<graph edge>  ::=
Edge <edge name>
(
<column name> <data type> SOURCE ID
, <column name> <data type> DESTINATION ID
[ , <column name> <data type> TIMESTAMP ]
[ {, <column name> <data type> } ... ]
)' metadata={'Header 1': '图相关DDL', 'Header 2': 'Create Graph'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

- **URI**: `/db/{graph_name}/relationship/{euid}/property`
- **METHOD**: GET
- **RESPONSE**: 边属性字典  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/relationship/14_0_2_0/property
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
{
""weight"": 0.8,
""begin"": 20180922
}
}
```  
#### 6.8.9.获取边的属性  
- **URI**: `/db/{graph_name}/relationship/{euid}/property/{field}`' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}"
使用TuGraph Browser时，默认的端口号是多少？,"page_content='可视化操作手册

2.操作指南

2.1.访问

当用户完成图数据库的安装后，可以通过浏览器访问Browser。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7070。  
- 例如：127.0.0.1:7070。
- 推荐使用Chrome。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.1.访问'}","page_content='快速上手

2.安装

2.1.通过docker快速体验

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```  
5. 前端访问  
访问tugraph-db-browser: `http://x.x.x.x:7070`，数据库地址格式为 `bolt://ip:bolt_port`（老版本不用填），默认用户名为 `admin`，密码为 `73@TuGraph`。
首次登录会默认跳转修改密码页面，请尽快修改默认密码避免安全风险。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.1.通过docker快速体验'}","page_content='可视化操作手册（旧版）

操作详情

1.连接数据库

当用户完成图数据库的安装后，可以通过浏览器进行访问，TuGraph Browser 工具。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7090。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '1.连接数据库'}"
TuGraph-DB是否支持运行图算法？是否有示例图算法可以参考？,"page_content='图算法介绍

2\. 流图推理简介

TuGraph计算引擎（TuGraph Analytics\[1\]）是蚂蚁集团开源的大规模分布式实时图计算引擎（流图引擎），实现了流批一体的图计算模型，支持了丰富的图计算算法。TuGraph Analytics的流图计算能力，能处理连续输入的数据流，并支持增量的计算模式，极大得提高了数据的计算效率和实时性。TuGraph Analytics解决了业界大规模数据关联分析的实时计算问题，已广泛应用于数仓加速、金融风控、知识图谱以及社交推荐等场景。  
随着业务场景中问题复杂度的提升，基于传统的迭代图算法已无法满足业务的实际需求。例如在反洗钱场景中，利用图神经网络算法处理复杂的交易关系，能够捕获到节点的局部图结构信息。通过聚合邻接节点的特征信息，每个交易节点都可以感知到周边图网络结构的信息。类似的图神经网络等AI模型的推理逻辑，是无法基于传统的图迭代计算模式直接高效地表达的。' metadata={'Header 1': '图算法介绍', 'Header 2': '2\\. 流图推理简介'}","page_content='图算法介绍

2\. 流图推理简介

受上述问题启发，我们思考是否可以将TuGraph Analytics的流图计算能力与图神经网络等深度学习模型相结合，开发一套基于流图计算的模型推理系统。最终期望的推理系统具备如下能力：  
-   对于图算法工程师，在图迭代计算过程中，能够方便地使用机器学习模型的推理能力。  
-   对于AI算法工程师，可以通过TuGraph Analytics分布式流式计算的能力实现实时的模型推理。  
众所周知，在深度学习为代表的数据科学领域，Python已经成为数据分析、模型训练和推理框架的主流开发语言，并提供了丰富的开发库和框架生态。而以Hadoop全家桶为代表的大数据计算引擎领域，基于Java语言开发的系统仍占据一席之地，当然TuGraph Analytics也在其中。这种语言差异带来的“互操作性”成本，使得相当一部分大数据和AI生态组件无法轻松地融合，这也是TuGraph Analytics支持图推理需要亟待解决的问题。' metadata={'Header 1': '图算法介绍', 'Header 2': '2\\. 流图推理简介'}","page_content='🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！

仅需 5 步，即可呈现 🎊

4. 演示

<img width=""332"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/7ca76607-41a1-4afe-9427-cf7599de6889"">  
同样的，Tugraph Analytics 终端也会实时输出操作信息，并自动启动计算任务。  
<img width=""611"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/d8d0d73a-4c07-4ecd-bcac-4633a742933a"">' metadata={'Header 1': '🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！', 'Header 2': '仅需 5 步，即可呈现 🎊', 'Header 3': '4. 演示'}"
Python存储过程接口包含哪些重要组件和功能？,"page_content='Procedure API

5.Procedure v2接口

5.2.加载存储过程

```  
#### 5.2.2.获取存储过程详情  
在服务器运行过程中，用户可以随时获取单个存储过程的详情，包括代码。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin/custom_pagerank')
>>> r.status_code
200
>>> r.text
'{""description"":""Custom Page Rank Procedure"", ""name"":""custom_pagerank"", ""read_only"":true, ""code_base64"":<CODE>, ""code_type"":""so""}'
```  
#### 5.2.3.调用存储过程  
调用存储过程的代码示例如下：  
```Cypher
CALL plugin.cpp.custom_pagerank(10)
YIELD node, pr WITH node, pr' metadata={'Header 1': 'Procedure API', 'Header 2': '5.Procedure v2接口', 'Header 3': '5.2.加载存储过程'}","page_content='Procedure API

4.1.编写存储过程

4.1.2.编写Python存储过程

与 C++类似，Python 存储过程也可以调用 core API，一个简单的例子如下：  
```python
def Process(db, input):
txn = db.CreateReadTxn()
it = txn.GetVertexIterator()
n = 0
while it.IsValid():
if it.GetLabel() == 'student' and it['age'] and it['age'] == 10:
n = n + 1
it.Next()
return (True, str(nv))
```  
Python 存储过程返回的是一个 tuple，其中第一个元素是一个布尔值，表示该存储过程是否成功执行；第二个元素是一个`str`，里面是需要返回的结果。  
Python 存储过程不需要编译，可以直接加载。' metadata={'Header 1': 'Procedure API', 'Header 2': '4.1.编写存储过程', 'Header 3': '4.1.2.编写Python存储过程'}","page_content='Procedure API

5.Procedure v2接口

5.2.加载存储过程

#### 5.2.1.列出已加载的存储过程  
在服务器运行过程中，用户可以随时获取存储过程列表。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin')
>>> r.status_code
200
>>> r.text
'{""plugins"":[{""description"":""Custom Page Rank Procedure"", ""name"":""custom_pagerank"", ""read_only"":true}]}'
```  
#### 5.2.2.获取存储过程详情  
在服务器运行过程中，用户可以随时获取单个存储过程的详情，包括代码。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin/custom_pagerank')
>>> r.status_code
200
>>> r.text' metadata={'Header 1': 'Procedure API', 'Header 2': '5.Procedure v2接口', 'Header 3': '5.2.加载存储过程'}"
当执行 CallGql 函数时，如果操作成功和失败分别返回什么？,"page_content='C++客户端

2.使用示例

2.4.调用GQL

@param [in]  graph       (Optional) the graph to query.
@param [in]  json_format (Optional) Returns the format， true is json，Otherwise, binary
format.
@param [in]  timeout     (Optional) Maximum execution time, overruns will be interrupted.
@param [in]  url         (Optional) Node address of calling gql.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.4.调用GQL'}","page_content='C++客户端

2.使用示例

2.5.向leader发送GQL请求

const std::string& graph = ""default"", bool json_format = true,
double timeout = 0);
@param [out] result      The result.
@param [in]  gql         inquire statement.
@param [in]  graph       (Optional) the graph to query.
@param [in]  json_format (Optional) Returns the format， true is json，Otherwise, binary
format.
@param [in]  timeout     (Optional) Maximum execution time, overruns will be interrupted.
@returns True if it succeeds, false if it fails.
```' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.5.向leader发送GQL请求'}","page_content='Java客户端

2.使用示例

2.4.调用GQL

@param timeout: Maximum execution time, overruns will be interrupted
@param url: (Optional) Node address of calling GQL
@return: the result of GQL query execution
public String callGql(String gql, String graph, double timeout, String url)
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。
注：JAVA不支持默认参数，因此，JAVA中的默认参数是使用重载函数实现的。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.4.调用GQL'}"
TuGraph 中复杂图分析操作如何执行？,"page_content='HTAP

2.设计

在 TuGraph 中，OLTP 为图事务引擎，在图 4.4对应事务操作；OLAP 为图分析引擎，对应简单图分析操作（比如 SPSP）和复杂图分析操作（比如 PageRank），前者可以直接在图存储上执行，而后者需要额外导出快照执行。  
- 事务操作，即图事务引擎测的操作，为局部图的增删查改操作，典型的应用为 K 跳访问 K-Hop。
- 简单分析操作，是图分析引擎中较为简单的部分，通常也是局部的图分析操作，比如两点间最短路算法 SPSP、Jaccard 算法。
- 复杂分析操作，是图分析引擎中较为复杂的部分，通常涉及全图的多轮数据迭代操作，比如网页排序算法 PageRank、社区发现算法 Louvain。  
如架构图所示，我们在图中增加了外部存储，使得图分析的数据源不局限在图数据库中，可以直接从文本文件读取。  
- 图存储，即图数据库中的存储，有精心设计的数据结构，能够完成实时增删查改。
- 外部存储，可以是 RDBMS 或文本文件，以边表的简单方式存储，仅供一次性批量读取，和批量结果写入。在计算层，和整体架构图中的接口对应。' metadata={'Header 1': 'HTAP', 'Header 2': '2.设计'}","page_content='Traversal API

1. 简介

TuGraph 强大的在线分析处理（OLAP）能力是其区别于其它图数据库的一个重要特性。
借助 C++ OLAP API（olap_on_db.h），用户可以快速地导出一个需要进行复杂分析的子图，然后在其上运行诸如 PageRank、连通分量、社区发现等迭代式图计算过程，最后根据结果做出相应决策。
导出和计算的过程都可以通过并行处理的方式进行加速，从而实现几乎实时的分析处理，避免了传统解决方案需要将数据导出、转换、再导入（ETL）到专门的分析系统进行离线处理的冗长步骤。  
TuGraph 内置了大量常用的图分析算法和丰富的辅助接口，因此用户几乎不需要自己来实现具体的图计算过程，只需在实现自己的存储过程时将相应算法库的头文件（.h 文件）包含到自己程序中，并在编译时链接相应的动态库文件（.so）即可。
一般情况下，用户需要自己实现的只有将需要分析的子图抽取出来的过程。  
目前 Traversal API 仅支持 C++。' metadata={'Header 1': 'Traversal API', 'Header 2': '1. 简介'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}"
filter_output_default函数的主要作用是什么？,"page_content='OlapOnDisk API

3. 其他常用函数功能描述

3.2 图写入

- `void Write(ConfigBase<EdgeData> & config, ParallelVector<VertexData>& array, size_t array_size, std::string name, std::function<bool(VertexData &)> filter_output = filter_output_default<VertexData&>)`：把array中数据写回文件中，各参数表示意义分别是：
- `config`：需要加载的配置参数。该参数内保存了该图的一般信息（如数据来源，算法名称，数据输入、输出路径，点个数等）以及根据不同数据来源、不同算法所配置的不同信息参数。
- `array`：待写入数据的数组
- `array_size`：待写入数据的数字长度
- `name`：算法名称
- `filter_output`：写入数据规则函数，待写入数据需要满足该函数的要求。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '3. 其他常用函数功能描述', 'Header 3': '3.2 图写入'}","page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

ret = client.callCypher(""MATCH (n) RETURN n LIMIT 100"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert len(res) == 21
ret = client.callCypher(""CALL db.flushDB()"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```python' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}","page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb1 --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7073 --rpc_port 9093"",
""cleanup_dir"":[""./testdb1""]}' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}"
在Java运行时，MyBatis Generator的XML配置文件应如何配置targetProject？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}"
"在给定的代码中，`@Property(""class"")`注解指定了什么数据库字段名？","page_content='Graph View

示例介绍

shardCount = 128
);
```  
HLA 代码
```java
//build graph view.
final String graphName = ""social_network"";
GraphViewDesc graphViewDesc = GraphViewBuilder
.createGraphView(graphName)
.withShardNum(128)
.withBackend(BackendType.RocksDB)
.withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class,
String.class, ValueEdge.class, Integer.class))
.build();' metadata={'Header 1': 'Graph View', 'Header 2': '示例介绍'}","page_content='src/cypher/execution_plan/visitor/visitor.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

namespace cypher {
class OpBase;
class Aggregate;
class AllNodeScan;
class AllNodeScanDynamic;
class Apply;
class Argument;
class CartesianProduct;
class OpCreate;
class OpGqlCreate;
class OpDelete;
class OpGqlDelete;
class Distinct;
class ExpandAll;
class OpFilter;
class InQueryCall;
class GqlInQueryCall;
class Limit;
class OpMerge;
class OpGqlMerge;
class NodeByIdSeek;
class NodeByLabelScan;
class NodeByLabelScanDynamic;
class NodeIndexSeek;
class NodeIndexSeekDynamic;
class Optional;
class ProduceResults;
class Project;
class RelationshipCount;
class OpRemove;
class OpGqlRemove;
class OpSet;
class OpGqlSet;
class Skip;
class Sort;
class StandaloneCall;
class OpGqlStandaloneCall;
class TopN;
class Union;
class Unwind;
class VarLenExpand;
class VarLenExpandInto;
class Traversal;
class OpGqlTraversal;
// nested op
class ImmediateArgument;
}  // namespace cypher

namespace cypher {

// cyclic visitor
class Visitor {
 public:
    virtual ~Visitor() = default;
    virtual void Visit(const OpBase &op) = 0;
    virtual void Visit(const Aggregate &op) = 0;
    virtual void Visit(const AllNodeScan &op) = 0;
    virtual void Visit(const AllNodeScanDynamic &op) = 0;
    virtual void Visit(const Apply &op) = 0;
    virtual void Visit(const Argument &op) = 0;
    virtual void Visit(const CartesianProduct &op) = 0;
    virtual void Visit(const OpCreate &op) = 0;
    virtual void Visit(const OpDelete &op) = 0;
    virtual void Visit(const Distinct &op) = 0;
    virtual void Visit(c' metadata={'file_name': 'visitor.h', 'file_path': 'src/cypher/execution_plan/visitor/visitor.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/execution_plan/visitor/visitor.h'}","page_content='src/cypher/execution_plan/ops/op_merge.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

//
// Created by ljp on 20-2-16.
//
#pragma once

#include ""cypher/execution_plan/ops/op.h""
#include ""parser/clause.h""

namespace cypher {

class OpMerge : public OpBase {
    const SymbolTable &sym_tab_;
    std::vector<parser::Clause::TYPE_MERGE> merge_data_;
    PatternGraph *pattern_graph_ = nullptr;
    bool standalone_;
    bool summary_;

    static void ExtractProperties(const parser::TUP_PROPERTIES &properties, VEC_STR &fields,
                                  std::vector<lgraph::FieldData> &values) {
        using namespace parser;
        Expression map_literal = std::get<0>(properties);
        CYPHER_THROW_ASSERT(map_literal.type == Expression::NA ||
                            map_literal.type == Expression::MAP);
        if (map_literal.type != Expression::MAP) return;
        for (auto &prop : map_literal.Map()) {
            fields.emplace_back(prop.first);
            Expression p;
            if (prop.second.type == Expression::LIST) {
                p = prop.second.List().at(0);
            } else if (prop.second.type == Expression::MAP) {
                CYPHER_TODO();
            } else {
                p = prop.second;
            }
            switch (p.type) {
            case Expression::INT:
                values.emplace_back(p.Int());
                break;
            case Expression::DOUBLE:
                values.emplace_back(p.Double());
                break;
            case Expression::STRING:
                values.emplace_back(p.String());
     ' metadata={'file_name': 'op_merge.h', 'file_path': 'src/cypher/execution_plan/ops/op_merge.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/execution_plan/ops/op_merge.h'}"
在tugraph中是否能通过cypher语句删除图中的重复关系？,"page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

简介

TuGraph 图数据库提供了 JAVA、C++、Python 等多种语言的 SDK 支持，方便客户在各种场景下使用。用户使用 SDK 向TuGraph服务器发送Cypher请求，服务器则以 JSON形式返回数据。近日，TuGraph 推出了一款面向 JAVA 客户端用户的开发工具 TuGraph-OGM (Object Graph Mapping)，为用户提供了对象操作接口，相较 Cypher/JSON 接口应用起来更加便捷。  
OGM 类似于关系数据库中的 ORM（Object Relational Model），可以将数据库返回的数据自动映射成 JAVA 中的对象，方便用户读取，而用户对这些对象的更新操作也可以被自动翻译成 Cypher 语句发送给服务器。这样即便是完全不懂 Cypher 的用户，也可以通过操作对象与数据库进行交互，大大降低了图数据库的使用门槛。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '简介'}","page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}","page_content='TuGraph-DataX

4.导出TuGraph

4.2.参数说明

在使用DataX导出TuGraph数据时，需要将reader设置为tugraphreader并配置以下5个参数：  
* **url**
* 描述：TuGraph的bolt server地址 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **username**
* 描述：TuGraph的用户名 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **password**
* 描述：TuGraph的密码 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **graphName**
* 描述：所选取的需要同步的TuGraph子图 <br />
* 必选：是 <br />
* 默认值：无 <br />  
* **queryCypher**
* 描述：通过cypher语句读取TuGraph中的数据 <br />
* 必选：否 <br />
* 默认值：无 <br />' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '4.导出TuGraph', 'Header 3': '4.2.参数说明'}"
在默认情况下，第一次快照的时间如何设置？,"page_content='数据库运行

4.服务配置

4.1.配置参数

| ha_first_snapshot_start_time | 字符串                   | 第一次打快照的时间，格式为""HH:MM:SS""，表示为在下一个HH:MM:SS时间点第一次打snapshot，以后每ha_snapshot_interval_s秒打一次。默认值为""""，表示在0-ha_snapshot_interval_s内的任一时刻随机打第一次snapshot，以后每ha_snapshot_interval_s秒打一次snapshot |
| enable_ip_check              | 布尔值                   | 允许 IP 白名单，默认值为 false。                                                                                                                                                             |' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='数据库运行

4.服务配置

4.1.配置参数

| ha_node_remove_ms            | 整型                    | 节点被视为完全死亡并从列表中删除的间隔（以毫秒为单位）。默认值为 120000。                                                                                                                                          |
| ha_first_snapshot_start_time | 字符串                   | 第一次打快照的时间，格式为""HH:MM:SS""，表示为在下一个HH:MM:SS时间点第一次打snapshot，以后每ha_snapshot_interval_s秒打一次。默认值为""""，表示在0-ha_snapshot_interval_s内的任一时刻随机打第一次snapshot，以后每ha_snapshot_interval_s秒打一次snapshot |' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='src/server/ha_state_machine.cpp/ ﻿/* Copyright (c) 2022 AntGroup. All Rights Reserved. */

#include ""braft/protobuf_file.h""
#include ""braft/raft.h""
#include ""braft/util.h""

#include ""brpc/channel.h""
#include ""braft/cli.h""
#include ""brpc/closure_guard.h""

#include ""server/ha_state_machine.h""
#include ""restful/server/rest_server.h""

namespace braft {
    DECLARE_bool(raft_enable_witness_to_leader);
    DECLARE_bool(enable_first_snapshot_config);
    DECLARE_string(first_snapshot_start_time);
}

void lgraph::HaStateMachine::Start() {
    // check ha node can be started
    butil::EndPoint addr;
    butil::str2endpoint(config_.host.c_str(), config_.rpc_port, &addr);
    if (butil::IP_ANY == addr.ip) {
        throw std::runtime_error(""TuGraph can't be started from IP_ANY (0.0.0.0) in HA mode."");
    }
    if (node_) {
        LOG_WARN() << ""HaStateMachine already started."";
        return;
    }
    ::lgraph::StateMachine::Start();

    // bootstrap
    if (config_.ha_bootstrap_role == 1) {
        const int64_t BOOTSTRAP_LOG_INDEX = 1024;
        if (config_.ha_is_witness) {
            ::lgraph::StateMachine::Stop();
            throw std::runtime_error(""Can not bootstrap on witness node"");
        }
#if LGRAPH_SHARE_DIR
        LOG_WARN() << ""Bootstrapping is not necessary in this version, ignored"";
#else
        if (galaxy_->GetRaftLogIndex() != -1) {
            LOG_INFO() << ""Bootstrapping from existing data..."";
        }

        LOG_DEBUG() << ""Bootstrapping..."";
        int64_t new_log_index = galaxy_->GetRaftLogIndex() + BOOTSTRAP_LOG_INDEX;
        // change the log index in DB
        galaxy_->BootstrapRaftLogIndex(new_log_index);
        // now bootstrap
        braft::BootstrapOptions options;
        options.group_conf.add_peer(braft::PeerId(addr));
        options.fsm = this;
        options.node_owns_fsm = false;
        std::string prefix = ""local://"" + config_.ha_dir;
        options.log_uri = prefix + ""/log"";
        options.raft_meta_uri = prefix + ""/raft_meta"";
        options.snapshot_uri = pr' metadata={'file_name': 'ha_state_machine.cpp', 'file_path': 'src/server/ha_state_machine.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/server/ha_state_machine.cpp'}"
如果您想提交非原创作品给蚂蚁集团，您需要标注哪些信息？,"page_content='src/plugin/plugin_manager_impl.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <stdexcept>
#include <string>

#include ""fma-common/binary_buffer.h""
#include ""fma-common/binary_read_write_helper.h""

#include ""core/defs.h""



namespace fma_common {

template<>
inline size_t BinaryWrite(fma_common::BinaryBuffer& stream, const lgraph_api::Parameter& param) {
    return fma_common::BinaryWrite(stream, param.name) +
           fma_common::BinaryWrite(stream, param.index) +
           fma_common::BinaryWrite(stream, param.type);
}

template<>
inline size_t BinaryRead(fma_common::BinaryBuffer& stream, lgraph_api::Parameter& param) {
    size_t s, t, u;
    if ((s = fma_common::BinaryRead(stream, param.name)) != 0) {
        if ((t = fma_common::BinaryRead(stream, param.index)) != 0) {
            if ((u = fma_common::BinaryRead(stream, param.type)) != 0) {
                return s + t + u;
            }
        }
    }
    throw std::runtime_error(""Failed to read parameter from stream, bad content"");
}

template<>
inline size_t BinaryWrite(fma_common::BinaryBuffer& stream, const lgraph_api::SigSpec& sig_spec) {
    return fma_common::BinaryWrite(stream, sig_spec.input_list) +
           fma_common::BinaryWrite(stream, sig_spec.result_list);
}


template<>
inline size_t BinaryRead(fma_common::BinaryBuffer& stream, lgraph_api::SigSpec& sig_spec) {
    size_t s, t;
    if ((s = fma_common::BinaryRead(stream, sig_spec.input_list)) != 0) {
        if ((t = fma_common::BinaryRead(stream, sig_spec.result_list)) != 0) {
            return s + t;
        }
    }
  ' metadata={'file_name': 'plugin_manager_impl.h', 'file_path': 'src/plugin/plugin_manager_impl.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/plugin/plugin_manager_impl.h'}","page_content='src/core/managed_object.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <atomic>
#include <mutex>

#include ""fma-common/pipeline.h""
#include ""fma-common/timed_task.h""
#include ""fma-common/type_traits.h""
#include ""fma-common/utils.h""

#include ""core/thread_id.h""

#define GC_DEBUG 0

#if GC_DEBUG
#define GC_DBG_REF(o) FMA_LOG() << ""Referencing "" << (o);
#define GC_DBG_DEREF(o) FMA_LOG() << ""Dereferencing "" << (o);
#define GC_DBG_DEL(o) FMA_LOG() << ""Deleting "" << (o);
#else
#define GC_DBG_REF(o)
#define GC_DBG_DEREF(o)
#define GC_DBG_DEL(o)
#endif

namespace lgraph {

namespace _detail {
// Reference counted object
// NOTE: References are kept in Thread-Local-Storage, so Reference(tid) and Dereference(tid)
// must be paired with the same tid.
// Do NOT use this class directly unless you are pretty sure about what
// you are doing. Use GabageCollectedObject and ScopedRef instead.
template <typename T>
class RefCountedObj {
    // number of managers currently referencing this object
    // two GabageCollectedObject can use the same RefCountedObj when one is copy constructed
    // When GabageCollectedObject is destructed, it will try to delete this object
    // only when manager_count_==1
    std::atomic<int64_t> manager_count_;
    T* obj_;
    std::vector<fma_common::PadForCacheLine<uint64_t>> references_;

 public:
    explicit RefCountedObj(T* obj, size_t max_threads = LGRAPH_MAX_THREADS)
        : manager_count_(1), obj_(obj),
            references_(max_threads, fma_common::PadForCacheLine<uint64_t>(0)) {}

    ~RefCountedObj() {
        FMA_ASS' metadata={'file_name': 'managed_object.h', 'file_path': 'src/core/managed_object.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/managed_object.h'}","page_content='src/cypher/parser/clause.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <boost/any.hpp>

#include ""procedure/procedure.h""
#include ""cypher/parser/expression.h""
#include ""cypher/parser/data_typedef.h""
#include ""cypher/parser/symbol_table.h""

namespace parser {

static std::string Serialize(const TUP_PROPERTIES &properties,
                             const size_t &cur_indent = 0, const size_t &indent_size = 2);
static std::string Serialize(const TUP_NODE_PATTERN &node_pattern,
                             const size_t &cur_indent = 0, const size_t &indent_size = 2);
static std::string Serialize(const TUP_RELATIONSHIP_PATTERN &relationship_pattern,
                             const size_t &cur_indent = 0, const size_t &indent_size = 2);
static std::string Serialize(const TUP_PATTERN_ELEMENT &pattern_element,
                             const size_t &cur_indent = 0, const size_t &indent_size = 2);
static std::string Serialize(const TUP_PATTERN_PART &pattern_part,
                             const size_t &cur_indent = 0, const size_t &indent_size = 2);
static std::string Serialize(const VEC_PATTERN &pattern,
                             const size_t &cur_indent = 0, const size_t &indent_size = 2);
static std::string Serialize(const TUP_RETURN &tup_return,
                             const size_t &cur_indent = 0, const size_t &indent_size = 2);
static std::string Serialize(const TUP_RETURN_BODY &return_body,
                             const size_t &cur_indent = 0, const size_t &indent_size = 2);
static std::string Serialize_1(const TUP_RETURN_IT' metadata={'file_name': 'clause.h', 'file_path': 'src/cypher/parser/clause.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/parser/clause.h'}"
web端导入点数据后，不同的方式查询得到结果不同,"page_content='可视化操作手册

2.操作指南

2.4.图项目

- 从第N行，开始：从第N行开始读取数据，系统默认从第0行开始读取数据，如需跳过表头可输入1。
- 属性映射：下拉选择数据列对应的属性字段。
- 数据预览：系统会预读数据文件的前5行。  
![数据导入-数据映射](../../../images/browser/graphbuild-import-datamapping.png)  
文件上传成功后，可以点击`继续导入`按钮继续导入其他数据，或者点击`前往图查询`按钮在`图查询`页面查询已导入的数据。  
![数据导入-导入成功](../../../images/browser/graphbuild-import-success.png)  
#### 2.4.3.图查询  
在`图项目`界面点击图项目选项卡中的`图查询`按钮，可以查询和访问图项目中的图数据，产品提供`语句查询`、`路径查询`、`点查询`等多种模式查询图数据，支持切换图项目和查询结果展示。  
![图查询-按钮](../../../images/browser/query-button.png)' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='Bolt客户端

使用示例

//创建索引
session.run(""CALL db.addIndex(\""person\"", \""name\"", false)"");
//插入点数据
session.run(""create (n1:person {name:'jack',id:1}), (n2:person {name:'lucy',id:2})"");
//插入边数据
session.run(""match (n1:person {id:1}), (n2:person {id:2}) create (n1)-[r:is_friend]->(n2)"");
//查询点和边
Result res = session.run(""match (n)-[r]->(m) return n,r,m"");
//Parameterized Query
String cypherQuery = ""MATCH (n1:person {id:$id})-[r]-(n2:person {name:$name}) RETURN n1, r, n2"";' metadata={'Header 1': 'Bolt客户端', 'Header 2': '使用示例'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

###### c.数据映射  
文件上传成功后，需要在`数据导入`页面设置`数据对应表`，将数据文件中的数据列和目标点/边、对应属性建立映射关系。  
- 数据对应表：展示已经上传的数据问题。
- 文件名称：上传的数据文件名称。
- 文件大小：上传的数据文件大小。
- 读取结果：数据文件上传结果，success为读取成功。
- 删除：在页面中删除，不会删除本地文件。
- 数据文件映射：每个已上传的数据文件都需要配置映射关系。
- 标签：选择该文件对应的点或边类型，只能选择一类点或一类边。
- 从第N行，开始：从第N行开始读取数据，系统默认从第0行开始读取数据，如需跳过表头可输入1。
- 属性映射：下拉选择数据列对应的属性字段。
- 数据预览：系统会预读数据文件的前5行。  
![数据导入-数据映射](../../../images/browser/graphbuild-import-datamapping.png)  
文件上传成功后，可以点击`继续导入`按钮继续导入其他数据，或者点击`前往图查询`按钮在`图查询`页面查询已导入的数据。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}"
对象图映射（OGM）支持什么？,"page_content='TuGraph-OGM

1.简介

> TuGraph-OGM 项目在其他仓库开源。  
TuGraph-OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。同时 TuGraph-OGM 兼容 Neo4j-OGM，Neo4j 生态用户可以无缝迁移到 TuGraph 数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '1.简介'}","page_content='功能概览

5.客户端工具

OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。  
命令行工具`lgraph_cypher`是查询客户端，可用于向 TuGraph 服务器提交 OpenCypher 请求。`lgraph_cypher`客户端有两种执行模式：单命令模式和交互式模式。' metadata={'Header 1': '功能概览', 'Header 2': '5.客户端工具'}","page_content='TuGraph Java Client

特性

- Java中的RPC客户端
- OGM，即对象图映射，支持将图中的实体和关系映射到Java对象，从而加速Java开发过程。' metadata={'Header 1': 'TuGraph Java Client', 'Header 2': '特性'}"
如何在单节点模式下实例化liblgraph_client_python.client对象？,"page_content='Python客户端

3.RPC Client

3.1.实例化client对象

#### 3.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
```python
client = liblgraph_client_python.client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, url: str, user: str, password: str)
```  
#### 3.1.2.实例化HA集群直连连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化。
```python
client = liblgraph_client_python.client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"")
```
```' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.1.实例化client对象'}","page_content='Python客户端

3.RPC Client

3.1.实例化client对象

client按照如下格式进行实例化
```python
client = liblgraph_client_python.client([""189.33.97.23:9091"",""189.33.97.24:9091"", ""189.33.97.25:9091""], ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, urls: list, user: str, password: str)
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.1.实例化client对象'}","page_content='Python客户端

3.RPC Client

3.1.实例化client对象

```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 3.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化
```python
client = liblgraph_client_python.client([""189.33.97.23:9091"",""189.33.97.24:9091"", ""189.33.97.25:9091""], ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, urls: list, user: str, password: str)
```' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.1.实例化client对象'}"
如果传递给 `GetRoleInfo` 函数的角色名非法，会抛出哪种异常？,"page_content='Cypher API

5.附录2. 内置procedures列表

5.2.内置procedures完整列表

| dbms.security.getRoleInfo             | 获取角色详细信息                              | dbms.security.getRoleInfo(role::STRING) :: (role_info::MAP)                                                                                                                             |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '5.2.内置procedures完整列表'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

}
}
```  
#### 6.2.4.获取角色信息  
列出给定角色的信息。  
- **URI**: `/role/{role_name}`
- **METHOD**: GET
- **RESPONSE**: 角色信息。  
**Example request.**  
```
• GET http://localhost:7070/role/role1
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

""disabled"": false,
""description"": ""Builtin administrator group."",
""permissions"": {""default"":""FULL"", ""graph1"":""FULL""}
},
""role1"": {
""disabled"": true,
""description"": ""Another role"",
""permissions"": {""default"":""READ""}
}
}
```  
#### 6.2.4.获取角色信息  
列出给定角色的信息。  
- **URI**: `/role/{role_name}`
- **METHOD**: GET
- **RESPONSE**: 角色信息。  
**Example request.**  
```
• GET http://localhost:7070/role/role1
• Accept: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}"
TuGraph 的部署方式有哪些？,"page_content='功能概览

1.1.部署方式

TuGraph目前提供云部署、Docker部署以及安装包部署三种部署方式，用户可根据实际情况选择适合的部署方式。' metadata={'Header 1': '功能概览', 'Header 2': '1.1.部署方式'}","page_content='部署高可用模式

1.原理

提供服务，该`leader`将每个请求复制同步到`follower`，并在请求同步到服务器后才能响应客户端。这样，如果任何服务器发生故障，其他服务器仍将具有到目前为止已写入的所有数据。如果`leader`
服务器发生故障，其他服务器将自动选择出新的`leader`。  
TuGraph的高可用模式提供两种类型的节点：`replica`节点和`witness`节点。其中，`replica`节点是普通节点，有日志有数据，可对外提供服务。
而`witness`节点是一种只接收心跳和日志但不保存数据的节点。根据部署需求，`leader`节点和`follower`节点可以灵活的部署为`replica`节点或`witness`节点。
基于此，TuGraph高可用模式的部署方式有两种：一是普通部署模式，二是带witness的简约部署模式。  
对于普通部署模式，`leader`和所有`follower`均为`replica`类型的节点。写入请求由`leader`提供服务，该`leader`将每个请求复制同步到`follower`，' metadata={'Header 1': '部署高可用模式', 'Header 2': '1.原理'}","page_content='环境和版本选择

3. 部署方式选择

TuGraph部署仅需一台服务器（高可用模式需要多台），可根据实际资源情况和使用场景，选择适合的部署方式。  
| 部署方式     | 描述                   | 备注                                                                                      |
|----------|----------------------|-----------------------------------------------------------------------------------------|
| 云部署      | 阿里云计算巢一键部署，免费试用      | 新手适用，流程参考 [链接](../5.installation&running/5.cloud-deployment.md)              |' metadata={'Header 1': '环境和版本选择', 'Header 2': '3. 部署方式选择'}"
根据使用MATCH和SKIP语句的查询结果，跳过第一行后返回的第一位人物的名字是什么？,"page_content='ISO GQL

2.Clauses

2.7.SKIP

`SKIP`指定结果偏移行数。  
#### 未使用SKIP  
```
MATCH (n:Person)
RETURN n.name LIMIT 3
```  
返回结果  
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""},{""n.name"":""Dennis Quaid""}]
```  
#### 使用SKIP  
```
MATCH (n:Person)
RETURN n.name SKIP 1 LIMIT 2
```  
返回结果
```JSON
[{""n.name"":""Corin Redgrave""},{""n.name"":""Dennis Quaid""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.7.SKIP'}","page_content='ISO GQL

2.Clauses

2.1.MATCH

```  
##### 带过滤条件的边匹配  
```
MATCH (n:Person)-[e:BORN_IN WHERE e.weight > 20]->(m)
RETURN n.name, e.weight, m.name
```  
返回结果
```JSON
[{""e.weight"":20.549999237060547,""m.name"":""New York"",""n.name"":""John Williams""},{""e.weight"":20.6200008392334,""m.name"":""New York"",""n.name"":""Lindsay Lohan""}]
```  
#### 路径匹配  
##### 不定跳查询  
```
MATCH (n:Person)-[e]->{2,3}(m:Person)
RETURN m.name LIMIT 2
```  
返回结果
```JSON
[{""m.name"":""Liam Neeson""},{""m.name"":""Natasha Richardson""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.1.MATCH'}","page_content='Cypher API

2.Clauses

2.5.SKIP

- ✓ Skip first three records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 3
```  
- ✓ Return middle two records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 1
LIMIT 2
```  
- ❏ Using an expression with SKIP to return a subset of the records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP toInteger(3*rand())+ 1
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.5.SKIP'}"
导入数据时，如果操作失败，是否可以继续导入？,"page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}","page_content='C++客户端

2.使用示例

2.12.从字节流中导入点边数据

@param [in]  continue_on_error   (Optional) whether to continue when importing data fails.
@param [in]  thread_nums         (Optional) maximum number of threads.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  timeout             (Optional) Maximum execution time, overruns will be
interrupted.
@returns True if it succeeds, false if it fails.
```' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='Java客户端

2.使用示例

2.14.从文件中导入点边数据

@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param skipPackages: skip packages number
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromFile(String confFile, String delimiter, boolean continueOnError, int threadNums,' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.14.从文件中导入点边数据'}"
如果不定义表头并使用空的Result()初始化表，你接下来应该使用什么方法为表设置表头？,"page_content='Use Graph

Example

```sql
-- Set current using graph.
USE GRAPH modern;

INSERT INTO tbl_result
SELECT
a.id,
b.id,
c.id,
c.kind,
d.id,
d.type
FROM (
MATCH (a) -> (b) where b.id > 0 and a.lang is null
MATCH (a) <- (c) where label(c) = 'person'
Let c.kind = 'k' || cast(c.age / 10 as varchar)
MATCH (c) -> (d) where d != b
Let d.type = if (label(d) = 'person', 1, 0)
RETURN a, b, c, d
)
;
```' metadata={'Header 1': 'Use Graph', 'Header 2': 'Example'}","page_content='Use Instance

Example

```sql
Use instance geaflow;
USE GRAPH modern;

INSERT INTO tbl_result
SELECT
a.id,
b.id,
c.id,
c.kind,
d.id,
d.type
FROM (
MATCH (a) -> (b) where b.id > 0 and a.lang is null
MATCH (a) <- (c) where label(c) = 'person'
Let c.kind = 'k' || cast(c.age / 10 as varchar)
MATCH (c) -> (d) where d != b
Let d.type = if (label(d) = 'person', 1, 0)
RETURN a, b, c, d
);
```' metadata={'Header 1': 'Use Instance', 'Header 2': 'Example'}","page_content='Bolt客户端

使用示例

Result result1 = session.run(cypherQuery, parameters(""id"", 1, ""name"", ""lucy""));
while (result1.hasNext()) {
Record record = result1.next();
System.out.println(""n1: "" + record.get(""n1"").asMap());
System.out.println(""r: "" + record.get(""r"").asMap());
System.out.println(""n2: "" + record.get(""n2"").asMap());
}
//删除点数据
session.run(""match (n1:person {id:1}) delete n1"");
//删除边数据
session.run(""match (n1:person {id:1})-[r]-(n2:person{id:2}) delete r"");
//删除边模型' metadata={'Header 1': 'Bolt客户端', 'Header 2': '使用示例'}"
蚂蚁集团的个人贡献者许可协议主要目的是什么？,"page_content='src/cypher/execution_plan/optimization/opt_rewrite_with_schema_inference.h/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

//
// Created by seijiang on 23-07-19.
//
#pragma once

#include ""db/galaxy.h""
#include ""cypher/execution_plan/ops/op_expand_all.h""
#include ""cypher/execution_plan/ops/op_all_node_scan.h""
#include ""cypher/execution_plan/ops/op_all_node_scan_dynamic.h""
#include ""cypher/execution_plan/ops/op_node_index_seek.h""
#include ""cypher/execution_plan/ops/op_node_index_seek_dynamic.h""
#include ""cypher/execution_plan/ops/op_node_by_label_scan.h""
#include ""cypher/execution_plan/ops/op_node_by_label_scan_dynamic.h""
#include ""cypher/execution_plan/optimization/opt_pass.h""
#include ""cypher/execution_plan/optimization/rewrite/schema_rewrite.h""

namespace cypher {

/* Opt Rewrite With Schema Inference:
 * Graph : MovieDemo
 * example Cypher:
 * match p=(n0)-[e0]->(n1)-[e1]->(n2)-[e2]->(m:keyword) return COUNT(p);
 * is equivalent to :
 * match p=(n0:user)-[e0:is_friend]->(n1:user)-[e1:rate]->(n2:movie)-[e2:has_keyword]->(m:keyword)
 *return COUNT(p);
 *
 * Plan before optimization:
 * Produce Results
 *     Aggregate [COUNT(p)]
 *         Expand(All) [n2 --> m ]
 *             Expand(All) [n1 --> n2 ]
 *                 Expand(All) [n0 --> n1 ]
 *                     All Node Scan [n0]
 *
 * Plan after optimization:
 * Produce Results
 *     Aggregate [COUNT(p)]
 *         Expand(All) [n2 --> m ]
 *             Expand(All) [n1 --> n2 ]
 *                 Expand(All) [n0 --> n1 ]
 *                     Node By Label Scan [n0:user]
 **/

// removed test case in cypher_plan_' metadata={'file_name': 'opt_rewrite_with_schema_inference.h', 'file_path': 'src/cypher/execution_plan/optimization/opt_rewrite_with_schema_inference.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/execution_plan/optimization/opt_rewrite_with_schema_inference.h'}","page_content='src/core/managed_object.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <atomic>
#include <mutex>

#include ""fma-common/pipeline.h""
#include ""fma-common/timed_task.h""
#include ""fma-common/type_traits.h""
#include ""fma-common/utils.h""

#include ""core/thread_id.h""

#define GC_DEBUG 0

#if GC_DEBUG
#define GC_DBG_REF(o) FMA_LOG() << ""Referencing "" << (o);
#define GC_DBG_DEREF(o) FMA_LOG() << ""Dereferencing "" << (o);
#define GC_DBG_DEL(o) FMA_LOG() << ""Deleting "" << (o);
#else
#define GC_DBG_REF(o)
#define GC_DBG_DEREF(o)
#define GC_DBG_DEL(o)
#endif

namespace lgraph {

namespace _detail {
// Reference counted object
// NOTE: References are kept in Thread-Local-Storage, so Reference(tid) and Dereference(tid)
// must be paired with the same tid.
// Do NOT use this class directly unless you are pretty sure about what
// you are doing. Use GabageCollectedObject and ScopedRef instead.
template <typename T>
class RefCountedObj {
    // number of managers currently referencing this object
    // two GabageCollectedObject can use the same RefCountedObj when one is copy constructed
    // When GabageCollectedObject is destructed, it will try to delete this object
    // only when manager_count_==1
    std::atomic<int64_t> manager_count_;
    T* obj_;
    std::vector<fma_common::PadForCacheLine<uint64_t>> references_;

 public:
    explicit RefCountedObj(T* obj, size_t max_threads = LGRAPH_MAX_THREADS)
        : manager_count_(1), obj_(obj),
            references_(max_threads, fma_common::PadForCacheLine<uint64_t>(0)) {}

    ~RefCountedObj() {
        FMA_ASS' metadata={'file_name': 'managed_object.h', 'file_path': 'src/core/managed_object.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/managed_object.h'}","page_content='src/cypher/execution_plan/scheduler.cpp/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

//
// Created by wt on 18-8-14.
//
#include ""./antlr4-runtime.h""
#include ""geax-front-end/ast/AstNode.h""
#include ""geax-front-end/ast/AstDumper.h""
#include ""geax-front-end/isogql/GQLResolveCtx.h""
#include ""geax-front-end/isogql/GQLAstVisitor.h""
#include ""geax-front-end/isogql/parser/AntlrGqlParser.h""

#include ""tools/lgraph_log.h""
#include ""core/task_tracker.h""

#include ""parser/generated/LcypherLexer.h""
#include ""parser/generated/LcypherParser.h""
#include ""parser/cypher_base_visitor.h""
#include ""parser/cypher_base_visitor_v2.h""
#include ""parser/cypher_error_listener.h""

#include ""cypher/execution_plan/execution_plan.h""
#include ""cypher/execution_plan/scheduler.h""
#include ""cypher/execution_plan/execution_plan_v2.h""
#include ""cypher/rewriter/GenAnonymousAliasRewriter.h""
#include ""cypher/rewriter/MultiPathPatternRewriter.h""
#include ""cypher/rewriter/PushDownFilterAstRewriter.h""

#include ""server/bolt_session.h""

namespace cypher {

void Scheduler::Eval(RTContext *ctx, const lgraph_api::GraphQueryType &type,
                     const std::string &script, ElapsedTime &elapsed) {
    if (type == lgraph_api::GraphQueryType::CYPHER) {
        if (ctx->is_cypher_v2_) {
            EvalCypher2(ctx, script, elapsed);
        } else {
            EvalCypher(ctx, script, elapsed);
        }
    } else {
        EvalGql(ctx, script, elapsed);
    }
}

bool Scheduler::DetermineReadOnly(cypher::RTContext *ctx,
                                  const lgraph_api::GraphQueryType &query_type,
          ' metadata={'file_name': 'scheduler.cpp', 'file_path': 'src/cypher/execution_plan/scheduler.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/execution_plan/scheduler.cpp'}"
TuGraph Mini Runtime Image 不包含哪些功能？,"page_content='Docker部署

1.简介

- TuGraph Compile Image：提供编译环境，可以用于TuGraph的编译，测试；
- TuGraph Runtime Image：提供二进制可运行环境，附带TuGraph库和可执行文件；
- TuGraph Mini Runtime Image: 提供二进制可运行环境，不包含TuGraph中Java、Python相关的功能，无C++ plugin编译运行，仅so上传。' metadata={'Header 1': 'Docker部署', 'Header 2': '1.简介'}","page_content='Docker部署

2.现有Docker Image

2.2.命名规范

`tugraph/tugraph-runtime-[os name & version]:[tugraph-runtime version]`  
例如：`tugraph/tugraph-runtime-centos7:3.4.0`  
#### 2.2.3.TuGraph Mini Runtime Image  
提供二进制可运行环境，不包含TuGraph种Java、Python相关的功能，无C++ plugin编译运行，仅so上传。  
`tugraph/tugraph-mini-runtime-[os name & version]:[tugraph-runtime version]`  
例如： `tugraph/tugraph-mini-runtime-centos7:3.4.0`' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.2.命名规范'}","page_content='Docker部署

2.现有Docker Image

2.2.命名规范

#### 2.2.1.TuGraph Compile Image  
提供编译环境，可以用于TuGraph的编译。  
`tugraph/tugraph-compile-[os name & version]:[tugraph compile version]`  
例如： `tugraph/tugraph-compile-centos7:1.2.0`  
#### 2.2.2.TuGraph Runtime Image  
提供二进制可运行环境，附带TuGraph库和可执行文件。  
`tugraph/tugraph-runtime-[os name & version]:[tugraph-runtime version]`  
例如：`tugraph/tugraph-runtime-centos7:3.4.0`  
#### 2.2.3.TuGraph Mini Runtime Image  
提供二进制可运行环境，不包含TuGraph种Java、Python相关的功能，无C++ plugin编译运行，仅so上传。' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.2.命名规范'}"
OlapOnDB API文档中介绍的Procedure及Embed主要使用了哪些辅助函数？,"page_content='OlapOnDB API

2. 模型

Procedure及Embed使用到的辅助函数主要包含在OlapOnDB类，还有一些使用频率较高的函数都会逐一介绍  
在TuGraph中OLAP相关的有以下常用的数据结构：  
1. DB图分析类 `OlapOnDB<EdgeData>`
2. 点数组`ParallelVector<VertexData>`
3. 点集合`ParallelBitset`
4. 边数据结构`AdjUnit/AdjUnit<Empty>`
5. 边集合数据结构`AdjList<EdgeData>`' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '2. 模型'}","page_content='OlapOnDB API

1. 简介

一般用户需要自己实现的只是将需要分析的子图抽取出来的过程。用户也可以通过使用TuGraph中丰富的辅助接口实现自己的图分析算法。  
该文档主要介绍Procedure及Embed的接口设计，并介绍部分常用接口，具体的接口信息参见include/lgraph/olap_on_db.h文件。' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '1. 简介'}","page_content='OlapOnDisk API

1. 简介

TuGraph的Standalone模式可用于加载图数据文件，其中图数据文件来源可包含text文本文件、BINARY_FILE二进制文件和ODPS源。在该模式下，TuGraph可实现多数据来源快速加载成图，然后在该图上运行如BFS、WCC、SSSP等迭代式算法，并输出最终结果至终端。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph内置了大量的常见图分析算法和丰富的辅助接口，因此用户几乎不需要自己实现具体的图计算过程，只需要在实现自己的存储过程的时候将相应算法库的头文件(.h)包含到自己的程序中，并在编译阶段链接自己的动态库文件即可。  
该文档主要介绍了Standalone的常用接口，使用到的辅助函数主要包含在OlapOnDB类。同时为帮助用户理解方便，对BFS算法进行举例说明。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '1. 简介'}"
在尝试为用户设置新密码时，哪些异常可能会被抛出？,"page_content='RESTful API Legacy

3.登录

3.1.登录

用户通过用户名和密码发送登录请求。登录成功会收到带有签名的令牌(Json Web Token)和判断是否为默认密码的布尔型变量，客户端储存该令牌，并且用于以后的每次发送请求。如果登录失败会收到“Authentication failed”错误。  
- **URI**: `/login`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| jwt | 令牌 | 字符串 |
| default_password | 是否为默认密码 | 布尔值 |  
**Example request.**  
```
• POST http://localhost:7070/login
• Accept: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '3.登录', 'Header 3': '3.1.登录'}","page_content='src/python/FMA_shell/lgraph_shell/db.py/ import requests
import sys
import json
from requests.exceptions import Timeout


class request_exception(Exception):
    def __init__(self, message, r):
        self.response = r
        super(request_exception, self).__init__(message)


class db():
    def __init__(self, host, port, username, password, graph):
        self.http_headers = {""Content-Type"": ""application/json"", ""Accept"": ""application/json""}
        self.graph = graph
        self.login(host, port, username, password, graph)

    def login(self, host, port, username, password, graph):
        login_url = ""http://{IP}:{PORT}/login"".format(IP=host, PORT=port)
        j_data = {}
        j_data[""user""] = username
        j_data[""password""] = password
        r = requests.post(url=login_url, json=j_data)
        if r.status_code != requests.codes.ok:
            raise request_exception(""Error occured during Post request"", r)
        jwt = r.json()[""jwt""]
        self.jwt = jwt
        self.http_headers[""Authorization""] = ""Bearer "" + jwt
        self.cypher_url = ""http://{IP}:{PORT}/cypher"".format(IP=host, PORT=port)
        self.root_url = ""http://{IP}:{PORT}"".format(IP=host, PORT=port)
        self.graph = graph

    def post_cypher_request(self, data, timeout=None):
        dest_url = self.cypher_url
        data[""graph""] = self.graph
        r = requests.post(url=dest_url, headers=self.http_headers, json=data, timeout=timeout)
        if r.status_code != requests.codes.ok:
            raise request_exception(""Error occured during Post request"", r)
        return r

    def post_root_request(self, data, dest, timeout=None):
        dest_url = self.root_url + dest
        r = requests.post(url=dest_url, headers=self.http_headers, json=data, timeout=timeout)
        if r.status_code != requests.codes.ok:
            raise request_exception(""Error occured during Post request"", r)
        return r

    def get_root_request(self, dest, timeout=None):
        dest_url = self.root_url + dest
        r = requests.get(ur' metadata={'file_name': 'db.py', 'file_path': 'src/python/FMA_shell/lgraph_shell/db.py', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/python/FMA_shell/lgraph_shell/db.py'}","page_content='Cypher API

5.附录2. 内置procedures列表

* dbms.security.changeUserPassword(user_name, new_password)

Change the current user's password.  
**Parameters:**  
| parameter    | parameter type | description     |
| ------------ | -------------- | --------------- |
| user_name    | string     | the user's name |
| new_password | string     | new password    |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL dbms.security.changeUserPassword('quest','73@TuGraph')
```  
**Example output:**  
```
true
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* dbms.security.changeUserPassword(user_name, new_password)'}"
如何使用 liblgraph_python_api.Galaxy 类创建一个新的用户账户？,"page_content='Python Olap API

5. lgraph_db API

PyGalaxy:

- `PyGalaxy(self, dir_path: str)`: 构造函数，dir_path为db路径
- `SetCurrentUser(self, user: str password: str)-> void`: 设置用户
- `SetUser(self, user: std::string)-> void`: 设置用户
- `OpenGraph(self, graph: str, read_only: bool)-> PyGraphDB`: 创建PyGraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'PyGalaxy:'}","page_content='Python Olap API

5. lgraph_db API

Galaxy

- `Galaxy(dir_path: std::string)`: 构造函数，dir_path为db路径
- `SetCurrentUser(user: std::string, password: std::string)-> cython.void`: 设置用户
- `SetUser(user: std::string)-> cython.void`: 设置用户
- `OpenGraph(graph: std::string, read_only: bint)-> GraphDB`: 创建GraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Galaxy'}","page_content='Sampling API

2. 图数据预处理

在采样操作之前，根据图数据路径加载图数据，并映射成olapondb图分析类，代码如下：  
```python
galaxy = PyGalaxy(args.db_path) # 根据路径创建一个galaxy实例
galaxy.SetCurrentUser(args.username, args.password) # 设置当前用户
db = galaxy.OpenGraph('default', False) # 打开图数据库指定db
txn = db.CreateReadTxn() # 创建一个事务实例
olapondb = PyOlapOnDB('Empty', db, txn) # 根据图加载方式、图数据库实例、事务实例实例化OlapOnDB
del txn
del db
del galaxy
```' metadata={'Header 1': 'Sampling API', 'Header 2': '2. 图数据预处理'}"
调用liblgraph_python_api.GraphDB的哪个方法可以删除一个顶点标签？,"page_content='Python客户端

3.RPC Client

| deleteProcedure(self: liblgraph_client_python.client, procedure_type: str, procedure_name: str, graph: str) -> (bool, str)                                                                                            | bool DeleteProcedure(std::string& result, const std::string& procedure_type, const std::string& procedure_name, const std::string& graph)' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client'}","page_content='Python Olap API

5. lgraph_db API

Transaction：

```
GetVertexIndexIterator(
label: std::string,
field: std::string,
key_start: std::string,
key_end: std::string)-> VertexIndexIterator
```
获取索引迭代器。迭代器的field值为 [key_start, key_end]。所以在key_start=key_end=v时，返回指向field值为v的点的迭代器  
lgraph_db_python.py是lgraph_db.pxd中C++类 Galaxy与GraphDB的包装，将C++类包装为Python类，将lgraph_db_python.py编译为Python拓展后，可以直接在Python文件或Python命令行中`import lgraph_db_python`访问lgraph_db_python.PyGraphDB与PyGraphDB.PyGalaxy。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Transaction：'}","page_content='Python Olap API

5. lgraph_db API

见procedures/algo_cython/lgraph_db.pxd与lgraph_db_python.py文件。  
lgraph_db.pxd中接口用法与功能基本与C++接口相同，lgraph_db.pxd中声明的接口都由C++实现，在py文件中必须通过`from cython.cimports.olap_base import *`的方式导入，由Cython编译py文件后才能运行。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API'}"
角色被禁用后，用户将从该角色中获得什么权限？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

```  
#### 6.2.6.禁用角色  
角色可以被禁用。角色被禁用后，具有该角色的用户将不再从该角色中获得任何权限。只有管理员可以执行此操作。  
- **URI**: `/role/{role_name}/disable`
- **METHOD**: POST
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/disable
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.6.禁用角色  
角色可以被禁用。角色被禁用后，具有该角色的用户将不再从该角色中获得任何权限。只有管理员可以执行此操作。  
- **URI**: `/role/{role_name}/disable`
- **METHOD**: POST
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/disable' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='可视化操作手册

2.操作指南

2.5.控制台

- 禁用角色：禁用之后，对应角色图访问权限失效。
- 当一个用户拥有两个角色对同一个图有操作权限时，当禁用其中一个角色时，另一个角色权限同样有效。  
![角色管理-禁用](../../../images/browser/role-disable.png)
![角色管理-启用](../../../images/browser/role-enable.png)  
###### d.删除角色  
在`角色管理`界面点击`删除`按钮删除对应的角色。  
![角色管理-删除](../../../images/browser/role-delete.png)  
#### 2.5.2.数据库信息  
##### 2.5.2.1.基础信息  
`基础信息`获取当前系统运行的状态，并展示关键信息。  
![数据库信息-基础信息](../../../images/browser/db_basic.png)  
|参数    |含义    |
|-------|--------|
|TuGraph版本号|当前TuGraph的版本号，x.x.x|' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.5.控制台'}"
TuGraph的可视化监控主要使用了哪些软件？,"page_content='运维监控

1.设计思路

可视化监控并不是TuGraph自身不可或缺的一部分，因此在设计时将可视化监控作为TuGraph周边生态中的一个应用，来减少和TuGraph数据库的耦合度，以及对于TuGraph自身的影响。TuGraph可视化监控采用目前最火热的开源解决方案，TuGraph Monitor + Prometheus + Grafana来实现。其中TuGraph Monitor作为TuGraph服务的客户端，通过TCP链接向TuGraph服务发起Procedure请求，TuGraph服务在接收到请求后收集自身所在机器的cpu，memory，disk，io，以及请求数量等指标的统计结果进行响应。TuGraph Monitor在接收到TuGraph响应的指标数据后，将数据包装成prometheus需要的格式，保存在内存中，等待Prometheus服务通过http请求获取。Prometheus服务会定期通过http请求从TuGraph' metadata={'Header 1': '运维监控', 'Header 2': '1.设计思路'}","page_content='功能概览

6.生态工具

6.3.运维监控

TuGraph 使用 Prometheus 加 Grafana 的监控框架，采用松耦合的方式。Prometheus 从 TuGraph 的监控接口获取监控信息，存储在本地时序数据库中，然后通过 Grafana 在网页端交互展示。  
TuGraph 提供的监控的状态包括图数据库的状态和服务器的状态，前者包括读写负载、点边数量等数据库端的状态，后者包括内存、CPU、硬盘等服务器的实时状态。如果某些监控状态超过了预期的阈值，就需要主动告警，通常需要对接其他运维管控系统，比如群消息、邮件告警等。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.3.运维监控'}","page_content='功能概览

6.生态工具

6.2.可视化交互

TuGraph Browser 是面向图数据库直接使用者的可视化交互界面，功能上覆盖了 TuGraph 的绝大部分能力，包括数据导入、图模型建立、数据增删查改、监控运维等操作链路。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.2.可视化交互'}"
TuGraph 服务在哪个文件中读取其配置？,"page_content='数据库运行

4.服务配置

4.2.服务器配置文件

TuGraph 的配置文件以 JSON 格式存储。建议将大多数配置存储在配置文件中，并且仅在需要时使用命令行选项临时修改某些配置参数。
一个典型的配置文件如下：  
```json
{
""directory"" : ""/var/lib/lgraph/data"",
""host"" : ""0.0.0.0"",
""port"" : 7070,
""rpc_port"" : 9090,
""enable_rpc"" : true,
""bolt_port"": 7687,
""enable_ha"" : false,
""verbose"" : 1,
""log_dir"" : ""/var/log/lgraph_log"",
""disable_auth"" : false,
""ssl_auth"" : false,
""server_key"" : ""/usr/local/etc/lgraph/server-key.pem"",
""server_cert"" : ""/usr/local/etc/lgraph/server-cert.pem"",' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.2.服务器配置文件'}","page_content='数据库运行

4.服务配置

TuGraph 服务器在启动时从配置文件和命令行选项加载配置，如果在配置文件和命令行中同一选项指定了不同的值，将优先使用命令行中指定的值。' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置'}","page_content='数据库运行

1.前置条件

TuGraph 运行的前置条件为 TuGraph 正确安装，参考[安装流程](1.environment.md)。  
TuGraph 运行需要保证库文件 liblgraph.so 的文件位置在环境变量 LD_LIBRARY_PATH。  
运行 TuGraph 进程的用户不需要超级权限，但需要对配置文件（一般为lgraph.json）及文件中涉及的文件有读权限，并且对数据文件夹、日志文件夹等有写权限。' metadata={'Header 1': '数据库运行', 'Header 2': '1.前置条件'}"
该接口`StudentMapper`中`selectVertex`方法的超时设置是多少毫秒？,"page_content='demo/MultithreadClient/cypher_sender.cpp/ 
#include ""tools/json.hpp""
#include ""cypher_sender.h""
#include <boost/algorithm/string/trim_all.hpp>
#include <fstream>
#include <unordered_map>

const static float PRECIISION = 1000 * 1000;

void cypher_thread_func(multithread_client::ClientThread* thread) {
    while (true) {
        std::string param = thread->fetch();
        if (param == """") {
            return;
        }
        nlohmann::json obj = nlohmann::json::parse(param);
        std::string res;
        auto start = std::chrono::steady_clock::now();
        bool ret = thread->get_channel()->CallCypher(res,  obj[""Cypher""].get<std::string>(),
                obj[""Graph""].get<std::string>());
        auto end = std::chrono::steady_clock::now();
        multithread_client::PerformanceIndicator& indicator = thread->get_indicator()[param];
        indicator.time_used +=
                std::chrono::duration_cast<std::chrono::microseconds>(end - start).count();
        if (ret) {
            if (indicator.result.empty()) indicator.result = std::move(res);
            ++indicator.success_query;
        }
        ++indicator.total_query;
    }
}

namespace multithread_client {

    CypherSender::CypherSender(const Config& conf)
            : config(conf)
            , pool(conf) {}

    bool CypherSender::parse_line(std::string& line, uint32_t& times) {
        boost::trim_all(line);
        nlohmann::json obj = nlohmann::json::parse(line);
        if (!obj.contains(""Cypher"") || !obj.contains(""Graph"") || !obj.contains(""Times"")) {
            return false;
        }
        times = obj[""Times""].get<uint32_t>();
        return true;
    }

    void CypherSender::file_reader() {
        std::fstream ifs(config.input, std::fstream::in);
        std::string line;
        while (std::getline(ifs, line)) {
            if (line.empty()) continue;
            size_t idx = 0;
            if ((idx = line.find(""##""), idx != std::string::npos)) {
                if (idx == 0) continue;
                line = line.substr(0, idx);' metadata={'file_name': 'cypher_sender.cpp', 'file_path': 'demo/MultithreadClient/cypher_sender.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/demo/MultithreadClient/cypher_sender.cpp'}","page_content='数据导入

6.在线全量导入

6.1 从原数据导入

--generate_sst_threads
How many threads to generate sst files. Default=15.
--read_rocksdb_threads
How many threads to read rocksdb in the final stage.
Default=15.
--vid_num_per_reading
How many vertex data to read each time. Default=10000.
--max_size_per_reading
Maximum size of kvs per reading. Default=33554432.
--compact           Whether to compact. Default=0.
--keep_vid_in_memoryWhether to keep vids in memory. Default=1.
--enable_fulltext_index' metadata={'Header 1': '数据导入', 'Header 2': '6.在线全量导入', 'Header 3': '6.1 从原数据导入'}","page_content='动态图

接口

}

interface TemporaryGraph<K, VV, EV> {
/** 从增量图中获取vertex */
IVertex<K, VV> getVertex();

/** 从增量图中获取edges */
List<IEdge<K, EV>> getEdges();

/** 更新vertex value */
void updateVertexValue(VV value);

}

interface HistoricalGraph<K, VV, EV> {
/** 获取图数据最新版本id */
Long getLatestVersionId();

/** 获取图数据所有版本 */
List<Long> getAllVersionIds();

/** 获取图数据所有vertex */
Map<Long, IVertex<K, VV>> getAllVertex();' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
PathTraversal 类中展开当前前沿的操作可以使用哪些类型的过滤函数？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
```  
上述为 FrontierTraversal 的三种遍历方式，即从当前的点集合出发，对集合中的每个点，依次访问每条出边/入边/出边和入边，若满足用户自定义的过滤条件（其中，edge_filter 为面向边的过滤函数，neighbour_filter 则为面向邻居点的过滤函数），则将邻居点加入新的点集合。  
```c
ParallelVector<size_t> & GetFrontier();
```  
当前点集合的扩展结束后，新的点集合可以通过上述方法取得。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &, Path &, IteratorHelper &)> out_edge_filter = nullptr,' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
```  
上述为 FrontierTraversal 的三种遍历方式，即从当前的点集合出发，对集合中的每个点，依次访问每条出边/入边/出边和入边，若满足用户自定义的过滤条件（其中，edge_filter 为面向边的过滤函数，neighbour_filter 则为面向邻居点的过滤函数），则将邻居点加入新的点集合。  
```c' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

std::function<bool(InEdgeIterator &, Path &, IteratorHelper &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &, Path &, IteratorHelper &)> out_neighbour_filter = nullptr,
std::function<bool(VertexIterator &, Path &, IteratorHelper &)> in_neighbour_filter = nullptr
);
```  
PathTraversal 的三种遍历方式与 FrontierTraversal 类似，只是用户自定义的过滤函数中增加了两个参数，其中：Path 包含了到新扩展的这条边之前的路径，IteratorHelper 可用于将路径中的点/边转为数据库中对应的迭代器，相关文档可参考对应的 C++ API 文档。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}"
当在只读交易中调用函数时，会抛出哪种异常？,"page_content='src/core/wal.h/ /**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <chrono>

#include ""fma-common/timed_task.h""
#include ""core/kv_table_comparators.h""
#include ""./sync_file.h""

namespace lgraph {

class Wal {
    // Each wal will be access by at most one thread at a time. This is guaranteed by
    // the single-writer design of LMDB. So the WriteXXX() functions do not need locking.
    // The only data exception is the access of the list of waiting txns, which
    // is always guarded with a mutex and a condition variable.

    // transaction status waiting for batch commit
    struct WaitingTxn {
        WaitingTxn(mdb_size_t tid, SyncFile* f) : txn_id(tid), file(f) {}

        mdb_size_t txn_id;
        std::promise<void> promise;
        SyncFile* file;
    };

 private:
    MDB_env* env_;
    std::string log_dir_;
    std::atomic<bool> exit_flag_;
    // the log_file records txn and kv operations
    uint64_t next_log_file_id_ = 0;
    std::atomic<SyncFile*> log_file_;
    // this file records only meta-operations like opening and dropping tables
    SyncFile dbi_file_;
    mdb_size_t curr_txn_id_;
    std::atomic<int64_t> op_id_;    // -1 indicates completion of current txn

    std::mutex mutex_;
    std::condition_variable cond_;
    std::deque<WaitingTxn> waiting_txns_;
    size_t log_rotate_interval_;
    std::chrono::system_clock::time_point last_log_rotate_time_;
    size_t batch_time_ms_ = 50;
    std::chrono::system_clock::time_point last_batch_time_;
    // The flusher thread flushes wal on constant intervals and notifies waiting
    // txns' metadata={'file_name': 'wal.h', 'file_path': 'src/core/wal.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/wal.h'}","page_content='src/core/mock_kv.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <map>
#include <string>

#include ""fma-common/binary_read_write_helper.h""
#include ""fma-common/fma_stream.h""
#include ""fma-common/type_traits.h""

#include ""core/data_type.h""
#include ""core/lmdb_exception.h""
#include ""core/value.h""

namespace lgraph {
typedef int (*KeySortFunc)(const MDB_val*, const MDB_val*);

class MockKvIterator;

class MockKvTransaction {
    friend class MockKvIterator;
    friend class MockKvStore;
    friend class MockKvTable;

    bool valid_ = true;
    DISABLE_COPY(MockKvTransaction);

 public:
    MockKvTransaction() {}

    MockKvTransaction(MockKvTransaction&& rhs) {
        valid_ = rhs.valid_;
        rhs.valid_ = false;
    }

    MockKvTransaction& operator=(MockKvTransaction&& rhs) {
        valid_ = rhs.valid_;
        rhs.valid_ = false;
        return *this;
    }

    MockKvTransaction Fork() { return MockKvTransaction(); }

    bool IsReadOnly() const { return false; }

    void Commit() { valid_ = false; }

    void Abort() { valid_ = false; }

    bool IsValid() const { return valid_; }

    size_t TxnId() { return 0; }

    int64_t LastOpId() { return 0; }
};

class MockKvTable {
    friend class MockKvIterator;

    std::string name_;
    std::shared_ptr<std::map<std::string, std::string,
                             std::function<bool(const std::string&, const std::string&)>>>
        map_;
    KeySortFunc sort_func_;

    static int CompareAsInt(const MDB_val* a, const MDB_val* b) {
        if (a->mv_size == 4) {
            int ai = (int)_' metadata={'file_name': 'mock_kv.h', 'file_path': 'src/core/mock_kv.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/core/mock_kv.h'}","page_content='src/cypher/cypher_exception.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

#pragma once

#include <exception>
#include <string>
#include ""core/data_type.h""
#include ""fma-common/string_formatter.h""

namespace lgraph {

#ifndef NDEBUG
#define CYPHER_TODO_FILE_NAME std::string(__FILE__)
#else
#define CYPHER_TODO_FILE_NAME """"
#endif

#define CYPHER_TODO()                                                                        \
    do {                                                                                     \
        throw lgraph::CypherException(                                                       \
            fma_common::StringFormatter::Format(""Function not implemented yet: {} at {}:{}"", \
                                                __func__, CYPHER_TODO_FILE_NAME, __LINE__)); \
    } while (0)

#define CYPHER_INTL_ERR()                                                               \
    do {                                                                                \
        throw lgraph::CypherException(fma_common::StringFormatter::Format(              \
            ""Internal error: {} at {}:{}"", __func__, CYPHER_TODO_FILE_NAME, __LINE__)); \
    } while (0)

#define CYPHER_THROW_ASSERT(pred)       \
    do {                                \
        if (!(pred)) CYPHER_INTL_ERR(); \
    } while (0)

#define CYPHER_PARSER_CHECK(pred, msg)                               \
    if (!(pred)) {                                                   \
        throw lgraph::ParserException(""error around '"" + msg + ""'""); \
    }
#define CYPHER_ARGUMENT_ERROR()  ' metadata={'file_name': 'cypher_exception.h', 'file_path': 'src/cypher/cypher_exception.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/cypher_exception.h'}"
UDF的支持中，如果开发的函数的语言是Python，模块通常放在什么位置？,"page_content='src/python/lgraph_task_runner.py/ '''
This is the entry point to python plugins.
MasterThread starts the worker threads and waits until program terminates.
ModuleManager manages modules in Python space.
WorkerThread trys to pop task from a queue shared between C++ and Python, and then
execute it. If the task is read_only and in_process=False, the WorkerThread will
execute the task with a subprocess, otherwise it executes directly in the process.
'''

import os, sys
import time

sys.path.append(os.path.dirname(__file__))

python2 = (sys.hexversion < 0x3000000)

if python2:
    from importlib import import_module
    from imp import reload
else:
    import queue
    from importlib import reload, import_module
import traceback
import logging
import logging.handlers as handlers

from liblgraph_python_api import *
import lgraph_db_python


def setup_logger(level=logging.INFO):
    '''
    Setup root logger so we can easily use it
    Params:
        level:  string  logging level
    '''
    logging.root.setLevel(level)
    # formatter = logging.Formatter('[%(asctime)s] %(name)s-%(levelname)s: %(message)s')
    # handler = logging.StreamHandler(sys.stdout)
    # handler.setFormatter(formatter)
    # logging.root.addHandler(handler)


setup_logger(logging.WARN)


class PluginManager:
    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        pass

    def __init__(self, db_dir):
        self.functions = {}
        self.db_dir = db_dir
        self.plugin_dir = None

    def LoadModule(self, module_name):
        logging.info('trying to load module %s' % module_name)
        error_code = PluginErrorCode.SUCCESS_WITH_SIGNATURE
        output = """"
        try:
            path = self.plugin_dir + ""/"" + module_name + "".so""
            if python2:
                module = imp.load_source(module_name, path)
            else:
                import importlib.util
                spec = importlib.util.spec_from_file_location(module_name, path)
                module = importlib.util.mo' metadata={'file_name': 'lgraph_task_runner.py', 'file_path': 'src/python/lgraph_task_runner.py', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/python/lgraph_task_runner.py'}","page_content='src/BuildCythonExtension.cmake/ set(CMAKE_MODULE_PATH ${CMAKE_SOURCE_DIR}/src/cython/)

find_package(PythonInterp 3)
find_package(PythonExtensions REQUIRED)
find_package(Cython REQUIRED)
message(STATUS ""PYTHON_EXECUTABLE: ${PYTHON_EXECUTABLE}"")
message(STATUS ""PYTHON_VERSION_STRING: ${PYTHON_VERSION_STRING}"")
message(STATUS ""PYTHON_INCLUDE_DIR: ${PYTHON_INCLUDE_DIR}"")
message(STATUS ""PYTHON_LIBRARY: ${PYTHON_LIBRARY}"")
message(STATUS ""CYTHON_EXECUTABLE: ${CYTHON_EXECUTABLE}"")
message(STATUS ""CYTHON_VERSION: ${CYTHON_VERSION}"")

set(CYTHON_FLAGS "" -I${CMAKE_SOURCE_DIR}/src/cython/ -I${CMAKE_SOURCE_DIR}/include/cython/"")
add_cython_target(lgraph_db_python cython/lgraph_db_python.py CXX)
add_library(lgraph_db_python MODULE ${lgraph_db_python})
python_extension_module(lgraph_db_python)
target_link_libraries(lgraph_db_python lgraph libgomp.a crypto dl)' metadata={'file_name': 'BuildCythonExtension.cmake', 'file_path': 'src/BuildCythonExtension.cmake', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/BuildCythonExtension.cmake'}","page_content='src/cython/FindPythonExtensions.cmake/ #.rst:
#
# This module defines CMake functions to build Python extension modules and
# stand-alone executables.
#
# The following variables are defined:
# ::
#
#   PYTHON_PREFIX                     - absolute path to the current Python
#                                       distribution's prefix
#   PYTHON_SITE_PACKAGES_DIR          - absolute path to the current Python
#                                       distribution's site-packages directory
#   PYTHON_RELATIVE_SITE_PACKAGES_DIR - path to the current Python
#                                       distribution's site-packages directory
#                                       relative to its prefix
#   PYTHON_SEPARATOR                  - separator string for file path
#                                       components.  Equivalent to ``os.sep`` in
#                                       Python.
#   PYTHON_PATH_SEPARATOR             - separator string for PATH-style
#                                       environment variables.  Equivalent to
#                                       ``os.pathsep`` in Python.
#   PYTHON_EXTENSION_MODULE_SUFFIX    - suffix of the compiled module. For example, on
#                                       Linux, based on environment, it could be ``.cpython-35m-x86_64-linux-gnu.so``.
#
#
#
# The following functions are defined:
#
# .. cmake:command:: python_extension_module
#
# For libraries meant to be used as Python extension modules, either dynamically
# loaded or directly linked.  Amend the configuration of the library target
# (created using ``add_library``) with additional options needed to build and
# use the referenced library as a Python extension module.
#
#   python_extension_module(<Target>
#                           [LINKED_MODULES_VAR <LinkedModVar>]
#                           [FORWARD_DECL_MODULES_VAR <ForwardDeclModVar>]
#                           [MODULE_SUFFIX <ModuleSuffix>])
#
# Only extension modules that are configured to be built as MODULE libraries can
# be runtime-loa' metadata={'file_name': 'FindPythonExtensions.cmake', 'file_path': 'src/cython/FindPythonExtensions.cmake', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cython/FindPythonExtensions.cmake'}"
在文本中，哪种资源名称对应的颜色设置为固定的“light-orange”？,"page_content='运维监控

2.部署方案

2.4.第四步

""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""total_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-purple"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""self""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

- 点样式
- 应用点类型：设置对应点类型的展示样式，支持同时配置多个点类型外观。
- 大小：对应点类型的展示大小。
- 颜色：对应点类型的展示颜色。
- 图标：对应点类型的图标样式。
- 显示文本：对应点类型显示的文本内容，默认为id。
- 高级配置：根据设置的条件标记对应的点数据。
- 边样式
- 应用边类型：设置对应边类型的展示样式。
- 颜色：对应点类型的展示颜色。
- 边宽：对应边类型的展示宽度。
- 显示文本：对应边类型显示的文本内容，默认不显示。
- 高级配置：根据设置的条件按颜色展示对应的边数据，支持同时配置多个边类型外观。  
![图分析-外观](../../../images/browser/graphanalysis-style-appearance.png)  
##### 2.4.4.8.视图切换  
图分析中支持2D图谱视图、列表视图以及JSON视图。
![图分析-视图-2D](../../../images/browser/graphanalysis-view-2D.png)' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

![图分析-布局样式-布局参数](../../../images/browser/graphanalysis-style-layout-parameters.png)  
详细布局参数可参考[AntV-G6](https://g6.antv.antgroup.com/api/graph-layout/guide)。  
##### 2.4.4.7.外观样式  
在`操作栏`区域点击`外观`按钮，在`左边栏`点击`点样式`或`边样式`进行外观样式配置。
- 点样式
- 应用点类型：设置对应点类型的展示样式，支持同时配置多个点类型外观。
- 大小：对应点类型的展示大小。
- 颜色：对应点类型的展示颜色。
- 图标：对应点类型的图标样式。
- 显示文本：对应点类型显示的文本内容，默认为id。
- 高级配置：根据设置的条件标记对应的点数据。
- 边样式
- 应用边类型：设置对应边类型的展示样式。
- 颜色：对应点类型的展示颜色。
- 边宽：对应边类型的展示宽度。
- 显示文本：对应边类型显示的文本内容，默认不显示。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}"
导入图库的数据如何删除,"page_content='可视化操作手册

2.操作指南

2.4.图项目

###### c.数据映射  
文件上传成功后，需要在`数据导入`页面设置`数据对应表`，将数据文件中的数据列和目标点/边、对应属性建立映射关系。  
- 数据对应表：展示已经上传的数据问题。
- 文件名称：上传的数据文件名称。
- 文件大小：上传的数据文件大小。
- 读取结果：数据文件上传结果，success为读取成功。
- 删除：在页面中删除，不会删除本地文件。
- 数据文件映射：每个已上传的数据文件都需要配置映射关系。
- 标签：选择该文件对应的点或边类型，只能选择一类点或一类边。
- 从第N行，开始：从第N行开始读取数据，系统默认从第0行开始读取数据，如需跳过表头可输入1。
- 属性映射：下拉选择数据列对应的属性字段。
- 数据预览：系统会预读数据文件的前5行。  
![数据导入-数据映射](../../../images/browser/graphbuild-import-datamapping.png)  
文件上传成功后，可以点击`继续导入`按钮继续导入其他数据，或者点击`前往图查询`按钮在`图查询`页面查询已导入的数据。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

###### b.上传文件  
在`数据导入`页面上传需要导入的数据文件，将数据导入到图项目中。  
![数据导入-上传文件](../../../images/browser/graphbuild-import.png)  
- 分隔符：数据文件的列分隔符。
- 文件上传：支持上传多个文件。
- 支持弹窗中选择多个上传文件。
- 支持将文件拖拽至页面中上传。
- 支持同时上传点文件和边文件。  
###### c.数据映射  
文件上传成功后，需要在`数据导入`页面设置`数据对应表`，将数据文件中的数据列和目标点/边、对应属性建立映射关系。  
- 数据对应表：展示已经上传的数据问题。
- 文件名称：上传的数据文件名称。
- 文件大小：上传的数据文件大小。
- 读取结果：数据文件上传结果，success为读取成功。
- 删除：在页面中删除，不会删除本地文件。
- 数据文件映射：每个已上传的数据文件都需要配置映射关系。
- 标签：选择该文件对应的点或边类型，只能选择一类点或一类边。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='TuGraph-OGM

使用TuGraph-OGM

通过OGM进行增删改查

// 清空数据库
session.deleteAll(Movie.class);        // 删除所有Movie节点
session.purgeDatabase();               // 删除全部数据
```' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '使用TuGraph-OGM', 'Header 3': '通过OGM进行增删改查'}"
当使用 TuGraph 批量创建边时，如果请求成功，响应中将返回什么内容？,"page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 200: OK' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}"
TuGraph为什么选择使用B+树作为其底层存储数据结构？,"page_content='性能优先

3.存储数据结构

TuGraph底层采用B+树来支持实时的增删查改事务。  
在排序树的数据结构中，B+树和LSM树为主要代表。B+树在树节点中使用拆分和合并式来更新排序数据，而 LSM 树在日志中追加更新，以进行延迟数据合并。B+ 早期用在文件系统的实现中，通过将数据保存 在自适应长度的叶子节点中，解决硬盘顺序操作和随机操作性能存在数据量级差别的问题，有较均衡的读写性能。LSM 树的主要优势使用 WAL(Write Ahead Log) 进行更新，将更新操作变成顺序操作，在键值较小时性能优势尤为突出。WAL 意味着将数据的更新合并推迟，批量更新能提升综合效率，也使得系统的调度变得复杂。如果更新合并完成前，恰好对其中的数据继续读取，LSM 树就需要读取几个层级局部合并的日志，会导致读取放大和空间放大，从而影响读效率。' metadata={'Header 1': '性能优先', 'Header 2': '3.存储数据结构'}","page_content='性能优先

3.存储数据结构

总结来说，B+ 树有较好的顺序读写性能，而 LSM 树在数据随机写方面占优。此外 LSM 树采用后台合并的方式，使得性能的波动难以预期，性能波动和上层存储和计算的关联性较弱，增加了整体设计的成本。综上考虑，TuGraph 选用 B+ 树作为读性能优先的实现。' metadata={'Header 1': '性能优先', 'Header 2': '3.存储数据结构'}","page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}"
"接口 ""CallProcedureToLeader"" 支持哪些参数设置以改变返回结果的格式？","page_content='Java客户端

2.使用示例

2.7.向leader调用存储过程

@param jsonFormat: (Optional) Return format of calling stored procedure
@return: the result of procedure execution
public String callProcedureToLeader(String procedureType, String procedureName, String param, double procedureTimeOut,
boolean inProcess, String graph)
```
本接口支持在HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.7.向leader调用存储过程'}","page_content='Python客户端

3.RPC Client

3.7.向leader调用存储过程

```python
ret, res = client.callProcedureToLeader(""CPP"", ""khop"", kHopParamGen(), 1000, false, ""default"")
```
```
callProcedureToLeader(self: liblgraph_client_python.client, procedure_type: str, procedure_name: str, param: str, procedure_time_out: float, in_process: bool, graph: str, json_format: bool) -> (bool, str)
```
本接口支持在HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.7.向leader调用存储过程'}","page_content='Java客户端

2.使用示例

2.6.调用存储过程

public String callProcedure(String procedureType, String procedureName, String param, double procedureTimeOut,
boolean inProcess, String graph, String url)
```
本接口支持在单机模式和HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}"
如何提高查询效率？,"page_content='QA汇总

Cypher QA

拼接查询慢

Q：查询语句 Where 后使用 and 进行拼接查询速度较慢，语句应如何优化改进？
示例：  
```
MATCH (n1),(n2) CALL algo.allShortestPaths(n1,n2)
YIELD nodeIds,relationshipIds,cost
WHERE id(n1) IN [0] AND id(n2) IN [3938]
RETURN nodeIds,relationshipIds,cost
```  
A：目前 cypher 查询引擎正在优化中。现阶段语句改写可以通过 with 向下传递进行优化。
示例：  
```
MATCH (n1) where id(n1) in [0] with n1
MATCH (n2) where id(n2) in [3938] with n1, n2
CALL algo.allShortestPaths(n1,n2) YIELD nodeIds,relationshipIds,cost
RETURN nodeIds,relationshipIds,cost
```' metadata={'Header 1': 'QA汇总', 'Header 2': 'Cypher QA', 'Header 3': '拼接查询慢'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

- 执行：点击`执行`按钮，发送输入的查询语句至后台运行。  
![图查询-执行按钮](../../../images/browser/query-execute-button.png)  
- 收藏：点击`收藏`按钮，将当前语句查询窗口的内容保存成模板，以便下次使用。  
![图查询-收藏按钮](../../../images/browser/query-bookmark-button.png)  
- 下载：点击`下载`按钮，将当前语句查询窗口的内容保存成文本文件并下载至本地，以便下次使用。  
![图查询-下载按钮](../../../images/browser/query-download-button.png)  
详细Cypher使用指南请参考文档：[Cypher API](../8.query/1.cypher.md)  
###### b.收藏列表  
以列表方式展示已经收藏的查询语句，点击列表中的收藏模板可以使用其中的语句。支持关键字搜索、名称修改以及删除。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='RESTful API Legacy

4.查询

4.2.调用带参数的 Cypher

Cypher 支持使用参数进行查询。当调用带参数的 Cypher 查询时，TuGraph 会缓存该查询的
执行计划（execution plan），以加速后续同类查询的速度。  
- **URI**: `/cypher`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| graph | 数据库 | 字符串 |
| cypher | 查询语句 | 字符串 |
| parameters | 参数 | 列表 |  
- **RESPONSE**:  
与 [调用 Cypher](#%E8%B0%83%E7%94%A8Cypher) 相同。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/cypher
• Accept: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '4.查询', 'Header 3': '4.2.调用带参数的 Cypher'}"
FieldData 类中的 integer() 方法在什么情况下会抛出 std::bad_cast 异常？,"page_content='QA汇总

数据导入QA

读取oracle数据报错

Q：读取oracle数据报错
""error_message"":""Error parsing file memory_file_stream\n\tError occurred at offset 0, exception detail:\n\tjson reading failed, error msg : std::bad_cast\n>Error line....""，如何解决？
A：看起来像在处理数据的时候遇到特使符号导致报错的，建议用相对较小的表以及数据可以尝试测一下' metadata={'Header 1': 'QA汇总', 'Header 2': '数据导入QA', 'Header 3': '读取oracle数据报错'}","page_content='src/cypher/cypher_types.h/ ﻿/**
 * Copyright 2022 AntGroup CO., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 */

//
// Created by wt on 19-11-20.
//
#pragma once

#include <unordered_map>
#include ""core/data_type.h""
#include ""cypher/cypher_exception.h""

namespace cypher {

struct FieldData {
    typedef std::unordered_map<std::string, cypher::FieldData> CYPHER_FIELD_DATA_MAP;
    typedef std::vector<cypher::FieldData> CYPHER_FIELD_DATA_LIST;
    // TODO(lingsu) : a default state should be added
    enum FieldType { SCALAR, ARRAY, MAP } type;

    lgraph::FieldData scalar;
    CYPHER_FIELD_DATA_LIST* array = nullptr;
    CYPHER_FIELD_DATA_MAP* map = nullptr;

    FieldData() : type(SCALAR) {}

    explicit FieldData(bool rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(int8_t rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(int16_t rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(int32_t rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(int64_t rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(float rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(double rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(const lgraph::Date& rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(const lgraph::DateTime& rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(const std::string& rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(std::string&& rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(const char* rhs) : type(SCALAR), scalar(rhs) {}

    explicit FieldData(const char* rhs, size_t s) : type(SCALAR), scalar(rhs, ' metadata={'file_name': 'cypher_types.h', 'file_path': 'src/cypher/cypher_types.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/cypher_types.h'}","page_content='src/lgraph_api/lgraph_types.cpp/ /**
* Copyright 2022 AntGroup CO., Ltd.
*
* Licensed under the Apache License, Version 2.0 (the ""License"");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
* http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an ""AS IS"" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*/
#include ""lgraph/lgraph_types.h""
#include ""bolt/temporal.h""
#include ""fma-common/utils.h""

namespace lgraph_api {

std::any FieldData::ToBolt() const {
    switch (type) {
    case FieldType::NUL:
        return {};
    case FieldType::BOOL:
        return data.boolean;
    case FieldType::INT8:
        return data.int8;
    case FieldType::INT16:
        return data.int16;
    case FieldType::INT32:
        return data.int32;
    case FieldType::INT64:
        return data.int64;
    case FieldType::FLOAT:
        {
            // bolt protocol does not have float type
            return fma_common::DoubleDecimalPlaces(data.sp, 5);
        }
    case FieldType::DOUBLE:
        return data.dp;
    case FieldType::STRING:
        return *data.buf;
    case FieldType::DATE:
        return bolt::Date{data.int32};
    case FieldType::DATETIME: {
            int64_t sec = data.int64 / 1000000;
            int64_t micro = data.int64 % 1000000;
            return bolt::LocalDateTime{sec, micro*1000};
        }
    case FieldType::FLOAT_VECTOR: {
            std::vector<std::any> ret;
            ret.reserve(data.vp->size());
            for (auto& d : *data.vp) {
                ret.emplace_back((double)d);
            }
            return ret;
        }
    default:
        throw std::runtime_error(""ToBolt meet unsupported data type."");
    }
}
}  // namespace lgraph_api
' metadata={'file_name': 'lgraph_types.cpp', 'file_path': 'src/lgraph_api/lgraph_types.cpp', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/lgraph_api/lgraph_types.cpp'}"
TuGraph-DB的存储引擎用了kv数据库么？如果是，基于什么kv数据库构建的？,"page_content='TuGraph产品架构

1.简介

![产品架构](../../../images/architecture.png)  
上图从功能模块的角度，以 TuGraph 为例，给出了企业级图数据库的整体架构，自下而上包括：  
- 软硬件环境。涉及图数据库的开发和使用环境。TuGraph 主要基于底层的 C++语言开发，能够兼容市面上大部分操作系统和 CPU。
- 存储层，包括 KV 存储层和图存储层。存储层需要支持计算层所需的各个功能。
- 计算层。计算层应包括图事务引擎、图分析引擎和图神经网络引擎，也包含了服务端提供的多种编程接口，包括描述式查询语言 Cypher，存储过程等。
- 客户端。客户端 SDK 应支持 Java、Python、C++ 等多种语言，也支持命令行的交互方式。Browser 和 Explorer 通过网页端交互的方式，降低了图数据库的使用门槛。
- 在生态工具方面，覆盖了企业级图数据库的开发、运维、管理等链路，提升可用性。' metadata={'Header 1': 'TuGraph产品架构', 'Header 2': '1.简介'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}"
请问下怎么没找到新版的browser-resource，怎么进行新旧版本的web切换呢,"page_content='数据库运行

3.服务操作

3.4.新旧前端切换

进入容器，可以通过修改配置文件""/usr/local/etc/lgraph.json""中的""web""参数来选择使用老版本或新版本的前端。对于老版本，可以将""web""的值设为""/usr/local/share/lgraph/resource""；对于新版本，可以将""web""的值设为""/usr/local/share/lgraph/browser-resource""。完成配置文件的修改后，请执行命令 `docker restart tugraph` 以使更改生效。需要注意的是，新版本是默认选项。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.4.新旧前端切换'}","page_content='快速上手

2.安装

2.2.新旧前端说明

进入容器，可以通过修改配置文件""/usr/local/etc/lgraph.json""中的""web""参数来选择使用老版本或新版本的前端。对于老版本，可以将""web""的值设为""/usr/local/share/lgraph/resource""；对于新版本，可以将""web""的值设为""/usr/local/share/lgraph/browser-resource""。完成配置文件的修改后，请执行命令 `docker restart tugraph` 以使更改生效。需要注意的是，新版本是默认选项。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.2.新旧前端说明'}","page_content='数据库运行

4.服务配置

4.2.服务器配置文件

""bolt_port"": 7687,
""enable_ha"" : false,
""verbose"" : 1,
""log_dir"" : ""/var/log/lgraph_log"",
""disable_auth"" : false,
""ssl_auth"" : false,
""server_key"" : ""/usr/local/etc/lgraph/server-key.pem"",
""server_cert"" : ""/usr/local/etc/lgraph/server-cert.pem"",
""web"" : ""/usr/local/share/lgraph/browser-resource""
}
```' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.2.服务器配置文件'}"
tugraph进行大规模数据查询时是否对图数据进行了压缩？,"page_content='TuGraph与ARM架构

内容：

**测试介绍：**

TuGraph在测试中使用Client/Server分离的模式，来模拟真实的用户使用场景。在结果中，TuGraph在不同规模的数据集下均表现优异，在大规模100GB的数据集（2.8亿个点，18亿条边）上，TuGraph的吞吐率较上一次官方纪录提升了31%。在300GB数据集上，TuGraph测试了超过内存容量的数据吞吐量，虽然较100GB的性能有所下降，但考虑内存和硬盘的读写性能鸿沟，该结果也在预期之内。**除了性能测试，TuGraph在****系统事务性、可恢复性、正确性、稳定性等方面均达到官方标准，体现了TuGraph高并发低延迟的强大性能优势。**  
在性能测试中，我们发现并解决了一些值得注意的问题。其一是有的系统页大小默认为64KB，这个对图系统随机数据读写并不友好，调整为X86更普遍的4KB有助于提升性能。其二是在云上使用云盘，会比本地硬盘的读写带宽和稳定性差很多，如果能够在测试前进行数据预热和及时的硬盘性能监控，更有助于获得理想的结果。' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '内容：', 'Header 3': '**测试介绍：**'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

0 映射原理

TuGraph-OGM 将 JAVA 对象映射为图的对象，类映射为点，类的属性映射为图中的属性，类中的方法映射为操作 TuGraph 的查询语句。  
以电影场景为例，对演员、电影、导演之间的关系进行数据化，就形成了非常典型的图数据。举一个简单的示例，演员Alice在1990年和2019年分别出演了两部电影《Jokes》和《Speed》，其中《Jokes》的导演是Frank Darabont。  
以图的思维来看，演员、导演、电影可以被映射为三种不同的节点，而出演、执导可以被映射为两种边，映射结果如上图所示，将数据存入图数据库后，相关的开发人员就可以使用各类图查询语言对数据进行查询。  
但对非图数据库相关的开发人员来说，这个例子中的演员、导演、电影作为实体，同样可以映射为类中的对象，而与实体相关联的对象可以通过集合存储，这是大多数开发人员熟悉的领域。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '0 映射原理'}","page_content='图数据库智能化建设与探索

**04\. 技术分享｜CStore Compaction模块的设计与优化**

“TuGraph Analytics本质上是一款图分析OLAP数据库。CStore作为一个单机版存储引擎，提供了坚实的存储基础。同时，RocksDB也可以作为TuGraph Analytics的存储基础。我们采用LDBC提供的通用社交网络图数据集进行了基准测试，测试涉及让TuGraph Analytics分别连结RocksDB以及我们自有版本的CStore进行分析。在同步与异步compaction（数据压缩整理）两种方式下进行了读写性能测试：同步方式意味着数据写入完成后进行compaction，完成之后再进行读性能测试；异步方式则是写入和compaction同时进行，写入完成后立即测试读性能。在这两种情境下，使用CStore的TuGraph Analytics的读性能超过了使用RocksDB的三倍以上。”' metadata={'Header 1': '图数据库智能化建设与探索', 'Header 2': '**04\\. 技术分享｜CStore Compaction模块的设计与优化**'}"
TuGraph选择使用哪一种树结构作为其存储数据结构，并简述选择这种结构的主要原因是什么？,"page_content='性能优先

3.存储数据结构

总结来说，B+ 树有较好的顺序读写性能，而 LSM 树在数据随机写方面占优。此外 LSM 树采用后台合并的方式，使得性能的波动难以预期，性能波动和上层存储和计算的关联性较弱，增加了整体设计的成本。综上考虑，TuGraph 选用 B+ 树作为读性能优先的实现。' metadata={'Header 1': '性能优先', 'Header 2': '3.存储数据结构'}","page_content='性能优先

3.存储数据结构

TuGraph底层采用B+树来支持实时的增删查改事务。  
在排序树的数据结构中，B+树和LSM树为主要代表。B+树在树节点中使用拆分和合并式来更新排序数据，而 LSM 树在日志中追加更新，以进行延迟数据合并。B+ 早期用在文件系统的实现中，通过将数据保存 在自适应长度的叶子节点中，解决硬盘顺序操作和随机操作性能存在数据量级差别的问题，有较均衡的读写性能。LSM 树的主要优势使用 WAL(Write Ahead Log) 进行更新，将更新操作变成顺序操作，在键值较小时性能优势尤为突出。WAL 意味着将数据的更新合并推迟，批量更新能提升综合效率，也使得系统的调度变得复杂。如果更新合并完成前，恰好对其中的数据继续读取，LSM 树就需要读取几个层级局部合并的日志，会导致读取放大和空间放大，从而影响读效率。' metadata={'Header 1': '性能优先', 'Header 2': '3.存储数据结构'}","page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}"
TuGraph-DB使用的boost库是什么版本？,"page_content='TuGraph Java Client

版本选择

| Client Version | TuGraph Version |
|----------------|-----------------|
| 1.1.1          | 3.3.3           |
| 1.2.1, 1.2.2   | 3.4.x, 3.5.0    |
| 1.3.0          | 3.6.0           |
| 1.4.0, 1.4.1   | 4.0.0, 4.0.1    |  
**注意**:  
- 3.3.0~3.3.2 版本的 TuGraph Server 是在 java-client 重构前的遗留版本，本仓库不支持这些版本。
- 1.1.0 和 1.2.0 因 pom 文件中的 ${revision} 变量引入的无法使用的问题而不可用[1]。' metadata={'Header 1': 'TuGraph Java Client', 'Header 2': '版本选择'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

三、TuGraph-DB高可用集群部署与应用

1.TuGraph-DB高可用（V3.6）

关于 TuGraph-DB 高可用集群的部署方式和 client 应用，相关文档已经放到了 tugraph-db.readthedocs.io 网站上。  
现在支持 C++、Java 和 Python 多种版本的 client SDK。' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '三、TuGraph-DB高可用集群部署与应用', 'Header 3': '1.TuGraph-DB高可用（V3.6）'}","page_content='环境分类

2.依赖系统库

针对三种环境，除去TuGraph的运行包，所需要的系统库如下：
* 编译环境，包括gcc、python、java等编译器，也包含antlr4、pybind11等，具体参见tugraph-db源码目录 ci/images/tugraph-compile-*-Dockerfile。
* 运行环境，主要由存储过程引入，包括gcc、boost、cmake等，具体参见tugraph-db源码目录 ci/images/tugraph-runtime-*-Dockerfile。
* 精简运行环境，无，可以参见tugraph-db源码目录 ci/images/ tugraph-mini-runtime-*-Dockerfile。' metadata={'Header 1': '环境分类', 'Header 2': '2.依赖系统库'}"
TuGraph适合哪些类型的用户？,"page_content='环境和版本选择

1. 简介

TuGraph为不同需求的用户提供了差异化的系统环境和部署方式，来满足新手、系统开发者、生产运维人员、研究人员等不同用户的需求。' metadata={'Header 1': '环境和版本选择', 'Header 2': '1. 简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}","page_content='TuGraph在图计算系统建设中的作用

TuGraph 技术优势

TuGraph 开源版特色

为什么要去开源单机版而不是分布式版本？主要是考虑到它的部署和使用成本比分布式版本要低得多，同时功能也很完整、独立。我们希望这样可以让许多刚开始使用图数据库或有使用图数据库解决问题的想法的人，可以先尝试用我们的单机版图数据库。因为它的部署非常简单，如果跑起来没有问题，那么再考虑是否需要分布式版本。如果确实需要，我们可以再跟进这个问题。  
我们的单机版图数据库已经能够支持 TB 级别的数据，我们内部也有很多情况使用单机版图数据库。在单台机器上，我们最大的数据量也达到了 2TB 多，在线上运行，能够处理百亿级别的点边。事实上，大多数用户使用单机版图数据库都是足够的。由于单机版的图数据库很容易优化，我们对它进行了极致的优化，因此单机版图数据库在性能上可以满足绝大多数场景的需求。此外，它的系统特性也很全面，包括高可用性、多图支持、权限管理、日志记录等，它可以被看作是一个成熟、易用的图数据库，类似于 MySQL。  
开源TuGraph特点包括:  
-   单机版图数据库能够处理数据量几个 TB 的数据，前提是磁盘足够大。' metadata={'Header 1': 'TuGraph在图计算系统建设中的作用', 'Header 2': 'TuGraph 技术优势', 'Header 3': 'TuGraph 开源版特色'}"
TuGraph的REST API中，POST请求主要用途是什么？,"page_content='RESTful API Legacy

2.请求与数据格式

2.1请求

TuGraph 支持 HTTP GET/POST/PUT/DELETE 请求。其中：  
- GET 请求用于只读请求，如读取点属性，边属性等操作；
- POST 请求用于创建实体，提交 Cypher，以及加载和调用存储过程；
- PUT 请求用于修改已有实体，如修改点属性，边属性等；
- DELETE 请求用于删除已有实体，如删除点，边等。  
在高可用模式下，用户可以在请求的报头(request header)中设置 `server_version` 来保证请求的服务器有足够新的数据。
当前的 `server_version` 可以从服务器返回的报头中获取。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '2.请求与数据格式', 'Header 3': '2.1请求'}","page_content='RESTful API

2.请求与响应格式

2.2请求类型

接口用于将本地文件上传至TuGraph所在机器。可以上传文本文件，二进制文件，可以上传大文件，也可以上传小文件，对于大文件，客户端在上传时应该对文件做切分，每个文件分片不大于1MB，参数Begin-Pos和Size对应本次分片在完整文件中的偏移量与分片大小。参数需要放在http请求的报文头，请求内容对应文件分片内容。本接口请求头不止有token参数  
- **URI**:     /upload_file
- **METHOD**:  POST
- **REQUEST**:  
| header参数  | 参数说明        | 参数类型             | 是否必填       |
| ------- |-------------|------------------|------------|
| File-Name   | 文件名称        | 字符串类型            | 是          |' metadata={'Header 1': 'RESTful API', 'Header 2': '2.请求与响应格式', 'Header 3': '2.2请求类型'}","page_content='RESTful API

2.请求与响应格式

2.2请求类型

| body参数  | 参数说明 | 参数类型    | 是否必填       |
| ------- |------|---------|------------|
| result   | 查询结果 | json字符串 | 是          |  
**Example request.**  
```
{""script"" : ""Match (n) return n"", ""graph"" : ""default""}
```  
#### 2.2.5. 上传文件
接口用于将本地文件上传至TuGraph所在机器。可以上传文本文件，二进制文件，可以上传大文件，也可以上传小文件，对于大文件，客户端在上传时应该对文件做切分，每个文件分片不大于1MB，参数Begin-Pos和Size对应本次分片在完整文件中的偏移量与分片大小。参数需要放在http请求的报文头，请求内容对应文件分片内容。本接口请求头不止有token参数  
- **URI**:     /upload_file
- **METHOD**:  POST
- **REQUEST**:' metadata={'Header 1': 'RESTful API', 'Header 2': '2.请求与响应格式', 'Header 3': '2.2请求类型'}"
安装部署TuGraph外存配置的最低和建议分别是多少？,"page_content='环境准备

1.硬件环境

1.3. 外存

我们强烈建议用户使用 NVMe SSD 作为外存，数据库有大量的写操作需要同步的外存，通常为随机写，外存的读写性能很容易成为整体数据库运行的性能瓶颈。因此，高IOPS、低延迟的 NVMe SSD 是最优的选择。  
如果现实条件只能使用 SATA接口的SSD，或者云上的网盘，性能虽然会受到影响，但 TuGraph 依然能正确的运行。  
外存大小建议为实际数据大小的4倍，比如数据为1TB，则准备4TB的硬盘会比较稳妥。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.3. 外存'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='云部署

2.实例说明

TuGraph部署的为社区开源版本，源码参考Github Repo，目前可以选择的实例规格如下：  
| 规格族         | vCPU与内存                 | 系统盘              | 公网带宽      |
|----------------|-------------------------|-------------------|-----------|
| ecs.r7a.xlarge | AMD 内存型 r7a，4vCPU 32GiB | ESSD云盘 200GiB PL0 | 固定带宽1Mbps |
| ecs.r6.xlarge  | 内存型r6，4vCPU 32GiB       | ESSD云盘 200GiB PL0 | 固定带宽1Mbps |  
预估费用在创建实例时可实时看到（目前为免费）。 如需更多规格、其他服务（如集群高可用性要求、企业级支持服务等），请联系我们 tugraph@service.alipay.com。' metadata={'Header 1': '云部署', 'Header 2': '2.实例说明'}"
在创建一个TuGraph数据库时，如果指定的目录不存在，构造函数会如何处理？,"page_content='TuGraph-db

3. 从源代码编译

建议在Linux系统中构建TuGraph，Docker环境是个不错的选择。如果您想设置一个新的环境，请参考[Dockerfile]  
以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build' metadata={'Header 1': 'TuGraph-db', 'Header 2': '3. 从源代码编译'}","page_content='src/BuildLGraphServer.cmake/ # tcmalloc
option(LINK_TCMALLOC ""Link tcmalloc if possible"" ON)
if (LINK_TCMALLOC)
    find_path(GPERFTOOLS_INCLUDE_DIR NAMES gperftools/heap-profiler.h)
    find_library(GPERFTOOLS_LIBRARIES NAMES tcmalloc_and_profiler)
    if (GPERFTOOLS_INCLUDE_DIR AND GPERFTOOLS_LIBRARIES)
        set(CMAKE_CXX_FLAGS ""-DBRPC_ENABLE_CPU_PROFILER"")
        set(FMA_GPERFTOOLS_INCLUDE_DIR ${GPERFTOOLS_INCLUDE_DIR})
    else ()
        set(GPERFTOOLS_LIBRARIES """")
    endif ()
endif ()

# gflags
include(cmake/FindGFlags.cmake)

# leveldb
find_path(LEVELDB_INCLUDE_PATH NAMES leveldb/db.h)
find_library(LEVELDB_LIB NAMES leveldb)
if ((NOT LEVELDB_INCLUDE_PATH) OR (NOT LEVELDB_LIB))
    message(FATAL_ERROR ""Fail to find leveldb"")
endif ()

# protbuf
include(cmake/GenerateProtobuf.cmake)
GenerateProtobufCpp(${CMAKE_CURRENT_LIST_DIR}/protobuf
        PROTO_SRCS PROTO_HEADERS
        ${CMAKE_CURRENT_LIST_DIR}/protobuf/ha.proto
        ${CMAKE_CURRENT_LIST_DIR}/protobuf/tugraph_db_management.proto)

include_directories(${DEPS_INCLUDE_DIR})

# brpc
set(BRPC_LIB libbrpc.a)
set(BRAFT_LIB libbraft.a)

############### liblgraph_server_lib ######################

set(TARGET_SERVER_LIB lgraph_server_lib)

add_library(${TARGET_SERVER_LIB} STATIC
        plugin/plugin_context.cpp
        plugin/python_plugin.cpp
        plugin/cpp_plugin.cpp
        server/bolt_handler.cpp
        server/bolt_server.cpp
        server/lgraph_server.cpp
        server/state_machine.cpp
        server/ha_state_machine.cpp
        server/db_management_client.cpp
        import/import_online.cpp
        import/import_v2.cpp
        import/import_v3.cpp
        restful/server/rest_server.cpp
        restful/server/stdafx.cpp
        http/http_server.cpp
        http/import_manager.cpp
        http/import_task.cpp
        http/algo_task.cpp
        ${PROTO_SRCS})

target_compile_options(${TARGET_SERVER_LIB} PUBLIC
        -DGFLAGS_NS=${GFLAGS_NS}
        -D__const__=
        -pipe
        -fPIC -fno-omit-frame-pointer)

if (NOT (CMAKE_SYSTEM' metadata={'file_name': 'BuildLGraphServer.cmake', 'file_path': 'src/BuildLGraphServer.cmake', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/BuildLGraphServer.cmake'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.3 通过OGM进行增操作**

OGM支持对TuGraph的实体执行CRUD 操作，同时支持发送任意TuGraph支持的Cypher语句，包括通过CALL调用存储过程。  
**CREATE**  
在完成图对象的构建后，即可通过类的实例化创建节点，当两个节点互相存储在对方的集合（该集合在构建时被标注为边）中，就形成了一条边，最后使用session.save方法将数据存入数据库。  
注意：TuGraph数据库为强schema类型数据库，在创建实体前需要该数据的label已经存在，且新建过程中需要提供唯一的主键。  
```
Movie jokes = new Movie（""Jokes""，1990）； // 新建Movie节点jokes session.save(jokes); // 将jokes存储在TuGraph中

Movie speed = new Movie(""Speed"", 2019);

Actor alice = new Actor(""Alice Neeves"");

alice.actsIn(speed);

session.save(speed);' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.3 通过OGM进行增操作**'}"
VertexIterator 的 GetNumOutEdges 方法默认的 n_limit 参数值是多少？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr,' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

std::function<bool(VertexIterator &, Path &, IteratorHelper &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &, Path &, IteratorHelper &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &, Path &, IteratorHelper &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &, Path &, IteratorHelper &)> out_edge_filter = nullptr,' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

std::function<bool(VertexIterator &, Path &, IteratorHelper &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &, Path &, IteratorHelper &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &, Path &, IteratorHelper &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &, Path &, IteratorHelper &)> out_neighbour_filter = nullptr,' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}"
试图加入高可用集群时节点的默认等待秒数是多少？,"page_content='数据库运行

4.服务配置

4.1.配置参数

| ha_node_join_group_s         | 整形                    | 节点尝试加入高可用集群的等待时长，单位秒，默认是 10。                                                                                                                                                      |
| ha_bootstrap_role            | 整形                    | 是否使用bootstrap方式启动，以及使用该方式启动的服务器角色，0代表不使用bootstrap方式启动，1代表使用bootstrap方式启动且本节点为leader，2代表使用bootstrap方式启动且本节点为follower，只有这3种选项。 默认值为 0。                                              |' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='数据库运行

4.服务配置

4.1.配置参数

| ha_conf                      | 字符串                   | 根据 host1:port1,host2:port2,host3:port3 初始化HA集群，默认值为空。                                                                                                                             |
| ha_node_join_group_s         | 整形                    | 节点尝试加入高可用集群的等待时长，单位秒，默认是 10。                                                                                                                                                      |' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='部署高可用模式

3.启动初始备份组

3.2.初始数据不一致

```  
**使用bootstrap启动HA集群时需要注意两点：**
1. 需要等待`leader`节点生成snapshot并且成功启动之后再加入`follower`节点，否则`follower`节点可能加入失败。在启动`follower`节点时可以将`ha_node_join_group_s`参数配置的稍大，以在加入HA集群时多次等待和超时重试。
2. HA集群只有在第一次启动时可以使用bootstrap模式，后续再启动时只能使用普通模式(见3.1节)启动，尤其不能让同一个集群的多个节点以bootstrap模式启动，否则可能产生数据不一致的情况' metadata={'Header 1': '部署高可用模式', 'Header 2': '3.启动初始备份组', 'Header 3': '3.2.初始数据不一致'}"
生成Mapper接口的时候，XMLMAPPER类型将如何实现接口方法？,"page_content='动态图

接口

}

interface HistoricalGraph<K, VV, EV> {
/** 获取图数据最新版本id */
Long getLatestVersionId();

/** 获取图数据所有版本 */
List<Long> getAllVersionIds();

/** 获取图数据所有vertex */
Map<Long, IVertex<K, VV>> getAllVertex();

/** 获取图数据指定版本的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions);

/** 获取图数据指定版本并满足过滤条件的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions, IVertexFilter<K, VV> vertexFilter);' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='动态图

接口

| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='动态图

接口

/** 获取图数据指定版本的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions);

/** 获取图数据指定版本并满足过滤条件的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions, IVertexFilter<K, VV> vertexFilter);

/** 获取图数据指定版本的快照 */
GraphSnapShot<K, VV, EV> getSnapShot(long version);

}

interface GraphSnapShot<K, VV, EV> {
/** 获取当前版本id */
long getVersion();
/** 获取vertex */
VertexQuery<K, VV> vertex();
/** 获取edges */
EdgeQuery<K, EV> edges();

}' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
GCN模型的主要组成部分是什么？,"page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.4.构建GCN模型

def forward(self, g, features):
h = features
for i, layer in enumerate(self.layers):
if i != 0:
h = self.dropout(h)
h = layer(g, h)
return h

def build_model():
in_size = feature_len  #feature_len为feature的长度，在此处为1433
out_size = classes  #classes为类别数，在此处为7
model = GCN(in_size, 16, out_size)  #16为隐藏层大小
return model
```
本教程将构建一个两层图卷积网络（GCN）。每层通过聚合邻居信息来计算新的点表示。' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.4.构建GCN模型'}","page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.4.构建GCN模型

```python
class GCN(nn.Module):
def __init__(self, in_size, hid_size, out_size):
super().__init__()
self.layers = nn.ModuleList()
# two-layer GCN
self.layers.append(dgl.nn.GraphConv(in_size, hid_size, activation=F.relu))
self.layers.append(dgl.nn.GraphConv(hid_size, out_size))
self.dropout = nn.Dropout(0.5)

def forward(self, g, features):
h = features
for i, layer in enumerate(self.layers):
if i != 0:
h = self.dropout(h)
h = layer(g, h)
return h' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.4.构建GCN模型'}","page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.5.训练GCN模型

```python
loss_fcn = nn.CrossEntropyLoss()
def train(graph, model, model_save_path):
optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)
model.train()
s = time.time()
load_time = time.time()
graph = dgl.add_self_loop(graph)
logits = model(graph, graph.ndata['feat'])
loss = loss_fcn(logits, graph.ndata['label'])
optimizer.zero_grad()
loss.backward()
optimizer.step()
train_time = time.time()
current_loss = float(loss)' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.5.训练GCN模型'}"
TuGraph-DB的单元测试使用的是什么框架？,"page_content='单元测试

1.简介

TuGraph单元测试采用gtest框架，可以选择一次跑全部test或者制定某些test。' metadata={'Header 1': '单元测试', 'Header 2': '1.简介'}","page_content='集成测试

2.TuGraph集成测试框架

TuGraph采用pytest框架作为自己的集成测试框架，pytest框架作为目前使用最广泛的cs端集成测试框架，以其灵活简单，容易上手，并且支持参数化的使用方式而著称，TuGraph基于pytest提供的功能，抽象出了不同的工具，通过参数来控制各个工具的处理逻辑，以方便大家进行高效的测试代码开发。  
更多pytest信息请参考官网: [https://docs.pytest.org/en/7.2.x/getting-started.html](https://docs.pytest.org/en/7.2.x/getting-started.html)' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架'}","page_content='集成测试

1.TuGraph集成测试的意义

在单元测试与功能测试中，有部分用例直接开启galaxy或statemachine来进行测试，这并不是一个完整的流程。在完整的cs架构中，用户请求是通过客户端发往服务端，网络通信是必不可少的，为了避免单元测试不完整带来的bug，针对这种情况，使用集成测试框架进行全链路的完整测试。' metadata={'Header 1': '集成测试', 'Header 2': '1.TuGraph集成测试的意义'}"
tugraph-db可以先用cypher找一个子图，然后在这个子图上跑图分析吗？例如pagerank、kcore什么的！,"page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}"
HA集群的snapshot何时删除？,"page_content='集群管理

4. 生成snapshot

出于节点启动时设置ha_snapshot_interval_s为-1以默认不打snapshot或其他原因，
当需要让某个节点手动生成snapshot时，可以使用`lgraph_peer`的`snapshot`命令。命令示例如下所示：  
```shell
$ lgraph_peer --command snapshot --peer {peer_id}
```  
其中：  
- `--command snapshot` 指定要执行的操作为snapshot，即生成快照。
- `--peer {peer_id}` 指定要生成快照的节点的rpc网络地址，如 `127.0.0.1:9092`。' metadata={'Header 1': '集群管理', 'Header 2': '4. 生成snapshot'}","page_content='数据库运行

4.服务配置

4.1.配置参数

| ha_node_remove_ms            | 整型                    | 节点被视为完全死亡并从列表中删除的间隔（以毫秒为单位）。默认值为 120000。                                                                                                                                          |
| ha_first_snapshot_start_time | 字符串                   | 第一次打快照的时间，格式为""HH:MM:SS""，表示为在下一个HH:MM:SS时间点第一次打snapshot，以后每ha_snapshot_interval_s秒打一次。默认值为""""，表示在0-ha_snapshot_interval_s内的任一时刻随机打第一次snapshot，以后每ha_snapshot_interval_s秒打一次snapshot |' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='src/server/ha_state_machine.h/ ﻿/* Copyright (c) 2022 AntGroup. All Rights Reserved. */

#pragma once
#include <chrono>
#include ""tools/lgraph_log.h""
#include ""core/global_config.h""
#include ""server/state_machine.h""

#ifndef _WIN32
#include ""braft/raft.h""
#include ""brpc/closure_guard.h""
#include ""brpc/server.h""

#include ""core/lightning_graph.h""
#include ""protobuf/ha.pb.h""

namespace lgraph {

class HaStateMachine : public StateMachine, public braft::StateMachine {
 public:
    struct Config : public ::lgraph::StateMachine::Config {
        std::string ha_conf;
        std::string ha_dir;
        int ha_election_timeout_ms = 500;
        int ha_snapshot_interval_s = 7 * 24 * 3600;
        int ha_heartbeat_interval_ms = 1000;     // send heartbeat every 1 sec
        int ha_node_offline_ms = 600 * 1000;  // node will be made offline after this period
        int ha_node_remove_ms = 1200 * 1000;  // node will be removed from peer list after 20 min
        int ha_bootstrap_role;
        int ha_node_join_group_s;
        bool ha_is_witness;
        bool ha_enable_witness_to_leader;
        std::string ha_first_snapshot_start_time = """";

        Config() {}
        explicit Config(const GlobalConfig& c) : ::lgraph::StateMachine::Config(c) {
            ha_conf = c.ha_conf;
            ha_dir = c.ha_log_dir;
            ha_election_timeout_ms = c.ha_election_timeout_ms;
            ha_snapshot_interval_s = c.ha_snapshot_interval_s;
            ha_heartbeat_interval_ms = c.ha_heartbeat_interval_ms;
            ha_node_offline_ms = c.ha_node_offline_ms;
            ha_node_remove_ms = c.ha_node_remove_ms;
            ha_bootstrap_role = c.ha_bootstrap_role;
            ha_node_join_group_s = c.ha_node_join_group_s;
            ha_is_witness = c.ha_is_witness;
            ha_enable_witness_to_leader = c.ha_enable_witness_to_leader;
            ha_first_snapshot_start_time = c.ha_first_snapshot_start_time;
        }
    };

 protected:
    braft::Node* volatile node_;
    std::atomic<int64_t> leader_term_;
    std::atomic<' metadata={'file_name': 'ha_state_machine.h', 'file_path': 'src/server/ha_state_machine.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/server/ha_state_machine.h'}"
TuGraph-DB目前支持哪种查询语言，并计划在将来支持哪种查询语言？,"page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='试用体验：TuGraph — 简单高效的图数据库

支持RESTful API

除了支持Cypher查询语言，TuGraph还提供了RESTful API接口。这使得我可以通过编程方式与图数据库进行交互，更好地将TuGraph集成到我的应用程序中。API设计合理，易于使用，为我提供了灵活性和自由度。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持RESTful API'}"
语句里面有没有开启事务和结束事务的关键字,"page_content='Cypher API

5.附录2. 内置procedures列表

5.2.内置procedures完整列表

| dbms.task.terminateTask               | 中止任务                                  | dbms.task.terminateTask(task_id::STRING)::(::VOID)                                                                                                                                      |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '5.2.内置procedures完整列表'}","page_content='src/cypher/parser/generated/LcypherLexer.h/ 
// Generated from src/cypher/grammar/Lcypher.g4 by ANTLR 4.13.0

#pragma once


#include ""antlr4-runtime.h""


namespace parser {


class  LcypherLexer : public antlr4::Lexer {
public:
  enum {
    T__0 = 1, T__1 = 2, T__2 = 3, T__3 = 4, T__4 = 5, T__5 = 6, T__6 = 7, 
    T__7 = 8, T__8 = 9, T__9 = 10, T__10 = 11, T__11 = 12, T__12 = 13, T__13 = 14, 
    T__14 = 15, T__15 = 16, T__16 = 17, T__17 = 18, T__18 = 19, T__19 = 20, 
    T__20 = 21, T__21 = 22, T__22 = 23, T__23 = 24, T__24 = 25, T__25 = 26, 
    T__26 = 27, T__27 = 28, T__28 = 29, T__29 = 30, T__30 = 31, T__31 = 32, 
    T__32 = 33, T__33 = 34, T__34 = 35, T__35 = 36, T__36 = 37, T__37 = 38, 
    T__38 = 39, T__39 = 40, T__40 = 41, T__41 = 42, T__42 = 43, T__43 = 44, 
    T__44 = 45, EXPLAIN = 46, PROFILE = 47, UNION = 48, ALL = 49, OPTIONAL_ = 50, 
    MATCH = 51, UNWIND = 52, AS = 53, MERGE = 54, ON = 55, CREATE = 56, 
    SET = 57, DETACH = 58, DELETE_ = 59, REMOVE = 60, CALL = 61, YIELD = 62, 
    WITH = 63, DISTINCT = 64, RETURN = 65, ORDER = 66, BY = 67, L_SKIP = 68, 
    LIMIT = 69, ASCENDING = 70, ASC = 71, DESCENDING = 72, DESC = 73, USING = 74, 
    JOIN = 75, START = 76, WHERE = 77, OR = 78, XOR = 79, AND = 80, NOT = 81, 
    IN = 82, STARTS = 83, ENDS = 84, CONTAINS = 85, REGEXP = 86, IS = 87, 
    NULL_ = 88, COUNT = 89, ANY = 90, NONE = 91, SINGLE = 92, TRUE_ = 93, 
    FALSE_ = 94, EXISTS = 95, CASE = 96, ELSE = 97, END = 98, WHEN = 99, 
    THEN = 100, StringLiteral = 101, EscapedChar = 102, HexInteger = 103, 
    DecimalInteger = 104, OctalInteger = 105, HexLetter = 106, HexDigit = 107, 
    Digit = 108, NonZeroDigit = 109, NonZeroOctDigit = 110, OctDigit = 111, 
    ZeroDigit = 112, ExponentDecimalReal = 113, RegularDecimalReal = 114, 
    FILTER = 115, EXTRACT = 116, UnescapedSymbolicName = 117, CONSTRAINT = 118, 
    DO = 119, FOR = 120, REQUIRE = 121, UNIQUE = 122, MANDATORY = 123, SCALAR = 124, 
    OF = 125, ADD = 126, DROP = 127, IdentifierStart = 128, IdentifierPart = 129, 
    Escaped' metadata={'file_name': 'LcypherLexer.h', 'file_path': 'src/cypher/parser/generated/LcypherLexer.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/parser/generated/LcypherLexer.h'}","page_content='src/cypher/parser/generated/LcypherParser.h/ 
// Generated from src/cypher/grammar/Lcypher.g4 by ANTLR 4.13.0

#pragma once


#include ""antlr4-runtime.h""


namespace parser {


class  LcypherParser : public antlr4::Parser {
public:
  enum {
    T__0 = 1, T__1 = 2, T__2 = 3, T__3 = 4, T__4 = 5, T__5 = 6, T__6 = 7, 
    T__7 = 8, T__8 = 9, T__9 = 10, T__10 = 11, T__11 = 12, T__12 = 13, T__13 = 14, 
    T__14 = 15, T__15 = 16, T__16 = 17, T__17 = 18, T__18 = 19, T__19 = 20, 
    T__20 = 21, T__21 = 22, T__22 = 23, T__23 = 24, T__24 = 25, T__25 = 26, 
    T__26 = 27, T__27 = 28, T__28 = 29, T__29 = 30, T__30 = 31, T__31 = 32, 
    T__32 = 33, T__33 = 34, T__34 = 35, T__35 = 36, T__36 = 37, T__37 = 38, 
    T__38 = 39, T__39 = 40, T__40 = 41, T__41 = 42, T__42 = 43, T__43 = 44, 
    T__44 = 45, EXPLAIN = 46, PROFILE = 47, UNION = 48, ALL = 49, OPTIONAL_ = 50, 
    MATCH = 51, UNWIND = 52, AS = 53, MERGE = 54, ON = 55, CREATE = 56, 
    SET = 57, DETACH = 58, DELETE_ = 59, REMOVE = 60, CALL = 61, YIELD = 62, 
    WITH = 63, DISTINCT = 64, RETURN = 65, ORDER = 66, BY = 67, L_SKIP = 68, 
    LIMIT = 69, ASCENDING = 70, ASC = 71, DESCENDING = 72, DESC = 73, USING = 74, 
    JOIN = 75, START = 76, WHERE = 77, OR = 78, XOR = 79, AND = 80, NOT = 81, 
    IN = 82, STARTS = 83, ENDS = 84, CONTAINS = 85, REGEXP = 86, IS = 87, 
    NULL_ = 88, COUNT = 89, ANY = 90, NONE = 91, SINGLE = 92, TRUE_ = 93, 
    FALSE_ = 94, EXISTS = 95, CASE = 96, ELSE = 97, END = 98, WHEN = 99, 
    THEN = 100, StringLiteral = 101, EscapedChar = 102, HexInteger = 103, 
    DecimalInteger = 104, OctalInteger = 105, HexLetter = 106, HexDigit = 107, 
    Digit = 108, NonZeroDigit = 109, NonZeroOctDigit = 110, OctDigit = 111, 
    ZeroDigit = 112, ExponentDecimalReal = 113, RegularDecimalReal = 114, 
    FILTER = 115, EXTRACT = 116, UnescapedSymbolicName = 117, CONSTRAINT = 118, 
    DO = 119, FOR = 120, REQUIRE = 121, UNIQUE = 122, MANDATORY = 123, SCALAR = 124, 
    OF = 125, ADD = 126, DROP = 127, IdentifierStart = 128, IdentifierPart = 129, 
    Esca' metadata={'file_name': 'LcypherParser.h', 'file_path': 'src/cypher/parser/generated/LcypherParser.h', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/cypher/parser/generated/LcypherParser.h'}"
如何使用命令创建一个新的角色，并为其提供描述信息？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='可视化操作手册

2.操作指南

2.5.控制台

![账户管理-删除](../../../images/browser/account-delete.png)  
##### 2.5.1.2.角色管理  
###### a.添加角色  
在`角色管理`界面点击`添加`按钮创建新的角色，用户需要输入角色名称、角色描述以及图权限。  
![角色管理-添加角色按钮](../../../images/browser/role-add-button.png)  
- 角色名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图权限：browser支持全部、读、写和无共四类图权限配置。
- 全部：对应图的读和写权限，包含编辑图模型权限（schema）。
- 读写：对应图的写权限，不包含编辑图模型权限（schema）。
- 只读：对应图的读权限。
- 无：无法访问和操作对应图。
- 角色冲突：当两个角色对同一个图有不同图权限，同时对一个账户授权了这两个角色，该账户对该图的图权限为两个角色的并集。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.5.控制台'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}"
TuGraph查询语句不支持任意长度路径吧？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属性不会存在相同的值。
由于底层存储设计，组合索引key需要保存属性的长度，因此，' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}"
如果在Java运行时，targetProject在xml配置文件中应如何配置？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}"
2024年功能更新计划中支持什么角色和工具？,"page_content='技术规划

3. 2024年功能更新

在2024年度，我们计划的功能更新包括：  
| 版本号   | 功能                 | 计划时间    |
|-------|--------------------|---------|
| 4.2.x | HA支持Witness角色和管理工具 | 2024.3  |
| 4.2.x | Bolt支持流处理和参数化查询    | 2024.3  |
| x.x.x | GeaX支持Cypher       | 2024.6  |
| x.x.x | 支持组合索引             | 2024.6  |
| x.x.x | 数据导入功能优化           | 2024.6  |
| x.x.x | 【社区功能】支持地理数据类型使用   | 2024.6  |
| x.x.x | Cypher能力提升         | 2024.9  |
| x.x.x | 支持Schema快速变更       | 2024.9  |
| x.x.x | 向量化支持              | 2024.12 |' metadata={'Header 1': '技术规划', 'Header 2': '3. 2024年功能更新'}","page_content='技术规划

3. 2024年功能更新

| x.x.x | 支持组合索引             | 2024.6  |
| x.x.x | 数据导入功能优化           | 2024.6  |
| x.x.x | 【社区功能】支持地理数据类型使用   | 2024.6  |
| x.x.x | Cypher能力提升         | 2024.9  |
| x.x.x | 支持Schema快速变更       | 2024.9  |
| x.x.x | 向量化支持              | 2024.12 |
| x.x.x | RPQ支持              | 2024.12 |
| x.x.x | 【可选】查询引擎升级         | 2024.12 |
| x.x.x | 【社区功能】支持GraphAr    | 2024.12 |' metadata={'Header 1': '技术规划', 'Header 2': '3. 2024年功能更新'}","page_content='技术规划

4. 期望社区共创的功能

| x.x.x | 属性默认值支持                 | 2024.x |
| x.x.x | Embedded TuGraph-DB最佳实践 | 2024.x |
| x.x.x | Bolt显式事务支持              | 2024.x |
| x.x.x | List、Map和Decimal等数据类型扩展 | 2024.x |
| x.x.x | 探索多存储引擎                 | 2024.x |  
一些更加简单的功能，我们会在github的issue中打上 good first issue 的标签，欢迎对图数据库感兴趣的技术爱好者共同研讨。' metadata={'Header 1': '技术规划', 'Header 2': '4. 期望社区共创的功能'}"
"调用 ""CallGql"" 接口时，如何指定要查询的图的名称？","page_content='C++客户端

2.使用示例

2.4.调用GQL

```C++
std::string str;
bool ret = client.CallGql(str,
""CALL db.createVertexLabel('actor', 'name', 'name', string, false, 'age', int8, true)"");
```
```
bool CallGql(std::string& result, const std::string& gql,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0, const std::string& url = """");
@param [out] result      The result.
@param [in]  gql         inquire statement.
@param [in]  graph       (Optional) the graph to query.' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.4.调用GQL'}","page_content='Java客户端

2.使用示例

2.5.向leader发送GQL请求

```java
String res = client.callGqlToLeader(""CALL db.edgeLabels()"", ""default"", 10);
log.info(""db.edgeLabels() : "" + res);
```
```
@param gql: inquire statement.
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of cypher query execution
public String callGqlToLeader(String cypher, String graph, double timeout)
```
本接口只支持在HA模式下使用，在HA模式下的client中，为防止向未同步数据的follower发送请求，
用户可以直接向leader发送请求，leader由集群选出。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.5.向leader发送GQL请求'}","page_content='C++客户端

2.使用示例

2.5.向leader发送GQL请求

```C++
std::string str;
bool ret = client.CallGqlToLeader(str,
""CALL db.createVertexLabel('actor', 'name', 'name', string, false, 'age', int8, true)"");
```
```
bool CallGqlToLeader(std::string& result, const std::string& gql,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0);
@param [out] result      The result.
@param [in]  gql         inquire statement.
@param [in]  graph       (Optional) the graph to query.' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.5.向leader发送GQL请求'}"
图中能把属性值展示出来吗？,"page_content='可视化操作手册

2.操作指南

2.4.图项目

##### 2.4.4.4.属性筛选  
在`操作栏`区域点击`筛选`按钮，在`左边栏`点击`属性筛选`进行筛选过滤。用户可以选择要筛选的点或边类型，以及对应的属性值进行设置，检索到筛选组条件的数据后会在画布上高亮选中对应的点或边数据。
- 请选择点/边类型：选择需要检索的点类型或边类型。
- 属性条件：设置需要检索的属性条件，可以设置多组，取并集筛选结果。
- 添加筛选组：可以多组筛选条件，取并集筛选结果。
- 重置：可以清空筛选条件。  
![图分析-筛选-属性筛选](../../../images/browser/graphanalysis-queryfilter-attributefilter.png)  
##### 2.4.4.5.统计筛选  
在`操作栏`区域点击`筛选`按钮，在`左边栏`点击`统计筛选`进行画布数据统计。用户可以选择要统计的点或边类型，以及对应的属性值进行设置，系统会自动根据用户选择的点/边类型和属性进行分组统计，支持按照图表和列表两种方式展示结果，同时点击图表或列表区域的数值可以高亮选中画布中的数据。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

##### 2.4.4.5.统计筛选  
在`操作栏`区域点击`筛选`按钮，在`左边栏`点击`统计筛选`进行画布数据统计。用户可以选择要统计的点或边类型，以及对应的属性值进行设置，系统会自动根据用户选择的点/边类型和属性进行分组统计，支持按照图表和列表两种方式展示结果，同时点击图表或列表区域的数值可以高亮选中画布中的数据。  
![图分析-筛选-统计筛选](../../../images/browser/graphanalysis-queryfilter-statisticalfilter.png)
![图分析-统计筛选-图表切换](../../../images/browser/graphanalysis-queryfilter-statisticalfilter-chartswitch.png)  
##### 2.4.4.6.点边布局' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

###### c.插入数据  
Browser提供可视化方式在对应图项目中插入点或边数据。点击`插入数据`按钮，在`插入数据`页签选择点类型或边类型，输入属性值，点击确定完成数据插入。  
![插入数据-按钮](../../../images/browser/query-result-insert-button.png)  
![插入数据](../../../images/browser/query-result-insert.png)  
###### d.下载执行结果  
Browser提供图查询结果导出成文本文件功能。点击`下载执行结果`按钮，系统会自动将结果保存成文本文件并下载至本地。  
![下载执行结果-按钮](../../../images/browser/query-result-download.png)
![下载执行结果-按钮](../../../images/browser/query-result-downloadtxt.png)  
###### e.全屏展示' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}"
tugraph-db如何与neo4j驱动连接？,"page_content='业务开发指南

连接tugraph-db

驱动连接

tugraph-db兼容neo4j的通讯协议，因此可以使用neo4j的驱动连接tugraph-db的server。  
[bolt driver 使用介绍](./7.client-tools/5.bolt-client.md)  
[bolt driver 使用例子](https://github.com/TuGraph-family/tugraph-db/tree/master/demo/Bolt)' metadata={'Header 1': '业务开发指南', 'Header 2': '连接tugraph-db', 'Header 3': '驱动连接'}","page_content='图数据库智能化建设与探索

**02\. 技术分享｜TuGraph-DB兼容Neo4j客户端：Bolt协议设计与实现**

“兼容Neo4j客户端的最大优势在于生态支持。以客户端为例，Neo4j官方自身支持五种编程语言的客户端，社区又贡献了两种，共计七种语言的客户端得以直接使用。此外，还有一系列与上下游生态相接的组件，如与Apache Spark或Apache Kafka的连接，都有现成的代码可供利用。在编程框架方面，特别是Java，例如OGM（Object-Graph Mapping，对象图映射）以及一些业务开发框架，如Spring，这些所需的相关代码都已现成，无需重新编写。这种做法极大地节约了研发资源，我们可以将这些资源重新投入到提升数据库本身能力上。”' metadata={'Header 1': '图数据库智能化建设与探索', 'Header 2': '**02\\. 技术分享｜TuGraph-DB兼容Neo4j客户端：Bolt协议设计与实现**'}","page_content='QA汇总

数据导入QA

数据导出到csv

Q：怎么把存储于tugraph的某些指定的点/边类型的全量数据，导出到csv文件中？
A：使用neo4j driver 连接tugraph，直接发送cypher 语句 ""match (n) return n"" 就可以了。结果是流式返回的，不管多少数据都可以读出来，不会引发内存oom' metadata={'Header 1': 'QA汇总', 'Header 2': '数据导入QA', 'Header 3': '数据导出到csv'}"
图模型中某些边设置了属性，这些有属性的边在导入数据之后进行查询，发现查不到这些边数据,"page_content='性能优先

4.数据编码

对于属性图模型而言，除了图拓扑编码外，属性数据也会很大程度影响功能和性能，我们先讨论属性数据如何与拓扑数据共存的编码格式。从目前的调研来看，属性编码有两种方式，我们称之为基于指针索引将属性数据单独存储的离散编码，和将属性数据和拓扑数据打包在一起的紧凑编码。离散编码根据程度的不同，可以每个属性都单独存储，或者每条边的属性打包后各自存储，下面的讨论对两种情况都适用。  
点查询。属性编码主要针对边，不涉及点查询。  
单边查询。离散编码通过指针定位边，紧凑编码则需要二分查找定位边的位置，离散编码有略微的优势。  
边遍历。离散编码在边遍历过程需要不断地进行指针跳转进行随机数据访问，而紧凑编码提前把数据排列在一起，顺序访问的特性使得效率大大提升。 由规律三知对边的遍历操作很普遍，紧凑编码在边遍历的优势明显。  
单边更新。离散编码对边的更新仅需找到对应的指针位置，插入数据后修改前后指针指向。紧凑编码则需要对紧凑排列的数据进行重编码，对整个边值进行重新写入，开销显著大于离散编码的情形。' metadata={'Header 1': '性能优先', 'Header 2': '4.数据编码'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

###### c.数据映射  
文件上传成功后，需要在`数据导入`页面设置`数据对应表`，将数据文件中的数据列和目标点/边、对应属性建立映射关系。  
- 数据对应表：展示已经上传的数据问题。
- 文件名称：上传的数据文件名称。
- 文件大小：上传的数据文件大小。
- 读取结果：数据文件上传结果，success为读取成功。
- 删除：在页面中删除，不会删除本地文件。
- 数据文件映射：每个已上传的数据文件都需要配置映射关系。
- 标签：选择该文件对应的点或边类型，只能选择一类点或一类边。
- 从第N行，开始：从第N行开始读取数据，系统默认从第0行开始读取数据，如需跳过表头可输入1。
- 属性映射：下拉选择数据列对应的属性字段。
- 数据预览：系统会预读数据文件的前5行。  
![数据导入-数据映射](../../../images/browser/graphbuild-import-datamapping.png)  
文件上传成功后，可以点击`继续导入`按钮继续导入其他数据，或者点击`前往图查询`按钮在`图查询`页面查询已导入的数据。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}"
"在""TuGraph-DataX""项目中如何通过job配置文件将""actors.csv""导入到TuGraph？","page_content='TuGraph-DataX

3. 导入TuGraph

3.1.文本数据通过DataX导入TuGraph

tt0286112,Shaolin Soccer,2001,7.3
tt4701660,The Mermaid,2016,6.3
```  
`roles.csv`  
```
nm015950,Tianchou Yin,tt0188766
nm015950,Steel Leg,tt0286112
nm0628806,,tt0188766
nm0628806,coach,tt0286112
nm0156444,PiaoPiao Liu,tt0188766
nm2514879,Ruolan Li,tt4701660
```  
然后建三个 DataX 的 job 配置文件：
`job_actors.json`  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"": 1
}
},
""content"": [
{
""reader"": {
""name"": ""txtfilereader"",
""parameter"": {
""path"": [""actors.csv""],' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '3. 导入TuGraph', 'Header 3': '3.1.文本数据通过DataX导入TuGraph'}","page_content='TuGraph-DataX

3. 导入TuGraph

3.1.文本数据通过DataX导入TuGraph

nm2514879,Ruolan Li,tt4701660
```  
然后建三个 DataX 的 job 配置文件：
`job_actors.json`  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"": 1
}
},
""content"": [
{
""reader"": {
""name"": ""txtfilereader"",
""parameter"": {
""path"": [""actors.csv""],
""encoding"": ""UTF-8"",
""column"": [
{
""index"": 0,
""type"": ""string""
},
{
""index"": 1,
""type"": ""string""
}
],
""fieldDelimiter"": "",""
}
},
""writer"": {
""name"": ""tugraphwriter"",
""parameter"": {
""url"": ""bolt://127.0.0.1:27687"",
""username"": ""admin"",' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '3. 导入TuGraph', 'Header 3': '3.1.文本数据通过DataX导入TuGraph'}","page_content='数据导入

3.配置文件

3.2.配置文件示例

还描述了三个数据文件，两个点的数据文件`actors.csv`和`movies.csv`，一个边的数据文件`roles.csv`。每个部分都描述了：文件的路径（path）、数据类型（format）、信息头占开头几行（header）、是哪个 label 的数据（label）、文件中每行数据中的每个列对应的字段是哪个。  
对于上述配置文件，import 工具在执行的过程中会先在 TuGraph 中创建`actor`、`movie`、`role`这三个 label，然后再执行三个文件的数据导入。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.2.配置文件示例'}"
创建新子图时需要哪些参数？,"page_content='Cypher API

5.附录2. 内置procedures列表

* dbms.graph.createGraph(graph_name, description, max_size_GB)

create a new subgraph in this graph database .  
**Parameters:**  
| parameter   | parameter type | description              |
| ----------- | -------------- | -------------------------------- |
| graph_name  | string     | the name of new subgraph     |
| description | string     | description of new subgraph      |
| max_size_GB | integer    | Upper limit of subgraph capacity |  
**Output:**  
if successful , it will return true.  
**Example input:**  
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* dbms.graph.createGraph(graph_name, description, max_size_GB)'}","page_content='可视化操作手册（旧版）

操作详情

3.工作台

- 然后点击“一键创建模型”——>""一键创建数据""，就可以完成内置的 Movie 数据图谱的构建  
#### 3.2 创建子图和示例  
##### 3.2.1 创建子图  
- 点击新建子图
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/4.tugraph-browser-create-subgraph-01.png)
- 填写表单信息
![alt 填写表单](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/5.tugraph-browser-create-subgraph-02.png)
- 子图名称
- 子图描述
- 配置信息
- 点击确认，提示创建成功
- 切换子图' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '3.工作台'}","page_content='RESTful API Legacy

6.Deprecated

6.5.子图管理

TuGraph 支持多子图，子图之间完全独立，不同的子图可以对不同用户开放不同权限。管理员可以添加和删除子图。  
#### 6.5.1.创建新子图  
- **URI**: `/db`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | 子图名 | 字符串 |
| config | 配置 | 字典，格式为 { {列名 1}:{列值 1},... } |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""name"":""graph1"",
""config"" : {
""max_size_GB"":2048,' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.5.子图管理'}"
在test_export_default函数中，如何验证导出后再次导入的数据是否与原始数据一致？,"page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb1 --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7073 --rpc_port 9093"",
""cleanup_dir"":[""./testdb1""]}' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}","page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

ret = client.callCypher(""MATCH (n) RETURN n LIMIT 100"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert len(res) == 21
ret = client.callCypher(""CALL db.flushDB()"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```python' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}","page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_export_default(self, importor, exportor, importor_1, server, client):
ret = client.callCypher(""MATCH (n) RETURN n LIMIT 100"", ""default"")
assert ret[0]
res = json.loads(ret[1])
log.info(""res : %s"", res)
assert len(res) == 21
```  
#### 2.3.4.其他测试' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}"
Work函数在处理节点vi时，返回值代表什么？,"page_content='OlapBase API

7. 图类OlapBase

7.4 批处理操作

函数用途:对active_vertices中对应为1的节点执行work函数，第三个参数表示累加的基数，默认为0；
第四个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考/include/lgraph/olap_base.h中具体代码

使用示例:输出Graph中节点1，2，3的所有出度邻居，并统计这三个节点的总出度
*/' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.4 批处理操作'}","page_content='Python Olap API

4. Olap API

图类OlapBase

```python
# 函数名称:ProcessVertexInRange[ReducedSum, Algorithm](
#           work: (algo: Algorithm, vi: size_t)-> ReducedSum,
#           lower: size_t, upper: size_t,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#     函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
#     第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}","page_content='OlapOnDB API

3. 算法举例

3.1 主函数

auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
/*
函数用途：从所有节点中获取pagerank值最大的节点编号

函数流程描述：该函数对点集合all_vertices中所有为1的位对应的节点vi（又称为活跃点）执行Func A，再将Func A的返回值作为Func B的第二个输入参数，得到局部最大值（因为第一个输入参数为0，因此实际上返回值就是每个节点的pagerank值），最后再将所有线程的返回值汇总，再次 执行Func B得到全局返回值，并存入max_pr_vi变量中
*/
size_t max_pr_vi = olapondb.ProcessVertexActive<size_t>(

//Func A
[&](size_t vi) {
return vi;
},
all_vertices,
0,

//Func B
[&](size_t a, size_t b) {
return pr[a] > pr[b] ? a : b;
}
);' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.1 主函数'}"
TuGraph Explorer 的功能现在在哪里可以找到？,"page_content='功能概览

6.生态工具

6.2.可视化交互

TuGraph Browser 是面向图数据库直接使用者的可视化交互界面，功能上覆盖了 TuGraph 的绝大部分能力，包括数据导入、图模型建立、数据增删查改、监控运维等操作链路。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.2.可视化交互'}","page_content='可视化操作手册（旧版）

作用

TuGraph Browser 的主要功能是为使用图数据库的开发人员，提供可视化的图数据开发，图数据管理和维护等功能。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '作用'}","page_content='可视化操作手册（旧版）

操作详情

3.工作台

##### 3.3.6 帮助  
- 其中记录了 TuGraph-browser 的使用方式
![alt 查询](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/16.TuGraph-browser-help.png)  
#### 3.4 控制台  
##### 3.4.1 数据库基础信息  
- 展示数据库相关的基础配置信息
![alt 查询](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/17.tugraph-browser-config.png)  
##### 3.4.2 权限管理  
- 用来创建用户和角色的功能模块，用户可以在这里进行权限的管理操作' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '3.工作台'}"
在批量创建点的操作中，如果请求成功，TuGraph 会返回什么？,"page_content='RESTful API Legacy

2.请求与数据格式

2.3.返回值

TuGraph 返回的 HTTP 状态码包含以下四种：  
- 200 OK: 操作成功
- 307 Temporary Redirect: 操作被重定向，一般用于高可用模式下，把操作重定向到 master 上
- 400 Bad Request: 输入有误，例如 URI 错误，或者请求中的 JSON 参数错误
- 500 Internal Server Error: 服务器端错误  
当操作成功时，返回的 JSON 中包含操作的返回值。当操作重定向时，返回的 HTTP 报头中的 `location` 域包含重定向目的地址。
当发生输入错误或者服务器错误时，返回的 JSON 中包含 `error_message` 域，其内容是错误提示。  
在高可用模式下，服务器还会在报头中设置 `server_version`，以告知客户端当前服务器的数据版本号。当客户端在不同的服务器之间切换时，该数据版本号可以保证客户端不会读到错误的历史数据。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '2.请求与数据格式', 'Header 3': '2.3.返回值'}","page_content='TuGraph-Restful-Server

5.返回值

通用返回格式  
|  body参数  | 参数说明  |  参数类型  |  是否必填  |
|:--------:|:-----:|:------:| :-----: |
| errorCode |  状态码  |  字符串  |  是  |
| errorMessage | 错误信息  |  字符串  |  是  |
| data | 返回的数据 |  字符串  |  是  |  
TuGraph 返回的 HTTP 状态码包含以下四种：  
- 200 OK: 操作成功
- 400 Bad Request: 输入有误，例如 URI 错误，或者请求中的 JSON 参数错误
- 401 Unauthorized: 未通过鉴权认证，例如用户名密码错误，token超过有效期等
- 500 Internal Server Error: 服务器端错误
当操作成功时，返回的 data 中包含操作的返回值。
当发生输入错误或者服务器错误时，返回的 errorMessage 中包含错误提示。' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '5.返回值'}","page_content='TuGraph-Restful-Server

7.接口

7.7 批量创建schema请求

用户通过此类请求批量创建schema，请求报文在http body 中将创建schema的目标子图和schema信息发送给server，如果拿到返回errorCode为200的响应报文即为正常创建
#### 7.7.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_schema
#### 7.7.2 REQUEST
|  body参数  |    参数说明    |  参数类型  |  是否必填  |
|:--------:|:----------:|:------:| :-----: |
| graph |   创建目标子图   |  字符串  |  是  |
| schema | schema描述信息 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.7 批量创建schema请求'}"
tugraph能否支持混合检索 vector+知识图谱？,"page_content='QA汇总

内核引擎QA

边支持索引

Q: TuGraph 的边是否支持索引？
A: TuGraph 在引擎层支持边索引，可通过存储过程使用。Cypher的边索引功能正在开发支持中。' metadata={'Header 1': 'QA汇总', 'Header 2': '内核引擎QA', 'Header 3': '边支持索引'}","page_content='试用体验：TuGraph — 简单高效的图数据库

支持RESTful API

除了支持Cypher查询语言，TuGraph还提供了RESTful API接口。这使得我可以通过编程方式与图数据库进行交互，更好地将TuGraph集成到我的应用程序中。API设计合理，易于使用，为我提供了灵活性和自由度。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持RESTful API'}","page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}"
TuGraph 数据预热的主要目的是什么？,"page_content='数据预热

1.简介

TuGraph 是基于磁盘的数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '数据预热', 'Header 2': '1.简介'}","page_content='功能概览

4.核心功能

4.5 数据预热

TuGraph 是基于磁盘的图数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.5 数据预热'}","page_content='数据预热

1.数据预热命令

数据预热可以通过工具 `lgraph_warmup` 来进行。它的使用示例如下：  
```bash
$ lgraph_warmup -d {directory} -g {graph_list}
```  
其中：  
- `-d {db_dir}` 选项指定了 TuGraph 服务器的数据目录  
- `-g {graph_list}` 选项指定需要进行数据预热的图名称，用逗号分隔  
根据数据大小和所使用的磁盘类型不同，预热过程运行时间也不同。机械磁盘上预热一个大数据库可能耗时较长，请耐心等待。' metadata={'Header 1': '数据预热', 'Header 2': '1.数据预热命令'}"
InEdgeIterator 类的 GetSrc 方法返回什么信息？,"page_content='OlapOnDB API

4. 其他常用函数功能描述

4.7 获取入边集合

```C++
AdjList<EdgeData> InEdges(size_t vid)

// 使用示例：输出节点vid的所有入度邻居
for (auto & edge : olapondb.InEdges(vid)) {
size_t dst = edge.neighbour;
printf(""src = %lu,dst = %lu\n"",vid,dst);
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.7 获取入边集合'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

```c
ParallelVector<size_t> & GetFrontier();
```  
当前点集合的扩展结束后，新的点集合可以通过上述方法取得。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &, Path &, IteratorHelper &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &, Path &, IteratorHelper &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &, Path &, IteratorHelper &)> in_edge_filter = nullptr,' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='src/lucene/src/main/java/ScoreEdgeUid.java/ public class ScoreEdgeUid {
    public float score;
    public long srcId;
    public long destId;
    public int labelId;
    public int edgeId;
    public String toString() {
        return ""srcId: "" + this.srcId +
                "", destId:"" + this.destId +
                "", labelId:"" + this.labelId +
                "", edgeId:"" + this.edgeId +
                "", score:"" + this.score;
    }
}
' metadata={'file_name': 'ScoreEdgeUid.java', 'file_path': 'src/lucene/src/main/java/ScoreEdgeUid.java', 'url': 'https://github.com/Sun-HR02/tugraph-db/blob/master/src/lucene/src/main/java/ScoreEdgeUid.java'}"
可选匹配子句OPTIONAL MATCH在查询中有什么作用？,"page_content='ISO GQL

2.Clauses

2.2.OPTIONAL MATCH

`OPTIONAL MATCH`匹配图模式，如果未命中，则返回`null`。  
#### 查询命中  
```
OPTIONAL MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
#### 查询未命中  
```
OPTIONAL MATCH (n:Person{name:'Redgrave Michael'})
RETURN n.birthyear
```  
返回结果  
```JSON
[{""n.birthyear"":null}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.2.OPTIONAL MATCH'}","page_content='ISO GQL

2.Clauses

2.1.MATCH

`MATCH`子句式是GQL最基础的子句，几乎所有查询都是通过 `MATCH`展开。  
`MATCH`子句用于指定在图中搜索的匹配模式，用来匹配满足一定条件的点或者路径。  
#### 点查询  
##### 查询所有点  
```
MATCH (n)
RETURN n
```  
##### 查询特定标签的点  
```
MATCH (n:Person)
RETURN n
```  
##### 通过属性匹配点  
```
MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
##### 通过过滤条件匹配点  
```
MATCH (n:Person WHERE n.birthyear > 1910)
RETURN n.name LIMIT 2
```  
返回结果
```JSON' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.1.MATCH'}","page_content='Cypher API

2.Clauses

2.1.Summary

|                         | OPTIONAL MATCH                        | 支持   |
|                         | MANDATORY MATCH                       | 待支持 |
| Projecting clauses      | RETURN … [AS]                        | 支持   |
|                         | WITH … [AS]                          | 支持   |
|                         | UNWIND … [AS]                        | 支持   |
| Reading sub-clauses     | WHERE                                 | 支持   |' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.1.Summary'}"
GraphDB 实例无法使用的情况是什么？,"page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

一、高可用架构介绍

2.高可用性代表系统的可用性程度，是进行系统设计时的准则之一

怎样去衡量系统的可用性和不可用性呢？这就引出了高可用性的概念。高可用性代表系统的可用性程度，是进行系统设计的准则之一。高可用性，是系统的一个非常重要的能力，通常是通过提高系统的容错能力来实现的。可用性的一个度量方式是根据系统损毁无法提供服务的时间和系统正常运行时间的比值来得到的。下图右侧表格展示了衡量一个系统可用性和不可用性的等级。  
TuGraph-DB 对于可用性的要求，至少是 4 个 9 级别，也就是一年之内宕机时间不能超过 53 分钟。我们在开源之前服务的一个银行用户就已经达到了一个极高可用的等级，也就是 5 个 9 的等级。' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '一、高可用架构介绍', 'Header 3': '2.高可用性代表系统的可用性程度，是进行系统设计时的准则之一'}","page_content='数据库运行

3.服务操作

3.2.停止服务

user@host:~/tugraph$ cat ./lgraph.pid
93

user@host:~/tugraph$ ./lgraph_server -d stop -c lgraph.json
20200508122334.857: Stopping lgraph...
20200508122334.857: Process stopped.
```' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.2.停止服务'}","page_content='Python Olap API

5. lgraph_db API

GraphDB：

- `CreateReadTxn()-> Transaction`: 创建只读事务
- `CreateWriteTxn()-> Transaction`: 创建写事务
- `ForkTxn(txn: Transaction)-> Transaction`: 复制事务，只能复制读事务' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'GraphDB：'}"
TuGraph 运行需要保证哪个库文件的位置在环境变量 LD_LIBRARY_PATH 中？,"page_content='数据库运行

1.前置条件

TuGraph 运行的前置条件为 TuGraph 正确安装，参考[安装流程](1.environment.md)。  
TuGraph 运行需要保证库文件 liblgraph.so 的文件位置在环境变量 LD_LIBRARY_PATH。  
运行 TuGraph 进程的用户不需要超级权限，但需要对配置文件（一般为lgraph.json）及文件中涉及的文件有读权限，并且对数据文件夹、日志文件夹等有写权限。' metadata={'Header 1': '数据库运行', 'Header 2': '1.前置条件'}","page_content='环境分类

2.依赖系统库

针对三种环境，除去TuGraph的运行包，所需要的系统库如下：
* 编译环境，包括gcc、python、java等编译器，也包含antlr4、pybind11等，具体参见tugraph-db源码目录 ci/images/tugraph-compile-*-Dockerfile。
* 运行环境，主要由存储过程引入，包括gcc、boost、cmake等，具体参见tugraph-db源码目录 ci/images/tugraph-runtime-*-Dockerfile。
* 精简运行环境，无，可以参见tugraph-db源码目录 ci/images/ tugraph-mini-runtime-*-Dockerfile。' metadata={'Header 1': '环境分类', 'Header 2': '2.依赖系统库'}","page_content='环境分类

1.分类

根据环境所承载功能的不同，区分为编译环境，运行环境，以及精简运行环境。
* 编译环境，具备TuGraph编译的所有依赖库，包含运行环境的所有依赖，并且能够编译TuGraph源码，但不包含预编译好的TuGraph可执行文件和库文件，供开发者编译源码使用。
* 运行环境，具备GCC/Java/Python环境，能够运行TuGraph的所有功能，并且能承载全文索引，java client，c++源码上传为plugin，以及python plugin的完整功能，内置TuGraph预编译好的可执行文件和库文件，供客户直接安装使用，无需编译源码。
* 精简运行环境，约等于裸系统加预编译TuGraph，仅能运行TuGraph的基本功能，无C++ plugin编译运行，仅so上传，无全文索引，无python plugin，供快速搭建试用。  
TuGraph编译后，会把所有的依赖库以.a的形式打包在一起，因此原则上运行不需要的其他的依赖库。但TuGraph支持存储过程，即在服务端编译C++代码，因此在环境中依然需要涉及的编译器。' metadata={'Header 1': '环境分类', 'Header 2': '1.分类'}"
GetNumOutEdges函数如何在达到限制时响应？,"page_content='OlapBase API

7. 图类OlapBase

7.1 基本信息

- `size_t NumVertices()`：获取点数
- `size_t NumEdges()`：获取边数
- `size_t OutDegree(size_t vid)`：点vid的出度
- `size_t InDegree(size_t vid)`：点vid的入度' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.1 基本信息'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}","page_content='C++客户端

2.使用示例

2.14.从文件中导入点边数据

@param [in]  thread_nums         (Optional) maximum number of threads.
@param [in]  skip_packages       (Optional) skip packages number.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  timeout             (Optional) Maximum execution time, overruns will be
interrupted.
@returns True if it succeeds, false if it fails.
```' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.14.从文件中导入点边数据'}"
文本中的 BFS 算法在每次迭代中怎样更新活跃顶点数量？,"page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

active_out.Clear();
num_activations = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t num_activations = 0;
for (auto& edge : graph.OutEdges(vi)) {   //每一次循环从根节点出发，查找邻近的相邻节点，对其parent值改变，并num_activations+1操作
size_t dst = edge.neighbour;
if (parent[dst] == (size_t)-1) {
auto lock = graph.GuardVertexLock(dst);
if (parent[dst] == (size_t)-1) {
parent[dst] = vi;
num_activations += 1;
active_out.Add(dst);       //存放当前循环阶段找到的节点
}
}
}
return num_activations;
},
active_in);' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}","page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

for (int ii = 0; num_activations != 0; ii++) {       //num_activations表示当前循环阶段找到的节点个数
printf(""activates(%d) <= %lu\n"", ii, num_activations);
discovered_vertices += num_activations;         //discovered_vertices表示当前循环阶段找到节点的总个数
active_out.Clear();
num_activations = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t num_activations = 0;
for (auto& edge : graph.OutEdges(vi)) {   //每一次循环从根节点出发，查找邻近的相邻节点，对其parent值改变，并num_activations+1操作
size_t dst = edge.neighbour;' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}","page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

if (parent[dst] == (size_t)-1) {
auto lock = graph.GuardVertexLock(dst);
if (parent[dst] == (size_t)-1) {
parent[dst] = vi;
num_activations += 1;
active_out.Add(dst);       //存放当前循环阶段找到的节点
}
}
}
return num_activations;
},
active_in);
active_in.Swap(active_out);
}
// 返回全部节点数
return discovered_vertices;
}
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}"
角色名的允许的最大长度是多少字节？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}"
URIs 用于修改和启用角色的 HTTP 方法是什么？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.7.启用角色  
启用一个被禁用的角色。  
- **URI**: `/role/{role_name}/enable`
- **METHOD**: POST
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/enable
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}"
