Q,K1,K2,K3
在添加边时，如果指定的值不包含在value_dict中将如何处理？,"page_content='业务开发指南

边类型操作

边类型添加字段

>该操作会同步变更所有该类型边的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于边类型`edge1`，一次添加了两个字段: `field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是`0`.
```
CALL db.alterLabelAddFields('edge', 'edge1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型添加字段'}","page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}","page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}"
在使用LIMIT子句时，如果查询数据库中前两个人的名字，返回的名字是什么？,"page_content='ISO GQL

2.Clauses

2.8.LIMIT

`LIMIT`限制结果行数。  
#### 使用LIMIT  
```
MATCH (n:Person)
RETURN n.name LIMIT 2;
```  
返回结果
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.8.LIMIT'}","page_content='Cypher API

2.Clauses

2.6.LIMIT

- ✓ Return a subset of the records  
```
MATCH (n:person)
RETURN n.name
LIMIT 3
```  
- ❏ Using an expression with LIMIT to return a subset of the records  
```
MATCH (n:person)
RETURN n.name
LIMIT toInteger(3 * rand())+ 1
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.6.LIMIT'}","page_content='Cypher API

2.Clauses

2.5.SKIP

- ✓ Skip first three records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 3
```  
- ✓ Return middle two records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 1
LIMIT 2
```  
- ❏ Using an expression with SKIP to return a subset of the records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP toInteger(3*rand())+ 1
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.5.SKIP'}"
如何查询数据库中现有角色及其相关信息？,"page_content='可视化操作手册

2.操作指南

2.5.控制台

`控制台`提供可视化的的账户管理和数据库信息查看功能，它为用户提供了全面的账户和角色管理功能，包括账户的增删改查以及禁用，角色的增删改查以及禁用。此外，它也为用户提供了便捷的数据库信息查看功能，让用户可以轻松地查看图数据库的基础信息和配置信息。其中，基础信息主要包括版本号、运行时间、CPP编译版本号等，而数据库配置信息则包括端口号、系统功能参数配置等。  
#### 2.5.1.账户管理  
##### 2.5.1.1.账户管理  
###### a.添加账户  
在`账户管理`界面点击`添加`按钮创建新的账户，用户需要输入账户名称、账户描述、账户密码以及相关角色。  
![账户管理-添加账户按钮](../../../images/browser/account-add-button.png)  
- 账户名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 相关角色：新建账户时必须要选择一个角色，在账户添加成功后，系统会自动生成一个与账户名称一样的角色。  
![账户管理-添加账户](../../../images/browser/account-add.png)  
###### b.编辑账户  
在`账户管理`界面点击`添加`按钮创建新的账户，用户可以编辑账户描述、账户密码以及相关角色。  
![账户管理-编辑账户](../../../images/browser/account-edit.png)  
###### c.禁用账户  
在`账户管理`界面点击`禁用`按钮禁止对应的账户登录和访问，点击`启用`按钮开启对应的账户登录和访问权限。  
![账户管理-禁用](../../../images/browser/account-disable.png)
![账户管理-启用](../../../images/browser/account-enable.png)  
###### d.删除账户  
在`账户管理`界面点击`删除`按钮删除对应的账户。  
![账户管理-删除](../../../images/browser/account-delete.png)  
##### 2.5.1.2.角色管理  
###### a.添加角色  
在`角色管理`界面点击`添加`按钮创建新的角色，用户需要输入角色名称、角色描述以及图权限。  
![角色管理-添加角色按钮](../../../images/browser/role-add-button.png)  
- 角色名称：支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图权限：browser支持全部、读、写和无共四类图权限配置。
- 全部：对应图的读和写权限，包含编辑图模型权限（schema）。
- 读写：对应图的写权限，不包含编辑图模型权限（schema）。
- 只读：对应图的读权限。
- 无：无法访问和操作对应图。
- 角色冲突：当两个角色对同一个图有不同图权限，同时对一个账户授权了这两个角色，该账户对该图的图权限为两个角色的并集。  
![角色管理-添加角色](../../../images/browser/role-add.png)  
###### b.编辑角色  
在`角色管理`界面点击`编辑`按钮编辑已有角色，用户可以编辑角色描述以及图权限。  
![角色管理-编辑角色](../../../images/browser/role-edit.png)  
###### c.禁用角色  
在`角色管理`界面点击`禁用`按钮禁止对应的角色，点击`启用`按钮开启对应的角色。禁用角色后，对应角色图访问权限失效。  
- 禁用角色：禁用之后，对应角色图访问权限失效。
- 当一个用户拥有两个角色对同一个图有操作权限时，当禁用其中一个角色时，另一个角色权限同样有效。  
![角色管理-禁用](../../../images/browser/role-disable.png)
![角色管理-启用](../../../images/browser/role-enable.png)  
###### d.删除角色  
在`角色管理`界面点击`删除`按钮删除对应的角色。  
![角色管理-删除](../../../images/browser/role-delete.png)  
#### 2.5.2.数据库信息  
##### 2.5.2.1.基础信息  
`基础信息`获取当前系统运行的状态，并展示关键信息。  
![数据库信息-基础信息](../../../images/browser/db_basic.png)  
|参数    |含义    |
|-------|--------|
|TuG' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.5.控制台'}","page_content='部署高可用模式

9.查看服务器状态

备份组的当前状态可以在 TuGraph 可视化工具、REST API 以及 Cypher 查询中获取。  
在 TuGraph 可视化工具中，可以在 DBInfo 部分中找到备份组中的服务器及其角色列表。  
使用 REST API 时，可以使用`GET /info/peers` 请求获取信息。  
在 Cypher 中，使用`CALL dbms.listServers()`语句来查询当前备份组的状态信息。' metadata={'Header 1': '部署高可用模式', 'Header 2': '9.查看服务器状态'}","page_content='场景：影视

2.查询示例

2.1.示例一

查询影片 'Forrest Gump' 的所有演员，返回影片和演员构成的子图。  
```
MATCH (m:movie {title: 'Forrest Gump'})<-[:acted_in]-(a:person) RETURN a, m
```' metadata={'Header 1': '场景：影视', 'Header 2': '2.查询示例', 'Header 3': '2.1.示例一'}"
tugraph可以最多创建多少点边和点边上最多创建多少属性？,"page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='TuGraph图模型说明

2. 图项目、点、边、属性命名规则和建议

2.2 使用限制

|**描述**|**最大个数**|
|-------- |--------- |
|用户数、角色数|65536|
|图项目的个数|4096|
|每个图项目的点和边类型数量之和|4096|
|每个点或边类型的属性数量|1024|  
注：
1、特殊字符和关键字说明：使用特殊字符或非保留关键字时，需要使用反单引号/backquote（``）进行引用；  
示例： ```match (`match`:match) return `match`.id limit 1```  
2、大小写敏感性：TuGraph大小写敏感；  
3、图项目、点/边、属性名称之间可以重复使用，同一点或边下的属性名称不可以重复；  
4、属性名字保留关键字：SRC_ID / DST_ID / SKIP' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '2. 图项目、点、边、属性命名规则和建议', 'Header 3': '2.2 使用限制'}","page_content='TuGraph图模型说明

2. 图项目、点、边、属性命名规则和建议

2.1 命名规则

图项目、点、边和属性是识别符。该节描述了在TuGraph中识别符的允许的语法。
下面的表描述了每类识别符的最大长度和允许的字符。  
|**识别符** |**长度** |**允许的字符**|
|---------  |---------  |---------  |
|用户、角色、图项目|1-64字符|允许中文、字母、数字、下划线，且首字符不为数字|
|点类型、边类型、属性|1~256字符|允许中文、字母、数字、下划线，且首字符不为数字|' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '2. 图项目、点、边、属性命名规则和建议', 'Header 3': '2.1 命名规则'}"
我下载了4.3.2镜像，启动成功了，进入容器后没有 setup.sh 脚本是改变目录了吗？,"page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}","page_content='快速上手

2.安装

2.2.新旧前端说明

进入容器，可以通过修改配置文件""/usr/local/etc/lgraph.json""中的""web""参数来选择使用老版本或新版本的前端。对于老版本，可以将""web""的值设为""/usr/local/share/lgraph/resource""；对于新版本，可以将""web""的值设为""/usr/local/share/lgraph/browser-resource""。完成配置文件的修改后，请执行命令 `docker restart tugraph` 以使更改生效。需要注意的是，新版本是默认选项。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.2.新旧前端说明'}","page_content='文档地图

TuGraph最新版本

| 描述                  | 文件                                         | 链接                                                                                                                                                                                              |
|---------------------|--------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| CentOS7 安装包         | tugraph-4.5.0-1.el7.x86_64.rpm             | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.5.0/tugraph-4.5.0-1.el7.x86_64.rpm)                                                                                      |
| CentOS8 安装包         | tugraph-4.5.0-1.el8.x86_64.rpm             | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.5.0/tugraph-4.5.0-1.el8.x86_64.rpm)                                                                                      |
| Ubuntu18.04 安装包     | tugraph-4.5.0-1.x86_64.deb                 | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.5.0/tugraph-4.5.0-1.x86_64.deb)                                                                                          |
| CentOS7 预安装镜像       | tugraph-runtime-centos7-4.5.0.tar          | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.5.0/tugraph-runtime-centos7-4.5.0.tar) 、[访问](https://hub.docker.com/r/tugraph/tugraph-runtime-centos7)                   |
| CentOS8 预安装镜像       | tugraph-runtime-centos8-4.5.0.tar          | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.5.0/tugraph-runtime-centos8-4.5.0.tar) 、[访问](https://hub.docker.com/r/tugraph/tugraph-runtime-centos8)                   |
| Ubuntu18.04 预安装镜像   | tugraph-runtime-ubuntu18.04-4.5.0.tar      | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.' metadata={'Header 1': '文档地图', 'Header 2': 'TuGraph最新版本'}"
lgraph_server -d start的方式启动，不是会在pwd路径下生成pid文件吗？这个pid文件有参数能控制路径吗？,"page_content='数据库运行

3.服务操作

3.2.停止服务

用户可以使用`kill`命令以及`lgraph_server -d stop`命令停止 TuGraph 守护进程。由于可能在同一台计算机上运行多个 TuGraph 服务器进程，因此我们使用`.pid`文件区分不同的服务器进程，该文件写入启动该进程的工作目录。因此，需要在相同工作目录中运行`lgraph_server-d stop`命令，以停止正确的服务器进程。  
```shell
user@host:~/tugraph$ ./lgraph_server -d start -c lgraph.json
20200508122306.378: Starting lgraph...
20200508122306.379: The service process is started at pid 93.

user@host:~/tugraph$ cat ./lgraph.pid
93

user@host:~/tugraph$ ./lgraph_server -d stop -c lgraph.json
20200508122334.857: Stopping lgraph...
20200508122334.857: Process stopped.
```' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.2.停止服务'}","page_content='数据库运行

3.服务操作

3.3.重启服务

用户也可以通过`lgraph_server -d restart`来重启 TuGraph 服务：  
```bash
$ ./lgraph_server -d restart
Stopping lgraph...
Process stopped.
Starting lgraph...
The service process is started at pid 20899.
```' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.3.重启服务'}","page_content='数据库运行

3.服务操作

3.1.启动服务

TuGraph 需要通过 `lgraph_server -d start` 命令行启动，启动命令示例如下：  
```bash
$ ./lgraph_server -d start -c lgraph.json
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.1.启动服务'}"
如果在使用ARM机器（如M1芯片的Mac）编译TuGraph，应该如何修改cmake命令？,"page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.3 通过OGM进行增操作**

OGM支持对TuGraph的实体执行CRUD 操作，同时支持发送任意TuGraph支持的Cypher语句，包括通过CALL调用存储过程。  
**CREATE**  
在完成图对象的构建后，即可通过类的实例化创建节点，当两个节点互相存储在对方的集合（该集合在构建时被标注为边）中，就形成了一条边，最后使用session.save方法将数据存入数据库。  
注意：TuGraph数据库为强schema类型数据库，在创建实体前需要该数据的label已经存在，且新建过程中需要提供唯一的主键。  
```
Movie jokes = new Movie（""Jokes""，1990）； // 新建Movie节点jokes session.save(jokes); // 将jokes存储在TuGraph中

Movie speed = new Movie(""Speed"", 2019);

Actor alice = new Actor(""Alice Neeves"");

alice.actsIn(speed);

session.save(speed);

/1 将speed节点与alice节点通过ACTS_IN进行连接 11 存储speed节点以及speed关联的边和alice节点
```' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.3 通过OGM进行增操作**'}","page_content='从源码编译

2.编译介绍

以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`，如果在arm机器编译（如M1芯片的Mac中，需要加上` -DENABLE_BUILD_ON_AARCH64=ON`）
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build
$ cmake .. -DOURSYSTEM=centos7
$ make
$ make package
```' metadata={'Header 1': '从源码编译', 'Header 2': '2.编译介绍'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}"
启动参数中cleanup_dir指定的目录用于执行什么操作？,"page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}","page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='OlapOnDisk API

2. 算法举例

2.2 配置类MyConfig

MyConfig配置类函数用于提供算法逻辑计算时所需的配置信息，继承于ConfigBase<EdgeData>,其中EdgeDate可根据加载图类型不同选择Empty（无权图）、int（带权图权重为整数）或者double（带权图权重为double）类型。  
MyConfig配置类一般根据算法不同，需要额外配置信息如下：  
1.算法所需参数
2.算法名称
3.配置类内Print函数
其余公用成员继承与ConfigBase，可参考src/olap/olap_config.h查阅。  
```C++
class MyConfig : public ConfigBase<Empty> {
public:

// 算法所需参数初始化
size_t root = 0;
std::string name = std::string(""bfs"");
void AddParameter(fma_common::Configuration & config) {
ConfigBase<Empty>::AddParameter(config);
config.Add(root, ""root"", true)
.Comment(""the root of bfs"");
}
void Print() {
ConfigBase<Empty>::Print();
std::cout << ""  name: "" << name << std::endl;
if (root != size_t(-1)) {
std::cout << ""  root: "" << root << std::endl;
} else {
std::cout << ""  root: UNSET"" << std::endl;
}
}
// 配置文件接受命令行参数，该用例会顺次读取命令行调用算法时的参数，优先使用用户指定数值，若用户并未指定则选择默认参数。
MyConfig(int &argc, char** &argv): ConfigBase<Empty>(argc, argv) {
fma_common::Configuration config;
AddParameter(config);
config.ExitAfterHelp(true);
config.ParseAndFinalize(argc, argv);
Print();
}
};
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.2 配置类MyConfig'}"
使用什么命令来启动 TuGraph？,"page_content='数据库运行

3.服务操作

3.1.启动服务

TuGraph 需要通过 `lgraph_server -d start` 命令行启动，启动命令示例如下：  
```bash
$ ./lgraph_server -d start -c lgraph.json
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.1.启动服务'}","page_content='场景：流浪地球

2.使用说明

前置条件：TuGraph已安装' metadata={'Header 1': '场景：流浪地球', 'Header 2': '2.使用说明'}","page_content='数据库运行

1.前置条件

TuGraph 运行的前置条件为 TuGraph 正确安装，参考[安装流程](1.environment.md)。  
TuGraph 运行需要保证库文件 liblgraph.so 的文件位置在环境变量 LD_LIBRARY_PATH。  
运行 TuGraph 进程的用户不需要超级权限，但需要对配置文件（一般为lgraph.json）及文件中涉及的文件有读权限，并且对数据文件夹、日志文件夹等有写权限。' metadata={'Header 1': '数据库运行', 'Header 2': '1.前置条件'}"
TuGraph团队为了提高解析速度所进行的优化包括了哪些主要手段？,"page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='性能优先

1.简介

TuGraph目前是世界上最快的图数据库，在图数据库标准评测LDBC SNB Interactive位居榜首（2023.3）。TuGraph的设计基于性能优先，致力于打造高性能的单机图数据库。该文档是TuGraph基于性能优先在存储层的核心设计。' metadata={'Header 1': '性能优先', 'Header 2': '1.简介'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}"
当中止一个正在执行的任务时，应该使用哪种HTTP请求方法？,"page_content='部署高可用模式

6.停止服务器

当服务器通过`CTRL-C`下线时，它将通知当前的`leader`服务器，告知其从备份组中删除该下线的服务器。如果`leader`服务器下线，
它将在下线前将`leader`身份权限传给另一台服务器。  
如果服务器被终止或者与备份组中的其他服务器失去连接，则该服务器将被视为失败节点，`leader`服务器将在特定时限后将其从备份组中删除。  
如果任何服务器离开备份组并希望重新加入，则必须从`--ha_conf HOST:PORT`选项开始，其中`HOST`是当前备份组中的某台服务器的 IP 地址。' metadata={'Header 1': '部署高可用模式', 'Header 2': '6.停止服务器'}","page_content='RESTful API Legacy

6.Deprecated

6.4.任务管理

TuGraph 提供长任务的跟踪和中止功能。用户可以通过 REST API 来查询当前正在运行的在 Cypher 和存储过程查询，并选择中止正在执行的查询。  
任务管理对应的 URI 格式为  
```
http://{host}:{port}/task/{thread_id}/{task_id}
```  
#### 6.4.1.查询正在执行的任务  
- **URI**: `/task`
- **METHOD**: GET
- **RESPONSE**:  
返回的 JSON 为一个数组，其中每一个元素格式如下：  
| 域名         | 说明                         | 类型   |
| ------------ | ---------------------------- | ------ |
| description  | 任务描述                     | 字符串 |
| time_elapsed | 任务已经执行的时间，单位为秒 | 浮点   |
| task_id      | 任务 ID                      | 字符串 |  
**Example request.**  
```
• GET http://localhost:7070/task
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""description"" : ""[CPP_PLUGIN] scan_graph"",
""time_elapsed"" : 13.987,
""task_id"" : ""3_10""
},
{
""description"" : ""[CYPHER] MATCH(n) return n"",
""time_elapsed"" : 30.887,
""task_id"" : ""2_6""
}
]
}
```  
#### 6.4.2.中止任务  
- **URI**: `/task/{task_id}`
其中 `{task_id}` 是 `GET /task` 返回结果中的 `task_id`。
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• DELETE http://localhost:7070/task/3_10
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.4.任务管理'}","page_content='数据库运行

3.服务操作

3.2.停止服务

用户可以使用`kill`命令以及`lgraph_server -d stop`命令停止 TuGraph 守护进程。由于可能在同一台计算机上运行多个 TuGraph 服务器进程，因此我们使用`.pid`文件区分不同的服务器进程，该文件写入启动该进程的工作目录。因此，需要在相同工作目录中运行`lgraph_server-d stop`命令，以停止正确的服务器进程。  
```shell
user@host:~/tugraph$ ./lgraph_server -d start -c lgraph.json
20200508122306.378: Starting lgraph...
20200508122306.379: The service process is started at pid 93.

user@host:~/tugraph$ cat ./lgraph.pid
93

user@host:~/tugraph$ ./lgraph_server -d stop -c lgraph.json
20200508122334.857: Stopping lgraph...
20200508122334.857: Process stopped.
```' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.2.停止服务'}"
AllocVertexSubset函数用来做什么？,"page_content='OlapBase API

7. 图类OlapBase

7.2 点集和边集及其相关操作

- `ParallelVector<VertexData> AllocVertexArray<VertexData>()`：分配一个类型为VertexData的数组，大小为点个数
- `void fill_vertex_array<V>(V * array, V value)`：将数组array中的所有元素赋值为value
- `ParallelBitset AllocVertexSubset()`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `AdjList<EdgeData> OutEdges(size_t vid)`：获取点v的所有出边集合
- `AdjList<EdgeData> InEdges(size_t vid)`：获取点v的所有入边集合
- `void Transpose()`：对有向图进行图反转
- `LoadFromArray(char * edge_array, VertexId input_vertices, EdgeId input_edges,  EdgeDirectionPolicy edge_direction_policy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.2 点集和边集及其相关操作'}","page_content='Python Olap API

4. Olap API

图类OlapBase

- `NumVertices()-> size_t`：获取点数
- `NumEdges()-> size_t`：获取边数
- `OutDegree(size_t vid)-> size_t`：点vid的出度
- `InDegree(size_t vid)-> size_t`：点vid的入度  
- `AllocVertexArray[VertexData]() ->ParallelVector[VertexData]`：分配一个类型为VertexData的数组，大小为点个数
- `AllocVertexSubset()-> ParallelBitset`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `OutEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有出边集合
- `InEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有入边集合
- `Transpose()-> cython.void`：对有向图进行图反转
- `LoadFromArray(edge_array: cython.p_char, input_vertices: size_t, input_edges: size_t, edge_direction_policy: EdgeDirectionPolicy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。  
- `AcquireVertexLock(vid: size_t)-> cython.void`：对点vid加锁，禁止其它线程对该锁对应的点数据进行访存
- `void ReleaseVertexLock(vid: size_t)-> cython.void`：对点vid解锁，所有线程均可访存该锁对应的点数据  
TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程，在Python中与C++使用方法稍有不同。  
```python
# 函数名称:ProcessVertexInRange[ReducedSum, Algorithm](
#           work: (algo: Algorithm, vi: size_t)-> ReducedSum,
#           lower: size_t, upper: size_t,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#     函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
#     第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
#     具体实现请参考include/lgraph/olap_base.h中具体代码
#
#     使用示例:统计数组parent数组中有出边的点个数

import cython
from cython.cimports.olap_base import *


@cython.cclass
class CountCore:
graph: cython. pointer(OlapBase[Empty])
parent: ParallelVector[size_t]

@cython.cfunc
@cython.nogil
def Work(self, vi: size_t) -> size_t:
if self.graph.OutDegree(self.parent[vi]) > 0:
return 1
return 0

def run(self, pointer_g: cython' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}","page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

`bfs`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关定义、数据结构的初始化
2. 使用批处理函数对每个节点进行循环计算，每一轮找到与当前节点相邻的全部节点，并在该轮次终止时进行交换。
3. 直到找到全部节点，返回节点个数discovered_vertices。  
```C++
size_t BFSCore(Graph<Empty>& graph, size_t root_vid, ParallelVector<size_t>& parent){

size_t root = root_vid;
auto active_in = graph.AllocVertexSubset();   //分配数组，active_in用于存放上一循环阶段已找到的节点
active_in.Add(root);            //把跟节点加入数组中
auto active_out = graph.AllocVertexSubset();  //分配数组active_out用于存放当前循环阶段找到的节点
parent.Fill((size_t)-1);               //将parent数组中的节点赋值为-1，-1表示未被找到
parent[root] = root;
size_t num_activations = 1;       //表示当前循环阶段找到的节点个数
size_t discovered_vertices = 0;    //表示当前循环阶段找到节点的总个数

for (int ii = 0; num_activations != 0; ii++) {       //num_activations表示当前循环阶段找到的节点个数
printf(""activates(%d) <= %lu\n"", ii, num_activations);
discovered_vertices += num_activations;         //discovered_vertices表示当前循环阶段找到节点的总个数
active_out.Clear();
num_activations = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t num_activations = 0;
for (auto& edge : graph.OutEdges(vi)) {   //每一次循环从根节点出发，查找邻近的相邻节点，对其parent值改变，并num_activations+1操作
size_t dst = edge.neighbour;
if (parent[dst] == (size_t)-1) {
auto lock = graph.GuardVertexLock(dst);
if (parent[dst] == (size_t)-1) {
parent[dst] = vi;
num_activations += 1;
active_out.Add(dst);       //存放当前循环阶段找到的节点
}
}
}
return num_activations;
},
active_in);
active_in.Swap(active_out);
}
// 返回全部节点数
return discovered_vertices;
}
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}"
web端导入10G数据报错,"page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

#### 6.10.1.指定文件内容导入  
- **URI**: `/db/{graph_name}/import/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |
| data | 要导入的文件内容（建议最大在 16MB 左右，最长不超过 17MB） | 字符串 / 数组 / 对象 |
| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""description"": ""{\\""files\\"":[{\\""columns\\"":[\\""SRC_ID\\"",\\""role\\"",\\""DST_ID\\""],\\""format\\"":\\""CSV\\"",\\""label\\"":\\""role\\"",\\""SRC_ID\\"":\\""actor\\"",\\""DST_ID\\"":\\""movie\\""}]}""}"",
""data"": ""1,Role1,2\n3,Role2,4\n"",
""continue_on_error"": true,
""delimiter"": "",""
}
```  
上述 description 的值是如下 json 序列化后的字符串  
```json
{
""files"": [
{
""format"": ""CSV"",
""label"": ""role"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""log"": ""Missing src uid 1\n""
}
```  
由于请求中指定了在出错时继续，该返回信息说明 SRC_ID 为 1 的边没有被导入，而其他信息导入成功。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}","page_content='TuGraph-Restful-Server

7.接口

7.8 数据导入请求

用户通过此类请求导入已经上传的数据文件。导入不论成功或失败，都将删除已上传文件。数据导入请求在server中实现为一个异步任务，响应返回并不意味着导入已完成，返回的是任务id，后续可以通过此任务id查询导入进度
#### 7.8.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_data
#### 7.8.2 REQUEST
|  body参数  |          参数说明           |  参数类型  | 是否必填 |
|:--------:|:-----------------------:|:------:|:----:|
| graph |         导入目标子图          |  字符串  |  是   |
| schema |       导入schema描述        | json字符串  |  是   |
| delimiter |           分隔符           |  字符串  |  是   |
| continueOnError |     单行数据出错是否跳过错误并继续     |  boolean  |  否   |
| skipPackages |         跳过的包个数          |  字符串  |  否   |
| taskId |  任务id   |  字符串  |  否   |
| other | 其他参数 |  json字符串  |  否   |  
#### 7.8.3 RESPONSE
|    body参数     |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| taskId | 任务编号 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.8 数据导入请求'}","page_content='QA汇总

数据导入QA

读取oracle数据报错

Q：读取oracle数据报错
""error_message"":""Error parsing file memory_file_stream\n\tError occurred at offset 0, exception detail:\n\tjson reading failed, error msg : std::bad_cast\n>Error line....""，如何解决？
A：看起来像在处理数据的时候遇到特使符号导致报错的，建议用相对较小的表以及数据可以尝试测一下' metadata={'Header 1': 'QA汇总', 'Header 2': '数据导入QA', 'Header 3': '读取oracle数据报错'}"
TuGraph支持的导出格式？,"page_content='数据导出

1.简介

TuGraph 可以通过 `lgraph_export` 工具来对已经存放在TuGraph的图数据进行数据导出。 `lgraph_export` 工具可以将指定 TuGraph 数据库的数据以 `csv` 或者 `json` 文件形式导出到指定目录，同时导出这些数据进行再导入时需要的配置文件 `import.config` ，详细描述可参见[配置文件](1.data-import.md)。' metadata={'Header 1': '数据导出', 'Header 2': '1.简介'}","page_content='TuGraph-DataX

4.导出TuGraph

4.1.配置样例

TuGraph支持使用DataX导出数据，使用如下配置即可将数据导出到文本数据中  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"":1
}
},
""content"": [
{
""reader"": {
""name"": ""tugraphreader"",
""parameter"": {
""username"": ""admin"",
""password"": ""73@TuGraph"",
""graphName"": ""Movie_8C5C"",
""queryCypher"": ""match (n:person) return n.id,n.name,n.born;"",
""url"": ""bolt://127.0.0.1:27687""
}
},
""writer"": {
""name"": ""txtfilewriter"",
""parameter"": {
""path"": ""./result"",
""fileName"": ""luohw"",
""writeMode"": ""truncate""
}
}
}
]
}
}
```  
使用这个配置文件，可以把TuGraph Movie_8C5C子图中person节点的id,name和born属性全部导出出来，
导出到当前目录下的result目录中，文件名称为luohw+随机后缀。' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '4.导出TuGraph', 'Header 3': '4.1.配置样例'}","page_content='TuGraph图模型说明

1. 数据模型

1.2. 数据类型

TuGraph支持多种可用于属性的数据类型。具体支持的数据类型如下：  
| **数据类型** | **最小值**          | **最大值**          | **描述**                            |
| ------------ | ------------------- | ------------------- | ----------------------------------- |
| BOOL         | false               | true                | 布尔值                              |
| INT8         | -128                | 127                 | 8位整型                          |
| INT16        | -32768              | 32767               | 16位整型                         |
| INT32        | - 2^31              | 2^31 - 1            | 32位整型                         |
| INT64        | - 2^63              | 2^63 - 1            | 64位整型                         |
| DATE         | 0000-00-00          | 9999-12-31          | ""YYYY-MM-DD"" 格式的日期             |
| DATETIME     | 0000-00-00 00:00:00.000000 | 9999-12-31 23:59:59.999999 | ""YYYY-MM-DD HH:mm:ss[.ffffff]"" 格式的日期时间 |
| FLOAT        |                     |                     | 32位浮点数                       |
| DOUBLE       |                     |                     | 64位浮点数                       |
| STRING       |                     |                     | 不定长度的字符串                    |
| BLOB         |                     |                     | 二进制数据（在输入输出时使用Base64编码） |
| POINT        |                     |                     | EWKB格式数据，表示点              |
| LINESTRING   |                     |                     | EWKB格式数据，表示线              |
| POLYGON      |                     |                     | EWKB格式数据，表示面(多边形)       |
| FLOAT_VECTOR |                     |                     | 包含32位浮点数的动态向量               |' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.2. 数据类型'}"
TuGraph的调优，除了语句前加EXPLAIN和PROFILE还有没有别的方式,"page_content='场景：流浪地球

2.使用说明

前置条件：TuGraph已安装' metadata={'Header 1': '场景：流浪地球', 'Header 2': '2.使用说明'}","page_content='TuGraph-DataX

4.导出TuGraph

4.1.配置样例

TuGraph支持使用DataX导出数据，使用如下配置即可将数据导出到文本数据中  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"":1
}
},
""content"": [
{
""reader"": {
""name"": ""tugraphreader"",
""parameter"": {
""username"": ""admin"",
""password"": ""73@TuGraph"",
""graphName"": ""Movie_8C5C"",
""queryCypher"": ""match (n:person) return n.id,n.name,n.born;"",
""url"": ""bolt://127.0.0.1:27687""
}
},
""writer"": {
""name"": ""txtfilewriter"",
""parameter"": {
""path"": ""./result"",
""fileName"": ""luohw"",
""writeMode"": ""truncate""
}
}
}
]
}
}
```  
使用这个配置文件，可以把TuGraph Movie_8C5C子图中person节点的id,name和born属性全部导出出来，
导出到当前目录下的result目录中，文件名称为luohw+随机后缀。' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '4.导出TuGraph', 'Header 3': '4.1.配置样例'}","page_content='场景：三体

2.使用说明

前置条件：TuGraph已安装。' metadata={'Header 1': '场景：三体', 'Header 2': '2.使用说明'}"
RpcSingleClient 构造函数需要哪些参数？,"page_content='Python客户端

3.RPC Client

3.1.实例化client对象

#### 3.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
```python
client = liblgraph_client_python.client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, url: str, user: str, password: str)
```  
#### 3.1.2.实例化HA集群直连连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化。
```python
client = liblgraph_client_python.client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, url: str, user: str, password: str)
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 3.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化
```python
client = liblgraph_client_python.client([""189.33.97.23:9091"",""189.33.97.24:9091"", ""189.33.97.25:9091""], ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, urls: list, user: str, password: str)
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.1.实例化client对象'}","page_content='C++客户端

2.使用示例

2.1.实例化client对象

引入依赖并实例化  
#### 2.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
``` C++
RpcClient client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
RpcClient(const std::string& url, const std::string& user, const std::string& password);
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```  
#### 2.1.2.实例化HA集群直接连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化
``` C++
RpcClient client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
RpcClient(const std::string& url, const std::string& user, const std::string& password);
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 2.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化。
```java
std::vector<std::string> urls = {""189.33.97.23:9091"", ""189.33.97.24:9091"", ""189.33.97.25:9091""};
TuGraphDbRpcClient client = new TuGraphDbRpcClient(urls, ""admin"", ""73@TuGraph"");
```
```
RpcClient(std::vector<std::string>& urls, std::string user, std::string password)
@param urls: tugraph host list
@param user: login user name
@param password: login password
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.1.实例化client对象'}","page_content='RPC API

5.存储过程

5.1.加载存储过程

加载存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称
- read_only: 必要参数，是否只读
- code: 必要参数，存储过程文件读入生成的ByteString
- desc: 可选参数，存储过程描述
- code_type: 可选参数，存储过程代码类型，PY、SO、CPP、ZIP四者之一  
以C++为例，用户加载存储过程的方式如下所示：
```C++
std::string content;
if (!FieldSpecSerializer::FileReader(source_file, content)) {
std::swap(content, result);
return false;
}
LGraphRequest req;
req.set_is_write_op(true);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
pluginRequest->set_version(version);
lgraph::LoadPluginRequest* loadPluginRequest = pluginRequest->mutable_load_plugin_request();
loadPluginRequest->set_code_type([](const std::string& type) {
std::unordered_map<std::string, lgraph::LoadPluginRequest_CodeType> um{
{""SO"", lgraph::LoadPluginRequest::SO},
{""PY"", lgraph::LoadPluginRequest::PY},
{""ZIP"", lgraph::LoadPluginRequest::ZIP},
{""CPP"", lgraph::LoadPluginRequest::CPP}};
return um[type];
}(code_type));
loadPluginRequest->set_name(procedure_name);
loadPluginRequest->set_desc(procedure_description);
loadPluginRequest->set_read_only(read_only);
loadPluginRequest->set_code(content);
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
加载存储过程的响应不包含参数，如果加载失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.1.加载存储过程'}"
Cython是如何导入与Olap相关的模块和图数据库模块的？,"page_content='Python Olap API

4. Olap API

见procedures/algo_cython/olap_base.pxd文件，用法与功能基本与C++接口相同，olap_base.pxd中声明的接口都由C++实现，在py文件中必须通过`from cython.cimports.olap_base import *`的方式导入，由Cython编译py文件后才能运行。' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API'}","page_content='Python Olap API

3. Cython

Cython是一种高效的编程语言，是Python的超集。Cython能将py文件翻译为C/C++代码后编译为Python拓展类，在Python中通过import调用。在TuGraph中，所有的Python plugin都由Cython编译为Python拓展类后使用。  
Cython的Pure Python模式在保证Python语法的同时具有C/C++的性能，TuGraph Python接口均使用Cython实现。  
[Cython 文档](https://cython.readthedocs.io/en/latest/index.html)' metadata={'Header 1': 'Python Olap API', 'Header 2': '3. Cython'}","page_content='Python Olap API

6. 算法插件示例

下面为Python实现的BFS算法的代码示例：
```python
# cython: language_level=3, cpp_locals=True, boundscheck=False, wraparound=False, initializedcheck=False
# distutils: language = c++

# 注释作用如下：
# language_level=3: 使用Python3
# cpp_locals=True: 需要c++17，使用std::optional管理Python代码中的C++对象，可以避免C++对象的拷贝构造
# boundscheck=False: 关闭索引的边界检查
# wraparound=False: 关闭负数下标的处理（类似Python List）
# initializedcheck=False: 关闭检查内存是否初始化，关闭检查后运行性能更快
# language = c++: 将此py文件翻译为C++而不是C文件，TuGraph使用大量模板函数，所以都应该使用C++

import json

import cython
from cython.cimports.olap_base import *
from cython.cimports.lgraph_db import *
# 从procedures/algo_cython/ 中cimportolap_base.pxd与lgraph_db.pxd, 类似C++中#include ""xxx.h""

from cython.cimports.libc.stdio import printf
# 类似C++中#include <stdio.h>
# 其他常见的还有cython.cimports.libcpp.unordered_map等

import time


@cython.cclass
# cython.cclass 表示BFSCore为C类型的Class
class BFSCore:
graph: cython.pointer(OlapBase[Empty])
# cython.pointer(OlapBase[Empty])表示OlapBase[Empty]的指针，类似C++中OlapBase[Empty]*
# cython提供了常见类型的指针，如cython.p_int, cython.p_char等，表示int*, char*, ...
parent: ParallelVector[size_t]
active_in: ParallelBitset
active_out: ParallelBitset
root: size_t
# root: size_t 声明root为C++ size_t类型变量，等效于root = cython.declare(size_t)
# 不声明类型的变量为Python object类型
# 声明变量类型会大幅提高性能，同时在多线程部分，只有C/C++类型的变量可以访问

@cython.cfunc
# cython.cfunc 表示Work为C类型的函数，参数与返回值应声明
# cfunc性能好，能接受C/C++对象为参数、返回值，但是不能在其他python文件中调用
# 类似的有cython.ccall，如Standalone函数，可以在其他python文件中调用
@cython.nogil
# cython.nogil 表示释放Python全局解释锁，在nogil修饰的部分，不能访问Python对象
# 在多线程部分，都应有nogil修饰器
@cython.exceptval(check=False)
# cython.exceptval(check=False) 表示禁用异常传播，将忽略函数内部引发的Python异常
def Work(self, vi: size_t) -> size_t:
degree = cython.declare(size_t, self.graph.OutDegree(vi))
out_edges = cython.declare(AdjList[Empty], self.graph.OutEdges(vi))
i = cython.declare(size_t, 0)
local_num_activations = cython.declare(size_t, 0)
dst: size_t
for i in range(degree):
dst = out_edges[i].neighbour
if self.parent[dst] == cython.cast(size' metadata={'Header 1': 'Python Olap API', 'Header 2': '6. 算法插件示例'}"
在调用db.addEdgeIndex时，'unique'参数和'pair_unique'参数有何不同？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.addEdgeIndex(label_name, field_name, unique, pair_unique)

create an index on some field of one edge label .  
**Parameters:**  
| parameter | parameter type | description               |
| ---------- | -------------- | ------------------------------------- |
| label_name | string     | name of the label             |
| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |
| pair_unique | boolean    | Specifies whether the index is pair_unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.addEdgeIndex('BornIn', 'id', true, false)
```  
**Example output:**  
```
Added index [BornIn:id]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addEdgeIndex(label_name, field_name, unique, pair_unique)'}","page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}","page_content='业务开发指南

边类型操作

边类型添加索引

>该操作会同步构建索引数据，数据量大的时候，有时间消耗。  
如下例子，对于边类型`edge1`，给字段`field1`添加了一个非唯一索引。
```
CALL db.addEdgeIndex('edge1', 'field1', false, false)
```
如下例子，对于边类型`edge1`，给字段`field2`添加了一个唯一索引。
```
CALL db.addEdgeIndex('edge1', 'field2', true, false)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型添加索引'}"
图数据库相比于关系型数据库有什么优势？,"page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.1. 性能

在关联关系处理上，使用关系型数据库不可避免地要使用表的JOIN操作，这会对性能产生较大影响；而图数据库则直接跳转访问类指针，操作关联数据的效率更高，比关系型数据库提高2到4个数量级的性能。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.1. 性能'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.3. 直观性

使用图的方式表达现实世界的关系更直接和自然，在万物互联的时代尤为突出。如果使用关系型数据，先建立实体表，再建立关系表，最后映射数据，需要高度的抽象思维。在图数据上进行分析查询时，可以直观地通过点边连接的拓扑结构找到所需数据，无需任何专业知识。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.3. 直观性'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.2. 兼容性

现实中，项目进程通常不断演变，数据的内容甚至数据格式也在不断变化。在关系型数据库中，这意味着表结构的变化或建立多个新表，对源数据的修改非常大。而在图数据库中，仅需添加新的点、边和属性，并将其设置为对应的类型即可。从本质上说，一个表代表一种类型的数据，一个点代表一个特定的数据。这意味着关系型数据库更关注数据类型，而图数据库更关注数据个体及其关联关系。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.2. 兼容性'}"
在创建节点的时候，报错：message: Vertex unique index value [xxx] is too long，是属性值太长了吗？,"page_content='Vector index

创建向量索引

如下json定义了一个点类型，名字是`person`, 里面有个字段是`embedding`，类型是`FLOAT_VECTOR`，用来存储向量数据。
目前向量数据只能在点上创建。  
```json
{
""label"": ""person"",
""primary"": ""id"",
""type"": ""VERTEX"",
""properties"": [{
""name"": ""id"",
""type"": ""INT32"",
""optional"": false
}, {
""name"": ""age"",
""type"": ""INT32"",
""optional"": false
}, {
""name"": ""embedding"",
""type"": ""FLOAT_VECTOR"",
""optional"": false
}]
}

```
把上面这个json序列化成字符串，作为参数传入，建议使用驱动的参数化特性，避免自己拼接语句。
```
CALL db.createVertexLabelByJson($json_data)
```
给`embedding`字段添加向量索引，第三个参数是个map，里面可以设置一些向量索引的配置参数，如下，`dimension`设置向量维度是4
```
CALL db.addVertexVectorIndex('person','embedding', {dimension: 4});
```  
再定义一个边，用来测试，如下json定义了一个边类型，名字是`like`。
```json
{
""label"": ""like"",
""type"": ""EDGE"",
""constraints"": [
[""person"", ""person""]
],
""properties"": []
}
```
把上面这个json序列化成字符串，作为参数传入。
```
CALL db.createEdgeLabelByJson($json_data)
```  
写入几条测试数据
```
CREATE (n1:person {id:1, age:10, embedding: [1.0,1.0,1.0,1.0]})
CREATE (n2:person {id:2, age:20, embedding: [2.0,2.0,2.0,2.0]})
CREATE (n3:person {id:3, age:30, embedding: [3.0,3.0,3.0,3.0]})
CREATE (n1)-[r:like]->(n2),
(n2)-[r:like]->(n3),
(n3)-[r:like]->(n1);
```' metadata={'Header 1': 'Vector index', 'Header 2': '创建向量索引'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createLabel(label_type, label_name, extra, field_spec...)

Create a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| extra      | string     | for edge, it means constraints; for vertex, it means primary property |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.
for edge, `extra` should be a json array string, like this `[[""label1"",""label2""], [""label3"",""label4""]]`, if edge has no constraints, give an empty json array, like this `[]`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createLabel('vertex', 'new_label', 'id', ['id','int32',false], ['name','string', true]);
CALL db.createLabel('edge', 'new_edge', '[[""id1"",""id2""]]', ['id','int32',false], ['name', 'string', true]);
```  
**Example output:**  
```
Vertex label [new_label] successfully added.
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createLabel(label_type, label_name, extra, field_spec...)'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}"
使用 GET 方法获取具体边属性时，如果边不存在该属性，会返回什么错误代码？,"page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/relationship/{euid}
```  
与 Nodes 功能类似，Relationships 提供边（edge）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。每一条边都可以由一个唯一 ID（euid）来标识。这个 ID 可以从在插入边时获得，或者在 [列出所有边](#%E5%88%97%E5%87%BA%E6%89%80%E6%9C%89%E8%BE%B9) 操作中得到。  
#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| fields | 数据列名 | 列表 |
| edge | 边数据 | 列表 |  
其中 edge 是一个数据列表，其中每个元素都是一条边，其定义如下：  
| 域名        | 说明     | 类型                                                   |
| ----------- | -------- | ------------------------------------------------------ |
| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 20' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}","page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}","page_content='业务开发指南

边类型操作

边类型添加字段

>该操作会同步变更所有该类型边的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于边类型`edge1`，一次添加了两个字段: `field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是`0`.
```
CALL db.alterLabelAddFields('edge', 'edge1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型添加字段'}"
TuGraph针对不同用户的需求提供了哪些类型的系统环境？,"page_content='环境和版本选择

1. 简介

TuGraph为不同需求的用户提供了差异化的系统环境和部署方式，来满足新手、系统开发者、生产运维人员、研究人员等不同用户的需求。' metadata={'Header 1': '环境和版本选择', 'Header 2': '1. 简介'}","page_content='环境准备

2.软件环境

2.1. 操作系统

TuGraph 能够兼容主流操作系统，包括Ubuntu、CentOS、SUSE、银河麒麟、 中标麒麟、UOS等，均通过测试认证。  
其中最稳定使用的系统版本是 Ubuntu 18.04、CentOS 7、CentOS 8。' metadata={'Header 1': '环境准备', 'Header 2': '2.软件环境', 'Header 3': '2.1. 操作系统'}","page_content='环境分类

2.依赖系统库

针对三种环境，除去TuGraph的运行包，所需要的系统库如下：
* 编译环境，包括gcc、python、java等编译器，也包含antlr4、pybind11等，具体参见tugraph-db源码目录 ci/images/tugraph-compile-*-Dockerfile。
* 运行环境，主要由存储过程引入，包括gcc、boost、cmake等，具体参见tugraph-db源码目录 ci/images/tugraph-runtime-*-Dockerfile。
* 精简运行环境，无，可以参见tugraph-db源码目录 ci/images/ tugraph-mini-runtime-*-Dockerfile。' metadata={'Header 1': '环境分类', 'Header 2': '2.依赖系统库'}"
TuGraph-DB新增支持的空间数据类型有哪些？,"page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

实现思路

在TuGraph-DB的实现，基于boost geometry库的基础上进行封装，用EWKB格式存储数据，其中Point类型为定长存储50，其余皆为变长存储。我们支持了Point, Linestring与Polygon三种类型，同时支持了WGS84, CARTESIAN两种坐标系，数据类型与坐标系均可根据需要拓展。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现', 'Header 3': '实现思路'}","page_content='空间数据类型在TuGraph-DB中的实现

定义空间数据类型

TuGraph-DB当前已经支持Point、Linestring与Polygon三种类型  
-   • Point：点，创建方式例如POINT(2.0, 2.0, 7203)  
-   • Linestring：折线，创建方式例如LINESTRING(0 2,1 1,2 0)  
-   • Polygon：多边形，创建方式例如POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '定义空间数据类型'}","page_content='TuGraph图模型说明

1. 数据模型

1.2. 数据类型

TuGraph支持多种可用于属性的数据类型。具体支持的数据类型如下：  
| **数据类型** | **最小值**          | **最大值**          | **描述**                            |
| ------------ | ------------------- | ------------------- | ----------------------------------- |
| BOOL         | false               | true                | 布尔值                              |
| INT8         | -128                | 127                 | 8位整型                          |
| INT16        | -32768              | 32767               | 16位整型                         |
| INT32        | - 2^31              | 2^31 - 1            | 32位整型                         |
| INT64        | - 2^63              | 2^63 - 1            | 64位整型                         |
| DATE         | 0000-00-00          | 9999-12-31          | ""YYYY-MM-DD"" 格式的日期             |
| DATETIME     | 0000-00-00 00:00:00.000000 | 9999-12-31 23:59:59.999999 | ""YYYY-MM-DD HH:mm:ss[.ffffff]"" 格式的日期时间 |
| FLOAT        |                     |                     | 32位浮点数                       |
| DOUBLE       |                     |                     | 64位浮点数                       |
| STRING       |                     |                     | 不定长度的字符串                    |
| BLOB         |                     |                     | 二进制数据（在输入输出时使用Base64编码） |
| POINT        |                     |                     | EWKB格式数据，表示点              |
| LINESTRING   |                     |                     | EWKB格式数据，表示线              |
| POLYGON      |                     |                     | EWKB格式数据，表示面(多边形)       |
| FLOAT_VECTOR |                     |                     | 包含32位浮点数的动态向量               |' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.2. 数据类型'}"
在CREATE LABEL命令中，如果要创建一个顶点标签，主要属性名称应该由哪个参数确定？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.createLabel(label_type, label_name, extra, field_spec...)

Create a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| extra      | string     | for edge, it means constraints; for vertex, it means primary property |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.
for edge, `extra` should be a json array string, like this `[[""label1"",""label2""], [""label3"",""label4""]]`, if edge has no constraints, give an empty json array, like this `[]`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createLabel('vertex', 'new_label', 'id', ['id','int32',false], ['name','string', true]);
CALL db.createLabel('edge', 'new_edge', '[[""id1"",""id2""]]', ['id','int32',false], ['name', 'string', true]);
```  
**Example output:**  
```
Vertex label [new_label] successfully added.
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createLabel(label_type, label_name, extra, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createEdgeLabel( label_name, field_spec...)

Create an edge label.  
**Parameters:**  
| parameter  | parameter type | description          |
| ---------- | -------------- | ------------------------ |
| label_name | string     | name of the label    |
| edge_constraints | string | edge constraints |
| field_spec | list       | specification of a field |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`, where optional is specified as true, only for  optional fields.  
`edge_constraints` is a json array string, This parameter limits the combination of starting and ending vertex of the edge, for example: `'[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]'`, which limits the edge direction can only be from `vertex_label1` to `vertex_label2` or from `vertex_label3` to `vertex_label4`. If you don't want to have any constraints, give an empty array string, like this `'[]'`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createEdgeLabel('KNOWS', '[]', 'name', 'int32', true)
```  
**Example output:**  
```
Added type [KNOWS]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createEdgeLabel( label_name, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createVertexLabel(label_name, primary_field, field_spec...)

Create a vertex label.  
**Scope:** whole instance.  
**Parameters:**  
| parameter  | parameter type | description          |
| ---------- | -------------- | ------------------------ |
| label_name | string     | name of  vertex label    |
| primary_field | string  | primary field of vertex label |
| field_spec | list       | specification of a field |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, true]`, where true is specified only for optional fields.  
**Output:** If successful, it returns a success message.  
**Example input:**  
```
CALL db.createVertexLabel('Person', 'id', 'id', 'int64', false, 'name', 'string', true)
```  
**Example output:**  
```
Added label [Person]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createVertexLabel(label_name, primary_field, field_spec...)'}"
在HA模式下，client可以向谁发送导入点边数据请求？,"page_content='Python客户端

3.RPC Client

3.12.从字节流中导入点边数据

```python
ret, res = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000)
```
```
importDataFromContent(self: liblgraph_client_python.client, desc: str, data: str, delimiter: str, continue_on_error: bool, thread_nums: int, graph: str, json_format: bool, timeout: float) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.12.从字节流中导入点边数据'}","page_content='Python客户端

3.RPC Client

3.14.从文件中导入点边数据

```python
ret, res = client.importDataFromFile(""./test/data/yago.conf"", "","", true, 16, 0, ""default"", 1000000000)
```
```
importDataFromFile(self: liblgraph_client_python.client, conf_file: str, delimiter: str, continue_on_error: bool, thread_nums: int, skip_packages: int, graph: str, json_format: bool, timeout: float) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.14.从文件中导入点边数据'}","page_content='Java客户端

2.使用示例

2.12.从字节流中导入点边数据

```java
boolean ret = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000);
log.info(""importDataFromContent : "" + ret);
```
```
@param desc: data format description
@param data: the data to be imported
@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromContent(String desc, String data, String delimiter, boolean continueOnError,
int threadNums, String graph, double timeout) throws UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}"
在只读事务中调用 SetFields 方法会抛出什么异常？,"page_content='RESTful API Legacy

6.Deprecated

6.9.索引

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/index/{label}/{field}
```  
提供索引操作，接受 GET/POST 请求。  
#### 6.9.1.创建索引  
该操作会启动一个创建索引的后台任务，用户可以通过列出该 Label 相关的所有索引来检查新建索引的状态。  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: POST
- **REQUEST**:  
| 域名    | 说明     | 类型                                  |
|-------|--------|-------------------------------------|
| label | Label 名 | 字符串                                 |
| field | 域名     | 字符串                                 |
| type  | 索引类型   | int类型，0表示非唯一索引，1表示全局唯一索引，2表示两点间唯一索引 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"": ""Person"",
""field"": ""birthyear"",
""is_unique"" : false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.9.2.列出所有索引  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""field"": ""name"",
""label"": ""City"",
""is_unique"": false
},
{
""field"": ""title"",
""label"": ""Film"",
""is_unique"": false
},
{
""field"": ""name"",
""label"": ""Person"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
#### 6.9.3.列出所有与某个 Label 相关的索引  
- **URI**: `/db/{graph_name}/index/{label}`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index/Person
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""label"": ""Person"",
""field"": ""name"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
##' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.9.索引'}","page_content='RESTful API Legacy

6.Deprecated

6.3.服务器状态

#### 6.3.1.修改服务器配置  
修改服务器配置，配置修改后立即生效，并将影响所有服务器。这些配置的优先级高于配置文件以及命令行参数。  
- **URI**: `/config`
- **METHOD**: PUT
- **REQUEST**:  
请求为一个字典，使用 `{""opt1"":v1}` 可以将名为`opt1`的配置修改为`v1`。  
| 配置名               | 说明                   | 值类型 |
| -------------------- | ---------------------- | ------ |
| OPT_DB_ASYNC         | 是否启用异步模式       | 布尔值 |
| OPT_TXN_OPTIMISTIC   | 是否默认使用乐观事务锁 | 布尔值 |
| OPT_AUDIT_LOG_ENABLE | 是否启用审计日志       | 布尔值 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• PUT http://localhost:7070/config
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""OPT_DB_ASYNC"": true,
""OPT_AUDIT_LOG_ENABLE"": false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.3.2.当前服务器状态  
- **URI**: `/info`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| lgraph_version | 服务器版本号 | 字符串 |
| git_branch | 服务器代码分支 | 字符串 |
| git_commit | 服务器代码版本 | 字符串 |
| web_commit | 前端码版本 | 字符串 |
| cpp_id | CPP 编译器 ID | 字符串 |
| cpp_version | CPP 编译器版本 | 字符串 |
| python_version | PYTHON 版本 | 字符串 |
| node | 点 uri | 字符串 |
| relationship | 边 uri | 字符串 |
| cpu | cpu 信息 | 字典，格式参见[服务器 CPU 状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8CPU%E7%8A%B6%E6%80%81) |
| disk | 硬盘 IO 信息 | 字典，格式参见[服务器硬盘状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E7%9B%98%E7%8A%B6%E6%80%81) |
| memory | 内存信息 | 字典，格式参见[服务器内存状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%86%85%E5%AD%98%E7%8A%B6%E6%80%81) |
| db_space | 图数据库占用空间 | 字典，格式参见[图数据库占用空间](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4) |
| db_config | 图数据库配置信息 | 字典，格式参见[图数据库配置信息](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF) |
| up_time | 数据库在线时长（秒） | 整型 |  
**Example request.**  
```
• GET http://localhost:7070/info
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""lgraph_version"": ""1.2.0"",
""git_branch"": ""master"",
""git_commit"": ""9e2977d"",' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.3.服务器状态'}","page_content='RESTful API

2.请求与响应格式

2.2请求类型

#### 2.2.1. 用户登陆
用户在登陆请求中携带用户名和密码发送到服务端。登录成功会收到带有签名的令牌(Json Web Token)和判断是否为默认密码的布尔型变量，客户端储存该令牌，在后续的请求中将令牌加入请求头的Authorization域中。如果登录失败会收到“Authentication failed”错误。  
- **URI**:     /login
- **METHOD**:  POST
- **REQUEST**:  
| body参数  | 参数说明 | 参数类型  | 是否必填       |
| ------- |------|-------|------------|
| userName   | 用户名  | 字符串类型   | 是          |
| password   | 用户密码 | 字符串类型 | 是          |  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data中包含令牌  
| body参数  | 参数说明 | 参数类型  | 是否必填       |
| ------- |------|-------|------------|
| authorization   | 令牌  | 字符串类型   | 是          |
| default_password  | 默认密码 | 布尔类型 | 是          |  
**Example request.**  
```
{""userName"" : ""test"", ""password"" : ""123456""}
```  
#### 2.2.2. 用户登出
用户登出，同时删除已经认证的token，用户后续发送请求时，需要重新登陆，并获取新的token。  
- **URI**:     /logout
- **METHOD**:  POST
- **REQUEST**:
http request header中携带调用login接口时返回的token，body中没有参数  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data为空  
#### 2.2.3. 身份刷新
已下发的token失效后，需要调用本接口重新认证。后端验证token合法性。token在初次登录后，1小时内有效，过期需要刷新  
- **URI**:     /refresh
- **METHOD**:  POST
- **REQUEST**:
http request header中携带调用login接口时返回的token，body中没有参数  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data中包含令牌  
| body参数  | 参数说明 | 参数类型  | 是否必填       |
| ------- |------|-------|------------|
| authorization   | 令牌  | 字符串类型   | 是          |  
#### 2.2.4. 调用cypher
用户对TuGraph的增删改查请求需要调用cypher接口，并通过标准的cypher查询语言发起  
- **URI**:     /cypher
- **METHOD**:  POST
- **REQUEST**:  
| body参数  | 参数说明     | 参数类型  | 是否必填       |
| ------- |----------|-------|------------|
| graph   | 查询的子图名称  | 字符串类型   | 是          |
| script   | cypher语句 | 字符串类型 | 是          |  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data中包含查询结果  
| body参数  | 参数说明 | 参数类型    | 是否必填       |
| ------- |------|---------|------------|
| result   | 查询结果 | json字符串 | 是          |  
**Example request.**  
```
{""script"" : ""Match (n) return n"", ""graph"" : ""default""}
```  
#### 2.2.5. 上传文件
接口用于将本地文件上传至TuGraph所在机器。可以上传文本文件，二进制文件，可以上传大文件，也可以上传小文件' metadata={'Header 1': 'RESTful API', 'Header 2': '2.请求与响应格式', 'Header 3': '2.2请求类型'}"
GetVertexIndexIterator函数在liblgraph_python_api.Transaction中用于获取什么类型的迭代器？,"page_content='Python Olap API

5. lgraph_db API

Transaction：

```
GetVertexIndexIterator(
label: std::string,
field: std::string,
key_start: std::string,
key_end: std::string)-> VertexIndexIterator
```
获取索引迭代器。迭代器的field值为 [key_start, key_end]。所以在key_start=key_end=v时，返回指向field值为v的点的迭代器  
lgraph_db_python.py是lgraph_db.pxd中C++类 Galaxy与GraphDB的包装，将C++类包装为Python类，将lgraph_db_python.py编译为Python拓展后，可以直接在Python文件或Python命令行中`import lgraph_db_python`访问lgraph_db_python.PyGraphDB与PyGraphDB.PyGalaxy。' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Transaction：'}","page_content='Python Olap API

5. lgraph_db API

VertexIndexIterator

- `GetVid()-> int64_t`: 获取点的vid' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'VertexIndexIterator'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends Gra' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
db.importor.dataImportor 函数在导入数据时是否可以指定错误继续执行和线程数？,"page_content='Java客户端

2.使用示例

2.12.从字节流中导入点边数据

```java
boolean ret = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000);
log.info(""importDataFromContent : "" + ret);
```
```
@param desc: data format description
@param data: the data to be imported
@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromContent(String desc, String data, String delimiter, boolean continueOnError,
int threadNums, String graph, double timeout) throws UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='数据导入

5.在线增量导入

在线导入模式可用于将一批文件导入已在运行中的 TuGraph 实例中。这对于处理通常以固定的时间间隔进行的增量批处理更新非常便利。`lgraph_import --online true`选项使导入工具能够在线模式工作。与`离线模式`一样，在线模式有自己的命令行选项集，可以使用`-h，--help`选项进行打印输出：  
```shell
$ lgraph_import --online true -h
Available command line options:
--online            Whether to import online.
-h, --help          Print this help message. Default=0.

Available command line options:
--log               Log file to use, empty means stderr. Default="""".
-v, --verbose       Verbose level to use, higher means more verbose.
Default=1.
-c, --config_file   Config file path.
-r, --url           DB REST API address.
-u, --username      DB username.
-p, --password      DB password.
-i, --continue_on_error
When we hit a duplicate uid or missing uid, should we
continue or abort. Default=0.
-g, --graph         The name of the graph to import into. Default=default.
--skip_packages     How many packages should we skip. Default=0.
--delimiter         Delimiter used in the CSV files
--breakpoint_continue
When the transmission process is interrupted,whether
to re-transmit from zero package next time. Default=false
-h, --help          Print this help message. Default=0.
```  
文件的相关配置在配置文件中指定，其格式与`离线模式`完全相同。但是，我们现在不是将数据导入本地数据库，而是将数据发送到正在运行的 TuGraph 实例中，该实例通常运行在与运行导入工具的客户端计算机不同的计算机上。因此，我们需要指定远程计算机的 HTTP 地址的URL、DB用户和密码。  
如果用户和密码有效，并且指定的图存在，导入工具将将数据发送到服务器，服务器随后解析数据并将其写入指定的图。数据将以大约 16MB 大小的包发送，在最近的换行符处中断。每个包都是以原子方式导入的，这意味着如果成功导入包，则成功导入所有数据，否则，任何数据都不会进入数据库。如果指定了`--continue_on_error true`，则忽略数据完整性错误，并忽略违规行。否则，导入将在第一个错误包处停止，并打印出已导入的包数。在这种情况下，用户可以修改数据以消除错误，然后使用`--skip_packages N`重做导入以跳过已导入的包。' metadata={'Header 1': '数据导入', 'Header 2': '5.在线增量导入'}","page_content='Java客户端

2.使用示例

2.14.从文件中导入点边数据

```java
boolean ret = client.importDataFromFile(""./test/data/yago.conf"", "","", true, 16, 0, ""default"", 1000000000);
log.info(""importDataFromFile : "" + ret);
```
```
@param confFile: data file contain format description and data
@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param skipPackages: skip packages number
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromFile(String confFile, String delimiter, boolean continueOnError, int threadNums,
int skipPackages, String graph, double timeout) throws IOException, UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.14.从文件中导入点边数据'}"
在尝试读取一个已完成索引构建的顶点时，应该使用哪个函数？,"page_content='RESTful API Legacy

6.Deprecated

6.9.索引

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/index/{label}/{field}
```  
提供索引操作，接受 GET/POST 请求。  
#### 6.9.1.创建索引  
该操作会启动一个创建索引的后台任务，用户可以通过列出该 Label 相关的所有索引来检查新建索引的状态。  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: POST
- **REQUEST**:  
| 域名    | 说明     | 类型                                  |
|-------|--------|-------------------------------------|
| label | Label 名 | 字符串                                 |
| field | 域名     | 字符串                                 |
| type  | 索引类型   | int类型，0表示非唯一索引，1表示全局唯一索引，2表示两点间唯一索引 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"": ""Person"",
""field"": ""birthyear"",
""is_unique"" : false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.9.2.列出所有索引  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""field"": ""name"",
""label"": ""City"",
""is_unique"": false
},
{
""field"": ""title"",
""label"": ""Film"",
""is_unique"": false
},
{
""field"": ""name"",
""label"": ""Person"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
#### 6.9.3.列出所有与某个 Label 相关的索引  
- **URI**: `/db/{graph_name}/index/{label}`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index/Person
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""label"": ""Person"",
""field"": ""name"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
##' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.9.索引'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

`图项目`提供可视化的图项目管理和图数据研发功能，它为用户提供了一系列便捷的图数据可视化操作，包括图项目的创建、修改、删除等管理操作，以及图数据的查询、点边统计等操作。此外，它也支持图模型的管理，使用户可以更加方便地进行图数据的管理和维护。  
#### 2.4.1.图项目管理  
在`图项目`界面，可以看到当前图数据库中的图项目。  
![图项目-首页](../../../images/browser/graphmanagement-homepage.png)  
##### 2.4.1.1.新建图项目  
在`图项目`界面，点击`新建图项目`按钮创建一个新的图项目。  
![图项目-新建图项目按钮](../../../images/browser/graphmanagement-creategraph.png)  
新建图项目需要通过`选择模板`和`填写配置`两个页面完成图项目的创建。  
- __选择模板__：产品提供空模板和demo模板两类模板。
- 空模板：全新的图项目，用户需要自己创建图模型和导入图数据，一般用于正式项目开发。
- demo模板：产品内置的demo数据，图项目创建成功后，系统会自动创建demo图模型并导入demo图数据，一般用于试用和学习。  
![图项目-选择模板](../../../images/browser/graphmanagement-selecttemplate.png)  
- __填写配置__：用户需要填写图项目基本信息，并点击`创建`按钮创建图项目。
- 图名称：新建图项目的名称，同时作为该图项目的唯一主键。支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图描述：新建图项目的描述，可用于详细说明该项目的背景和目标。
- 高级配置-最大存储空间：设置图项目最大可占用的存储空间，实际并不会提前占用物理存储空间，实际数据量达到最大存储空间阈值后不可再写入数据。  
![图项目-填写配置](../../../images/browser/graphmanagement-configure.png)  
创建成功后，可在`图项目`页面的图项目选项卡中查看。  
##### 2.4.1.2.编辑图项目  
在`图项目`界面，点击图项目选项卡中的`编辑`按钮（笔形图标），编辑对应图项目的基础信息。  
![图项目-编辑图项目按钮](../../../images/browser/graphmanagement-editgraph-button.png)  
编辑图项目功能可以修改`图描述`和`最大存储空间`。  
![图项目-编辑图项目](../../../images/browser/graphmanagement-editgraph.png)  
##### 2.4.1.3.删除图项目  
在`图项目`界面，点击图项目选项卡中的`删除`按钮（垃圾桶图标），删除对应的图项目。  
![图项目-删除图项目按钮](../../../images/browser/graphmanagement-deletegraph-button.png)  
_需要注意：图项目删除后无法恢复_。  
##### 2.4.1.4.点边统计  
在`图项目`界面，点击图项目选项卡中的`点边统计`按钮（刷新图标），统计对应图项目当前时间节点的点边数量。  
![图项目-点边统计按钮](../../../images/browser/graphmanagement-statistics-button.png)  
统计结果将展示在图项目选项卡上，已经统计过点边数据的图项目再次统计需要点击`刷新`按钮。  
![图项目-点边统计](../../../images/browser/graphmanagement-statistics.png)  
![图项目-刷新点边统计按钮](../../../images/browser/graphmanagement-statistics-refresh-button.png)  
##### 2.4.1.5.存储过程  
在`图项目`界面，点击图项目选项卡中的`存储过程`按钮（卡片最右侧图标），跳转到操作存储过程的图页面。  
![图项目-存储过程按钮](../../../images/browser/graphmanagement-procedure-button.png)  
在`存储过程`页面，可以新建存储过程，新建时需要填写""存储过程名称""、""存储过程类型""、""存储过程描述""，然后选择""版本""和""执行时是否修改数据库""  
![图项目-存储过程](../../../images/browser/graph' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='典型示例

PageRank动态图计算示例介绍

实例代码

```java

public class IncrGraphCompute {

private static final Logger LOGGER = LoggerFactory.getLogger(IncrGraphCompute.class);
// 计算结果路径
public static final String RESULT_FILE_PATH = ""./target/tmp/data/result/incr_graph"";
// 结果对比路径
public static final String REF_FILE_PATH = ""data/reference/incr_graph"";

public static void main(String[] args) {
// 获取执行环境
Environment environment = EnvironmentFactory.onLocalEnvironment();
// 执行作业提交
IPipelineResult result = submit(environment);
// 等待执行完成
result.get();
// 关闭执行环境
environment.shutdown();
}

public static IPipelineResult<?> submit(Environment environment) {
// 构建任务执行流
final Pipeline pipeline = PipelineFactory.buildPipeline(environment);
// 获取作业环境配置
Configuration envConfig = ((EnvironmentContext) environment.getEnvironmentContext()).getConfig();
// 指定保存计算结果的路径
envConfig.put(FileSink.OUTPUT_DIR, RESULT_FILE_PATH);

// graphview 名称
final String graphName = ""graph_view_name"";
// 创建增量图 graphview
GraphViewDesc graphViewDesc = GraphViewBuilder
.createGraphView(graphName)
// 设置 graphview 分片数, 可从配置中指定
.withShardNum(envConfig.getInteger(ExampleConfigKeys.ITERATOR_PARALLELISM))
// 设置 graphview backend 类型
.withBackend(BackendType.RocksDB)
// 指定 graphview 点边以及属性等schema信息
.withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class, Integer.class, ValueEdge.class, IntegerType.class))
.build();
// 将创建好的graphview信息添加到任务执行流
pipeline.withView(graphName, graphViewDesc);

// 提交任务并执行
pipeline.submit(new PipelineTask() {
@Override
public void execute(IPipelineTaskContext pipelineTaskCxt) {
Configuration conf = pipelineTaskCxt.getConfig();
// 1. 构建点数据输入源
PWindowSource<IVertex<Integer, Integer>> vertices =
// extract vertex from edge file
pipelineTaskCxt.buildSource(new RecoverableFileSource<>(""data/input/email_edge"",
// 指定每行数据的解析格式
line -> {
String[] fields = line.split("","");
IVertex<Integer, Integer> vertex1 = new ValueVertex<>(
Integer.valueOf(fields[0]), 1);
IVertex<Integer, Integer> vertex2 = new Value' metadata={'Header 1': '典型示例', 'Header 2': 'PageRank动态图计算示例介绍', 'Header 3': '实例代码'}"
在调用函数DeleteGraph时，如果操作未被授权会抛出什么异常？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.5.子图管理

TuGraph 支持多子图，子图之间完全独立，不同的子图可以对不同用户开放不同权限。管理员可以添加和删除子图。  
#### 6.5.1.创建新子图  
- **URI**: `/db`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | 子图名 | 字符串 |
| config | 配置 | 字典，格式为 { {列名 1}:{列值 1},... } |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""name"":""graph1"",
""config"" : {
""max_size_GB"":2048,
""description"": ""description of graph1""
}
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.5.2.删除子图  
- **URI**: `/db/{graph_name}`
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• DELETE http://localhost:7070/db/graph1
```  
**Example response.**  
```
• 200: OK
```  
#### 6.5.3.列出所有子图  
- **URI**: `/db`
- **METHOD**: GET
- **RESPONSE**: 子图列表  
**Example request.**  
```
• GET http://localhost:7070/db
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""graph1"": {
""max_size_GB"":1024,
""description"":""description of graph1""
}
}
```  
#### 6.5.4.获取子图信息  
- **URI**: `/db/{graph_name}`
- **METHOD**: GET
- **RESPONSE**: 子图列表  
**Example request.**  
```
• GET http://localhost:7070/db/graph1
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""max_size_GB"":1024,
""description"":""description of graph1""
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.5.子图管理'}","page_content='Cypher API

5.附录2. 内置procedures列表

* dbms.graph.deleteGraph(graph_name)

delete a subgraph in this graph database .  
| parameter  | parameter type | description              |
| ---------- | -------------- | ------------------------------------ |
| graph_name | string     | the name of subgraph to been deleted |  
**Output:**  
if successful , it will return true.  
**Example input:**  
```
CALL dbms.graph.deleteGraph('graph1')
```  
**Example output:**  
| success |
| ------- |
| true    |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* dbms.graph.deleteGraph(graph_name)'}"
在初始化每个节点的pagerank值时，当节点的出度大于0，pagerank值是如何计算的？,"page_content='OlapOnDB API

3. 算法举例

3.2 PageRank算法流程

`pagerank`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关数据结构的初始化
1. 每个节点pagerank值的初始化
1. 每个节点pagerank值的计算，活跃点为所有点（意味着所有点都需要计算pagerank值）
1. 得到每个节点经过`num_iterations`次迭代后的pagerank值  
```C++
void PageRankCore(OlapBase<Empty>& graph, int num_iterations, ParallelVector<double>& curr) {

// 相关数据结构的初始化
auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
auto curr = olapondb.AllocVertexArray<double>();
auto next = olapondb.AllocVertexArray<double>();
size_t num_vertices = olapondb.NumVertices();
double one_over_n = (double)1 / num_vertices;

// 每个节点pagerank值的初始化，和该节点的出度成反比
double delta = graph.ProcessVertexActive<double>(
[&](size_t vi) {
curr[vi] = one_over_n;
if (olapondb.OutDegree(vi) > 0) {
curr[vi] /= olapondb.OutDegree(vi);
}
return one_over_n;
},
all_vertices);

// 总迭代过程
double d = (double)0.85;
for (int ii = 0;ii < num_iterations;ii ++) {
printf(""delta(%d)=%lf\n"", ii, delta);
next.Fill((double)0);

/*
函数用途：计算所有节点的pagerank值

函数流程描述：该函数用于计算所有节点的pagerank值，对all_vertices中所有为1的位对应的节点vi执行Func C，得到本轮迭代中vi的pagerank值，并返回vi节点的pagerank变化值，最终经过函数内部处理汇总所有活跃节点的总变化值并返回，该值被存储在delta变量中
*/
delta = graph.ProcessVertexActive<double>(
// Func C
[&](size_t vi) {
double sum = 0;

// 从邻居中获取当前节点的pagerank值
for (auto & edge : olapondb.InEdges(vi)) {
size_t src = edge.neighbour;
sum += curr[src];
}
next[vi] = sum;

// pagerank值计算核心公式
next[vi] = (1 - d) * one_over_n + d * next[vi];
if (ii == num_iterations - 1) {
return (double)0;
} else {

// 相关中间变量统计
if (olapondb.OutDegree(vi) > 0) {
next[vi] /= olapondb.OutDegree(vi);
return fabs(next[vi] - curr[vi]) * olapondb.OutDegree(vi);
} else {
return fabs(next[vi] - curr[vi]);
}
}
},
all_vertices
);

// 将本轮迭代得到的pagerank值输出作为下一轮迭代的输入
curr.Swap(next);
}
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.2 PageRank算法流程'}","page_content='内置算法

扩展算法包

个性化网页排序

个性化网页排序程序实现了Personalized PageRank算法。该算法根据给定的源点，基于该源点个性化计算所有点对于源点的重要性排名。Rank值越高，表示该点对于源点越重要。与PageRank不同的是，初始化时源点Rank值为1，其余点Rank值为0；并且每轮传递结束后，Rank值会有一定的比例随即传递回源点。算法内容请参考 [https://cs.stanford.edu/people/plofgren/Fast-PPR_KDD_Talk.pdf](https://cs.stanford.edu/people/plofgren/Fast-PPR_KDD_Talk.pdf)。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': '个性化网页排序'}","page_content='典型示例

PageRank动态图计算示例介绍

PageRank的定义

PageRank算法最初作为互联网网页重要度的计算方法，1996年由Page和Brin提出，并用于谷歌搜索引擎的网页排序。事实上，PageRank 可以定义在任意有向图上，后来被应用到社会影响力分析、文本摘要等多个问题。
假设互联网是一个有向图，在其基础上定义随机游走模型，即一阶马尔可夫链，表示网页浏览者在互联网上随机浏览网页的过程。假设浏览者在每个网页依照连接出去的超链接以等概率跳转到下一个网页，并在网上持续不断进行这样的随机跳转，这个过程形成一阶马尔可夫链。PageRank表示这个马尔可夫链的平稳分布。每个网页的PageRank值就是平稳概率。
算法实现思路：1.假设图中每个点的初始影响值相同；2.计算每个点对其他点的跳转概率，并更新点的影响值；3.进行n次迭代计算，直到各点影响值不再变化，即收敛状态。' metadata={'Header 1': '典型示例', 'Header 2': 'PageRank动态图计算示例介绍', 'Header 3': 'PageRank的定义'}"
TuGraph 支持哪些数据导出格式？,"page_content='TuGraph图模型说明

1. 数据模型

1.2. 数据类型

TuGraph支持多种可用于属性的数据类型。具体支持的数据类型如下：  
| **数据类型** | **最小值**          | **最大值**          | **描述**                            |
| ------------ | ------------------- | ------------------- | ----------------------------------- |
| BOOL         | false               | true                | 布尔值                              |
| INT8         | -128                | 127                 | 8位整型                          |
| INT16        | -32768              | 32767               | 16位整型                         |
| INT32        | - 2^31              | 2^31 - 1            | 32位整型                         |
| INT64        | - 2^63              | 2^63 - 1            | 64位整型                         |
| DATE         | 0000-00-00          | 9999-12-31          | ""YYYY-MM-DD"" 格式的日期             |
| DATETIME     | 0000-00-00 00:00:00.000000 | 9999-12-31 23:59:59.999999 | ""YYYY-MM-DD HH:mm:ss[.ffffff]"" 格式的日期时间 |
| FLOAT        |                     |                     | 32位浮点数                       |
| DOUBLE       |                     |                     | 64位浮点数                       |
| STRING       |                     |                     | 不定长度的字符串                    |
| BLOB         |                     |                     | 二进制数据（在输入输出时使用Base64编码） |
| POINT        |                     |                     | EWKB格式数据，表示点              |
| LINESTRING   |                     |                     | EWKB格式数据，表示线              |
| POLYGON      |                     |                     | EWKB格式数据，表示面(多边形)       |
| FLOAT_VECTOR |                     |                     | 包含32位浮点数的动态向量               |' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.2. 数据类型'}","page_content='功能概览

6.生态工具

6.1.TuGraph DataX

![导入导出](../../../images/tugraph-datax.png)  
TuGraph 核心支持 CSV 和 JSON 合适的导入导出，提供空库导入和增量导入的模式。实际中会存在 MySQL、Kafka、Hive 等多数据源导入的需求，TuGraph 通过 DataX 做多数据源的对接。由于关系模型和图模型存在的差异，数据清洗的流程可以使用 SparkSQL 快速处理，TuGraph 本身仅关注 CSV 和 JSON 的简单场景导入可靠性和性能。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.1.TuGraph DataX'}","page_content='数据导出

1.简介

TuGraph 可以通过 `lgraph_export` 工具来对已经存放在TuGraph的图数据进行数据导出。 `lgraph_export` 工具可以将指定 TuGraph 数据库的数据以 `csv` 或者 `json` 文件形式导出到指定目录，同时导出这些数据进行再导入时需要的配置文件 `import.config` ，详细描述可参见[配置文件](1.data-import.md)。' metadata={'Header 1': '数据导出', 'Header 2': '1.简介'}"
"启动TuGraph的时候报这个错误：0x00007f7e5f272900 FATAL include/fma-common/binary_buffer.h:289] CHECK(gpos_ + size <= ppos_)      failedreading beyond the array: required size=4, actual size=2","page_content='TuGraph-Restful-Server

7.接口

7.5 上传文件请求

用户通过此类请求向server发送文件，可以对文件进行分片，分片大小不大于1MB，支持多线程乱序发送，请求报文在http header 中包含文件名，第一字节内容在文件中的偏移和分片大小，在body中包含文件内容，server收到请求后将验证分片大小是否与分片内容一致，一致时将文件分段写入文件。不一致时将返回errorCode为400的响应
#### 7.5.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/upload_files  
#### 7.5.2 REQUEST
| header参数  |    参数说明    |  参数类型  |  是否必填  |
|:---------:|:----------:|:------:| :-----: |
| File-Name |   文件名   |  字符串  |  是  |
| Begin-Pos | 开始位置在文件内的偏移 |  字符串  |  是  |
|   Size    | 文件分片大小 |  字符串  |  是  |
|  body参数   |  参数说明   |  参数类型  |  是否必填  |
|     -     | 文件内容 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.5 上传文件请求'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='环境准备

1.硬件环境

1.3. 外存

我们强烈建议用户使用 NVMe SSD 作为外存，数据库有大量的写操作需要同步的外存，通常为随机写，外存的读写性能很容易成为整体数据库运行的性能瓶颈。因此，高IOPS、低延迟的 NVMe SSD 是最优的选择。  
如果现实条件只能使用 SATA接口的SSD，或者云上的网盘，性能虽然会受到影响，但 TuGraph 依然能正确的运行。  
外存大小建议为实际数据大小的4倍，比如数据为1TB，则准备4TB的硬盘会比较稳妥。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.3. 外存'}"
如果在FrontierTraversal中开启了TRAVERSAL_PARALLEL标志，事务必须是怎样的？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterato' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends Gra' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentric function进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |  
- 详细接口  
```java
public interface VertexCentricTraversalFunction<K, VV, EV, M, R> extends VertexCentricFunction<K, VV
, EV, M> {

void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);
/** 图遍历算法初始化方法 */
void init(ITraversalRequest<K> traversalRequest);
/** 实现图遍历逻辑 */
void compute(K vertexId, Iterator<M> messageIterator);

void finish();

void close();

interface VertexCentricTraversalFuncContext<K, VV, EV, M, R> extends VertexCentricFuncContext<K,
VV, EV, M> {
/** 获取图遍历结果 */
void takeResponse(ITraversalResponse<R> response);
/** 获取开始图遍历的点 */
TraversalVertexQuery<K, VV> vertex();
/** 获取开始图遍历的边 */
TraversalEdgeQuery<K, EV> edges();

void broadcast(IGraphMessage<K, M> message);
}

interface TraversalVertexQuery<K, VV> extends VertexQuery<K, VV> {
/** 获取图遍历中点的迭代器 */
Iterator<K> loadIdIterator();
}

interface TraversalEdgeQuery<K, EV> extends EdgeQuery<K, EV> {
/** 通过指定的点id，获取对应的图遍历起点 */
TraversalEdgeQuery<K, EV> withId(K vertexId);
}
}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}"
使用 CSV 文件导入数据时，文件中的栏位与配置文件中的 columns 如何对应？,"page_content='数据导入

3.配置文件

3.2.配置文件示例

```json
{
""schema"": [
{
""label"": ""actor"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""aid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" }
],
""primary"": ""aid""
},
{
""label"": ""movie"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""mid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" },
{ ""name"": ""year"", ""type"": ""INT16"" },
{ ""name"": ""rate"", ""type"": ""FLOAT"", ""optional"": true }
],
""primary"": ""mid"",
""detach_property"": false
},
{
""label"": ""play_in"",
""type"": ""EDGE"",
""properties"": [{ ""name"": ""role"", ""type"": ""STRING"", ""optional"": true }],
""constraints"": [[""actor"", ""movie""]]
}
],
""files"": [
{
""path"": ""actors.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""actor"",
""columns"": [""aid"", ""name""]
},
{
""path"": ""movies.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""movie"",
""columns"": [""mid"", ""name"", ""year"", ""rate""]
},
{
""path"": ""roles.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""play_in"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
对于上述配置文件，定义了三个 label：两个点类型`actor`和`movie`，一个边类型`role`。每个 label 都描述了：label 的名字、类型（点还是边）、属性字段有哪些以及每个字段的类型。对于点，另外定义了 primary 字段是哪个；对于边，另外定义了 constraints 字段，用来限制边的起点和终点只能是哪些组合。  
还描述了三个数据文件，两个点的数据文件`actors.csv`和`movies.csv`，一个边的数据文件`roles.csv`。每个部分都描述了：文件的路径（path）、数据类型（format）、信息头占开头几行（header）、是哪个 label 的数据（label）、文件中每行数据中的每个列对应的字段是哪个。  
对于上述配置文件，import 工具在执行的过程中会先在 TuGraph 中创建`actor`、`movie`、`role`这三个 label，然后再执行三个文件的数据导入。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.2.配置文件示例'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='数据导入

3.配置文件

`lgraph_import`工具通过指定的配置文件进行环境配置。配置文件描述输入文件的路径、它们所代表的点/边以及点/边的格式。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件'}"
在创建一个顶点标签时，需要指定哪些参数？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.createLabel(label_type, label_name, extra, field_spec...)

Create a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| extra      | string     | for edge, it means constraints; for vertex, it means primary property |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.
for edge, `extra` should be a json array string, like this `[[""label1"",""label2""], [""label3"",""label4""]]`, if edge has no constraints, give an empty json array, like this `[]`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createLabel('vertex', 'new_label', 'id', ['id','int32',false], ['name','string', true]);
CALL db.createLabel('edge', 'new_edge', '[[""id1"",""id2""]]', ['id','int32',false], ['name', 'string', true]);
```  
**Example output:**  
```
Vertex label [new_label] successfully added.
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createLabel(label_type, label_name, extra, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createEdgeLabel( label_name, field_spec...)

Create an edge label.  
**Parameters:**  
| parameter  | parameter type | description          |
| ---------- | -------------- | ------------------------ |
| label_name | string     | name of the label    |
| edge_constraints | string | edge constraints |
| field_spec | list       | specification of a field |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`, where optional is specified as true, only for  optional fields.  
`edge_constraints` is a json array string, This parameter limits the combination of starting and ending vertex of the edge, for example: `'[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]'`, which limits the edge direction can only be from `vertex_label1` to `vertex_label2` or from `vertex_label3` to `vertex_label4`. If you don't want to have any constraints, give an empty array string, like this `'[]'`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createEdgeLabel('KNOWS', '[]', 'name', 'int32', true)
```  
**Example output:**  
```
Added type [KNOWS]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createEdgeLabel( label_name, field_spec...)'}","page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

TuGraph 是一个具备多图能力的强模式属性图数据库。在每一张子图中，每种点和边都需要有预定义的数据格式。数据格式由 Label 决定，每种 Label 都有自己的数据格式。用户可以使用 REST API 添加，删除和查询 Label 及其对应的数据格式。  
Label 操作对应的 URI 格式为  
```
http://{host}:{port}/db/{graph_name}/label/{type}/{label_name}
```  
其中{type}可以是 node 或者 relationship。  
#### 6.6.1.创建Label  
创建 Label 的过程同时也是定义其数据类型的过程。只有创建了 Label 才能在图中插入相应类型的点或者边。  
- **URI**: `/db/{graph_name}/label`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | Label 名 | 字符串 |
| fields | 数据列定义 | 列表 |
| is_vertex | 是否是点 Label | 布尔值 |
| primary | 点的主键属性 | 字符串 |
| edge_constraints | 边的约束 | 列表 |  
`primary` 在 `is_vertex` 为 `true` 的时候设置，这个字段只有点才有, 创建点的时候必须设置。  
`edge_constraints` 在 `is_vertex` 为 `false` 的时候设置，这个字段只有边有。这个字段限制了该边的起点和终点只能是哪些点的组合，比如：`[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]`，限制了该边只能是从 `vertex_label1` 到 `vertex_label2` 和 从 `vertex_label3` 到 `vertex_label4`。如果不想有任何限制，不设置该字段即可。  
其中`fields`为一个数组，其中每个元素定义数据的一列，内容如下：  
| 域名     | 说明                                     | 类型                                                                                                |
| -------- | ---------------------------------------- | --------------------------------------------------------------------------------------------------- |
| name     | 列名                                     | 字符串                                                                                              |
| type     | 列数据类型                               | 字符串，有以下类型： int8, int16, int32, int64, float, double, string, date, datetime, binary, bool |
| optional | 数据是否可以为空（可选，缺省值为 false） | 布尔值                                                                                              |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/label
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""name"":""Actor"",
""fields"": [
{""name"":""uid"", ""type"":""int64' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}"
TuGraph Browser 的默认端口号是什么？,"page_content='可视化操作手册

2.操作指南

2.1.访问

当用户完成图数据库的安装后，可以通过浏览器访问Browser。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7070。  
- 例如：127.0.0.1:7070。
- 推荐使用Chrome。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.1.访问'}","page_content='可视化操作手册（旧版）

操作详情

1.连接数据库

当用户完成图数据库的安装后，可以通过浏览器进行访问，TuGraph Browser 工具。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7090。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '1.连接数据库'}","page_content='可视化操作手册

2.操作指南

2.2.登录

![login](../../../images/browser/login.png)  
- 浏览器成功访问Browser后，首先进入的是登录页面（如上图所示），用户需要填写账号和密码进行登录。
- 数据库地址格式为：ip:bolt_port。
- 默认账号：admin。
- 默认密码：73@TuGraph。
- 用户首次登录后，会跳转至修改密码页面，密码修改成功后，使用新密码重新登录即可使用。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.2.登录'}"
在配置中，用于计算图表中显示的值的方法是什么？,"page_content='可视化操作手册

2.操作指南

2.4.图项目

`图项目`提供可视化的图项目管理和图数据研发功能，它为用户提供了一系列便捷的图数据可视化操作，包括图项目的创建、修改、删除等管理操作，以及图数据的查询、点边统计等操作。此外，它也支持图模型的管理，使用户可以更加方便地进行图数据的管理和维护。  
#### 2.4.1.图项目管理  
在`图项目`界面，可以看到当前图数据库中的图项目。  
![图项目-首页](../../../images/browser/graphmanagement-homepage.png)  
##### 2.4.1.1.新建图项目  
在`图项目`界面，点击`新建图项目`按钮创建一个新的图项目。  
![图项目-新建图项目按钮](../../../images/browser/graphmanagement-creategraph.png)  
新建图项目需要通过`选择模板`和`填写配置`两个页面完成图项目的创建。  
- __选择模板__：产品提供空模板和demo模板两类模板。
- 空模板：全新的图项目，用户需要自己创建图模型和导入图数据，一般用于正式项目开发。
- demo模板：产品内置的demo数据，图项目创建成功后，系统会自动创建demo图模型并导入demo图数据，一般用于试用和学习。  
![图项目-选择模板](../../../images/browser/graphmanagement-selecttemplate.png)  
- __填写配置__：用户需要填写图项目基本信息，并点击`创建`按钮创建图项目。
- 图名称：新建图项目的名称，同时作为该图项目的唯一主键。支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图描述：新建图项目的描述，可用于详细说明该项目的背景和目标。
- 高级配置-最大存储空间：设置图项目最大可占用的存储空间，实际并不会提前占用物理存储空间，实际数据量达到最大存储空间阈值后不可再写入数据。  
![图项目-填写配置](../../../images/browser/graphmanagement-configure.png)  
创建成功后，可在`图项目`页面的图项目选项卡中查看。  
##### 2.4.1.2.编辑图项目  
在`图项目`界面，点击图项目选项卡中的`编辑`按钮（笔形图标），编辑对应图项目的基础信息。  
![图项目-编辑图项目按钮](../../../images/browser/graphmanagement-editgraph-button.png)  
编辑图项目功能可以修改`图描述`和`最大存储空间`。  
![图项目-编辑图项目](../../../images/browser/graphmanagement-editgraph.png)  
##### 2.4.1.3.删除图项目  
在`图项目`界面，点击图项目选项卡中的`删除`按钮（垃圾桶图标），删除对应的图项目。  
![图项目-删除图项目按钮](../../../images/browser/graphmanagement-deletegraph-button.png)  
_需要注意：图项目删除后无法恢复_。  
##### 2.4.1.4.点边统计  
在`图项目`界面，点击图项目选项卡中的`点边统计`按钮（刷新图标），统计对应图项目当前时间节点的点边数量。  
![图项目-点边统计按钮](../../../images/browser/graphmanagement-statistics-button.png)  
统计结果将展示在图项目选项卡上，已经统计过点边数据的图项目再次统计需要点击`刷新`按钮。  
![图项目-点边统计](../../../images/browser/graphmanagement-statistics.png)  
![图项目-刷新点边统计按钮](../../../images/browser/graphmanagement-statistics-refresh-button.png)  
##### 2.4.1.5.存储过程  
在`图项目`界面，点击图项目选项卡中的`存储过程`按钮（卡片最右侧图标），跳转到操作存储过程的图页面。  
![图项目-存储过程按钮](../../../images/browser/graphmanagement-procedure-button.png)  
在`存储过程`页面，可以新建存储过程，新建时需要填写""存储过程名称""、""存储过程类型""、""存储过程描述""，然后选择""版本""和""执行时是否修改数据库""  
![图项目-存储过程](../../../images/browser/graph' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='数据库运行

4.服务配置

TuGraph 服务器在启动时从配置文件和命令行选项加载配置，如果在配置文件和命令行中同一选项指定了不同的值，将优先使用命令行中指定的值。' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置'}","page_content='OlapOnDisk API

3. 其他常用函数功能描述

3.2 图写入

- `void Write(ConfigBase<EdgeData> & config, ParallelVector<VertexData>& array, size_t array_size, std::string name, std::function<bool(VertexData &)> filter_output = filter_output_default<VertexData&>)`：把array中数据写回文件中，各参数表示意义分别是：
- `config`：需要加载的配置参数。该参数内保存了该图的一般信息（如数据来源，算法名称，数据输入、输出路径，点个数等）以及根据不同数据来源、不同算法所配置的不同信息参数。
- `array`：待写入数据的数组
- `array_size`：待写入数据的数字长度
- `name`：算法名称
- `filter_output`：写入数据规则函数，待写入数据需要满足该函数的要求。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '3. 其他常用函数功能描述', 'Header 3': '3.2 图写入'}"
TuGraph是由哪个团队开发的？,"page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。  
蚂蚁集团 2015 年开始自主研发分布式图数据库、流式图计算等图相关技术，2016 年发布自研分布式图数据库，并应用于支付宝。至今 TuGraph 已应用于蚂蚁内部 150 多个场景，包括在线支付的实时链路，以支付宝风险识别能力提升近 10 倍、风险审理分析效率提升 90%的成绩，验证了其高可靠性。  
LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，TuGraph 在功能完整性、吞吐率、响应速度等层面全球领先。  
目前，蚂蚁集团已形成了一套以图数据库为底座、同时包含流式图计算，离线图学习的大规模图计算系统。  
蚂蚁集团图数据库负责人洪春涛表示，图技术是未来大数据、人工智能和高性能计算产业发展的关键所在，它很有可能会成为下一代的数据底座。蚂蚁集团愿意通过开源持续输出核心技术优势，推动图数据库更广泛的应用生态，携手行业抢占技术高地，不断探索技术的可能性。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}"
图学习系统是解决什么问题的？,"page_content='Learn Tutorial

1.TuGraph 图学习模块简介

图学习是一种机器学习方法，其核心思想是利用图结构中的拓扑信息，通过顶点之间的联系及规律来进行数据分析和建模。不同于传统机器学习方法，图学习利用的数据形式为图结构，其中顶点表示数据中的实体，而边则表示实体之间的关系。通过对这些顶点和边进行特征提取和模式挖掘，可以揭示出数据中深层次的关联和规律，从而用于各种实际应用中。  
这个模块是一个基于图数据库的图学习模块，主要提供了四种采样算子：Neighbor Sampling、Edge Sampling、Random Walk Sampling 和 Negative Sampling。这些算子可以用于对图中的顶点和边进行采样，从而生成训练数据。采样过程是在并行计算环境下完成的，具有高效性和可扩展性。  
在采样后，我们可以使用得到的训练数据来训练一个模型。该模型可以用于各种图学习任务，比如预测、分类等。通过训练，模型可以学习到图中的顶点和边之间的关系，从而能够对新的顶点和边进行预测和分类。在实际应用中，这个模块可以被用来处理各种大规模的图数据，比如社交网络、推荐系统、生物信息学等。' metadata={'Header 1': 'Learn Tutorial', 'Header 2': '1.TuGraph 图学习模块简介'}","page_content='名词解释

2.图产品

> __图计算系统__：一般包括图数据库、图分析系统、图学习系统，有时也特指图分析系统。  
> __图数据库__：侧重于对图数据的增删改查、事务性操作等，如TuGraph DB、Neo4j、JanusGraph等。  
> __图分析系统__：解决图分析问题，可以细分为流水图分析、离线图分析，如TuGraph Analytics、GraphX等。  
> __图学习系统__：解决图学习问题，比如TuGraph Learn、DGL等。' metadata={'Header 1': '名词解释', 'Header 2': '2.图产品'}","page_content='TuGraph在图计算系统建设中的作用

TuGraph 技术优势

蚂蚁自己开发了一套图计算系统 TuGraph，既能解决图数据的存储问题，也能解决流式计算、离线计算和图学习的问题。目前，超过 100 个业务线和 300 多个场景都在使用这套系统。这套系统在 2021 年获得了世界互联网大会领先科技成果奖。  
在 TuGraph 中，性能是一个重要的因素，因为图数据集的体积很大，如果性能不佳就会浪费机器资源，导致许多情况下无法完成任务。比如，希望业务的查询能在几十毫秒内返回结果，但是如果做的性能不好，几秒钟才能返回结果，就无法作为在线查询使用。因此，我们是非常对性能是很重视的，其中在 LDBC-SNB 标准测试中（类似于数据库领域性能标准测试 TPC-C），TuGraph 仍然是世界纪录的保持者。  
TuGraph 的整个图存储是建立在完美哈希的基础上的，这是我们与其他图系统的一个重要区别。目前，大多数图系统使用的是基于数的存储，但数的问题在于永远存在一个 LogN 的查找操作。然而，在图中可以看到，不同的顶点之间实际上是无序的，不需要有顺序，所以顶点这个级别实际上是基于哈希的，理论上，顶点的读取是最优的。  
此外，TuGraph 还参与了许多标准的定制，整个系统在尽量往标准化的方向去做。  
除了为内部提供服务，我们还向外提供服务，主要是因为，作为一个系统，如果只为有限的客户提供服务，就很容易构建成一个专有系统。我们希望这是一个标准化、开放的系统，所以我们也在对外提供图计算系统的产品和服务。目前，我们也有很多外部客户，包括金融、工业、互联网以及政企领域。  
开源开放，共建发展  
整个图计算系统目前仍处于较早期的阶段，我们认为还有很多工作要做，包括提升应用性、性能和降低成本。所有的系统都会有这些问题。但是，如果希望普及，我们认为最重要的是有健康的生态，来推动图计算系统的发展，需要有更多的用户和更多的场景使用这个系统。  
所有的计算机系统都需要去有一个更开放、更大的生态才能促进发展。蚂蚁有一句话叫做“成熟一个、开放一个”，一个系统成熟以后，我们就会试着开放出去，让更多的人去用。今年 9 月，我们已经在 GitHub 上开源了 TuGraph 中的单机版图数据库，以及一个离线图分析引擎 TuGraph Compute。分布式图数据库和流式图计算现在已经包含在我们的商业化版本中，包括一站式图研发平台。我们计划在未来迭代更多更丰富的系统功能，希望能做得更好。' metadata={'Header 1': 'TuGraph在图计算系统建设中的作用', 'Header 2': 'TuGraph 技术优势'}"
VertexIterator GetVertexByUniqueCompositeIndex函数需要哪些参数？,"page_content='动态图

示例

```java
public class IncrGraphCompute {

private static final Logger LOGGER = LoggerFactory.getLogger(IncrGraphCompute.class);

public static void main(String[] args) {
Environment environment = EnvironmentFactory.onLocalEnvironment();
IPipelineResult result = submit(environment);
result.get();
environment.shutdown();
}

public static IPipelineResult<?> submit(Environment environment) {
final Pipeline pipeline = PipelineFactory.buildPipeline(environment);
final String graphName = ""graph_view_name"";
GraphViewDesc graphViewDesc = GraphViewBuilder.createGraphView(graphName)
.withShardNum(4)
.withBackend(BackendType.RocksDB)
.withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class, Integer.class, ValueEdge.class, IntegerType.class))
.build();
pipeline.withView(graphName, graphViewDesc);
pipeline.submit(new PipelineTask() {
@Override
public void execute(IPipelineTaskContext pipelineTaskCxt) {
Configuration conf = pipelineTaskCxt.getConfig();
PWindowSource<IVertex<Integer, Integer>> vertices =
// extract vertex from edge file
pipelineTaskCxt.buildSource(new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IVertex<Integer, Integer> vertex1 = new ValueVertex<>(
Integer.valueOf(fields[0]), 1);
IVertex<Integer, Integer> vertex2 = new ValueVertex<>(
Integer.valueOf(fields[1]), 1);
return Arrays.asList(vertex1, vertex2);
}), SizeTumblingWindow.of(10000));

PWindowSource<IEdge<Integer, Integer>> edges =
pipelineTaskCxt.buildSource( new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IEdge<Integer, Integer> edge = new ValueEdge<>(Integer.valueOf(fields[0]),
Integer.valueOf(fields[1]), 1);
return Collections.singletonList(edge);
}), SizeTumblingWindow.of(5000));

PGraphView<Integer, Integer, Integer> fundGraphView = pipelineTaskCxt.getGraphView(graphName);

PIncGraphView<Integer, Integer, Integer> incGraphView = fundGraphView.appendGraph(vertices, edges);
incGraphView.i' metadata={'Header 1': '动态图', 'Header 2': '示例'}","page_content='动态图

示例

```java
public class IncrGraphTraversalAll {

private static final Logger LOGGER =
LoggerFactory.getLogger(IncrGraphTraversalAll.class);

public static void main(String[] args) {
Environment environment = EnvironmentFactory.onLocalEnvironment();
Pipeline pipeline = PipelineFactory.buildPipeline(environment);
String graphName = ""graph_view_name"";
GraphViewDesc graphViewDesc = GraphViewBuilder.createGraphView(graphName)
.withShardNum(2)
.withBackend(BackendType.RocksDB)
.withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class, Integer.class, ValueEdge.class, IntegerType.class))
.build();
pipeline.withView(graphName, graphViewDesc);
pipeline.submit(new PipelineTask() {
@Override
public void execute(IPipelineTaskContext pipelineTaskCxt) {
PWindowSource<IVertex<Integer, Integer>> vertices =
pipelineTaskCxt.buildSource(new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IVertex<Integer, Integer> vertex1 = new ValueVertex<>(
Integer.valueOf(fields[0]), 1);
IVertex<Integer, Integer> vertex2 = new ValueVertex<>(
Integer.valueOf(fields[1]), 1);
return Arrays.asList(vertex1, vertex2);
}), SizeTumblingWindow.of(10000));

PWindowSource<IEdge<Integer, Integer>> edges =
pipelineTaskCxt.buildSource( new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IEdge<Integer, Integer> edge = new ValueEdge<>(Integer.valueOf(fields[0]),
Integer.valueOf(fields[1]), 1);
return Collections.singletonList(edge);
}), SizeTumblingWindow.of(5000));

PGraphView<Integer, Integer, Integer> fundGraphView =
pipelineTaskCxt.getGraphView(graphName);
PIncGraphView<Integer, Integer, Integer> incGraphView =
fundGraphView.appendGraph(vertices, edges);
incGraphView.incrementalTraversal(new IncGraphTraversalAlgorithms(3))
.start()
.sink(v -> {});
}
});
IPipelineResult result = pipeline.execute();
result.get();
}

public static class IncGraphTraversalAlgorithms extends IncVertexCentricTraversal<Integer,
' metadata={'Header 1': '动态图', 'Header 2': '示例'}","page_content='Python Olap API

5. lgraph_db API

VertexIndexIterator

- `GetVid()-> int64_t`: 获取点的vid' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'VertexIndexIterator'}"
rpc port怎么配置？,"page_content='RPC API

2.请求

2.1.建立连接

开发者向TuGraph服务发送RPC请求，首先要建立连接。以C++语言为例，开发者创建指定url的通道（channel），
由通道创建指定的服务存根（LGraphRPCService_Stub），后续即可通过存根像调用本地方法一样向远程
服务器发送请求。  
```C++
std::shared_ptr<lgraph_rpc::m_channel_options> options = std::make_shared<lgraph_rpc::m_channel_options>();
options->protocol = ""baidu_std"";
options->connection_type = """";
options->timeout_ms = 60 * 60 * 1000 /*milliseconds*/;
options->max_retry = 3;
std::string load_balancer = """";
std::shared_ptr<lgraph_rpc::m_channel> channel = std::make_shared<lgraph_rpc::m_channel>();
if (channel->Init(url.c_str(), load_balancer, options.get()) != 0)
throw RpcException(""Fail to initialize channel"");
LGraphRPCService_Stub stub(channel.get());
```' metadata={'Header 1': 'RPC API', 'Header 2': '2.请求', 'Header 3': '2.1.建立连接'}","page_content='RPC API

3.登录

登录请求信息包含以下参数：
- user: 必要参数，用户名
- pass: 必要参数，密码
以C++为例，用户使用构建好的服务存根发送登录请求：
```C++
auto* req = request.mutable_acl_request();
auto* auth = req->mutable_auth_request()->mutable_login();
auth->set_user(user);
auth->set_password(pass);
// send data
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req->set_client_version(server_version);
req->set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), req, &resp, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
token = res.acl_response().auth_response().token();
```
登录响应信息包含以下参数：
- token: 必要参数，登录成功会收到带有签名的令牌，即 Json Web Token，客户端储存该令牌，并且用于以后的每次发送请求。
如果登录失败会收到“Authentication failed”错误。' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}","page_content='RPC API

1.简介

TuGraph 提供丰富的 RPC API，以供开发者通过 RPC 请求远程调用 TuGraph 提供的服务。  
RPC（远程过程调用）是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。
相比REST，RPC 面向方法，主要用于函数方法的调用，可以适合更复杂通信需求的场景，且性能更高。
brpc是用c++语言编写的工业级RPC框架，基于brpc，TuGraph 提供了丰富的RPC API，本文档描述
TuGraph 的 RPC API 使用方式。' metadata={'Header 1': 'RPC API', 'Header 2': '1.简介'}"
图数据库在处理关联关系时相比关系型数据库有什么优势？,"page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.1. 性能

在关联关系处理上，使用关系型数据库不可避免地要使用表的JOIN操作，这会对性能产生较大影响；而图数据库则直接跳转访问类指针，操作关联数据的效率更高，比关系型数据库提高2到4个数量级的性能。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.1. 性能'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.3. 直观性

使用图的方式表达现实世界的关系更直接和自然，在万物互联的时代尤为突出。如果使用关系型数据，先建立实体表，再建立关系表，最后映射数据，需要高度的抽象思维。在图数据上进行分析查询时，可以直观地通过点边连接的拓扑结构找到所需数据，无需任何专业知识。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.3. 直观性'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.2. 兼容性

现实中，项目进程通常不断演变，数据的内容甚至数据格式也在不断变化。在关系型数据库中，这意味着表结构的变化或建立多个新表，对源数据的修改非常大。而在图数据库中，仅需添加新的点、边和属性，并将其设置为对应的类型即可。从本质上说，一个表代表一种类型的数据，一个点代表一个特定的数据。这意味着关系型数据库更关注数据类型，而图数据库更关注数据个体及其关联关系。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.2. 兼容性'}"
使用TuGraph Browser时，默认的登录密码是什么？,"page_content='可视化操作手册

2.操作指南

2.2.登录

![login](../../../images/browser/login.png)  
- 浏览器成功访问Browser后，首先进入的是登录页面（如上图所示），用户需要填写账号和密码进行登录。
- 数据库地址格式为：ip:bolt_port。
- 默认账号：admin。
- 默认密码：73@TuGraph。
- 用户首次登录后，会跳转至修改密码页面，密码修改成功后，使用新密码重新登录即可使用。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.2.登录'}","page_content='可视化操作手册（旧版）

操作详情

2.登录数据库

![alt 登录](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/1.tugraph-browser-lpgin.png)  
- 页面打开成功会，首先进图的是登录页面，用户需要填写账号和密码进行登录。
- 默认账号：admin
- 默认密码：73@TuGraph
- 建议用户登录后，及时修改初始化的密码' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '2.登录数据库'}","page_content='TuGraph-Restful-Server

7.接口

7.1 用户登陆

用于用户第一次与服务端通信时的鉴权操作，请求报文在 http body 中携带用户名和密码，响应报文在 http body 中会返回一个带有有效期的token，后续请求中需要在http header中携带该token作为凭证
#### 7.1.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/login
#### 7.1.2 REQUEST
|  body参数  |  参数说明  |  参数类型  |  是否必填  |
|:--------:|:------:|:------:| :-----: |
| userName |  用户名  |  字符串  |  是  |
| password |   密码   |  字符串  |  是  |
#### 7.1.3 RESPONSE
|    body参数     | 参数说明  |  参数类型  |  是否必填  |
|:-------------:|:-----:|:------:| :-----: |
| authorization | token |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.1 用户登陆'}"
SetFields函数的第一个版本中，field_value_strings参数的数据类型是什么？,"page_content='业务开发指南

点类型操作

点类型添加字段

>该操作会同步变更所有该类型点的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于点类型`node1`，一次添加了两个字段：`field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是0.
```
CALL db.alterLabelAddFields('vertex', 'node1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '点类型操作', 'Header 3': '点类型添加字段'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

Adds specified fields to the label.  
**Parameters:**  
| parameter    | parameter type | description           |
| ---------------- | -------------- | ------------------------- |
| label_type       | string     | either 'vertex' or 'edge' |
| label_name       | string     | name of the label     |
| field_value_spec | list       | specification of a field  |  
in which each `field_value_spec` is a list of string in the form of `[field_name, field_type, field_value, optional]`, where: `field_value` is the default value of the field.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelAddFields(
'vertex',
'new_label',
['birth_date', DATE, '', true],
['img', BLOB, '', true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}","page_content='业务开发指南

边类型操作

边类型添加字段

>该操作会同步变更所有该类型边的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于边类型`edge1`，一次添加了两个字段: `field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是`0`.
```
CALL db.alterLabelAddFields('edge', 'edge1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型添加字段'}"
DB和tuGraph Analytics是独立运行吗？,"page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。  
蚂蚁集团 2015 年开始自主研发分布式图数据库、流式图计算等图相关技术，2016 年发布自研分布式图数据库，并应用于支付宝。至今 TuGraph 已应用于蚂蚁内部 150 多个场景，包括在线支付的实时链路，以支付宝风险识别能力提升近 10 倍、风险审理分析效率提升 90%的成绩，验证了其高可靠性。  
LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，TuGraph 在功能完整性、吞吐率、响应速度等层面全球领先。  
目前，蚂蚁集团已形成了一套以图数据库为底座、同时包含流式图计算，离线图学习的大规模图计算系统。  
蚂蚁集团图数据库负责人洪春涛表示，图技术是未来大数据、人工智能和高性能计算产业发展的关键所在，它很有可能会成为下一代的数据底座。蚂蚁集团愿意通过开源持续输出核心技术优势，推动图数据库更广泛的应用生态，携手行业抢占技术高地，不断探索技术的可能性。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}","page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}"
RpcClient 构造函数需要什么参数用于用户登录？,"page_content='RPC API

3.登录

登录请求信息包含以下参数：
- user: 必要参数，用户名
- pass: 必要参数，密码
以C++为例，用户使用构建好的服务存根发送登录请求：
```C++
auto* req = request.mutable_acl_request();
auto* auth = req->mutable_auth_request()->mutable_login();
auth->set_user(user);
auth->set_password(pass);
// send data
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req->set_client_version(server_version);
req->set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), req, &resp, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
token = res.acl_response().auth_response().token();
```
登录响应信息包含以下参数：
- token: 必要参数，登录成功会收到带有签名的令牌，即 Json Web Token，客户端储存该令牌，并且用于以后的每次发送请求。
如果登录失败会收到“Authentication failed”错误。' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}","page_content='TuGraph-Restful-Server

7.接口

7.1 用户登陆

用于用户第一次与服务端通信时的鉴权操作，请求报文在 http body 中携带用户名和密码，响应报文在 http body 中会返回一个带有有效期的token，后续请求中需要在http header中携带该token作为凭证
#### 7.1.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/login
#### 7.1.2 REQUEST
|  body参数  |  参数说明  |  参数类型  |  是否必填  |
|:--------:|:------:|:------:| :-----: |
| userName |  用户名  |  字符串  |  是  |
| password |   密码   |  字符串  |  是  |
#### 7.1.3 RESPONSE
|    body参数     | 参数说明  |  参数类型  |  是否必填  |
|:-------------:|:-----:|:------:| :-----: |
| authorization | token |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.1 用户登陆'}","page_content='C++客户端

2.使用示例

2.1.实例化client对象

引入依赖并实例化  
#### 2.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
``` C++
RpcClient client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
RpcClient(const std::string& url, const std::string& user, const std::string& password);
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```  
#### 2.1.2.实例化HA集群直接连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化
``` C++
RpcClient client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
RpcClient(const std::string& url, const std::string& user, const std::string& password);
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 2.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化。
```java
std::vector<std::string> urls = {""189.33.97.23:9091"", ""189.33.97.24:9091"", ""189.33.97.25:9091""};
TuGraphDbRpcClient client = new TuGraphDbRpcClient(urls, ""admin"", ""73@TuGraph"");
```
```
RpcClient(std::vector<std::string>& urls, std::string user, std::string password)
@param urls: tugraph host list
@param user: login user name
@param password: login password
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.1.实例化client对象'}"
如何使用lgraph_cypher工具在命令行中以单命令模式提交一条Cypher查询并保存结果？,"page_content='命令行工具

1.单命令模式

在单命令模式下，`lgraph_cypher`可用于提交单个 Cypher 查询并将结果直接打印到终端，打印结果也可以容易地重定向写入指定文件。当用户需要从服务器获取大量结果并将其保存在文件中时，这非常便利。
在此模式下，`lgraph_cypher`工具具有以下选项：' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式'}","page_content='命令行工具

1.单命令模式

1.2.命令示例:

**cypher 命令文件查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -f /home/usr/cypher.json
```  
**cypher 命令单句查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -s ""MATCH (n) RETURN n""
```' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式', 'Header 3': '1.2.命令示例:'}","page_content='命令行工具

2.交互模式

2.2.command种类与说明:

除 Cypher 查询外，`lgraph_cypher` 的 shell 还接受以下命令：  
| 命令                     | 对应参数                           | 说明                                                                                                |
| ------------------------ | ---------------------------------- | --------------------------------------------------------------------------------------------------- |
| :help                    | \\                                 | 显示服务器信息与所有 command 对应说明。                                                             |
| :db_info                 | \\                                 | 当前服务器状态查询。对应 REST API 的/db/info。                                                      |
| :clear                   | \\                                 | 清空屏幕。                                                                                          |
| :use                     | {图的名称}                         | 使用该名称指定的图，默认值为`default` 。                                                            |
| :source                  | `-t {查询timeout值} -f {查询文件}` | 可交互模式下的 cypher 命令文件查询。超时阈值默认值为`150`秒。查询文件格式参考无交互式查询参数。     |
| :exit                    | \\                                 | 退出交互模式并返回原命令行。                                                                        |
| :format                  | `plain` or `table`                 | 更改 cypher 查询结果的显示模式。支持`plain`与`table`模式。                                          |
| :save all/command/result | `-f {文件路径}` `{cypher语句}`     | 存储 cypher 命令（command）或查询结果（result）或以上二者（all）。默认存储位置为`/saved_cypher.txt` |  
**注意:**  
- 每条命令都应该以冒号开始 `:`.  
**:save 命令例子:**  
```
:save all -f /home/usr/saved.txt match (n) where return n, n.name limit 1000
```' metadata={'Header 1': '命令行工具', 'Header 2': '2.交互模式', 'Header 3': '2.2.command种类与说明:'}"
数据和日志目录的持久化位置在哪里？,"page_content='安装指南

一键安装

数据存储配置

配置GeaFlow作业、图、表等数据的持久化存储，推荐使用HDFS。本地模式默认为容器内磁盘。
![install_storage_config](../../static/img/install_storage_config.png)' metadata={'Header 1': '安装指南', 'Header 2': '一键安装', 'Header 3': '数据存储配置'}","page_content='日志信息

2.服务器日志

2.1.服务器日志配置项

服务器日志的输出位置可以通过`log_dir`配置指定。服务器日志详细程度可通过`verbose`配置项指定。  
`log_dir`配置项默认为空。若`log_dir`配置项为空，则所有日志会输出到控制台(daemon模式下若log_dir配置项为空则不会向console输出任何日志)；若手动指定`log_dir`配置项，则日志文件会生成在对应的路径下面。单个日志文件最大大小为256MB。  
`verbose`配置项控制日志的详细程度，从粗到细分为`0, 1, 2`三个等级，默认等级为`1`。等级为`2`时，日志记录最详细，服务器将打印`DEBUG`及以上等级的全部日志信息；等级为`1`时，服务器将仅打印`INFO`等级及以上的主要事件的日志；等级为`0`时，服务器将仅打印`ERROR`等级及以上的错误日志。' metadata={'Header 1': '日志信息', 'Header 2': '2.服务器日志', 'Header 3': '2.1.服务器日志配置项'}","page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}"
TuGraph 的 Traversal API 当中对于遍历的起始点设置有哪三种方式？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterato' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

1. 简介

TuGraph 强大的在线分析处理（OLAP）能力是其区别于其它图数据库的一个重要特性。
借助 C++ OLAP API（olap_on_db.h），用户可以快速地导出一个需要进行复杂分析的子图，然后在其上运行诸如 PageRank、连通分量、社区发现等迭代式图计算过程，最后根据结果做出相应决策。
导出和计算的过程都可以通过并行处理的方式进行加速，从而实现几乎实时的分析处理，避免了传统解决方案需要将数据导出、转换、再导入（ETL）到专门的分析系统进行离线处理的冗长步骤。  
TuGraph 内置了大量常用的图分析算法和丰富的辅助接口，因此用户几乎不需要自己来实现具体的图计算过程，只需在实现自己的存储过程时将相应算法库的头文件（.h 文件）包含到自己程序中，并在编译时链接相应的动态库文件（.so）即可。
一般情况下，用户需要自己实现的只有将需要分析的子图抽取出来的过程。  
目前 Traversal API 仅支持 C++。' metadata={'Header 1': 'Traversal API', 'Header 2': '1. 简介'}","page_content='Procedure API

1.简介

当用户需要表达的查询/更新逻辑较为复杂（例如 Cypher 无法描述，或是对性能要求较高）时，相比调用多个请求并在客户端完成整个处理流程的方式，TuGraph 提供的存储过程是更简洁和高效的选择。  
与传统数据库类似，TuGraph 的存储过程运行在服务器端，用户通过将处理逻辑（即多个操作）封装到一个过程单次调用，并且可以在实现时通过并行处理的方式（例如使用相关的 C++ OLAP 接口以及基于其实现的内置算法）进一步提升性能。  
存储过程中有一类特殊的API来进行数据的并行操作，我们叫 Traversal API，见[文档](2.traversal.md)。' metadata={'Header 1': 'Procedure API', 'Header 2': '1.简介'}"
方法 `SetField` 的目的是什么？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

Adds specified fields to the label.  
**Parameters:**  
| parameter    | parameter type | description           |
| ---------------- | -------------- | ------------------------- |
| label_type       | string     | either 'vertex' or 'edge' |
| label_name       | string     | name of the label     |
| field_value_spec | list       | specification of a field  |  
in which each `field_value_spec` is a list of string in the form of `[field_name, field_type, field_value, optional]`, where: `field_value` is the default value of the field.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelAddFields(
'vertex',
'new_label',
['birth_date', DATE, '', true],
['img', BLOB, '', true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelModFields(label_type, label_name, field_spec...)

Modifies the specified fields in the label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.The target field should exist.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelModFields(
'vertex',
'new_label',
['birth_date', DATETIME, true],
['gender', BOOL, true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelModFields(label_type, label_name, field_spec...)'}","page_content='自定义函数

Create Function

这个命令用来引入一个自定义函数。  
**Syntax**
```
CREATE FUNCTION <function name> AS <implementation class>
```  
**Example**
```sql
CREATE FUNCTION mysssp AS 'com.antgroup.geaflow.dsl.udf.graph.SingleSourceShortestPath';
```' metadata={'Header 1': '自定义函数', 'Header 2': 'Create Function'}"
TuGraph-DB图数据库是由哪个团队开发的？,"page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}","page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。  
蚂蚁集团 2015 年开始自主研发分布式图数据库、流式图计算等图相关技术，2016 年发布自研分布式图数据库，并应用于支付宝。至今 TuGraph 已应用于蚂蚁内部 150 多个场景，包括在线支付的实时链路，以支付宝风险识别能力提升近 10 倍、风险审理分析效率提升 90%的成绩，验证了其高可靠性。  
LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，TuGraph 在功能完整性、吞吐率、响应速度等层面全球领先。  
目前，蚂蚁集团已形成了一套以图数据库为底座、同时包含流式图计算，离线图学习的大规模图计算系统。  
蚂蚁集团图数据库负责人洪春涛表示，图技术是未来大数据、人工智能和高性能计算产业发展的关键所在，它很有可能会成为下一代的数据底座。蚂蚁集团愿意通过开源持续输出核心技术优势，推动图数据库更广泛的应用生态，携手行业抢占技术高地，不断探索技术的可能性。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}"
TuGraph 的精简运行环境需要哪些系统库？,"page_content='环境分类

2.依赖系统库

针对三种环境，除去TuGraph的运行包，所需要的系统库如下：
* 编译环境，包括gcc、python、java等编译器，也包含antlr4、pybind11等，具体参见tugraph-db源码目录 ci/images/tugraph-compile-*-Dockerfile。
* 运行环境，主要由存储过程引入，包括gcc、boost、cmake等，具体参见tugraph-db源码目录 ci/images/tugraph-runtime-*-Dockerfile。
* 精简运行环境，无，可以参见tugraph-db源码目录 ci/images/ tugraph-mini-runtime-*-Dockerfile。' metadata={'Header 1': '环境分类', 'Header 2': '2.依赖系统库'}","page_content='环境和版本选择

2. 环境能力选择

用户可以根据实际使用场景，来选择不同的环境。编译环境的能力最完备，所需的第三方软件也越多。与其相对应的，精简运行环境几乎不需要安装任何依赖库，能运行TuGraph除存储过程外的基础功能。  
| 环境     | 用途             | 备注        |
|--------|----------------|-----------|
| 编译环境   | 从源码编译TuGraph   | 适用于开发人员   |
| 运行环境   | 运行TuGraph安装包   | 适用于大部分用户  |
| 精简运行环境 | 运行精简TuGraph安装包 | 对系运行统依赖较小 |  
不同环境的具体介绍参见 [链接](../5.installation&running/2.environment-mode.md)。' metadata={'Header 1': '环境和版本选择', 'Header 2': '2. 环境能力选择'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}"
函数 SetFrontier(std::function<bool(VertexIterator&)> root_vertex_filter) 是如何利用参数 root_vertex_filter 的？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterato' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Cypher API

3.Functions

3.3.Scalar functions

- id()
get the id of vertex.
**Scope:** whole instance.
**Example input:**  
```
MATCH (a)
RETURN id(a)
```  
**Example output:**  
| vid |
| --- |
| 1   |
| 2   |
| ... |  
- properties()
get a map containing all the properties of a node or relationship.
**Scope:** whole instance.
**Example input:**  
```
MATCH (n:person {name: 'Laurence Fishburne'})
RETURN n
```  
- head()
get the first element of a list.
**Scope:** whole instance.
**Example input:**  
```
WITH ['one','two','three'] AS coll RETURN coll, head(coll)
```  
**Example output:**  
| coll                  | head(coll)    |
| --------------------- | ------------- |
| [""one"",""two"",""three""] | ""one""         |  
- last()
get the last element of a list.
**Scope:** whole instance.
**Example input:**  
```
WITH ['one','two','three'] AS coll RETURN coll, last(coll)
```  
**Example output:**  
| coll                  | last(coll)    |
| --------------------- | ------------- |
| [""one"",""two"",""three""] | ""three""       |  
- toFloat()
Converts an integer or string value to a floating point number.
**Scope:** whole instance.
**Example input:**  
```
RETURN toFloat('11.5')
```  
**Example output:**  
| float |
| ----- |
| 11.5  |  
- toInteger()
Converts a floating point or string value to an integer value.
**Scope:** whole instance.
**Example input:**  
```
RETURN toInteger('2.3') AS integer
```  
**Example output:**  
| integer |
| ------- |
| 2       |  
- toString()
Converts an integer, float, boolean value to a string.
**Scope:** whole instance.
**Example input:**  
```
RETURN toString(2.3)
```  
- type()
get the string representation of the relationship type.
**Scope:** whole instance.
**Example input:**  
```
MATCH (n)-[r]->()
WHERE n.name = 'Laurence Fishburne'
RETURN type(r)
```  
**Example output:**  
| type     |
| -------- |
| acted_in |
| acted_in |' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.3.Scalar functions'}","page_content='Python Olap API

6. 算法插件示例

下面为Python实现的BFS算法的代码示例：
```python
# cython: language_level=3, cpp_locals=True, boundscheck=False, wraparound=False, initializedcheck=False
# distutils: language = c++

# 注释作用如下：
# language_level=3: 使用Python3
# cpp_locals=True: 需要c++17，使用std::optional管理Python代码中的C++对象，可以避免C++对象的拷贝构造
# boundscheck=False: 关闭索引的边界检查
# wraparound=False: 关闭负数下标的处理（类似Python List）
# initializedcheck=False: 关闭检查内存是否初始化，关闭检查后运行性能更快
# language = c++: 将此py文件翻译为C++而不是C文件，TuGraph使用大量模板函数，所以都应该使用C++

import json

import cython
from cython.cimports.olap_base import *
from cython.cimports.lgraph_db import *
# 从procedures/algo_cython/ 中cimportolap_base.pxd与lgraph_db.pxd, 类似C++中#include ""xxx.h""

from cython.cimports.libc.stdio import printf
# 类似C++中#include <stdio.h>
# 其他常见的还有cython.cimports.libcpp.unordered_map等

import time


@cython.cclass
# cython.cclass 表示BFSCore为C类型的Class
class BFSCore:
graph: cython.pointer(OlapBase[Empty])
# cython.pointer(OlapBase[Empty])表示OlapBase[Empty]的指针，类似C++中OlapBase[Empty]*
# cython提供了常见类型的指针，如cython.p_int, cython.p_char等，表示int*, char*, ...
parent: ParallelVector[size_t]
active_in: ParallelBitset
active_out: ParallelBitset
root: size_t
# root: size_t 声明root为C++ size_t类型变量，等效于root = cython.declare(size_t)
# 不声明类型的变量为Python object类型
# 声明变量类型会大幅提高性能，同时在多线程部分，只有C/C++类型的变量可以访问

@cython.cfunc
# cython.cfunc 表示Work为C类型的函数，参数与返回值应声明
# cfunc性能好，能接受C/C++对象为参数、返回值，但是不能在其他python文件中调用
# 类似的有cython.ccall，如Standalone函数，可以在其他python文件中调用
@cython.nogil
# cython.nogil 表示释放Python全局解释锁，在nogil修饰的部分，不能访问Python对象
# 在多线程部分，都应有nogil修饰器
@cython.exceptval(check=False)
# cython.exceptval(check=False) 表示禁用异常传播，将忽略函数内部引发的Python异常
def Work(self, vi: size_t) -> size_t:
degree = cython.declare(size_t, self.graph.OutDegree(vi))
out_edges = cython.declare(AdjList[Empty], self.graph.OutEdges(vi))
i = cython.declare(size_t, 0)
local_num_activations = cython.declare(size_t, 0)
dst: size_t
for i in range(degree):
dst = out_edges[i].neighbour
if self.parent[dst] == cython.cast(size' metadata={'Header 1': 'Python Olap API', 'Header 2': '6. 算法插件示例'}"
rpm包中包含新版前端页面资源吗？,"page_content='快速上手

2.安装

2.2.新旧前端说明

进入容器，可以通过修改配置文件""/usr/local/etc/lgraph.json""中的""web""参数来选择使用老版本或新版本的前端。对于老版本，可以将""web""的值设为""/usr/local/share/lgraph/resource""；对于新版本，可以将""web""的值设为""/usr/local/share/lgraph/browser-resource""。完成配置文件的修改后，请执行命令 `docker restart tugraph` 以使更改生效。需要注意的是，新版本是默认选项。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.2.新旧前端说明'}","page_content='功能概览

5.客户端工具

客户端主要分为各种编程语言的SDK，OGM以及命令行工具。  
客户端 SDK 主要用于二次开发，可以通过 RPC 或 REST 协议链接服务端。RPC 基于长链接有较好的性能，数据需要通过 protobuf 统一序列化。TuGraph 使用brpc，支持 Java、Python、C++ 的 rpc 客户端。REST 的协议比较宽泛，能够简单适配更加多样的环境，不同的编程语言能够简单对接。TuGraph 给出了 Python 的REST 客户端实例，命令行的交互也是用 REST 实现。  
OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。  
命令行工具`lgraph_cypher`是查询客户端，可用于向 TuGraph 服务器提交 OpenCypher 请求。`lgraph_cypher`客户端有两种执行模式：单命令模式和交互式模式。' metadata={'Header 1': '功能概览', 'Header 2': '5.客户端工具'}","page_content='TuGraph-Restful-Server

7.接口

7.2 刷新token

token到期后将无法使用此token与服务端正常通信，需要获取新的token作为后续请求的凭证，请求报文在http header中携带旧的token，响应报文在http body中返回新的token
#### 7.2.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/refresh
#### 7.2.2 REQUEST
|   header参数    |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| Authorization | 旧的token |  字符串  |  是  |  
#### 7.2.3 RESPONSE
|    body参数     |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| authorization | 新的token |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.2 刷新token'}"
请问一下镜像 tugraph-runtime-centos7启动大概需要多少资源,"page_content='文档地图

TuGraph最新版本

| 描述                  | 文件                                         | 链接                                                                                                                                                                                              |
|---------------------|--------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| CentOS7 安装包         | tugraph-4.5.0-1.el7.x86_64.rpm             | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.5.0/tugraph-4.5.0-1.el7.x86_64.rpm)                                                                                      |
| CentOS8 安装包         | tugraph-4.5.0-1.el8.x86_64.rpm             | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.5.0/tugraph-4.5.0-1.el8.x86_64.rpm)                                                                                      |
| Ubuntu18.04 安装包     | tugraph-4.5.0-1.x86_64.deb                 | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.5.0/tugraph-4.5.0-1.x86_64.deb)                                                                                          |
| CentOS7 预安装镜像       | tugraph-runtime-centos7-4.5.0.tar          | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.5.0/tugraph-runtime-centos7-4.5.0.tar) 、[访问](https://hub.docker.com/r/tugraph/tugraph-runtime-centos7)                   |
| CentOS8 预安装镜像       | tugraph-runtime-centos8-4.5.0.tar          | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.5.0/tugraph-runtime-centos8-4.5.0.tar) 、[访问](https://hub.docker.com/r/tugraph/tugraph-runtime-centos8)                   |
| Ubuntu18.04 预安装镜像   | tugraph-runtime-ubuntu18.04-4.5.0.tar      | [下载](https://tugraph-web.oss-cn-beijing.aliyuncs.com/tugraph/tugraph-4.' metadata={'Header 1': '文档地图', 'Header 2': 'TuGraph最新版本'}","page_content='TuGraph-db

2. 快速上手

一个简单的方法是使用docker进行设置，可以在DockerHub)中找到, 名称为`tugraph/tugraph-runtime-[os]:[tugraph version]`,
例如， `tugraph/tugraph-runtime-centos7:3.3.0`。  
更多详情请参考 [快速上手文档](和 [业务开发指南]' metadata={'Header 1': 'TuGraph-db', 'Header 2': '2. 快速上手'}","page_content='Docker部署

2.现有Docker Image

2.4. M1芯片支持

在 M1 芯片的机器上运行 amd64 容器可能造成未知错误。TuGraph提供 arm64 的镜像供 M1 机器使用。
包含compile和runtime两种镜像。  
在`tugraph-runtime-centos7:3.6.0`与`tugraph-compile-centos7:1.2.7`及之后，`tugraph-runtime-centos7`与`tugraph-compile-centos7`提供linux/amd64和linux/arm64/v8两种架构的镜像，可以在 M1 机器上通过docker pull获取arm64架构镜像。' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.4. M1芯片支持'}"
当创建组合索引时，需要提供哪些参数？,"page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='Vector index

创建向量索引

如下json定义了一个点类型，名字是`person`, 里面有个字段是`embedding`，类型是`FLOAT_VECTOR`，用来存储向量数据。
目前向量数据只能在点上创建。  
```json
{
""label"": ""person"",
""primary"": ""id"",
""type"": ""VERTEX"",
""properties"": [{
""name"": ""id"",
""type"": ""INT32"",
""optional"": false
}, {
""name"": ""age"",
""type"": ""INT32"",
""optional"": false
}, {
""name"": ""embedding"",
""type"": ""FLOAT_VECTOR"",
""optional"": false
}]
}

```
把上面这个json序列化成字符串，作为参数传入，建议使用驱动的参数化特性，避免自己拼接语句。
```
CALL db.createVertexLabelByJson($json_data)
```
给`embedding`字段添加向量索引，第三个参数是个map，里面可以设置一些向量索引的配置参数，如下，`dimension`设置向量维度是4
```
CALL db.addVertexVectorIndex('person','embedding', {dimension: 4});
```  
再定义一个边，用来测试，如下json定义了一个边类型，名字是`like`。
```json
{
""label"": ""like"",
""type"": ""EDGE"",
""constraints"": [
[""person"", ""person""]
],
""properties"": []
}
```
把上面这个json序列化成字符串，作为参数传入。
```
CALL db.createEdgeLabelByJson($json_data)
```  
写入几条测试数据
```
CREATE (n1:person {id:1, age:10, embedding: [1.0,1.0,1.0,1.0]})
CREATE (n2:person {id:2, age:20, embedding: [2.0,2.0,2.0,2.0]})
CREATE (n3:person {id:3, age:30, embedding: [3.0,3.0,3.0,3.0]})
CREATE (n1)-[r:like]->(n2),
(n2)-[r:like]->(n3),
(n3)-[r:like]->(n1);
```' metadata={'Header 1': 'Vector index', 'Header 2': '创建向量索引'}"
函数 `SetField` 抛出的异常之一是什么？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

Adds specified fields to the label.  
**Parameters:**  
| parameter    | parameter type | description           |
| ---------------- | -------------- | ------------------------- |
| label_type       | string     | either 'vertex' or 'edge' |
| label_name       | string     | name of the label     |
| field_value_spec | list       | specification of a field  |  
in which each `field_value_spec` is a list of string in the form of `[field_name, field_type, field_value, optional]`, where: `field_value` is the default value of the field.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelAddFields(
'vertex',
'new_label',
['birth_date', DATE, '', true],
['img', BLOB, '', true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}","page_content='Geaflow支持以下逻辑运算：  
操作|描述
----------------------|------
boolean1 OR boolean2 | 如果boolean1为true或boolean2为true，则返回true。
boolean1 AND boolean2 | 仅在boolean1为true和boolean2为true时才返回true。
NOT boolean | 返回给定布尔变量的NOT操作的结果。
boolean IS FALSE | 如果布尔变量为false，则返回true。如果布尔变量是UNKNOWN，则返回false。
boolean IS NOT FALSE | 如果布尔变量为true，则返回true。如果布尔变量是UNKNOWN，则返回true。
boolean IS TRUE | 如果布尔变量为true，则返回true。如果布尔变量是UNKNOWN，则返回false。
boolean IS NOT TRUE | 如果布尔变量为false，则返回true。如果布尔变量是UNKNOWN，则返回true。
value1 = value2 | 如果value1等于value2，则返回true。
value1 <> value2 | 如果value1不等于value2，则返回true。
value1 > value2 | 如果value1大于value2，则返回true。
value1 >= value2 | 如果value1大于或等于value2，则返回true。
value1 < value2 | 如果value1小于value2，则返回true。
value1 <= value2 | 如果value1小于或等于value2，则返回true。
value IS NULL | 如果value为null，则返回true。
value IS NOT NULL | 如果value不为null，则返回true。
value1 IS DISTINCT FROM value2 | 如果value1与value2不同，则返回true。如果value1和value2都为null，则它们被视为相等。
value1 IS NOT DISTINCT FROM value2 | 如果value1等于value2，则返回true。如果value1和value2都为null，则它们被视为相等。
value1 BETWEEN value2 AND value3 | 如果value1大于或等于value2且小于value3，则返回true。
value1 NOT BETWEEN value2 AND value3 | 如果value1小于value2或大于或等于value3，则返回true。
string1 LIKE string2 [ ESCAPE string3 ] | 对字符串string1进行模糊匹配，如果匹配到模式string2则返回true，如果不匹配则返回false。
string1 NOT LIKE string2 [ ESCAPE string3 ] | 对字符串string1进行模糊匹配，如果匹配到模式string2则返回false，如果不匹配则返回true。
value IN (value [, value]* ) | 如果value等于列表中的任何一个值，则返回true。
value NOT IN (value [, value]* ) | 如果value不等于列表中的任何一个值，则返回true。'","page_content='GeaFlow支持**Case**和**If**条件函数。
* [Case](#Case)
* [If](#If)'"
TuGraphClient是什么？,"page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='TuGraph Management

简介

TuGraph Management 是一款为TuGraph开发的算法任务管理工具。采用了sofastack与brpc作为通信框架，并使用sqlite进行持久化存储。  
主要功能：  
- 算法任务状态持久化存储  
- 算法任务结果持久化存储  
- 延时触发与定时触发算法任务支持' metadata={'Header 1': 'TuGraph Management', 'Header 2': '简介'}"
TuGraph 支持哪些类型的硬件平台？,"page_content='快速上手

1.简介

1.1.支持的平台

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的的平台。' metadata={'Header 1': '快速上手', 'Header 2': '1.简介', 'Header 3': '1.1.支持的平台'}","page_content='环境准备

1.硬件环境

1.1. CPU

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的硬件平台，测试认证过的硬件平台包括 Intel、AMD、Kunpeng、Hygon、飞腾等。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.1. CPU'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}"
"我想问一下字节流导入点边数据的api：boolean ret = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000);前两个参数的格式，是不是和执行导入脚本一样","page_content='Java客户端

2.使用示例

2.12.从字节流中导入点边数据

```java
boolean ret = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000);
log.info(""importDataFromContent : "" + ret);
```
```
@param desc: data format description
@param data: the data to be imported
@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromContent(String desc, String data, String delimiter, boolean continueOnError,
int threadNums, String graph, double timeout) throws UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='Python客户端

3.RPC Client

3.12.从字节流中导入点边数据

```python
ret, res = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000)
```
```
importDataFromContent(self: liblgraph_client_python.client, desc: str, data: str, delimiter: str, continue_on_error: bool, thread_nums: int, graph: str, json_format: bool, timeout: float) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.12.从字节流中导入点边数据'}","page_content='C++客户端

2.使用示例

2.12.从字节流中导入点边数据

```C++
std::string str;
ret = client.ImportDataFromContent(str, sImportContent[""person_desc""], sImportContent[""person""],"","");
```
```
bool ImportDataFromContent(std::string& result, const std::string& desc,
const std::string& data, const std::string& delimiter,
bool continue_on_error = false, int thread_nums = 8,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0);
@param [out] result              The result.
@param [in]  desc                data format description.
@param [in]  data                the data to be imported.
@param [in]  delimiter           data separator.
@param [in]  continue_on_error   (Optional) whether to continue when importing data fails.
@param [in]  thread_nums         (Optional) maximum number of threads.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  timeout             (Optional) Maximum execution time, overruns will be
interrupted.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}"
什么标签和属性用于表示OGM中类的映射为一个边类型？,"page_content='TuGraph-OGM

简介

TuGraph-OGM(Object Graph Mapping), 源自 `Neo4j-OGM` 项目，TuGraph-OGM
支持将JAVA对象（POJO）映射到TuGraph中，JAVA中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此JAVA开发人员可以在熟悉的生态中轻松地使用TuGraph数据库。同时TuGraph-OGM兼容Neo4j-OGM，Neo4j生态用户可以无缝迁移到TuGraph数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '简介'}","page_content='TuGraph-OGM

1.简介

> TuGraph-OGM 项目在其他仓库开源。  
TuGraph-OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。同时 TuGraph-OGM 兼容 Neo4j-OGM，Neo4j 生态用户可以无缝迁移到 TuGraph 数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '1.简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.1 构建图对象**

首先需要通过注解标明图中的实体。  
@NodeEntity：该注解标明的类为节点类。  
@Relationship：用于标明边，同时@Relationship中可指定label与边的指向。  
@Id：用于标明identity，是OGM中数据的唯一标识。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.1 构建图对象**'}"
如果在对 DateTime 对象使用 operator+= 或 operator-= 运算时发生溢出，会如何处理？,"page_content='Java客户端

2.使用示例

2.12.从字节流中导入点边数据

```java
boolean ret = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000);
log.info(""importDataFromContent : "" + ret);
```
```
@param desc: data format description
@param data: the data to be imported
@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromContent(String desc, String data, String delimiter, boolean continueOnError,
int threadNums, String graph, double timeout) throws UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='C++客户端

2.使用示例

2.12.从字节流中导入点边数据

```C++
std::string str;
ret = client.ImportDataFromContent(str, sImportContent[""person_desc""], sImportContent[""person""],"","");
```
```
bool ImportDataFromContent(std::string& result, const std::string& desc,
const std::string& data, const std::string& delimiter,
bool continue_on_error = false, int thread_nums = 8,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0);
@param [out] result              The result.
@param [in]  desc                data format description.
@param [in]  data                the data to be imported.
@param [in]  delimiter           data separator.
@param [in]  continue_on_error   (Optional) whether to continue when importing data fails.
@param [in]  thread_nums         (Optional) maximum number of threads.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  timeout             (Optional) Maximum execution time, overruns will be
interrupted.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='数据导入

5.在线增量导入

在线导入模式可用于将一批文件导入已在运行中的 TuGraph 实例中。这对于处理通常以固定的时间间隔进行的增量批处理更新非常便利。`lgraph_import --online true`选项使导入工具能够在线模式工作。与`离线模式`一样，在线模式有自己的命令行选项集，可以使用`-h，--help`选项进行打印输出：  
```shell
$ lgraph_import --online true -h
Available command line options:
--online            Whether to import online.
-h, --help          Print this help message. Default=0.

Available command line options:
--log               Log file to use, empty means stderr. Default="""".
-v, --verbose       Verbose level to use, higher means more verbose.
Default=1.
-c, --config_file   Config file path.
-r, --url           DB REST API address.
-u, --username      DB username.
-p, --password      DB password.
-i, --continue_on_error
When we hit a duplicate uid or missing uid, should we
continue or abort. Default=0.
-g, --graph         The name of the graph to import into. Default=default.
--skip_packages     How many packages should we skip. Default=0.
--delimiter         Delimiter used in the CSV files
--breakpoint_continue
When the transmission process is interrupted,whether
to re-transmit from zero package next time. Default=false
-h, --help          Print this help message. Default=0.
```  
文件的相关配置在配置文件中指定，其格式与`离线模式`完全相同。但是，我们现在不是将数据导入本地数据库，而是将数据发送到正在运行的 TuGraph 实例中，该实例通常运行在与运行导入工具的客户端计算机不同的计算机上。因此，我们需要指定远程计算机的 HTTP 地址的URL、DB用户和密码。  
如果用户和密码有效，并且指定的图存在，导入工具将将数据发送到服务器，服务器随后解析数据并将其写入指定的图。数据将以大约 16MB 大小的包发送，在最近的换行符处中断。每个包都是以原子方式导入的，这意味着如果成功导入包，则成功导入所有数据，否则，任何数据都不会进入数据库。如果指定了`--continue_on_error true`，则忽略数据完整性错误，并忽略违规行。否则，导入将在第一个错误包处停止，并打印出已导入的包数。在这种情况下，用户可以修改数据以消除错误，然后使用`--skip_packages N`重做导入以跳过已导入的包。' metadata={'Header 1': '数据导入', 'Header 2': '5.在线增量导入'}"
AlterEdgeLabelAddFields函数成功执行的条件是什么？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

Adds specified fields to the label.  
**Parameters:**  
| parameter    | parameter type | description           |
| ---------------- | -------------- | ------------------------- |
| label_type       | string     | either 'vertex' or 'edge' |
| label_name       | string     | name of the label     |
| field_value_spec | list       | specification of a field  |  
in which each `field_value_spec` is a list of string in the form of `[field_name, field_type, field_value, optional]`, where: `field_value` is the default value of the field.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelAddFields(
'vertex',
'new_label',
['birth_date', DATE, '', true],
['img', BLOB, '', true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelModFields(label_type, label_name, field_spec...)

Modifies the specified fields in the label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.The target field should exist.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelModFields(
'vertex',
'new_label',
['birth_date', DATETIME, true],
['gender', BOOL, true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelModFields(label_type, label_name, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createLabel(label_type, label_name, extra, field_spec...)

Create a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| extra      | string     | for edge, it means constraints; for vertex, it means primary property |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.
for edge, `extra` should be a json array string, like this `[[""label1"",""label2""], [""label3"",""label4""]]`, if edge has no constraints, give an empty json array, like this `[]`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createLabel('vertex', 'new_label', 'id', ['id','int32',false], ['name','string', true]);
CALL db.createLabel('edge', 'new_edge', '[[""id1"",""id2""]]', ['id','int32',false], ['name', 'string', true]);
```  
**Example output:**  
```
Vertex label [new_label] successfully added.
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createLabel(label_type, label_name, extra, field_spec...)'}"
带权图的边权重是什么类型的数值？,"page_content='OlapBase API

6. 自定义数据结构

6.2 组合数据结构

为了便于计算，我们根据计算场景不同，定义了几种点和边数据的数据结构，分别是：  
- `EdgeUnit<EdgeData>`：表示权值类型为EdgeData的边，用于解析输入文件，包含三个成员变量：
- `size_t src`：边的起始点
- `size_t dst`：边的终点
- `EdgeData edge_data`：边的权值
- `AdjUnit<EdgeData>`：表示权值类型为EdgeData的边，用于批处理计算过程中，包含两个成员变量：
- `size_t neighbour`：边的邻居点
- `EdgeData edge_data`：边的权值
- `AdjList<EdgeData>`：权值类型为EdgeData的点的邻接表，常用于表示点的入边和出边集合，包含两个成员变量：
- `AdjUnit<T> * begin`：列表的起始指针
- `AdjUnit<T> * end`：列表的结束指针。begin和end的用法类似于vector容器的begin和end指针，可以使用这两个指针对邻接表进行循环访问。' metadata={'Header 1': 'OlapBase API', 'Header 2': '6. 自定义数据结构', 'Header 3': '6.2 组合数据结构'}","page_content='Python Olap API

4. Olap API

自定义数据结构

- `Empty`：内容为空的特殊数据类型。
- `EdgeUnit[EdgeData]`：表示权值类型为EdgeData的边，用于解析输入文件，包含三个成员变量：
- `src: size_t`：边的起始点
- `dst: size_t`：边的终点
- `edge_data: EdgeData`：边的权值
- `AdjUnit[EdgeData]`：表示权值类型为EdgeData的边，用于批处理计算过程中，包含两个成员变量：
- `neighbour: size_t`：边的邻居点
- `edge_data: EdgeData`：边的权值
- `AdjList[EdgeData]`：权值类型为EdgeData的点的邻接表，常用于表示点的入边和出边集合，包含两个成员变量：
- `begin()-> cython.pointer(AdjUnit[T])`：列表的起始指针
- `end()-> cython.pointer(AdjUnit[T])`：列表的结束指针。
- `operator[](i: size_t)-> AdjUnit[EdgeData]`: 下标为i的数据' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '自定义数据结构'}","page_content='Sampling API

3. 图采样算子介绍

3.3.Nagetive算子：

采用负采样算法，生成不存在边的子图。
```python
Process(db_: lgraph_db_python.PyGraphDB, olapondb: lgraph_db_python.PyOlapOnDB, feature_num: size_t, num_samples: size_t, NodeInfo: list, EdgeInfo: list)
```
参数列表：
db_: 图数据库实例。
olapondb: 图分析类。
feature_num: size_t类型，feature特征向量的长度。
num_samples: size_t类型，生成不存在边的数量。
NodeInfo: list类型，点属性字典的列表，表示点的元数据信息。
EdgeInfo: list类型，边属性字典的列表，表示边的元数据信息。
返回值： 无。' metadata={'Header 1': 'Sampling API', 'Header 2': '3. 图采样算子介绍', 'Header 3': '3.3.Nagetive算子：'}"
RPC 是一种如何工作的通信协议？,"page_content='RPC API

1.简介

TuGraph 提供丰富的 RPC API，以供开发者通过 RPC 请求远程调用 TuGraph 提供的服务。  
RPC（远程过程调用）是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。
相比REST，RPC 面向方法，主要用于函数方法的调用，可以适合更复杂通信需求的场景，且性能更高。
brpc是用c++语言编写的工业级RPC框架，基于brpc，TuGraph 提供了丰富的RPC API，本文档描述
TuGraph 的 RPC API 使用方式。' metadata={'Header 1': 'RPC API', 'Header 2': '1.简介'}","page_content='RPC API

2.请求

2.1.建立连接

开发者向TuGraph服务发送RPC请求，首先要建立连接。以C++语言为例，开发者创建指定url的通道（channel），
由通道创建指定的服务存根（LGraphRPCService_Stub），后续即可通过存根像调用本地方法一样向远程
服务器发送请求。  
```C++
std::shared_ptr<lgraph_rpc::m_channel_options> options = std::make_shared<lgraph_rpc::m_channel_options>();
options->protocol = ""baidu_std"";
options->connection_type = """";
options->timeout_ms = 60 * 60 * 1000 /*milliseconds*/;
options->max_retry = 3;
std::string load_balancer = """";
std::shared_ptr<lgraph_rpc::m_channel> channel = std::make_shared<lgraph_rpc::m_channel>();
if (channel->Init(url.c_str(), load_balancer, options.get()) != 0)
throw RpcException(""Fail to initialize channel"");
LGraphRPCService_Stub stub(channel.get());
```' metadata={'Header 1': 'RPC API', 'Header 2': '2.请求', 'Header 3': '2.1.建立连接'}","page_content='Token使用说明

3. 客户端发送Token相关请求介绍

客户端会两种协议处理相关请求，一种是REST，一种是RPC。' metadata={'Header 1': 'Token使用说明', 'Header 2': '3. 客户端发送Token相关请求介绍'}"
TuGraph中主键的作用是什么？,"page_content='TuGraph-OGM

简介

TuGraph-OGM功能

TuGraph-OGM提供以下函数操作TuGraph：  
| 功能                  | 用法                                                                               |
|---------------------|----------------------------------------------------------------------------------|
| 插入单个节点\边            | void session.save(T object)                                                      |
| 批量插入节点\边            | void session.save(T object)                                                      |
| 删除节点与对应边            | void session.delete(T object)                                                    |
| 删除指定label的全部节点      | void session.deleteAll(Class\<T> type)                                           |
| 清空数据库               | void purgeDatabase()                                                             |
| 更新节点                | void session.save(T newObject)                                                   |
| 根据id查询单个节点          | T load(Class<T> type, ID id)                                                     |
| 根据ids查询多个节点         | Collection\<T> loadAll(Class\<T> type, Collection<ID> ids)                       |
| 根据label查询全部节点       | Collection\<T> loadAll(Class\<T> type)                                           |
| 条件查询                | Collection\<T> loadAll(Class\<T> type, Filters filters)                          |
| Cypher查询（指定返回结果类型）  | T queryForObject(Class\<T> objectType, String cypher, Map<String, ?> parameters) |
| Cypher查询   | Result query(String cypher, Map<String, ?> parameters)                           |' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '简介', 'Header 3': 'TuGraph-OGM功能'}","page_content='可视化操作手册（旧版）

操作详情

3.工作台

#### 3.1 快速上手  
- 首次登录，系统会默认创建 default 空图  
![alt 快速上手](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/2.tugraph-browser-quickstart-01.png)  
- 用户点击帮助选项，并选择快速上手  
![alt 帮助](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/3.tugraph-browser-quickstart-02.png)  
- 然后点击“一键创建模型”——>""一键创建数据""，就可以完成内置的 Movie 数据图谱的构建  
#### 3.2 创建子图和示例  
##### 3.2.1 创建子图  
- 点击新建子图
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/4.tugraph-browser-create-subgraph-01.png)
- 填写表单信息
![alt 填写表单](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/5.tugraph-browser-create-subgraph-02.png)
- 子图名称
- 子图描述
- 配置信息
- 点击确认，提示创建成功
- 切换子图
![alt 切换子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/6.tugraph-browser-use-graph-01.png)  
- 点击新建示例
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/create-scene-01.png)
- 选择示例并点击创建
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/select-scene.png)  
#### 3.3 查询  
![alt 查询](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/7.tugraph-browser-query-01.png)  
##### 3.3.1 页面组成  
- cypher 输入框
- 结果集展示区域  
##### 3.3.2 结果集展示区域功能详情  
- 结果集标签展示及功能
![alt 结果集标签](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/tugraph-browser-result.png)
- 这里展示了结果集的所有类型统计
- 点击不同的“label（标签）”，可以进行以下修改操作
- 修改展示颜色
- 修改节点大小或边的粗细
- 修改默认展示属性或系统属性
- 布局修改
- 力导布局
- 网格布局
- 树形布局
- 环境布局
- 边聚合
- 相同类型，方向的边可以进行合并
- 创建节点
- 点击创建节点按钮
- 选择节点类型
- 添写节点内容
- 创建关系
- 在画布中选择起点和终点
- 选择可以匹配的类型
- 填写节点信息
- 停止布局
- 当数据量过大，导致浏览器页面卡顿时候，可以点击这个停止布局的按钮，能够提高体验的流畅度
- 鼠标悬停
- 开启此功能，可以高亮显示鼠标悬停节点的一度邻居节点
- 结果集导出
- 可以将结果集导出为 png，json，csv 三种不同的文件形式
- 刷新
- 点击刷新按钮，会重新执行当前页面的初始 cypher 语句，并刷新结果集
- 最大化
- 点击最大化，结果集展示区域将全屏展示
- 结果集展示形式切换
- 支持图谱、表格、文本三种形式  
###' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '3.工作台'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}"
RpcException是什么类型的异常？,"page_content='RPC API

3.登录

登录请求信息包含以下参数：
- user: 必要参数，用户名
- pass: 必要参数，密码
以C++为例，用户使用构建好的服务存根发送登录请求：
```C++
auto* req = request.mutable_acl_request();
auto* auth = req->mutable_auth_request()->mutable_login();
auth->set_user(user);
auth->set_password(pass);
// send data
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req->set_client_version(server_version);
req->set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), req, &resp, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
token = res.acl_response().auth_response().token();
```
登录响应信息包含以下参数：
- token: 必要参数，登录成功会收到带有签名的令牌，即 Json Web Token，客户端储存该令牌，并且用于以后的每次发送请求。
如果登录失败会收到“Authentication failed”错误。' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}","page_content='RPC API

1.简介

TuGraph 提供丰富的 RPC API，以供开发者通过 RPC 请求远程调用 TuGraph 提供的服务。  
RPC（远程过程调用）是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。
相比REST，RPC 面向方法，主要用于函数方法的调用，可以适合更复杂通信需求的场景，且性能更高。
brpc是用c++语言编写的工业级RPC框架，基于brpc，TuGraph 提供了丰富的RPC API，本文档描述
TuGraph 的 RPC API 使用方式。' metadata={'Header 1': 'RPC API', 'Header 2': '1.简介'}","page_content='RPC API

5.存储过程

5.1.加载存储过程

加载存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称
- read_only: 必要参数，是否只读
- code: 必要参数，存储过程文件读入生成的ByteString
- desc: 可选参数，存储过程描述
- code_type: 可选参数，存储过程代码类型，PY、SO、CPP、ZIP四者之一  
以C++为例，用户加载存储过程的方式如下所示：
```C++
std::string content;
if (!FieldSpecSerializer::FileReader(source_file, content)) {
std::swap(content, result);
return false;
}
LGraphRequest req;
req.set_is_write_op(true);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
pluginRequest->set_version(version);
lgraph::LoadPluginRequest* loadPluginRequest = pluginRequest->mutable_load_plugin_request();
loadPluginRequest->set_code_type([](const std::string& type) {
std::unordered_map<std::string, lgraph::LoadPluginRequest_CodeType> um{
{""SO"", lgraph::LoadPluginRequest::SO},
{""PY"", lgraph::LoadPluginRequest::PY},
{""ZIP"", lgraph::LoadPluginRequest::ZIP},
{""CPP"", lgraph::LoadPluginRequest::CPP}};
return um[type];
}(code_type));
loadPluginRequest->set_name(procedure_name);
loadPluginRequest->set_desc(procedure_description);
loadPluginRequest->set_read_only(read_only);
loadPluginRequest->set_code(content);
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
加载存储过程的响应不包含参数，如果加载失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.1.加载存储过程'}"
match语句中是否支持set多个属性,"page_content='Match

Syntax

```sql
MatchStatement: MATCH PathPatthern (',' PathPatthern)* [WHERE boolExpr]

PathPatthern: Node ([Edge] Node)*
Node: '(' Identifier [ ':' StringLiteral ] [ WHERE boolExpr] ')'
Edge: '-' '[' Identifier [ ':' StringLiteral ] [ WHERE boolExpr] ']' '-'
| '-' '[' Identifier [ ':' StringLiteral ] [ WHERE boolExpr] ']' '->'
| '<-' '[' Identifier [ ':' StringLiteral ] [ WHERE boolExpr] ']' '-'
```' metadata={'Header 1': 'Match', 'Header 2': 'Syntax'}","page_content='ISO GQL

2.Clauses

2.1.MATCH

`MATCH`子句式是GQL最基础的子句，几乎所有查询都是通过 `MATCH`展开。  
`MATCH`子句用于指定在图中搜索的匹配模式，用来匹配满足一定条件的点或者路径。  
#### 点查询  
##### 查询所有点  
```
MATCH (n)
RETURN n
```  
##### 查询特定标签的点  
```
MATCH (n:Person)
RETURN n
```  
##### 通过属性匹配点  
```
MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
##### 通过过滤条件匹配点  
```
MATCH (n:Person WHERE n.birthyear > 1910)
RETURN n.name LIMIT 2
```  
返回结果
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```  
#### 边查询  
##### 出边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1970)-[e]->(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""BORN_IN"",""m.name"":""London"",""n.name"":""Christopher Nolan""},{""label(e)"":""DIRECTED"",""m.name"":null,""n.name"":""Christopher Nolan""}]
```  
##### 入边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1939)<-[e]-(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""HAS_CHILD"",""m.name"":""Rachel Kempson"",""n.name"":""Corin Redgrave""},{""label(e)"":""HAS_CHILD"",""m.name"":""Michael Redgrave"",""n.name"":""Corin Redgrave""}]
```  
##### 带过滤条件的边匹配  
```
MATCH (n:Person)-[e:BORN_IN WHERE e.weight > 20]->(m)
RETURN n.name, e.weight, m.name
```  
返回结果
```JSON
[{""e.weight"":20.549999237060547,""m.name"":""New York"",""n.name"":""John Williams""},{""e.weight"":20.6200008392334,""m.name"":""New York"",""n.name"":""Lindsay Lohan""}]
```  
#### 路径匹配  
##### 不定跳查询  
```
MATCH (n:Person)-[e]->{2,3}(m:Person)
RETURN m.name LIMIT 2
```  
返回结果
```JSON
[{""m.name"":""Liam Neeson""},{""m.name"":""Natasha Richardson""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.1.MATCH'}","page_content='Continue-Match

Syntax

```sql
MatchStatement
MatchStatement
```' metadata={'Header 1': 'Continue-Match', 'Header 2': 'Syntax'}"
TuGraph DB关于Antlr4改进了哪些性能方面的内容？,"page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

贡献和成果

对Antlr4的优化的效果十分显著，32 线程的并发性能提升超过 18 倍 。考虑到实际生产服务器性能远高于测试机型，实际的性能提升效果将比测试结果更高， 优化后 GQL 解析能力已能完全满足企业业务的需要。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '贡献和成果'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

当 TuGraph 遇见 Antlr4

ISO GQL（ISO/IEC 39075）是一种标准化的图数据库查询语言，蚂蚁集团是其主要贡献者之一。因此，Antlr4 作为一种强大的解析器生成器，成为了蚂蚁图数据库 TuGraph 生成 GQL 解释器的理想选择。Antlr4 能够帮助团队更快、更准确地构建图数据库的查询语言，从而提高产品性能和用户体验。  
然而，当我们从开发场景来到生产场景，超高的并发量带来一个严重问题：Antlr4 C++ target 的并发性能不足以支持所需的超高并发 GQL 请求。经过调研并与 Antlr 开源社区讨论，我们发现\*\*并发性能这个问题普遍存在，并且在过去 5 年中持续困扰着 C++生态的开发者。\*\*我们决定解决这个问题。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '当 TuGraph 遇见 Antlr4'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

TuGraph做了哪些工作

在调研讨论的过程中我们发现，多位开发者在论坛提出其耗时甚至多于 Java target 数倍之多。因此，我们决定从问题和开源代码出发，来定位、解决问题。  
这是一个典型的并发程序优化问题，根据以往的程序优化经验，我们分步推进该问题的解决：  
（1）识别问题  
通过对程序运行时的性能数据进行收集和分析，我们找到了程序运行瓶颈所在，通过调用分析，初步将问题定位为数据竞争导致的并发问题。  
（2）深入阅读 Antlr4 开源代码  
接下来，我们对 Antlr4 的源代码进行仔细的阅读和理解，掌握其内部的结构和核心逻辑，找出了核心的数据结构和关键的调用链路。为我们破解性能难题和分析修改的正确性做好了准备。  
（3）梳理数据竞争链路  
根据上述分析，我们判断问题的症结极大概率是数据竞争造成的。形成数据竞争至少有两个条件：一是线程之间共享内存数据，二是至少存在两个线程去读写某个共享内存。  
进一步地，我们通过分析程序中的并发访问情况，找到了可能引发数据竞争的所有代码段和共享变量（主要为 DFA、ATN 等结构），拼接出了数据竞争的完整链路。  
（4）破解数据竞争问题  
数据竞争问题是多线程程序中常见而又复杂的问题，可以考虑通过破解多种竞争条件来解决。就本文问题来说，也存在多种破解方案选择，如何制定最优的解决方案是一项极具挑战的工作，主要难点有两个：  
（i）保证修改后程序的正确性/稳定性  
（ii）保证方案的有效性（低成本）  
反复推演后，我们选择了提交给社区的优化方案，即通过改变关键数据的 ownership 接触对锁的依赖。针对上述两个难点的分析如下：  
经过源码分析并与开源社区讨论，我们确认关键数据结构的初始化构建是非常耗时的，但可以通过“只调用一次”（`call_once`）手段将成本均摊，而后续的增量构建相对开销较低，并且也可均摊。因此该优化方案的低时间成本是可以保证的。  
关于程序正确性的保证，我们通过双重验证来保证。首先在设计之初我们已经从源代码角度，推断出共享数据仍然是安全的，其次我们也设计了实验对此进行了验证，验证结果与我们的分析一致' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': 'TuGraph做了哪些工作'}"
TuGraph 和 OpenCypher 在处理节点和关系的标签数量上有什么不同？,"page_content='Cypher API

4.附录1. 语法扩充及不同

TuGraph查询语言与OpenCypher的不同点如下：  
- Label数量
- TuGraph: Each node/relationship must have one and only one label. So error occurs when there is no label, and the 1st label will be picked as the label if there are more than one label.
- OpenCypher: One node/relationship may have 0 to many labels.
- Schema.
- TuGraph: TuGraph has strong schema
- OpenCypher: schema-less' metadata={'Header 1': 'Cypher API', 'Header 2': '4.附录1. 语法扩充及不同'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

简介

TuGraph 图数据库提供了 JAVA、C++、Python 等多种语言的 SDK 支持，方便客户在各种场景下使用。用户使用 SDK 向TuGraph服务器发送Cypher请求，服务器则以 JSON形式返回数据。近日，TuGraph 推出了一款面向 JAVA 客户端用户的开发工具 TuGraph-OGM (Object Graph Mapping)，为用户提供了对象操作接口，相较 Cypher/JSON 接口应用起来更加便捷。  
OGM 类似于关系数据库中的 ORM（Object Relational Model），可以将数据库返回的数据自动映射成 JAVA 中的对象，方便用户读取，而用户对这些对象的更新操作也可以被自动翻译成 Cypher 语句发送给服务器。这样即便是完全不懂 Cypher 的用户，也可以通过操作对象与数据库进行交互，大大降低了图数据库的使用门槛。  
TuGraph-OGM 同时也兼容其他开源产品 OGM 工具如 Neo4j-OGM，方便用户将工程在不同数据库与 TuGraph数据库间无缝迁移。本文将对 TuGraph-OGM 进行全面的介绍。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '简介'}"
函数DeleteVertexIndex成功执行时返回什么值？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.deleteLabel(label_type, label_name)

Delete a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |  
**Output:**  
| field_name | field_type | description              |
| ---------- | ---------- | -------------------------------- |
| affected   | integer    | number of vertexes/edges deleted |  
**Example input:**  
```
CALL db.deleteLabel('vertex', 'Person')
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.deleteLabel(label_type, label_name)'}","page_content='动态图

示例

```java
public class IncrGraphTraversalAll {

private static final Logger LOGGER =
LoggerFactory.getLogger(IncrGraphTraversalAll.class);

public static void main(String[] args) {
Environment environment = EnvironmentFactory.onLocalEnvironment();
Pipeline pipeline = PipelineFactory.buildPipeline(environment);
String graphName = ""graph_view_name"";
GraphViewDesc graphViewDesc = GraphViewBuilder.createGraphView(graphName)
.withShardNum(2)
.withBackend(BackendType.RocksDB)
.withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class, Integer.class, ValueEdge.class, IntegerType.class))
.build();
pipeline.withView(graphName, graphViewDesc);
pipeline.submit(new PipelineTask() {
@Override
public void execute(IPipelineTaskContext pipelineTaskCxt) {
PWindowSource<IVertex<Integer, Integer>> vertices =
pipelineTaskCxt.buildSource(new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IVertex<Integer, Integer> vertex1 = new ValueVertex<>(
Integer.valueOf(fields[0]), 1);
IVertex<Integer, Integer> vertex2 = new ValueVertex<>(
Integer.valueOf(fields[1]), 1);
return Arrays.asList(vertex1, vertex2);
}), SizeTumblingWindow.of(10000));

PWindowSource<IEdge<Integer, Integer>> edges =
pipelineTaskCxt.buildSource( new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IEdge<Integer, Integer> edge = new ValueEdge<>(Integer.valueOf(fields[0]),
Integer.valueOf(fields[1]), 1);
return Collections.singletonList(edge);
}), SizeTumblingWindow.of(5000));

PGraphView<Integer, Integer, Integer> fundGraphView =
pipelineTaskCxt.getGraphView(graphName);
PIncGraphView<Integer, Integer, Integer> incGraphView =
fundGraphView.appendGraph(vertices, edges);
incGraphView.incrementalTraversal(new IncGraphTraversalAlgorithms(3))
.start()
.sink(v -> {});
}
});
IPipelineResult result = pipeline.execute();
result.get();
}

public static class IncGraphTraversalAlgorithms extends IncVertexCentricTraversal<Integer,
' metadata={'Header 1': '动态图', 'Header 2': '示例'}","page_content='Cypher API

5.附录2. 内置procedures列表

* algo.algo.native.extract(id, config))

get the field values of a list of vertexes or edges.  
**Parameters:**  
| parameter | parameter type | description                        |
| --------- | -------------- | ---------------------------------------------------------- |
| id    | ANY        | the id of vertexes or edges , the id must be variable      |
| config    | MAP        | the configuration of  this extraction of vertexes or edges |  
in which each `config` is a map in the form of `{isNode:true, filed:'HAS_CHILD'}`, if `isNode` is specified true, the `id` is a vertex id, or  it is an edge id.  
**Output:**  
If successful, it returns a list of the value of vertexes or edges specified field .  
**Example input:**  
```
with [2,3] as vids CALL algo.native.extract(vids,{isNode:true, field:'id'})
YIELD value  RETURN value
```  
**Example output:**  
| value |
| ----- |
| [4,5] |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* algo.algo.native.extract(id, config))'}"
现在tugraph-analytics是不支持窗口函数吗？,"page_content='可视化操作手册（旧版）

操作详情

3.工作台

#### 3.1 快速上手  
- 首次登录，系统会默认创建 default 空图  
![alt 快速上手](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/2.tugraph-browser-quickstart-01.png)  
- 用户点击帮助选项，并选择快速上手  
![alt 帮助](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/3.tugraph-browser-quickstart-02.png)  
- 然后点击“一键创建模型”——>""一键创建数据""，就可以完成内置的 Movie 数据图谱的构建  
#### 3.2 创建子图和示例  
##### 3.2.1 创建子图  
- 点击新建子图
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/4.tugraph-browser-create-subgraph-01.png)
- 填写表单信息
![alt 填写表单](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/5.tugraph-browser-create-subgraph-02.png)
- 子图名称
- 子图描述
- 配置信息
- 点击确认，提示创建成功
- 切换子图
![alt 切换子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/6.tugraph-browser-use-graph-01.png)  
- 点击新建示例
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/create-scene-01.png)
- 选择示例并点击创建
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/select-scene.png)  
#### 3.3 查询  
![alt 查询](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/7.tugraph-browser-query-01.png)  
##### 3.3.1 页面组成  
- cypher 输入框
- 结果集展示区域  
##### 3.3.2 结果集展示区域功能详情  
- 结果集标签展示及功能
![alt 结果集标签](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/tugraph-browser-result.png)
- 这里展示了结果集的所有类型统计
- 点击不同的“label（标签）”，可以进行以下修改操作
- 修改展示颜色
- 修改节点大小或边的粗细
- 修改默认展示属性或系统属性
- 布局修改
- 力导布局
- 网格布局
- 树形布局
- 环境布局
- 边聚合
- 相同类型，方向的边可以进行合并
- 创建节点
- 点击创建节点按钮
- 选择节点类型
- 添写节点内容
- 创建关系
- 在画布中选择起点和终点
- 选择可以匹配的类型
- 填写节点信息
- 停止布局
- 当数据量过大，导致浏览器页面卡顿时候，可以点击这个停止布局的按钮，能够提高体验的流畅度
- 鼠标悬停
- 开启此功能，可以高亮显示鼠标悬停节点的一度邻居节点
- 结果集导出
- 可以将结果集导出为 png，json，csv 三种不同的文件形式
- 刷新
- 点击刷新按钮，会重新执行当前页面的初始 cypher 语句，并刷新结果集
- 最大化
- 点击最大化，结果集展示区域将全屏展示
- 结果集展示形式切换
- 支持图谱、表格、文本三种形式  
###' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '3.工作台'}","page_content='Traversal API

1. 简介

TuGraph 强大的在线分析处理（OLAP）能力是其区别于其它图数据库的一个重要特性。
借助 C++ OLAP API（olap_on_db.h），用户可以快速地导出一个需要进行复杂分析的子图，然后在其上运行诸如 PageRank、连通分量、社区发现等迭代式图计算过程，最后根据结果做出相应决策。
导出和计算的过程都可以通过并行处理的方式进行加速，从而实现几乎实时的分析处理，避免了传统解决方案需要将数据导出、转换、再导入（ETL）到专门的分析系统进行离线处理的冗长步骤。  
TuGraph 内置了大量常用的图分析算法和丰富的辅助接口，因此用户几乎不需要自己来实现具体的图计算过程，只需在实现自己的存储过程时将相应算法库的头文件（.h 文件）包含到自己程序中，并在编译时链接相应的动态库文件（.so）即可。
一般情况下，用户需要自己实现的只有将需要分析的子图抽取出来的过程。  
目前 Traversal API 仅支持 C++。' metadata={'Header 1': 'Traversal API', 'Header 2': '1. 简介'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。  
<table><tbody><tr><td>算法类型</td><td>中文算法名</td><td>英文算法名</td><td>程序名</td></tr><tr><td rowspan=""5"">路径查询</td><td>广度优先搜索</td><td>Breadth-First Search</td><td>bfs</td></tr><tr><td>单源最短路径</td><td>Single-Source Shortest Path</td><td>sssp</td></tr><tr><td>全对最短路径</td><td>All-Pair Shortest Path</td><td>apsp</td></tr><tr><td>多源最短路径</td><td>Multiple-source Shortest Paths</td><td>mssp</td></tr><tr><td>两点间最短路径</td><td>Single-Pair Shortest Path</td><td>spsp</td></tr><tr><td rowspan=""9"">重要性分析</td><td>网页排序</td><td>Pagerank</td><td>pagerank</td></tr><tr><td>介数中心度</td><td>Betweenness Centrality</td><td>bc</td></tr><tr><td>置信度传播</td><td>Belief Propagation</td><td>bp</td></tr><tr><td>距离中心度</td><td>Closeness Centrality</td><td>clce</td></tr><tr><td>个性化网页排序</td><td>Personalized PageRank</td><td>ppr</td></tr><tr><td>带权重的网页排序</td><td>Weighted Pagerank Algorithm</td><td>wpagerank</td></tr><tr><td>信任指数排名</td><td>Trustrank</td><td>trustrank</td></tr><tr><td>sybil检测算法</td><td>Sybil Rank</td><td>sybilrank</td></tr><tr><td>超链接主题搜索</td><td>Hyperlink-Induced Topic Search</td><td>hits</td></tr><tr><td rowspan=""4"">关联性分析</td><td>平均集聚系数</td><td>Local Clustering Coefficient</td><td>lcc</td></tr><tr><td>共同邻居</td><td>Common Neighborhood</td><td>cn</td></tr><tr><td>度数关联度</td><td>Degree Correlation</td><td>dc</td></tr><tr><td>杰卡德系数</td><td>Jaccard Index</td><td>ji</td></tr><tr><td rowspan=""5"">图结构</td><td>直径估计</td><' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}"
当调用CallProcedure函数时，如果设置json_format参数为false，返回的结果格式是什么？,"page_content='Java客户端

2.使用示例

2.6.调用存储过程

```java
String result = client.callProcedure(""CPP"", ""khop"", kHopParamGen(), 1000, false, ""default"");
log.info(""testCallProcedure : "" + result);
```
```
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param param: the execution parameters
@param procedureTimeOut: Maximum execution time, overruns will be interrupted
@param inProcess: Running query or not
@param graph: the graph to query
@param jsonFormat: (Optional) Return format of calling stored procedure
@param url: (Optional) Node address of calling procedure
@return: the result of procedure execution
public String callProcedure(String procedureType, String procedureName, String param, double procedureTimeOut,
boolean inProcess, String graph, String url)
```
本接口支持在单机模式和HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}","page_content='C++客户端

2.使用示例

2.6.调用存储过程

```C++
std::string str;
bool ret = client.CallProcedure(str, ""CPP"", ""test_plugin1"", ""bcefg"");
```
```
bool CallProcedure(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& param,
double procedure_time_out = 0.0, bool in_process = false,
const std::string& graph = ""default"", bool json_format = true,
const std::string& url = """");
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  url                 (Optional) Node address of calling procedure.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}","page_content='Python客户端

3.RPC Client

3.6.调用存储过程

```python
ret, res = client.callProcedure(""CPP"", ""test_plugin1"", ""bcefg"", 1000, False, ""default"")
```
```
callProcedure(self: liblgraph_client_python.client, procedure_type: str, procedure_name: str, param: str, procedure_time_out: float, in_process: bool, graph: str, json_format: bool, url: str) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.6.调用存储过程'}"
在 PathTraversal 类中，通过调用哪个函数来通过传入的过滤器设置初始边界？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterato' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}","page_content='Traversal API

2. 接口说明

2.1. Snapshot

C++ OLAP API 中的 Snapshot 模版类用于表示抽取出来的静态子图，其中 EdgeData 用来表示该子图上每条边所用权值的数据类型（如果边不需要权值，使用 Empty 作为 EdgeData 即可）。  
抽取的子图通过 Snapshot 类的构造函数来描述：  
```c
Snapshot::Snapshot(
GraphDB & db,
Transaction & txn,
size_t flags = 0,
std::function<bool(VertexIterator &)> vertex_filter = nullptr,
std::function<bool(OutEdgeIterator &, EdgeData &)> out_edge_filter = nullptr
);
```  
其中，db 为数据库句柄，txn 为事务句柄，flags 为生成时使用的选项，可选值包括以下的组合：SNAPSHOT_PARALLEL 表示导出时使用多个线程进行并行；SNAPSHOT_UNDIRECTED 表示需要将导出的图变为无向图。
vertex_filter 是面向点的用户自定义过滤函数，返回值为 true 表示该点需要被包含到待抽取的子图中，反之则表示需要被排除。
out_edge_filter 是面向边的用户自定义过滤函数，返回值为 true 表示该边需要被包含到待抽取的子图中，反之则表示需要被排除。
当过滤函数为缺省值时，则表示需要将所有点/边都包含进来。  
Snapshot 类提供的其它方法请参考详细的 C++ API 文档（olap_on_db.h）。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.1. Snapshot'}"
GeaBase的主要部署方式需要多长时间？,"page_content='安装指南

一键安装

数据存储配置

配置GeaFlow作业、图、表等数据的持久化存储，推荐使用HDFS。本地模式默认为容器内磁盘。
![install_storage_config](../../static/img/install_storage_config.png)' metadata={'Header 1': '安装指南', 'Header 2': '一键安装', 'Header 3': '数据存储配置'}","page_content='安装指南

一键安装

文件存储配置

配置GeaFlow引擎JAR、用户JAR文件的持久化存储，推荐使用HDFS。本地模式默认为容器内磁盘。
![install_jar_config](../../static/img/install_jar_config.png)  
安装成功后，**管理员会自动切换到租户默认下的默认实例**，此时可以直接创建发布图计算任务。' metadata={'Header 1': '安装指南', 'Header 2': '一键安装', 'Header 3': '文件存储配置'}","page_content='安装指南

一键安装

集群配置

配置GeaFlow作业的运行时集群，推荐使用Kubernates。本地模式下默认为本地的代理地址${your.host.name}:8000，请确保本地已经启动minikube并设置好代理地址。如果设置K8S集群地址，请确保集群地址的连通性正常。
![install_cluster_config](../../static/img/install_cluster_config.png)  
K8S集群模式添加以下配置
```
# 存储限制为10Gi
""kubernetes.resource.storage.limit.size"":""10Gi""
# 服务API配置为K8S服务地址，一般为6443端口
""kubernetes.master.url"":""https://${your.host.name}:6443""
# 在K8S集群找到 /etc/kubernetes/admin.conf 配置文件，从上到下分别配置以下三个字段
""kubernetes.ca.data"":""""
""kubernetes.cert.data"":""""
""kubernetes.cert.key"":""""
```' metadata={'Header 1': '安装指南', 'Header 2': '一键安装', 'Header 3': '集群配置'}"
在图论中，图的基本元素包括哪些？,"page_content='Learn Tutorial

1.TuGraph 图学习模块简介

图学习是一种机器学习方法，其核心思想是利用图结构中的拓扑信息，通过顶点之间的联系及规律来进行数据分析和建模。不同于传统机器学习方法，图学习利用的数据形式为图结构，其中顶点表示数据中的实体，而边则表示实体之间的关系。通过对这些顶点和边进行特征提取和模式挖掘，可以揭示出数据中深层次的关联和规律，从而用于各种实际应用中。  
这个模块是一个基于图数据库的图学习模块，主要提供了四种采样算子：Neighbor Sampling、Edge Sampling、Random Walk Sampling 和 Negative Sampling。这些算子可以用于对图中的顶点和边进行采样，从而生成训练数据。采样过程是在并行计算环境下完成的，具有高效性和可扩展性。  
在采样后，我们可以使用得到的训练数据来训练一个模型。该模型可以用于各种图学习任务，比如预测、分类等。通过训练，模型可以学习到图中的顶点和边之间的关系，从而能够对新的顶点和边进行预测和分类。在实际应用中，这个模块可以被用来处理各种大规模的图数据，比如社交网络、推荐系统、生物信息学等。' metadata={'Header 1': 'Learn Tutorial', 'Header 2': '1.TuGraph 图学习模块简介'}","page_content='图算法介绍

1\. 图算法概述

在计算机科学中，图是一种表示实体（节点或顶点）以及实体之间关系（边）的数据结构。图模型可以天然地描述网络结构，能更清晰地表达复杂的数据关系和依赖，简化关联数据的理解和分析。在不同的场景下，图中点边具备不同的语义信息。比如在资金交易场景下，每个人可以抽象成一个点表示，人与人之间的转账关系可以抽象成一条边表示。通过图数据模型反映出各个实体之间的资金往来关系，让数据的关联分析更加直观和高效。  
在图数据模型上可以执行多种图算法，如社区检测，最短路径匹配，环路检测算法等。通过点边上的迭代计算，探索图模型中各个实体之间的关系。探索过程不依赖于数据的线性结构，从而便于识别隐藏的模式和关联关系。在主流迭代图算法中，节点通过消息传递的方式进行通信。每次迭代，节点可以接收来自它们邻居的消息，处理这些消息，然后决定是否发送新的消息给其他节点。迭代算法中，每个节点有一个状态，每次迭代它们都有可能更新这个状态直至收敛。例如，在PageRank算法中，每个节点的状态是其PageRank值，这个值在迭代过程中会随着邻居的值的更新而更新。  
图迭代算法解决了经典的图计算问题，但随着业务需求的复杂度提升，基于迭代的图算法存在着表达能力不足、自适应性能力差、异质图处理难度大等缺点。近年来随着深度学习的研究和应用的发展，以图神经网络（Graph Neural Networks，GNNs）为代表的一类神经网络算法，被设计用来捕获图中实体（节点）和关系（边）间的复杂模式。图神经网络能够结合节点特征和图的结构来学习节点和边的表示，相比之下，传统的迭代图算法通常不会直接从原始特征中学习，而更多地专注于结构特征。依赖于深度学习的天然优势，GNNs具有更强的表示学习能力，可以自动从数据中学习复杂的模式，这使得 GNNs 能够更好地处理多任务学习和迁移学习等问题。在社交网络分析、知识图谱、生物分子网络、推荐系统以及交通网络等领域，得到广泛应用。' metadata={'Header 1': '图算法介绍', 'Header 2': '1\\. 图算法概述'}","page_content='图相关DDL

Create Graph

**Syntax**
一个图至少包含一对点边，点表必须包含一个id字段作为主键，边表必须包含srcId和targetId作为主键，边表还可以有一个时间戳字段标识时间。  
```
CREATE GRAPH <graph name>
(
<graph vertex>
[ { , <graph vertex> } ... ]
, <graph edge>
[ { , <graph edge> } ... ]
) WITH （
storeType = <graph store type>
[ { , <config key> = <config value> } ... ]
);

<graph vertex>  ::=
VERTEX <vertex name>
(
<column name> <data type> ID
[ {, <column name> <data type> } ... ]
)

<graph edge>  ::=
Edge <edge name>
(
<column name> <data type> SOURCE ID
, <column name> <data type> DESTINATION ID
[ , <column name> <data type> TIMESTAMP ]
[ {, <column name> <data type> } ... ]
)

```  
**Example**
```sql
CREATE GRAPH dy_modern (
Vertex person (
id bigint ID,
name varchar,
age int
),
Vertex software (
id bigint ID,
name varchar,
lang varchar
),
Edge knows (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
),
Edge created (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
)
) WITH (
storeType = 'rocksdb',
shardCount = 2
);
```
这个例子创建了一张包含2个点2个边的图，存储类型为rocksdb, 分片数2个。' metadata={'Header 1': '图相关DDL', 'Header 2': 'Create Graph'}"
TuGraph支持哪些编程语言？,"page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

简介

TuGraph 图数据库提供了 JAVA、C++、Python 等多种语言的 SDK 支持，方便客户在各种场景下使用。用户使用 SDK 向TuGraph服务器发送Cypher请求，服务器则以 JSON形式返回数据。近日，TuGraph 推出了一款面向 JAVA 客户端用户的开发工具 TuGraph-OGM (Object Graph Mapping)，为用户提供了对象操作接口，相较 Cypher/JSON 接口应用起来更加便捷。  
OGM 类似于关系数据库中的 ORM（Object Relational Model），可以将数据库返回的数据自动映射成 JAVA 中的对象，方便用户读取，而用户对这些对象的更新操作也可以被自动翻译成 Cypher 语句发送给服务器。这样即便是完全不懂 Cypher 的用户，也可以通过操作对象与数据库进行交互，大大降低了图数据库的使用门槛。  
TuGraph-OGM 同时也兼容其他开源产品 OGM 工具如 Neo4j-OGM，方便用户将工程在不同数据库与 TuGraph数据库间无缝迁移。本文将对 TuGraph-OGM 进行全面的介绍。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '简介'}","page_content='Bolt客户端

客户端示例

在代码目录中的demo/Bolt下面有Golang、Java、JavaScript、Python、Rust 这几个语言的的例子。想要了解更多可见[客户端示例](https://github.com/TuGraph-family/tugraph-db/tree/master/demo)' metadata={'Header 1': 'Bolt客户端', 'Header 2': '客户端示例'}"
在这段代码中，如何获取存储过程响应的列表？,"page_content='Procedure API

4.2.如何使用存储过程

4.2.2.列出已加载的存储过程

在服务器运行过程中，用户可以随时获取存储过程列表。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin')
>>> r.status_code
200
>>> r.text
'{""plugins"":[{""description"":""Custom Page Rank Procedure"", ""name"":""age_10"", ""read_only"":true}]}'
```' metadata={'Header 1': 'Procedure API', 'Header 2': '4.2.如何使用存储过程', 'Header 3': '4.2.2.列出已加载的存储过程'}","page_content='RESTful API Legacy

5.存储过程

5.3.获取存储过程的详细信息

- **URI**: `/db/{graph_name}/cpp_plugin|python_plugin/{plugin_name}`
- **METHOD**: GET
- **RESPONSE**: 存储过程信息，包括代码，其格式为：
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | 存储过程名 | 字符串 |
| description | 存储过程描述 | 字符串 |
| read_only | 存储过程是否只读 | 布尔值 |
| code_base64 | 存储过程的代码 | 字符串，使用 base64 编码 |
| code_type | 上传代码的类型，C++类型可选 zip/so/cpp，Python 为 py | 字符串 |  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/cpp_plugin/echo
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
Output:
{
""name"" : ""echo"",
""description"" : ""A test plugin that returns the input"",
""code_base64"" : ""{base64 encoded echo.zip}"",
""read_only"" : true,
""code_type"" : ""zip""
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程', 'Header 3': '5.3.获取存储过程的详细信息'}","page_content='RESTful API Legacy

5.存储过程

5.2.列出所有存储过程

- **URI**: `/db/{graph_name}/cpp_plugin|python_plugin`
- **METHOD**: GET
- **RESPONSE**: 存储过程列表，其中每个元素是一个 plugin 的描述，其格式为：
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | 存储过程名 | 字符串 |
| description | 存储过程描述 | 字符串 |
| read_only | 存储过程是否只读 | 布尔值 |  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/cpp_plugin
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
Output:
{
[
{
""description"":""adds a vertex label to the db"",
""name"":""add_label"",
""read_only"":false
},
{
""description"": ""scans graph and get number of edges"",
""name"": ""scan_graph"",
""read_only"": true
}
]
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程', 'Header 3': '5.2.列出所有存储过程'}"
什么是RPC接口？,"page_content='RPC API

1.简介

TuGraph 提供丰富的 RPC API，以供开发者通过 RPC 请求远程调用 TuGraph 提供的服务。  
RPC（远程过程调用）是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。
相比REST，RPC 面向方法，主要用于函数方法的调用，可以适合更复杂通信需求的场景，且性能更高。
brpc是用c++语言编写的工业级RPC框架，基于brpc，TuGraph 提供了丰富的RPC API，本文档描述
TuGraph 的 RPC API 使用方式。' metadata={'Header 1': 'RPC API', 'Header 2': '1.简介'}","page_content='RPC API

2.请求

2.1.建立连接

开发者向TuGraph服务发送RPC请求，首先要建立连接。以C++语言为例，开发者创建指定url的通道（channel），
由通道创建指定的服务存根（LGraphRPCService_Stub），后续即可通过存根像调用本地方法一样向远程
服务器发送请求。  
```C++
std::shared_ptr<lgraph_rpc::m_channel_options> options = std::make_shared<lgraph_rpc::m_channel_options>();
options->protocol = ""baidu_std"";
options->connection_type = """";
options->timeout_ms = 60 * 60 * 1000 /*milliseconds*/;
options->max_retry = 3;
std::string load_balancer = """";
std::shared_ptr<lgraph_rpc::m_channel> channel = std::make_shared<lgraph_rpc::m_channel>();
if (channel->Init(url.c_str(), load_balancer, options.get()) != 0)
throw RpcException(""Fail to initialize channel"");
LGraphRPCService_Stub stub(channel.get());
```' metadata={'Header 1': 'RPC API', 'Header 2': '2.请求', 'Header 3': '2.1.建立连接'}","page_content='RPC API

3.登录

登录请求信息包含以下参数：
- user: 必要参数，用户名
- pass: 必要参数，密码
以C++为例，用户使用构建好的服务存根发送登录请求：
```C++
auto* req = request.mutable_acl_request();
auto* auth = req->mutable_auth_request()->mutable_login();
auth->set_user(user);
auth->set_password(pass);
// send data
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req->set_client_version(server_version);
req->set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), req, &resp, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
token = res.acl_response().auth_response().token();
```
登录响应信息包含以下参数：
- token: 必要参数，登录成功会收到带有签名的令牌，即 Json Web Token，客户端储存该令牌，并且用于以后的每次发送请求。
如果登录失败会收到“Authentication failed”错误。' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}"
在文本中，The Matrix参与了哪几种类型的关系？,"page_content='Cypher API

2.Clauses

2.2.MATCH

- Basic node finding  
- ✓ Get all nodes  
```
MATCH (n)
RETURN n
```  
- ✓ Get all nodes with a label  
```
MATCH (movie:movie)
RETURN movie.title
```  
- ✓ Related nodes  
```
MATCH (person {name: 'Laurence Fishburne'})-[]-(movie)
RETURN movie.title
```  
- ✓ Match with labels  
```
MATCH (:person {name: 'Laurence Fishburne'})-[]-(movie:movie)
RETURN movie.title
```  
- Relationship basics  
- ✓ Outgoing relationships  
```
MATCH (:person {name: 'Laurence Fishburne'})-[]->(movie)
RETURN movie.title
```  
- ✓ Directed relationships and variable  
```
MATCH (:person {name: 'Laurence Fishburne'})-[r]->(movie)
RETURN type(r)
```  
- ✓ Match on relationship type  
```
MATCH (matrix:movie {title: 'The Matrix'})<-[:acted_in]-(actor)
RETURN actor.name
```  
- ✓ Match on multiple relationship types  
```
MATCH (matrix {title: 'The Matrix'})<-[:acted_in|:directed]-(person)
RETURN person.name
```  
- ✓ Match on relationship type and use a variable  
```
MATCH (matrix {title: 'The Matrix'})<-[r:acted_in]-(actor)
RETURN r.role
```
- Relationships in depth  
- ❏ Relationship types with uncommon characters  
```
MATCH (n {name: 'Rob Reiner'})-[r:`TYPE WITH SPACE`]->()
RETURN type(r)
```  
- ✓ Multiple relationships  
```
MATCH (laurence {name: 'Laurence Fishburne'})-[:acted_in]->(movie)<-[:directed]-(director)
RETURN movie.title, director.name
```  
- ✓ Variable-length relationships  
```
MATCH (laurence {name: 'Laurence Fishburne'})-[:acted_in*1..3]-(movie:movie)
RETURN movie.title
```  
- ✓ Relationship variable in variable-length relationships  
```
MATCH p = (laurence {name: 'Laurence Fishburne'})-[:acted_in*2]-(co_actor)
RETURN p
```  
- ❏ Match with properties on a variable-length path  
```
MATCH p = (charlie:person)-[* {blocked:false}]-(martin:person)
WHERE charlie.name = 'Charlie Sheen' AND martin.name = 'Martin Sheen'
RETURN p
```  
- ✓ Zero-length paths  
```
MATCH (matrix:movie {title: 'The Matrix'})-[*0..1]-(x)
RETURN x
```  
- ✓ Na' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.2.MATCH'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.subgraph()

**Scope:** whole instance.  
**Parameters:**  
| parameter  | parameter type | description                                                           |
| ---------- | -------------- | --------------------------------------------------------------------- |
| vids       | list           | list of vertex id                                                     |  
**Output:**  
Get a json containing all the properties of nodes and relationships.  
**Example input:**  
```
CALL db.subgraph([3937,4126,4066,4010])
```  
**Example output**  
| subgraph |
| -------- |
| {""nodes"":[{""identity"":3937,""label"":""movie"",""properties"":{""duration"":136,""id"":1,""poster_image"":""http://image.tmdb.org/t/p/w185/gynBNzwyaHKtXqlEKKLioNkjKgN.jpg"",""rated"":""R"",""summary"":""Thomas A. Anderson is a man living two lives. By day he is an average computer programmer and by night a malevolent hacker known as Neo who finds himself targeted by the police when he is contacted by Morpheus a legendary computer hacker who reveals the shocking truth about our reality."",""tagline"":""Welcome to the Real World."",""title"":""The Matrix""}},{""identity"":4010,""label"":""user"",""properties"":{""id"":44,""login"":""Howard""}},{""identity"":4066,""label"":""user"",""properties"":{""id"":202,""login"":""Enoch""}},{""identity"":4126,""label"":""user"",""properties"":{""id"":464,""login"":""Wilburn""}}],""relationships"":[{""dst"":4126,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4010,""temporal_id"":0},{""dst"":4010,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4066,""temporal_id"":0},{""dst"":4066,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4126,""temporal_id"":0}]} |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.subgraph()'}","page_content='ISO GQL

2.Clauses

2.1.MATCH

`MATCH`子句式是GQL最基础的子句，几乎所有查询都是通过 `MATCH`展开。  
`MATCH`子句用于指定在图中搜索的匹配模式，用来匹配满足一定条件的点或者路径。  
#### 点查询  
##### 查询所有点  
```
MATCH (n)
RETURN n
```  
##### 查询特定标签的点  
```
MATCH (n:Person)
RETURN n
```  
##### 通过属性匹配点  
```
MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
##### 通过过滤条件匹配点  
```
MATCH (n:Person WHERE n.birthyear > 1910)
RETURN n.name LIMIT 2
```  
返回结果
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```  
#### 边查询  
##### 出边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1970)-[e]->(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""BORN_IN"",""m.name"":""London"",""n.name"":""Christopher Nolan""},{""label(e)"":""DIRECTED"",""m.name"":null,""n.name"":""Christopher Nolan""}]
```  
##### 入边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1939)<-[e]-(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""HAS_CHILD"",""m.name"":""Rachel Kempson"",""n.name"":""Corin Redgrave""},{""label(e)"":""HAS_CHILD"",""m.name"":""Michael Redgrave"",""n.name"":""Corin Redgrave""}]
```  
##### 带过滤条件的边匹配  
```
MATCH (n:Person)-[e:BORN_IN WHERE e.weight > 20]->(m)
RETURN n.name, e.weight, m.name
```  
返回结果
```JSON
[{""e.weight"":20.549999237060547,""m.name"":""New York"",""n.name"":""John Williams""},{""e.weight"":20.6200008392334,""m.name"":""New York"",""n.name"":""Lindsay Lohan""}]
```  
#### 路径匹配  
##### 不定跳查询  
```
MATCH (n:Person)-[e]->{2,3}(m:Person)
RETURN m.name LIMIT 2
```  
返回结果
```JSON
[{""m.name"":""Liam Neeson""},{""m.name"":""Natasha Richardson""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.1.MATCH'}"
使用什么命令启动 TuGraph 服务器？,"page_content='数据库运行

3.服务操作

3.1.启动服务

TuGraph 需要通过 `lgraph_server -d start` 命令行启动，启动命令示例如下：  
```bash
$ ./lgraph_server -d start -c lgraph.json
Starting lgraph...
The service process is started at pid 12109.
```  
此命令启动的 TuGraph 服务器进程为守护进程，它将从文件`lgraph.json`加载相关配置。服务器启动后，它将开始在日志文件中打印日志，之后可用该日志文件确定服务器的状态。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.1.启动服务'}","page_content='数据库运行

2.运行模式

2.1.运行普通进程

`lgraph_server -d run`命令可以将 TuGraph 作为普通进程运行。普通进程依赖命令行终端，因此终端结束时，TuGraph 进程也会自动终止。普通进程模式配合`--log_dir """"`可以将进程日志直接输出到终端，因此更方便调试。注：当不使用`-d run`命令时，将默认运行普通进程。  
lgraph_server的默认路径为：/usr/local/bin/lgraph_server 。  
lgraph.json的默认路径为：/usr/local/etc/lgraph.json 。  
启动命令：  
```shell
$ ./lgraph_server -d run -c lgraph.json --log_dir """"
```
或者：
```shell
$ ./lgraph_server -c lgraph.json --log_dir """"
```  
普通模式的运行输出示例：  
```shell
**********************************************************************
*                  TuGraph Graph Database v4.3.2                     *
*                                                                    *
*    Copyright(C) 2018-2023 Ant Group. All rights reserved.          *
*                                                                    *
**********************************************************************
Server is configured with the following parameters:
Backup log enable:                   0
DB directory:                        /var/lib/lgraph/data
HA enable:                           0
HTTP port:                           7070
HTTP web dir:                        /usr/local/share/lgraph/browser-resource
RPC enable:                          1
RPC port:                            9090
SSL enable:                          0
Whether the token is unlimited:      0
audit log enable:                    0
bind host:                           0.0.0.0
bolt port:                           7687
disable auth:                        0
durable:                             0
log dir:                             """"
log verbose:                         1
number of bolt io threads:           1
optimistic transaction:              0
reset admin password if you forget:  0
subprocess idle limit:               600
thread limit:                        0
[20240730 15:34:27.848783 0x00007f81bb3889c0 INFO  src/server/lgraph_server.h:78] [StateMachine] Builtin services are disabled according to ServerOptions.has_builtin_services
[2' metadata={'Header 1': '数据库运行', 'Header 2': '2.运行模式', 'Header 3': '2.1.运行普通进程'}","page_content='TuGraph DB BROWSER

启动TuGraph DB Browser

TuGraph DB BROWSER 是 TuGraph 图数据库的可视化平台。可以完成图谱、模型、数据等的创建和导入。同时可用使用 TuGraph Cypher 进行数据的操作。  
0. 环境准备  
- node.js >= 16  
1. 安装项目依赖  
```bash
npm install --force
```  
2. 本地研发  
```bash
npm run dev
```  
浏览器访问 http://localhost:8000  
3. 编译构建  
```bash
npm run build
```' metadata={'Header 1': 'TuGraph DB BROWSER', 'Header 2': '启动TuGraph DB Browser'}"
如果在添加顶点时存在相同的unique_id，将会发生什么？,"page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.addEdgeIndex(label_name, field_name, unique, pair_unique)

create an index on some field of one edge label .  
**Parameters:**  
| parameter | parameter type | description               |
| ---------- | -------------- | ------------------------------------- |
| label_name | string     | name of the label             |
| field_name | string     | specification of a field          |
| unique  | boolean    | Specifies whether the index is unique |
| pair_unique | boolean    | Specifies whether the index is pair_unique |  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.addEdgeIndex('BornIn', 'id', true, false)
```  
**Example output:**  
```
Added index [BornIn:id]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.addEdgeIndex(label_name, field_name, unique, pair_unique)'}"
TuGraph 支持哪些硬件架构？,"page_content='环境准备

1.硬件环境

1.1. CPU

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的硬件平台，测试认证过的硬件平台包括 Intel、AMD、Kunpeng、Hygon、飞腾等。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.1. CPU'}","page_content='快速上手

1.简介

1.1.支持的平台

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的的平台。' metadata={'Header 1': '快速上手', 'Header 2': '1.简介', 'Header 3': '1.1.支持的平台'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}"
TuGraph-OGM项目如何面向TuGraph数据库支持JAVA开发人员进行图对象映射？,"page_content='TuGraph-OGM

1.简介

> TuGraph-OGM 项目在其他仓库开源。  
TuGraph-OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。同时 TuGraph-OGM 兼容 Neo4j-OGM，Neo4j 生态用户可以无缝迁移到 TuGraph 数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '1.简介'}","page_content='TuGraph-OGM

简介

TuGraph-OGM(Object Graph Mapping), 源自 `Neo4j-OGM` 项目，TuGraph-OGM
支持将JAVA对象（POJO）映射到TuGraph中，JAVA中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此JAVA开发人员可以在熟悉的生态中轻松地使用TuGraph数据库。同时TuGraph-OGM兼容Neo4j-OGM，Neo4j生态用户可以无缝迁移到TuGraph数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

0 映射原理

TuGraph-OGM 将 JAVA 对象映射为图的对象，类映射为点，类的属性映射为图中的属性，类中的方法映射为操作 TuGraph 的查询语句。  
以电影场景为例，对演员、电影、导演之间的关系进行数据化，就形成了非常典型的图数据。举一个简单的示例，演员Alice在1990年和2019年分别出演了两部电影《Jokes》和《Speed》，其中《Jokes》的导演是Frank Darabont。  
以图的思维来看，演员、导演、电影可以被映射为三种不同的节点，而出演、执导可以被映射为两种边，映射结果如上图所示，将数据存入图数据库后，相关的开发人员就可以使用各类图查询语言对数据进行查询。  
但对非图数据库相关的开发人员来说，这个例子中的演员、导演、电影作为实体，同样可以映射为类中的对象，而与实体相关联的对象可以通过集合存储，这是大多数开发人员熟悉的领域。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '0 映射原理'}"
OPTIONAL MATCH在GQL中有什么作用？,"page_content='ISO GQL

2.Clauses

2.1.MATCH

`MATCH`子句式是GQL最基础的子句，几乎所有查询都是通过 `MATCH`展开。  
`MATCH`子句用于指定在图中搜索的匹配模式，用来匹配满足一定条件的点或者路径。  
#### 点查询  
##### 查询所有点  
```
MATCH (n)
RETURN n
```  
##### 查询特定标签的点  
```
MATCH (n:Person)
RETURN n
```  
##### 通过属性匹配点  
```
MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
##### 通过过滤条件匹配点  
```
MATCH (n:Person WHERE n.birthyear > 1910)
RETURN n.name LIMIT 2
```  
返回结果
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```  
#### 边查询  
##### 出边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1970)-[e]->(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""BORN_IN"",""m.name"":""London"",""n.name"":""Christopher Nolan""},{""label(e)"":""DIRECTED"",""m.name"":null,""n.name"":""Christopher Nolan""}]
```  
##### 入边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1939)<-[e]-(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""HAS_CHILD"",""m.name"":""Rachel Kempson"",""n.name"":""Corin Redgrave""},{""label(e)"":""HAS_CHILD"",""m.name"":""Michael Redgrave"",""n.name"":""Corin Redgrave""}]
```  
##### 带过滤条件的边匹配  
```
MATCH (n:Person)-[e:BORN_IN WHERE e.weight > 20]->(m)
RETURN n.name, e.weight, m.name
```  
返回结果
```JSON
[{""e.weight"":20.549999237060547,""m.name"":""New York"",""n.name"":""John Williams""},{""e.weight"":20.6200008392334,""m.name"":""New York"",""n.name"":""Lindsay Lohan""}]
```  
#### 路径匹配  
##### 不定跳查询  
```
MATCH (n:Person)-[e]->{2,3}(m:Person)
RETURN m.name LIMIT 2
```  
返回结果
```JSON
[{""m.name"":""Liam Neeson""},{""m.name"":""Natasha Richardson""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.1.MATCH'}","page_content='ISO GQL

2.Clauses

2.2.OPTIONAL MATCH

`OPTIONAL MATCH`匹配图模式，如果未命中，则返回`null`。  
#### 查询命中  
```
OPTIONAL MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
#### 查询未命中  
```
OPTIONAL MATCH (n:Person{name:'Redgrave Michael'})
RETURN n.birthyear
```  
返回结果  
```JSON
[{""n.birthyear"":null}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.2.OPTIONAL MATCH'}","page_content='ISO GQL

2.Clauses

2.4.NEXT

`NEXT`子句用于连接多个子句。  
#### 连接MATCH  
```
MATCH (n:Person) WHERE n.birthyear = 1970
RETURN n
NEXT
MATCH (m:Person) WHERE m.birthyear < 1968
RETURN n.name, n.birthyear, m.name LIMIT 2
```  
返回结果
```JSON
[{""m.name"":""Rachel Kempson"",""n.birthyear"":1970,""n.name"":""Christopher Nolan""},{""m.name"":""Michael Redgrave"",""n.birthyear"":1970,""n.name"":""Christopher Nolan""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.4.NEXT'}"
loadProcedure方法中，如何通过参数控制存储过程是否为只读？,"page_content='Java客户端

2.使用示例

2.8.加载存储过程

```java
boolean result = client.loadProcedure(""./test/procedure/khop.so"", ""CPP"", ""khop"", ""SO"", ""test loadprocedure"", true, ""v1"", ""default"");
log.info(""loadProcedure : "" + result);
```
```
@param sourceFile: the source_file contain procedure code
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param codeType: code type, currently supported PY, SO, CPP, ZIP
@param procedureDescription: procedure description
@param readOnly: procedure is read only or not
@param version: The version of procedure
@param graph: the graph to query.
@return: the result of procedure execution
public boolean loadProcedure(String sourceFile, String procedureType, String procedureName, String codeType,
String procedureDescription, boolean readOnly, String version, String graph) throws Exception
```
本接口支持在单机模式和HA模式下使用。其中，由于加载存储过程是写请求，HA模式下的client只能向leader发送加载存储过程请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.8.加载存储过程'}","page_content='Procedure API

5.Procedure v2接口

5.1.编写存储过程

用户可以通过使用 lgraph API 来编写 C++ 存储过程。一个简单的 C++ 存储过程举例如下：  
```c++
// peek_some_node_salt.cpp
#include <cstdlib>
#include ""lgraph/lgraph.h""
#include ""lgraph/lgraph_types.h""
#include ""lgraph/lgraph_result.h""

#include ""tools/json.hpp""

using json = nlohmann::json;
using namespace lgraph_api;

extern ""C"" LGAPI bool GetSignature(SigSpec &sig_spec) {
sig_spec.input_list = {
{.name = ""limit"", .index = 0, .type = LGraphType::INTEGER},
};
sig_spec.result_list = {
{.name = ""node"", .index = 0, .type = LGraphType::NODE},
{.name = ""salt"", .index = 1, .type = LGraphType::FLOAT}
};
return true;
}

extern ""C"" LGAPI bool ProcessInTxn(Transaction &txn,
const std::string &request,
Result &response) {
int64_t limit;
try {
json input = json::parse(request);
limit = input[""limit""].get<int64_t>();
} catch (std::exception &e) {
response.ResetHeader({
{""errMsg"", LGraphType::STRING}
});
response.MutableRecord()->Insert(
""errMsg"",
FieldData::String(std::string(""error parsing json: "") + e.what()));
return false;
}

response.ResetHeader({
{""node"", LGraphType::NODE},
{""salt"", LGraphType::FLOAT}
});
for (size_t i = 0; i < limit; i++) {
auto r = response.MutableRecord();
auto vit = txn.GetVertexIterator(i);
r->Insert(""node"", vit);
r->Insert(""salt"", FieldData::Float(20.23*float(i)));
}
return true;
}
```  
从代码中我们可以看到：
- 存储过程定义了一个获取签名的方法`GetSignature`。该方法返回了存储过程的签名，其中包含输入参数名称及其类型，返回参数及其类型。这使得Cypher查询语句在调用存储过程能够利用签名信息校验输入数据以及返回数据是否合理。
- 入口函数是`ProcessInTxn`函数，它的参数有三个，分别为：  
- `txn`: 存储过程所处的事务，通常来说即调用该存储过程的Cypher语句所处事务。
- `request`: 输入数据，其内容为`GetSignature`中定义的输入参数类型及其Cypher查询语句中传入的值经过json序列化后的字符串。e.g. `{num_iteration: 10}`
- `response`: 输出数据，为保证在Cypher语言中能够兼容，用户可以通过往`lgraph_api::Result` 写入存储过程处理后的数据，最后用`lgraph_api::Result::Dump`来序列化成json格式的数据。  
`ProcessInTxn`函数的返回值是一个布尔值。当它返回`true`的时候，表示该请求顺利完成，反之表示这个存储过程在执行过程中发现了错误。  
C++存储过程编写完毕后需要编译成动态链接库。TuGraph 提供了`compile.sh`脚本来帮助用户自动编译存储过程。`compile.sh`脚本只有一个参数，是该存储过程的名称，在上面的例子中就是`custom_pagerank`。编译调用命令行如下：  
```bash
g+' metadata={'Header 1': 'Procedure API', 'Header 2': '5.Procedure v2接口', 'Header 3': '5.1.编写存储过程'}","page_content='RPC API

5.存储过程

5.1.加载存储过程

加载存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称
- read_only: 必要参数，是否只读
- code: 必要参数，存储过程文件读入生成的ByteString
- desc: 可选参数，存储过程描述
- code_type: 可选参数，存储过程代码类型，PY、SO、CPP、ZIP四者之一  
以C++为例，用户加载存储过程的方式如下所示：
```C++
std::string content;
if (!FieldSpecSerializer::FileReader(source_file, content)) {
std::swap(content, result);
return false;
}
LGraphRequest req;
req.set_is_write_op(true);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
pluginRequest->set_version(version);
lgraph::LoadPluginRequest* loadPluginRequest = pluginRequest->mutable_load_plugin_request();
loadPluginRequest->set_code_type([](const std::string& type) {
std::unordered_map<std::string, lgraph::LoadPluginRequest_CodeType> um{
{""SO"", lgraph::LoadPluginRequest::SO},
{""PY"", lgraph::LoadPluginRequest::PY},
{""ZIP"", lgraph::LoadPluginRequest::ZIP},
{""CPP"", lgraph::LoadPluginRequest::CPP}};
return um[type];
}(code_type));
loadPluginRequest->set_name(procedure_name);
loadPluginRequest->set_desc(procedure_description);
loadPluginRequest->set_read_only(read_only);
loadPluginRequest->set_code(content);
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
加载存储过程的响应不包含参数，如果加载失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.1.加载存储过程'}"
在RPC调用中，如果回应的错误码不是成功，则抛出的异常类型是什么？,"page_content='RPC API

3.登录

登录请求信息包含以下参数：
- user: 必要参数，用户名
- pass: 必要参数，密码
以C++为例，用户使用构建好的服务存根发送登录请求：
```C++
auto* req = request.mutable_acl_request();
auto* auth = req->mutable_auth_request()->mutable_login();
auth->set_user(user);
auth->set_password(pass);
// send data
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req->set_client_version(server_version);
req->set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), req, &resp, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
token = res.acl_response().auth_response().token();
```
登录响应信息包含以下参数：
- token: 必要参数，登录成功会收到带有签名的令牌，即 Json Web Token，客户端储存该令牌，并且用于以后的每次发送请求。
如果登录失败会收到“Authentication failed”错误。' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}","page_content='RPC API

5.存储过程

5.2.调用存储过程

调用存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称
- param: 必要参数，存储过程参数
- result_in_json_format: 可选参数，调用结果是否以JSON格式返回
- in_process: 可选参数，未来支持
- timeout: 可选参数，调用存储过程的超时时间  
以C++为例，用户调用存储过程的方式如下所示：
```C++
LGraphRequest req;
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
lgraph::CallPluginRequest *cpRequest = pluginRequest->mutable_call_plugin_request();
cpRequest->set_name(procedure_name);
cpRequest->set_in_process(in_process);
cpRequest->set_param(param);
cpRequest->set_timeout(procedure_time_out);
cpRequest->set_result_in_json_format(json_format);
LGraphResponse res;
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
if (json_format) {
result = res.mutable_plugin_response()->mutable_call_plugin_response()->json_result();
} else {
result = res.mutable_plugin_response()->mutable_call_plugin_response()->reply();
}
```
调用存储过程的响应为以下两个参数之一：
- reply: ByteString格式的存储过程调用结果
- json_result: JSON格式的存储过程调用结果' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.2.调用存储过程'}","page_content='RPC API

2.请求

2.2.请求类型

TuGraph支持10种RPC请求，其中每种请求的功能如下表所示：  
| 请求              | 功能         |
|-----------------|------------|
| GraphApiRequest | 点边索引操作请求   |
| CypherRequest   | cypher请求   |
| PluginRequest   | 存储过程请求     |
| HARequest       | 高可用模式请求    |
| ImportRequest   | 数据导入请求     |
| GraphRequest    | 子图操作请求     |
| AclRequest      | 权限管理请求     |
| ConfigRequest   | 配置管理请求     |
| RestoreRequest  | 备份请求       |
| SchemaRequest   | schema管理请求 |  
用户发送请求时，需要传入以下参数：
- client_version: 可选参数，HA模式下可通过对比`client_version`和`server_version`防止响应过时的请求
- token: 必要参数，客户端登陆之后获得token，每次请求传入token以校验用户身份
- is_write_op: 可选参数，标志请求是否是写请求
- user: 可选参数，HA模式下主从之间同步请求时设置user，不需验证token  
服务处理完RPC请求之后发回响应，响应消息中除了包含每个请求的单独响应信息之外，还包含以下参数：
- error_code: 必要参数，标志请求处理状态
- redirect: 可选参数，HA模式下向follower发送写请求时处理失败，设置redirect为请求转发地址，即leader地址
- error: 可选参数，请求错误信息
- server_version: 可选参数，HA模式的请求响应中设置`server_version`以避免client读取数据时发生反向时间旅行问题  
:warning:  **除CypherRequest、PluginRequest、HARequest和AclRequest外，其余RPC接口将逐步废弃，其功能统一至CypherRequest接口。**' metadata={'Header 1': 'RPC API', 'Header 2': '2.请求', 'Header 3': '2.2.请求类型'}"
Transform操作中的swap_id函数是用来做什么的？,"page_content='Traversal API

2. 接口说明

2.1. Snapshot

C++ OLAP API 中的 Snapshot 模版类用于表示抽取出来的静态子图，其中 EdgeData 用来表示该子图上每条边所用权值的数据类型（如果边不需要权值，使用 Empty 作为 EdgeData 即可）。  
抽取的子图通过 Snapshot 类的构造函数来描述：  
```c
Snapshot::Snapshot(
GraphDB & db,
Transaction & txn,
size_t flags = 0,
std::function<bool(VertexIterator &)> vertex_filter = nullptr,
std::function<bool(OutEdgeIterator &, EdgeData &)> out_edge_filter = nullptr
);
```  
其中，db 为数据库句柄，txn 为事务句柄，flags 为生成时使用的选项，可选值包括以下的组合：SNAPSHOT_PARALLEL 表示导出时使用多个线程进行并行；SNAPSHOT_UNDIRECTED 表示需要将导出的图变为无向图。
vertex_filter 是面向点的用户自定义过滤函数，返回值为 true 表示该点需要被包含到待抽取的子图中，反之则表示需要被排除。
out_edge_filter 是面向边的用户自定义过滤函数，返回值为 true 表示该边需要被包含到待抽取的子图中，反之则表示需要被排除。
当过滤函数为缺省值时，则表示需要将所有点/边都包含进来。  
Snapshot 类提供的其它方法请参考详细的 C++ API 文档（olap_on_db.h）。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.1. Snapshot'}","page_content='Cypher API

3.Functions

3.3.Scalar functions

- id()
get the id of vertex.
**Scope:** whole instance.
**Example input:**  
```
MATCH (a)
RETURN id(a)
```  
**Example output:**  
| vid |
| --- |
| 1   |
| 2   |
| ... |  
- properties()
get a map containing all the properties of a node or relationship.
**Scope:** whole instance.
**Example input:**  
```
MATCH (n:person {name: 'Laurence Fishburne'})
RETURN n
```  
- head()
get the first element of a list.
**Scope:** whole instance.
**Example input:**  
```
WITH ['one','two','three'] AS coll RETURN coll, head(coll)
```  
**Example output:**  
| coll                  | head(coll)    |
| --------------------- | ------------- |
| [""one"",""two"",""three""] | ""one""         |  
- last()
get the last element of a list.
**Scope:** whole instance.
**Example input:**  
```
WITH ['one','two','three'] AS coll RETURN coll, last(coll)
```  
**Example output:**  
| coll                  | last(coll)    |
| --------------------- | ------------- |
| [""one"",""two"",""three""] | ""three""       |  
- toFloat()
Converts an integer or string value to a floating point number.
**Scope:** whole instance.
**Example input:**  
```
RETURN toFloat('11.5')
```  
**Example output:**  
| float |
| ----- |
| 11.5  |  
- toInteger()
Converts a floating point or string value to an integer value.
**Scope:** whole instance.
**Example input:**  
```
RETURN toInteger('2.3') AS integer
```  
**Example output:**  
| integer |
| ------- |
| 2       |  
- toString()
Converts an integer, float, boolean value to a string.
**Scope:** whole instance.
**Example input:**  
```
RETURN toString(2.3)
```  
- type()
get the string representation of the relationship type.
**Scope:** whole instance.
**Example input:**  
```
MATCH (n)-[r]->()
WHERE n.name = 'Laurence Fishburne'
RETURN type(r)
```  
**Example output:**  
| type     |
| -------- |
| acted_in |
| acted_in |' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.3.Scalar functions'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends Gra' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
在影视场景Demo中，如何通过Cypher语言查询影片'Forrest Gump'的所有演员以及他们扮演的角色？,"page_content='场景：影视

2.查询示例

2.1.示例一

查询影片 'Forrest Gump' 的所有演员，返回影片和演员构成的子图。  
```
MATCH (m:movie {title: 'Forrest Gump'})<-[:acted_in]-(a:person) RETURN a, m
```' metadata={'Header 1': '场景：影视', 'Header 2': '2.查询示例', 'Header 3': '2.1.示例一'}","page_content='场景：影视

2.查询示例

2.2.示例二

查询影片 'Forrest Gump' 的所有演员，列出演员在影片中扮演的角色。  
```
MATCH (m:movie {title: 'Forrest Gump'})<-[r:acted_in]-(a:person) RETURN a.name,r.role
```' metadata={'Header 1': '场景：影视', 'Header 2': '2.查询示例', 'Header 3': '2.2.示例二'}","page_content='场景：影视

2.查询示例

2.7.示例七

通过查询给'Forrest Gump'打高分的人也喜欢哪些影片，给喜欢'Forrest Gump'的用户推荐类似的影片。  
```
MATCH (m:movie {title:'Forrest Gump'})<-[r:rate]-(u:user)-[r2:rate]->(m2:movie) WHERE r.stars>3 AND r2.stars>3 RETURN m, u,m2
```' metadata={'Header 1': '场景：影视', 'Header 2': '2.查询示例', 'Header 3': '2.7.示例七'}"
TuGraph-DB图数据库社区版内置了多少种基础算法？,"page_content='内置算法

简介

TuGraph目前包含以下6个基础算法28种扩展算法，共34个图算法：' metadata={'Header 1': '内置算法', 'Header 2': '简介'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。  
<table><tbody><tr><td>算法类型</td><td>中文算法名</td><td>英文算法名</td><td>程序名</td></tr><tr><td rowspan=""5"">路径查询</td><td>广度优先搜索</td><td>Breadth-First Search</td><td>bfs</td></tr><tr><td>单源最短路径</td><td>Single-Source Shortest Path</td><td>sssp</td></tr><tr><td>全对最短路径</td><td>All-Pair Shortest Path</td><td>apsp</td></tr><tr><td>多源最短路径</td><td>Multiple-source Shortest Paths</td><td>mssp</td></tr><tr><td>两点间最短路径</td><td>Single-Pair Shortest Path</td><td>spsp</td></tr><tr><td rowspan=""9"">重要性分析</td><td>网页排序</td><td>Pagerank</td><td>pagerank</td></tr><tr><td>介数中心度</td><td>Betweenness Centrality</td><td>bc</td></tr><tr><td>置信度传播</td><td>Belief Propagation</td><td>bp</td></tr><tr><td>距离中心度</td><td>Closeness Centrality</td><td>clce</td></tr><tr><td>个性化网页排序</td><td>Personalized PageRank</td><td>ppr</td></tr><tr><td>带权重的网页排序</td><td>Weighted Pagerank Algorithm</td><td>wpagerank</td></tr><tr><td>信任指数排名</td><td>Trustrank</td><td>trustrank</td></tr><tr><td>sybil检测算法</td><td>Sybil Rank</td><td>sybilrank</td></tr><tr><td>超链接主题搜索</td><td>Hyperlink-Induced Topic Search</td><td>hits</td></tr><tr><td rowspan=""4"">关联性分析</td><td>平均集聚系数</td><td>Local Clustering Coefficient</td><td>lcc</td></tr><tr><td>共同邻居</td><td>Common Neighborhood</td><td>cn</td></tr><tr><td>度数关联度</td><td>Degree Correlation</td><td>dc</td></tr><tr><td>杰卡德系数</td><td>Jaccard Index</td><td>ji</td></tr><tr><td rowspan=""5"">图结构</td><td>直径估计</td><' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}"
TuGraph-DB支持的三种空间数据类型是什么？,"page_content='空间数据类型在TuGraph-DB中的实现

定义空间数据类型

TuGraph-DB当前已经支持Point、Linestring与Polygon三种类型  
-   • Point：点，创建方式例如POINT(2.0, 2.0, 7203)  
-   • Linestring：折线，创建方式例如LINESTRING(0 2,1 1,2 0)  
-   • Polygon：多边形，创建方式例如POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '定义空间数据类型'}","page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

实现思路

在TuGraph-DB的实现，基于boost geometry库的基础上进行封装，用EWKB格式存储数据，其中Point类型为定长存储50，其余皆为变长存储。我们支持了Point, Linestring与Polygon三种类型，同时支持了WGS84, CARTESIAN两种坐标系，数据类型与坐标系均可根据需要拓展。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现', 'Header 3': '实现思路'}","page_content='TuGraph图模型说明

1. 数据模型

1.2. 数据类型

TuGraph支持多种可用于属性的数据类型。具体支持的数据类型如下：  
| **数据类型** | **最小值**          | **最大值**          | **描述**                            |
| ------------ | ------------------- | ------------------- | ----------------------------------- |
| BOOL         | false               | true                | 布尔值                              |
| INT8         | -128                | 127                 | 8位整型                          |
| INT16        | -32768              | 32767               | 16位整型                         |
| INT32        | - 2^31              | 2^31 - 1            | 32位整型                         |
| INT64        | - 2^63              | 2^63 - 1            | 64位整型                         |
| DATE         | 0000-00-00          | 9999-12-31          | ""YYYY-MM-DD"" 格式的日期             |
| DATETIME     | 0000-00-00 00:00:00.000000 | 9999-12-31 23:59:59.999999 | ""YYYY-MM-DD HH:mm:ss[.ffffff]"" 格式的日期时间 |
| FLOAT        |                     |                     | 32位浮点数                       |
| DOUBLE       |                     |                     | 64位浮点数                       |
| STRING       |                     |                     | 不定长度的字符串                    |
| BLOB         |                     |                     | 二进制数据（在输入输出时使用Base64编码） |
| POINT        |                     |                     | EWKB格式数据，表示点              |
| LINESTRING   |                     |                     | EWKB格式数据，表示线              |
| POLYGON      |                     |                     | EWKB格式数据，表示面(多边形)       |
| FLOAT_VECTOR |                     |                     | 包含32位浮点数的动态向量               |' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.2. 数据类型'}"
产品是否支持麒麟操作系统？只有企业版支持么？,"page_content='QA汇总

安装部署QA

麒麟操作系统支持

Q：产品是否支持麒麟操作系统？只有企业版支持么？
A：开源和企业版都支持' metadata={'Header 1': 'QA汇总', 'Header 2': '安装部署QA', 'Header 3': '麒麟操作系统支持'}","page_content='环境准备

2.软件环境

2.1. 操作系统

TuGraph 能够兼容主流操作系统，包括Ubuntu、CentOS、SUSE、银河麒麟、 中标麒麟、UOS等，均通过测试认证。  
其中最稳定使用的系统版本是 Ubuntu 18.04、CentOS 7、CentOS 8。' metadata={'Header 1': '环境准备', 'Header 2': '2.软件环境', 'Header 3': '2.1. 操作系统'}","page_content='环境准备

1.硬件环境

1.1. CPU

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的硬件平台，测试认证过的硬件平台包括 Intel、AMD、Kunpeng、Hygon、飞腾等。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.1. CPU'}"
TuGraph-DB中存储Point类型数据的格式是什么？,"page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

实现思路

在TuGraph-DB的实现，基于boost geometry库的基础上进行封装，用EWKB格式存储数据，其中Point类型为定长存储50，其余皆为变长存储。我们支持了Point, Linestring与Polygon三种类型，同时支持了WGS84, CARTESIAN两种坐标系，数据类型与坐标系均可根据需要拓展。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现', 'Header 3': '实现思路'}","page_content='空间数据类型在TuGraph-DB中的实现

定义空间数据类型

TuGraph-DB当前已经支持Point、Linestring与Polygon三种类型  
-   • Point：点，创建方式例如POINT(2.0, 2.0, 7203)  
-   • Linestring：折线，创建方式例如LINESTRING(0 2,1 1,2 0)  
-   • Polygon：多边形，创建方式例如POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '定义空间数据类型'}","page_content='地理空间数据类型使用示例

3. 数据类型

目前在TuGraph中，我们已经支持了Point, Linestring与Polygon三种类型:  
- Point：点    point(2.0, 2.0, 7203)
- Linestring：折线 LINESTRING(0 2,1 1,2 0)
- Polygon：多边形  POLYGON((0 0,0 7,4 2,2 0,0 0))  
其中坐标点都是double型，创建图模型和插入数据示例如下：  
**创建标记美食位置的点模型**  
```
CALL db.createVertexLabel('food', 'id', 'id', int64, false, 'name', string, true,'pointTest',point,true)
```  
![image.png](../../../images/spatail/createVertexLabel.png)  
**插入标记美食点的数据**  
```
CREATE (n:food {id:10001, name: 'aco Bell',pointTest:point(3.0,4.0,7203)}) RETURN n
```  
![image.png](../../../images/spatail/createFoodData.png)  
**创建具有折线属性的点模型**  
```
CALL db.createVertexLabel('lineTest', 'id', 'id', int64, false, 'name', string, true,'linestringTest',linestring,true)
```  
![image.png](../../../images/spatail/createVertexLabel_lineTest.png)  
**插入具有折线属性的点数据**  
```
CREATE (n:lineTest {id:102, name: 'Tom',linestringTest:linestringwkt('LINESTRING(0 2,1 1,2 0)', 7203)}) RETURN n
```  
![image.png](../../../images/spatail/createLineTestData.png)  
**创建具有多边型属性的点模型**  
```
CALL db.createVertexLabel('polygonTest', 'id', 'id', int64, false, 'name', string, true,'polygonTest',polygon,true)
```  
![image.png](../../../images/spatail/createVertexLabel_PolygonTest.png)  
**插入具有多边型属性的点数据**  
```
CREATE (n:polygonTest {id:103, name: 'polygonTest',polygonTest:polygonwkt('POLYGON((0 0,0 7,4 2,2 0,0 0))', 7203)}) RETURN n
```' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '3. 数据类型'}"
TuGraph嵌入模式的API允许用户执行哪些操作？,"page_content='Procedure API

1.简介

当用户需要表达的查询/更新逻辑较为复杂（例如 Cypher 无法描述，或是对性能要求较高）时，相比调用多个请求并在客户端完成整个处理流程的方式，TuGraph 提供的存储过程是更简洁和高效的选择。  
与传统数据库类似，TuGraph 的存储过程运行在服务器端，用户通过将处理逻辑（即多个操作）封装到一个过程单次调用，并且可以在实现时通过并行处理的方式（例如使用相关的 C++ OLAP 接口以及基于其实现的内置算法）进一步提升性能。  
存储过程中有一类特殊的API来进行数据的并行操作，我们叫 Traversal API，见[文档](2.traversal.md)。' metadata={'Header 1': 'Procedure API', 'Header 2': '1.简介'}","page_content='RESTful API Legacy

1.简介

TuGraph 提供遵从 REST 规范的 HTTP API，以供开发者通过 HTTP 请求远程调用 TuGraph 提供的服务。  
本文档描述 TuGraph 的 HTTP API 使用方式。  
**注意：除""登陆""、""查询""和""存储过程""外，其余接口自 **2023年4月30日** 起将不再提供支持，统一使用Cypher接口提供服务。**' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '1.简介'}","page_content='功能概览

4.核心功能

4.2.存储过程

当用户需要表达的查询/更新逻辑较为复杂（例如 Cypher 无法描述，或是对性能要求较高）时，相比调用多个 REST 请求并在客户端完成整个
处理流程的方式，TuGraph 提供的存储过程（Procedure）是更简洁和高效的选择。  
从 3.5 版本开始，TuGraph 重新设计了新的存储过程编程范式，支持定义标准的签名和结果，支持POG编程。  
TuGraph 支持 POG (Procedres on Graph Query Languages) 编程和 POG 库，其中“Graph Query Languages”包含 Cypher 以及
制定中的 ISO GQL 等图查询语言。POG 库提供在查询语言中对用户定义的存储过程的访问，打破了查询语言和存储过程之间的界限，扩展了查询
语言的使用范围。  
> 这个文档描述了 [新的 Procedure 编程范式以及 POG](../9.olap&procedure/1.procedure/1.procedure.md)。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.2.存储过程'}"
Date 类的默认构造函数设置的日期是什么？,"page_content='GeaFlow支持以下日期函数：
* [from_unixtime](#from_unixtime)
* [from_unixtime_millis](#from_unixtime_millis)
* [unix_timestamp](#unix_timestamp)
* [unix_timestamp_millis](#unix_timestamp_millis)
* [isdate](#isdate)
* [now](#now)
* [day](#day)
* [weekday](#weekday)
* [lastday](#lastday)
* [day_of_month](#day_of_month)
* [week_of_year](#week_of_year)
* [date_add](#date_add)
* [date_sub](#date_sub)
* [date_diff](#date_diff)
* [add_months](#add_months)
* [date_format](#date_format)
* [date_part](#date_part)
* [date_trunc](#date_trunc)'","page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='表相关DDL

Create Table

数据类型

| 类型 | 说明 |
| -------- | -------- |
| BOOLEAN     | 布尔类型    |
| SHORT     | 短整形类型，范围: -2^15 + 1 ~ 2^15-1     |
| INT     |整形类型， 范围: -2^31 + 1 ~ 2^31-1     |
| LONG     | 长整形类型，范围: -2^63 + 1 ~ 2^63-1     |
| DOUBLE     |双精度浮点类型，范围: -2^1024 ~ +2^1024     |
| VARCHAR     |字符串类型  |
| TIMESTAMP   | 时间戳类型 |' metadata={'Header 1': '表相关DDL', 'Header 2': 'Create Table', 'Header 3': '数据类型'}"
在使用 bool DeleteVertexIndex 函数时，如果给定的 vertex_label 或 field 不存在会发生什么？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.deleteLabel(label_type, label_name)

Delete a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |  
**Output:**  
| field_name | field_type | description              |
| ---------- | ---------- | -------------------------------- |
| affected   | integer    | number of vertexes/edges deleted |  
**Example input:**  
```
CALL db.deleteLabel('vertex', 'Person')
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.deleteLabel(label_type, label_name)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelDelFields(label_type, label_name, field_names)

Delete specified fields from the label.  
**Parameters:**  
| parameter   | parameter type  | description           |
| ----------- | --------------- | ----------------------------- |
| label_type  | string      | either 'vertex' or 'edge'     |
| label_name  | string      | name of the label         |
| field_names | list of strings | names of the fields to delete |  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelDelFields('vertex', 'Person', ['name', 'image'])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelDelFields(label_type, label_name, field_names)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createVertexLabel(label_name, primary_field, field_spec...)

Create a vertex label.  
**Scope:** whole instance.  
**Parameters:**  
| parameter  | parameter type | description          |
| ---------- | -------------- | ------------------------ |
| label_name | string     | name of  vertex label    |
| primary_field | string  | primary field of vertex label |
| field_spec | list       | specification of a field |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, true]`, where true is specified only for optional fields.  
**Output:** If successful, it returns a success message.  
**Example input:**  
```
CALL db.createVertexLabel('Person', 'id', 'id', 'int64', false, 'name', 'string', true)
```  
**Example output:**  
```
Added label [Person]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createVertexLabel(label_name, primary_field, field_spec...)'}"
在单命令模式下，如何使用 lgraph_cypher 通过命令行参数来执行一条 Cypher 查询并将结果显示为表格格式？,"page_content='命令行工具

1.单命令模式

在单命令模式下，`lgraph_cypher`可用于提交单个 Cypher 查询并将结果直接打印到终端，打印结果也可以容易地重定向写入指定文件。当用户需要从服务器获取大量结果并将其保存在文件中时，这非常便利。
在此模式下，`lgraph_cypher`工具具有以下选项：' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式'}","page_content='命令行工具

1.单命令模式

1.2.命令示例:

**cypher 命令文件查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -f /home/usr/cypher.json
```  
**cypher 命令单句查询：**  
```powershell
$ ./lgraph_cypher.py -c /home/usr/lgraph_standalone.json -u user -P password -s ""MATCH (n) RETURN n""
```' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式', 'Header 3': '1.2.命令示例:'}","page_content='命令行工具

2.交互模式

2.2.command种类与说明:

除 Cypher 查询外，`lgraph_cypher` 的 shell 还接受以下命令：  
| 命令                     | 对应参数                           | 说明                                                                                                |
| ------------------------ | ---------------------------------- | --------------------------------------------------------------------------------------------------- |
| :help                    | \\                                 | 显示服务器信息与所有 command 对应说明。                                                             |
| :db_info                 | \\                                 | 当前服务器状态查询。对应 REST API 的/db/info。                                                      |
| :clear                   | \\                                 | 清空屏幕。                                                                                          |
| :use                     | {图的名称}                         | 使用该名称指定的图，默认值为`default` 。                                                            |
| :source                  | `-t {查询timeout值} -f {查询文件}` | 可交互模式下的 cypher 命令文件查询。超时阈值默认值为`150`秒。查询文件格式参考无交互式查询参数。     |
| :exit                    | \\                                 | 退出交互模式并返回原命令行。                                                                        |
| :format                  | `plain` or `table`                 | 更改 cypher 查询结果的显示模式。支持`plain`与`table`模式。                                          |
| :save all/command/result | `-f {文件路径}` `{cypher语句}`     | 存储 cypher 命令（command）或查询结果（result）或以上二者（all）。默认存储位置为`/saved_cypher.txt` |  
**注意:**  
- 每条命令都应该以冒号开始 `:`.  
**:save 命令例子:**  
```
:save all -f /home/usr/saved.txt match (n) where return n, n.name limit 1000
```' metadata={'Header 1': '命令行工具', 'Header 2': '2.交互模式', 'Header 3': '2.2.command种类与说明:'}"
reduce_plus函数是如何处理它的两个参数的？,"page_content='OlapBase API

7. 图类OlapBase

7.4 批处理操作

TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程。分别是：  
```c++
/*
函数名称:ReducedSum ProcessVertexInRange(std::function<ReducedSum(size_t)> work, size_t lower, size_t upper,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考include/lgraph/olap_base.h中具体代码

使用示例:统计数组parent数组中有出边的点个数
*/

auto vertex_num = graph.ProcessVertexInRange<size_t>(
[&](size_t i) {
if (graph.OutDegree(parent[i]) > 0) {
return 1;
}
},
0, parent.Size()
);
printf(""the number is %lu\n"",vertex_num);
```  
其中graph为图类OlapBase的实例化对象  
```C++
/*
函数名称:ReducedSum ProcessVertexActive(std::function<ReducedSum(size_t)> work, ParallelBitset &active_vertices,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对active_vertices中对应为1的节点执行work函数，第三个参数表示累加的基数，默认为0；
第四个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考/include/lgraph/olap_base.h中具体代码

使用示例:输出Graph中节点1，2，3的所有出度邻居，并统计这三个节点的总出度
*/

auto active_in = graph.AllocVertexSubset();
active_in.Add(1);
active_in.Add(2);
active_in.Add(3);
auto total_outdegree = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t local_outdegree = 0;
for (auto & edge : graph.OutEdges(vi)) {
size_t dst = edge.neighbour;
printf(""node %lu has neighbour %lu\n"",vi,dst);
local_outdegree += 1;
}
return local_outdegree;
},
active_in
);
printf(""total outdegree of node1,2,3 is %lu\n"",total_outdegree);
```' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.4 批处理操作'}","page_content='Cypher API

3.Functions

3.6.Mathematical functions

- abs()
get the absolute value of some data.
**Scope:** whole instance.
**Example input:**  
```
MATCH (a:person {name: 'Laurence Fishburne'}),(e:person {name: 'Carrie-Anne Moss'})
RETURN a.born, e.born, abs(a.born-e.born)
```  
**Example output:**  
| a.born | e.born | abs(a.born - e.born) |
|--------|--------|-----------------------|
| 1961   | 1967   | 6                     |  
- ceil()
Returns the smallest floating point number that is greater than or equal to a number and equal to a mathematical integer.
**Scope:** whole instance.
**Example input:**  
```
RETURN ceil(0.1)
```  
**Example output:**  
| ceil(0.1) |
| --------- |
| 1.0       |  
- floor()
get the largest floating point number that is less than or equal to the given number and equal to a mathematical integer.
**Scope:** whole instance.
**Example input:**  
```
RETURN floor(0.9)
```  
**Example output:**  
| floor(0.9) |
| ---------- |
| 0.0        |  
- round()
Returns the value of a number rounded to the nearest integer.
**Scope:** whole instance.
**Example input:**  
```
RETURN round(3.141592)
```  
**Example output:**  
| round |
| ----- |
| 3     |  
- rand()
Returns returns a random floating point number in the range from 0 (inclusive) to 1 exclusive).
**Scope:** whole instance.
**Example input:**  
```
RETURN rand()
```  
**Example output:**  
| rand()             |
| ------------------ |
| 0.9797131960534085 |  
- sign()
Get the signum of the given number: 0 if the number is 0, -1 for any negative number, and 1 for any positive number.
**Scope:** whole instance.
**Example input:**  
```
RETURN sign(-17), sign(0.1)
```  
**Example output:**  
| sign(-17) | sign(0.1) |
| --------- | --------- |
| -1        | 1         |  
TuGraph 查询语言与 OpenCypher 的不同点如下：  
- Label 数量
- TuGraph: Each node/relationship must have one and only one label. So error occurs when there is no label, and the 1st label will be picked as the label if there are more than ' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.6.Mathematical functions'}","page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}"
是否支持无向边,"page_content='QA汇总

Cypher QA

长边条件查询

Q：是否支持不定长边的条件查询？
示例：  
```
MATCH p=(v)-[e:acted_in|:rate*1..3]-(v2) WHERE id(v) IN [3937] AND e.stars = 3 RETURN p LIMIT 100
```  
A：目前还不支持不定长边的过滤查询。目前的代替方案只能是分开写。上面的示例，就需要从 1 跳到 3 跳都写一遍。' metadata={'Header 1': 'QA汇总', 'Header 2': 'Cypher QA', 'Header 3': '长边条件查询'}","page_content='Match

Syntax

Edge

匹配图上的边，类似Node节点可以指定边的类型以及对边的过滤条件。和Node不同的是,边需要指定方向，边的方向包括入边、出边和双向边。' metadata={'Header 1': 'Match', 'Header 2': 'Syntax', 'Header 3': 'Edge'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/relationship/{euid}
```  
与 Nodes 功能类似，Relationships 提供边（edge）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。每一条边都可以由一个唯一 ID（euid）来标识。这个 ID 可以从在插入边时获得，或者在 [列出所有边](#%E5%88%97%E5%87%BA%E6%89%80%E6%9C%89%E8%BE%B9) 操作中得到。  
#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| fields | 数据列名 | 列表 |
| edge | 边数据 | 列表 |  
其中 edge 是一个数据列表，其中每个元素都是一条边，其定义如下：  
| 域名        | 说明     | 类型                                                   |
| ----------- | -------- | ------------------------------------------------------ |
| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 20' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}"
FieldData类中提供哪些构造函数来初始化不同类型的数据？,"page_content='OlapBase API

6. 自定义数据结构

6.2 组合数据结构

为了便于计算，我们根据计算场景不同，定义了几种点和边数据的数据结构，分别是：  
- `EdgeUnit<EdgeData>`：表示权值类型为EdgeData的边，用于解析输入文件，包含三个成员变量：
- `size_t src`：边的起始点
- `size_t dst`：边的终点
- `EdgeData edge_data`：边的权值
- `AdjUnit<EdgeData>`：表示权值类型为EdgeData的边，用于批处理计算过程中，包含两个成员变量：
- `size_t neighbour`：边的邻居点
- `EdgeData edge_data`：边的权值
- `AdjList<EdgeData>`：权值类型为EdgeData的点的邻接表，常用于表示点的入边和出边集合，包含两个成员变量：
- `AdjUnit<T> * begin`：列表的起始指针
- `AdjUnit<T> * end`：列表的结束指针。begin和end的用法类似于vector容器的begin和end指针，可以使用这两个指针对邻接表进行循环访问。' metadata={'Header 1': 'OlapBase API', 'Header 2': '6. 自定义数据结构', 'Header 3': '6.2 组合数据结构'}","page_content='空间数据类型在TuGraph-DB中的实现

相关函数介绍

创建空间数据相关函数，以Point为例：  
| **函数名** | **描述** | **输入参数** | **返回值类型** |
| --- | --- | --- | --- |
| Point() | 根据坐标或EWKB创建Point | 坐标对(double, double) / EWKB format(string) | point |
| PointWKB() | 根据WKB与指定SRID创建Point | WKB format(string) , SRID(int) | point |
| PointWKT() | 根据WKT与指定SRID创建Point | WKT format(string) , SRID(int) | point |  
查询用相关函数：  
| **函数名** | **描述** | **输入参数** | **返回值类型** |
| --- | --- | --- | --- |
| Distance() | 计算两个空间数据间的距离 |
|
|
| 注：要求坐标系相同 | Spatial data1, Spatial data2 | double |
|
| Disjoint() | 判断两个空间数据是否相交 |
|
|
| 注：开发中 | Spatial data1, Spatial data2 | bool |
|
| WithinBBox() | 判断某个空间数据是否在给定的长方形区域内 |
|
|
| 注：开发中 | Spatial data, Point1 | bool |
|  
使用实例如下：  
```
#创建包含空间数据类型的点模型
CALLdb.createVertexLabel('food','id','id',int64,false,'name',string,true,'pointTest',point,true)

#插入标记美食点的数据
CREATE(n:food{id:10001,name:'acoBell',pointTest:point(3.0,4.0,7203)})RETURNn

#创建具有折线属性的点模型
CALLdb.createVertexLabel('lineTest','id','id',int64,false,'name',string,true,'linestringTest',linestring,true)

#插入具有折线属性的点数据
CREATE(n:lineTest{id:102,name:'Tom',linestringTest:linestringwkt('LINESTRING(02,11,20)',7203)})RETURNn

#创建具有多边型属性的点模型
CALLdb.createVertexLabel('polygonTest','id','id',int64,false,'name',string,true,'polygonTest',polygon,true)

#插入具有多边型属性的点数据
CREATE(n:polygonTest{id:103,name:'polygonTest',polygonTest:polygonwkt('POLYGON((00,07,42,20,00))',7203)})RETURNn



```' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '相关函数介绍'}","page_content='OlapBase API

6. 自定义数据结构

6.1 基本数据类型

我们自定义了点和边的数据结构表示，用于在覆盖所有点的同时节省内存空间：  
- `Empty`：内容为空的特殊数据类型。' metadata={'Header 1': 'OlapBase API', 'Header 2': '6. 自定义数据结构', 'Header 3': '6.1 基本数据类型'}"
TuGraph-DB是如何帮助解决旅行时选择路线的烦恼的？,"page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。  
蚂蚁集团 2015 年开始自主研发分布式图数据库、流式图计算等图相关技术，2016 年发布自研分布式图数据库，并应用于支付宝。至今 TuGraph 已应用于蚂蚁内部 150 多个场景，包括在线支付的实时链路，以支付宝风险识别能力提升近 10 倍、风险审理分析效率提升 90%的成绩，验证了其高可靠性。  
LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，TuGraph 在功能完整性、吞吐率、响应速度等层面全球领先。  
目前，蚂蚁集团已形成了一套以图数据库为底座、同时包含流式图计算，离线图学习的大规模图计算系统。  
蚂蚁集团图数据库负责人洪春涛表示，图技术是未来大数据、人工智能和高性能计算产业发展的关键所在，它很有可能会成为下一代的数据底座。蚂蚁集团愿意通过开源持续输出核心技术优势，推动图数据库更广泛的应用生态，携手行业抢占技术高地，不断探索技术的可能性。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}","page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}"
exists()函数用于检查什么？,"page_content='Cypher API

3.Functions

3.2.Predicate functions

- exists()
judge it whether a vertex or edge has the field .
**Scope:** whole instance.
**Example input:**  
```
MATCH (n)
WHERE exists(n.born)
RETURN n.name, n.born
```  
**Example output:**  
| exists(name) |
| ------------ |
| true         |' metadata={'Header 1': 'Cypher API', 'Header 2': '3.Functions', 'Header 3': '3.2.Predicate functions'}","page_content='SubQuery

Syntax

Exists Query

```sql
EXISTS PathPatthern
```' metadata={'Header 1': 'SubQuery', 'Header 2': 'Syntax', 'Header 3': 'Exists Query'}","page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}"
安装部署TuGraph硬件的最低和建议CPU配置分别是多少个核心？,"page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='环境准备

1.硬件环境

1.1. CPU

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的硬件平台，测试认证过的硬件平台包括 Intel、AMD、Kunpeng、Hygon、飞腾等。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.1. CPU'}","page_content='环境准备

2.软件环境

2.1. 操作系统

TuGraph 能够兼容主流操作系统，包括Ubuntu、CentOS、SUSE、银河麒麟、 中标麒麟、UOS等，均通过测试认证。  
其中最稳定使用的系统版本是 Ubuntu 18.04、CentOS 7、CentOS 8。' metadata={'Header 1': '环境准备', 'Header 2': '2.软件环境', 'Header 3': '2.1. 操作系统'}"
MappedVid 函数是用于什么目的？,"page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends Gra' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='Python Olap API

4. Olap API

图类OlapBase

- `NumVertices()-> size_t`：获取点数
- `NumEdges()-> size_t`：获取边数
- `OutDegree(size_t vid)-> size_t`：点vid的出度
- `InDegree(size_t vid)-> size_t`：点vid的入度  
- `AllocVertexArray[VertexData]() ->ParallelVector[VertexData]`：分配一个类型为VertexData的数组，大小为点个数
- `AllocVertexSubset()-> ParallelBitset`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `OutEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有出边集合
- `InEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有入边集合
- `Transpose()-> cython.void`：对有向图进行图反转
- `LoadFromArray(edge_array: cython.p_char, input_vertices: size_t, input_edges: size_t, edge_direction_policy: EdgeDirectionPolicy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。  
- `AcquireVertexLock(vid: size_t)-> cython.void`：对点vid加锁，禁止其它线程对该锁对应的点数据进行访存
- `void ReleaseVertexLock(vid: size_t)-> cython.void`：对点vid解锁，所有线程均可访存该锁对应的点数据  
TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程，在Python中与C++使用方法稍有不同。  
```python
# 函数名称:ProcessVertexInRange[ReducedSum, Algorithm](
#           work: (algo: Algorithm, vi: size_t)-> ReducedSum,
#           lower: size_t, upper: size_t,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#     函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
#     第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
#     具体实现请参考include/lgraph/olap_base.h中具体代码
#
#     使用示例:统计数组parent数组中有出边的点个数

import cython
from cython.cimports.olap_base import *


@cython.cclass
class CountCore:
graph: cython. pointer(OlapBase[Empty])
parent: ParallelVector[size_t]

@cython.cfunc
@cython.nogil
def Work(self, vi: size_t) -> size_t:
if self.graph.OutDegree(self.parent[vi]) > 0:
return 1
return 0

def run(self, pointer_g: cython' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void init(IncGraphComputeContext<K, VV, EV, M> incGraphContext) | 图计算初始化接口 | incGraphContext： 增量动态图计算的上下文，K表示vertex id的类型，VV表示vertex value类型，EV表示edge value类型，M表示发送消息的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮迭代对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 迭代计算接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 迭代计算完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型 |  
- 详细接口  
```java
public interface IncVertexCentricFunction<K, VV, EV, M> extends Function {

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncGraphContext<K, VV, EV, M> {
/** 获取job id */
long getJobId();

/** 获取当前迭代 id */
long getIterationId();

/** 获取运行时上下文 */
RuntimeContext getRuntimeContext();

/** 获取可变图 */
MutableGraph<K, VV, EV> getMutableGraph();

/** 获取增量图 */
TemporaryGraph<K, VV, EV> getTemporaryGraph();

/** 获取图存储上的历史图 */
HistoricalGraph<K, VV, EV> getHistoricalGraph();

/** 给指定vertex发送消息 */
void sendMessage(K vertexId, M message);

/** 给当前vertex邻居节点发送消息 */
void sendMessageToNeighbors(M message);

}

interface TemporaryGraph<K, VV, EV> {
/** 从增量图中获取vertex */
IVertex<K, VV> getVertex();

/** 从增量图中获取edges */
List<IEdge<K, EV>> getEdges();

/** 更新vertex value */
void updateVertexValue(VV value);

}

interface HistoricalGraph<K, VV, EV> {
/** 获取图数据最新版本id */
Long getLatestVersionId();

/** 获取图数据所有版本 */
List<Long> getAllVersionIds();

/** 获取图数据所有vertex */
Map<Long, IVertex<K, VV>> getAllVertex();

/** 获取图数据指定版本的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions);

/** 获取图数据指定版本并满足过滤条件的ve' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
当尝试更新一个存在的边但标签与指定的不符时，会发生什么？,"page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/relationship/{euid}
```  
与 Nodes 功能类似，Relationships 提供边（edge）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。每一条边都可以由一个唯一 ID（euid）来标识。这个 ID 可以从在插入边时获得，或者在 [列出所有边](#%E5%88%97%E5%87%BA%E6%89%80%E6%9C%89%E8%BE%B9) 操作中得到。  
#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| fields | 数据列名 | 列表 |
| edge | 边数据 | 列表 |  
其中 edge 是一个数据列表，其中每个元素都是一条边，其定义如下：  
| 域名        | 说明     | 类型                                                   |
| ----------- | -------- | ------------------------------------------------------ |
| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 20' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}","page_content='业务开发指南

边类型操作

边类型添加字段

>该操作会同步变更所有该类型边的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于边类型`edge1`，一次添加了两个字段: `field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是`0`.
```
CALL db.alterLabelAddFields('edge', 'edge1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型添加字段'}","page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}"
"批量在线导入是通过”CREATE (n), (m)“吗？","page_content='数据导入

5.在线增量导入

在线导入模式可用于将一批文件导入已在运行中的 TuGraph 实例中。这对于处理通常以固定的时间间隔进行的增量批处理更新非常便利。`lgraph_import --online true`选项使导入工具能够在线模式工作。与`离线模式`一样，在线模式有自己的命令行选项集，可以使用`-h，--help`选项进行打印输出：  
```shell
$ lgraph_import --online true -h
Available command line options:
--online            Whether to import online.
-h, --help          Print this help message. Default=0.

Available command line options:
--log               Log file to use, empty means stderr. Default="""".
-v, --verbose       Verbose level to use, higher means more verbose.
Default=1.
-c, --config_file   Config file path.
-r, --url           DB REST API address.
-u, --username      DB username.
-p, --password      DB password.
-i, --continue_on_error
When we hit a duplicate uid or missing uid, should we
continue or abort. Default=0.
-g, --graph         The name of the graph to import into. Default=default.
--skip_packages     How many packages should we skip. Default=0.
--delimiter         Delimiter used in the CSV files
--breakpoint_continue
When the transmission process is interrupted,whether
to re-transmit from zero package next time. Default=false
-h, --help          Print this help message. Default=0.
```  
文件的相关配置在配置文件中指定，其格式与`离线模式`完全相同。但是，我们现在不是将数据导入本地数据库，而是将数据发送到正在运行的 TuGraph 实例中，该实例通常运行在与运行导入工具的客户端计算机不同的计算机上。因此，我们需要指定远程计算机的 HTTP 地址的URL、DB用户和密码。  
如果用户和密码有效，并且指定的图存在，导入工具将将数据发送到服务器，服务器随后解析数据并将其写入指定的图。数据将以大约 16MB 大小的包发送，在最近的换行符处中断。每个包都是以原子方式导入的，这意味着如果成功导入包，则成功导入所有数据，否则，任何数据都不会进入数据库。如果指定了`--continue_on_error true`，则忽略数据完整性错误，并忽略违规行。否则，导入将在第一个错误包处停止，并打印出已导入的包数。在这种情况下，用户可以修改数据以消除错误，然后使用`--skip_packages N`重做导入以跳过已导入的包。' metadata={'Header 1': '数据导入', 'Header 2': '5.在线增量导入'}","page_content='数据导入

6.在线全量导入

6.1 从原数据导入

从原数据导入的执行方式是向运行中的TuGraph实例发送导入请求，
实例接到请求后先使用离线导入（V3）的方式将数据导入一个临时的db中，然后在实例中新建子图并将临时db的数据文件迁移到新子图中，最后刷新实例的元数据。
相比在线增量导入，在线全量导入的性能更高。
`lgraph_import --online true --online_type 1`选项使导入工具能够在线全量导入。
与`离线模式`一样，在线模式有自己的命令行选项集，可以使用`-h，--help`选项进行打印输出：  
```shell
$ lgraph_import --online true --online_type 1 -h
Available command line options:
--online_type       The type of import online, 0 for increment, 1 for full
import data,2 for full import file. Default=0.
--v3                Whether to use lgraph import V3. Default=1.
-h, --help          Print this help message. Default=0.

Available command line options:
--full              Whether to full import online. Default=0.
-h, --help          Print this help message. Default=0.

Available command line options:
-c, --config_file   Config file path.
-r, --url           DB REST API address.
-u, --user          DB username.
-p, --password      DB password.
-i, --continue_on_error
When we hit a duplicate uid or missing uid, should we
continue or abort. Default=0.
-g, --graph         The name of the graph to import into. Default=default.
--delimiter         Delimiter used in the CSV files. Default=,.
--log               Log dir to use, empty means stderr. Default="""".
-v, --verbose       Verbose level to use, higher means more verbose.
Default=1.
--overwrite         Whether to overwrite the existing DB if it already
exists. Default=0.
--parse_block_size  Block size per parse. Default=8388608.
--parse_block_threads
How many threads to parse the data block. Default=5.
--parse_file_threadsHow many threads to parse the files. Default=5.
--generate_sst_threads
How many threads to generate sst files. Default=15.
--read_rocksdb_threads
How many threads to read rocksdb in the final stage.
Default=15.
--vid_num_per_reading
How many vertex data to read each time. Default=10000.
--max_size_per_reading
Maximum size of kvs per reading. Default=33554432.
--compact           Whether to compact. Default=0.
--keep_vid_in' metadata={'Header 1': '数据导入', 'Header 2': '6.在线全量导入', 'Header 3': '6.1 从原数据导入'}","page_content='数据导入

6.在线全量导入

6.2 从数据库文件导入

从原数据在线全量导入尽管操作简单、性能较高，但是对服务器资源要求较高，且耗时较长。
一种更加通用的方式是先使用离线导入在一个空db中导入子图，得到data.mdb文件，然后把该文件在线导入到
TuGraph服务中。其使用方式如下所示：  
```shell
$ ./lgraph_import --online true --online_type 2 -h
Available command line options:
--online            Whether to import online. Default=0.
--v3                Whether to use lgraph import V3. Default=1.
-h, --help          Print this help message. Default=0.

Available command line options:
--online_type       The type of import online, 0 for increment, 1 for full
import data,2 for full import file. Default=0.
-h, --help          Print this help message. Default=0.

Available command line options:
-r, --url           DB REST API address.
-u, --user          DB username.
-p, --password      DB password.
-g, --graph         The name of the graph to import into. Default=default.
--path              The path of data file.
--remote            Whether to download file from remote server. Default=0.
-h, --help          Print this help message. Default=0.
```  
除普通在线导入用到的url, user和password参数之外，从数据库文件导入的在线全量导入方式
使用graph参数指定导入的子图名称，path参数指定文件路径，remote指定文件存在在远程或者本地。
如果是本地文件，则需要保证HA集群中所有的节点在path路径下都有该文件。如果是远程文件，则会先下载再导入。
需要注意的是，由于data.mdb只有一份，需要保证HA的各个节点和离线导入生成data.mdb的机器的环境完全一致，
以保证不会出现环境问题。' metadata={'Header 1': '数据导入', 'Header 2': '6.在线全量导入', 'Header 3': '6.2 从数据库文件导入'}"
lgraph_backup工具的主要功能是什么？,"page_content='备份恢复

1.数据备份

TuGraph 可以通过 `lgraph_backup` 工具来进行数据备份。
`lgraph_backup` 工具可以将一个 TuGraph 数据库中的数据备份到另一个目录下，它的用法如下：  
```bash
$ lgraph_backup -s {source_dir} -d {destination_dir} -c {true/false}
```  
其中：  
- `-s {source_dir}` 指定需要备份的数据库（源数据库）所在目录。
- `-d {destination_dir}` 指定备份文件（目标数据库）所在目录。
如果目标数据库不为空，`lgraph_backup` 会提示是否覆盖该数据库。
- `-c {true/false}` 指明是否在备份过程中进行 compaction。
compaction 能使产生的备份文件更紧凑，但备份时间也会变长。该选项默认为 `true`。' metadata={'Header 1': '备份恢复', 'Header 2': '1.数据备份'}","page_content='备份恢复

2.数据恢复

使用`lgraph_backup` 工具得到的目标数据库`{destination_dir}`备份了源数据库
`{source_dir}`的所有子图，但不包含HA集群的raft信息，从而保证服务和集群能
以备份数据库成功重启并与源数据库的数据一致。使用如下命令可以用备份数据库重启服务，
在服务启动时会恢复所有子图的存储过程，保证备份服务和原服务完全一致。  
```bash
$ lgraph_server -c lgraph.json --directory {destination_dir} -d start
```  
其中：  
- `-d {destination_dir}` 指定备份文件（目标数据库）所在目录。' metadata={'Header 1': '备份恢复', 'Header 2': '2.数据恢复'}","page_content='功能概览

4.核心功能

4.4.备份恢复

TUGraph的备份在功能上可分为主动/定时、离线/在线、全量/增量备份，用尽量小的存储和计算代价来完成备份。恢复功能可以恢复到最新的状态，或者历史标注的时间点，需要保证数据库是一致的状态。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.4.备份恢复'}"
在获取某个节点的所有属性时，通过什么方法和URI可以实现？,"page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/node/{vid}
```  
Nodes 提供节点（Vertex）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。  
#### 6.7.1.列出点数量和label数量  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| num_label | 点 label 数量 | 整数 |
| num_vertex | 点数量 | 整数 |  
_注意 num_vertex 返回的并不是准确的点数量，只是一个估计值。_  
#### 6.7.2.创建一个点  
向数据库中插入一个点。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 点属性 | 字典，其中 key 是列名，value 是相应值。value 必须是与列类型相应的类型，如列为 int32，则 value 只能是整数。 |  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新点 vid。该 ID 可用于后续的点操作中。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""property"" : {
""name"" : ""Passerby A"",
""birthyear"" : 1989
}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
21
}
```  
#### 6.7.3.批量创建点  
TuGraph 允许一次性插入多个点，以减少网络开销。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| fields | 点属性 | 列表 |
| values | 点数据 | 列表 |  
其中 fields 是一个字符串列表，列出一系列列名；values 是一个列表，其中每个元素是一个列表，列表中每个元素是列数据。  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新增加的点的 vid 列表，该列表中每一个 vid 按顺序对应请求中的每一个点。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""fields"" : [""name"", ""birthyear""],
""values"" : [[""alex"", 2000],
[""bob"", 1999]]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
22,
23
]
}
```  
#### 6.7.4.获取点  
- **URI**: `/db/{graph_name}/node/{vertex_id}`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}","page_content='OlapOnDB API

3. 算法举例

3.2 PageRank算法流程

`pagerank`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关数据结构的初始化
1. 每个节点pagerank值的初始化
1. 每个节点pagerank值的计算，活跃点为所有点（意味着所有点都需要计算pagerank值）
1. 得到每个节点经过`num_iterations`次迭代后的pagerank值  
```C++
void PageRankCore(OlapBase<Empty>& graph, int num_iterations, ParallelVector<double>& curr) {

// 相关数据结构的初始化
auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
auto curr = olapondb.AllocVertexArray<double>();
auto next = olapondb.AllocVertexArray<double>();
size_t num_vertices = olapondb.NumVertices();
double one_over_n = (double)1 / num_vertices;

// 每个节点pagerank值的初始化，和该节点的出度成反比
double delta = graph.ProcessVertexActive<double>(
[&](size_t vi) {
curr[vi] = one_over_n;
if (olapondb.OutDegree(vi) > 0) {
curr[vi] /= olapondb.OutDegree(vi);
}
return one_over_n;
},
all_vertices);

// 总迭代过程
double d = (double)0.85;
for (int ii = 0;ii < num_iterations;ii ++) {
printf(""delta(%d)=%lf\n"", ii, delta);
next.Fill((double)0);

/*
函数用途：计算所有节点的pagerank值

函数流程描述：该函数用于计算所有节点的pagerank值，对all_vertices中所有为1的位对应的节点vi执行Func C，得到本轮迭代中vi的pagerank值，并返回vi节点的pagerank变化值，最终经过函数内部处理汇总所有活跃节点的总变化值并返回，该值被存储在delta变量中
*/
delta = graph.ProcessVertexActive<double>(
// Func C
[&](size_t vi) {
double sum = 0;

// 从邻居中获取当前节点的pagerank值
for (auto & edge : olapondb.InEdges(vi)) {
size_t src = edge.neighbour;
sum += curr[src];
}
next[vi] = sum;

// pagerank值计算核心公式
next[vi] = (1 - d) * one_over_n + d * next[vi];
if (ii == num_iterations - 1) {
return (double)0;
} else {

// 相关中间变量统计
if (olapondb.OutDegree(vi) > 0) {
next[vi] /= olapondb.OutDegree(vi);
return fabs(next[vi] - curr[vi]) * olapondb.OutDegree(vi);
} else {
return fabs(next[vi] - curr[vi]);
}
}
},
all_vertices
);

// 将本轮迭代得到的pagerank值输出作为下一轮迭代的输入
curr.Swap(next);
}
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.2 PageRank算法流程'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.subgraph()

**Scope:** whole instance.  
**Parameters:**  
| parameter  | parameter type | description                                                           |
| ---------- | -------------- | --------------------------------------------------------------------- |
| vids       | list           | list of vertex id                                                     |  
**Output:**  
Get a json containing all the properties of nodes and relationships.  
**Example input:**  
```
CALL db.subgraph([3937,4126,4066,4010])
```  
**Example output**  
| subgraph |
| -------- |
| {""nodes"":[{""identity"":3937,""label"":""movie"",""properties"":{""duration"":136,""id"":1,""poster_image"":""http://image.tmdb.org/t/p/w185/gynBNzwyaHKtXqlEKKLioNkjKgN.jpg"",""rated"":""R"",""summary"":""Thomas A. Anderson is a man living two lives. By day he is an average computer programmer and by night a malevolent hacker known as Neo who finds himself targeted by the police when he is contacted by Morpheus a legendary computer hacker who reveals the shocking truth about our reality."",""tagline"":""Welcome to the Real World."",""title"":""The Matrix""}},{""identity"":4010,""label"":""user"",""properties"":{""id"":44,""login"":""Howard""}},{""identity"":4066,""label"":""user"",""properties"":{""id"":202,""login"":""Enoch""}},{""identity"":4126,""label"":""user"",""properties"":{""id"":464,""login"":""Wilburn""}}],""relationships"":[{""dst"":4126,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4010,""temporal_id"":0},{""dst"":4010,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4066,""temporal_id"":0},{""dst"":4066,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4126,""temporal_id"":0}]} |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.subgraph()'}"
知识图谱的基本元素包括哪些？,"page_content='Learn Tutorial

1.TuGraph 图学习模块简介

图学习是一种机器学习方法，其核心思想是利用图结构中的拓扑信息，通过顶点之间的联系及规律来进行数据分析和建模。不同于传统机器学习方法，图学习利用的数据形式为图结构，其中顶点表示数据中的实体，而边则表示实体之间的关系。通过对这些顶点和边进行特征提取和模式挖掘，可以揭示出数据中深层次的关联和规律，从而用于各种实际应用中。  
这个模块是一个基于图数据库的图学习模块，主要提供了四种采样算子：Neighbor Sampling、Edge Sampling、Random Walk Sampling 和 Negative Sampling。这些算子可以用于对图中的顶点和边进行采样，从而生成训练数据。采样过程是在并行计算环境下完成的，具有高效性和可扩展性。  
在采样后，我们可以使用得到的训练数据来训练一个模型。该模型可以用于各种图学习任务，比如预测、分类等。通过训练，模型可以学习到图中的顶点和边之间的关系，从而能够对新的顶点和边进行预测和分类。在实际应用中，这个模块可以被用来处理各种大规模的图数据，比如社交网络、推荐系统、生物信息学等。' metadata={'Header 1': 'Learn Tutorial', 'Header 2': '1.TuGraph 图学习模块简介'}","page_content='图相关DDL

Create Graph

**Syntax**
一个图至少包含一对点边，点表必须包含一个id字段作为主键，边表必须包含srcId和targetId作为主键，边表还可以有一个时间戳字段标识时间。  
```
CREATE GRAPH <graph name>
(
<graph vertex>
[ { , <graph vertex> } ... ]
, <graph edge>
[ { , <graph edge> } ... ]
) WITH （
storeType = <graph store type>
[ { , <config key> = <config value> } ... ]
);

<graph vertex>  ::=
VERTEX <vertex name>
(
<column name> <data type> ID
[ {, <column name> <data type> } ... ]
)

<graph edge>  ::=
Edge <edge name>
(
<column name> <data type> SOURCE ID
, <column name> <data type> DESTINATION ID
[ , <column name> <data type> TIMESTAMP ]
[ {, <column name> <data type> } ... ]
)

```  
**Example**
```sql
CREATE GRAPH dy_modern (
Vertex person (
id bigint ID,
name varchar,
age int
),
Vertex software (
id bigint ID,
name varchar,
lang varchar
),
Edge knows (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
),
Edge created (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
)
) WITH (
storeType = 'rocksdb',
shardCount = 2
);
```
这个例子创建了一张包含2个点2个边的图，存储类型为rocksdb, 分片数2个。' metadata={'Header 1': '图相关DDL', 'Header 2': 'Create Graph'}","page_content='应用场景

2. 工业领域

在生产和制造过程中会产生大量异构数据，如何有效的组织和管理这些数据是工业大数据中最重要的问题之一。这些数据包括设计文档、设备数据、仿真方案和结果、实验结果、经验文档等，关系错综复杂。传统的数据管理系统只能累积数据，而查找相关材料则往往力不从心。使用图模型，将这些不同类型的数据组织成一张网络，就可以方便地浏览和查找数据。  
| **场景**         | **描述**               |
|-----------------| -----------------------|
|供应链管理|供应链数据主要关心产品—部件—零件的对应关系、零件与供应商的对应关系、零件中的敏感成分等。相比于传统的物料管理（BOM）系统，使用图数据库的方案可以更方便地维护多个部件层次、多个供应商级别的复杂网络，从而为穿透式供应链提供基础支持。|
|文档管理|使用图数据库可以将不同类型的文档按不同关系有机地组织在一起。例如将部件设计文档、部件—零件关系、部件测试文档、相关经验文档等组织起来，在需要查找时就可以方便获取该部件的所有相关信息。|
|研发过程管理|产品研发和验证过程中需要进行大量仿真、试验和测试，每一个测试流程都会涉及大量不同的步骤。步骤之间的连接关系、每个步骤中使用的数据版本、算法版本等就构成了一张复杂的关系网络。使用图数据库可以更好管理这个关系网络，从而为研发过程中的数据复用、流程改进提供良好基础。|
|设备信息管理|制造业需要管理大量设备，设备之间又互相关联（供电关系、供料关系、空间关系），从而形成了一张复杂的网络。传统的数据库很难体现这种复杂关系。而使用图数据库则可以便捷表示这些关系，从而更好的管理设备信息。|' metadata={'Header 1': '应用场景', 'Header 2': '2. 工业领域'}"
TuGraph-DB是否支持存储过程？支持哪些编程语言的存储过程？,"page_content='Procedure API

3.存储过程语言支持

在 TuGraph 中，用户可以动态的加载，更新和删除存储过程。TuGraph 支持 C++ 语言、 Python 语言和 Rust 语言编写存储过程。在性能上 C++ 语言支持的最完整，性能最优。  
注意存储过程是在服务端编译执行的逻辑，和客户端的语言支持无关。' metadata={'Header 1': 'Procedure API', 'Header 2': '3.存储过程语言支持'}","page_content='试用体验：TuGraph — 简单高效的图数据库

开放存储过程的使用

TuGraph支持存储过程的使用，让我感到非常满意。存储过程允许我在数据库中定义自己的逻辑和操作，以更高效地处理数据。我可以根据需求编写存储过程，并直接在图数据库中调用，这大大简化了我的开发流程。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '开放存储过程的使用'}","page_content='RPC API

5.存储过程

为满足用户较为复杂的查询/更新逻辑，TuGraph支持 C 语言和 Python 语言编写的存储过程。
用户可以使用RPC请求对存储过程进行增删改查操作。' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程'}"
GetEdgeProp操作的目的是什么？,"page_content='Sampling API

3. 图采样算子介绍

3.4.EdgeSampling算子：

根据边采样率，生成采样边的子图。
```python
Process(db_: lgraph_db_python.PyGraphDB, olapondb:lgraph_db_python.PyOlapOnDB, feature_num: size_t, sample_rate: double, NodeInfo: list, EdgeInfo: list,EdgeInfo: list)
```
参数列表：
db_: 图数据库实例。
olapondb: 图分析类。
feature_num: size_t类型，feature特征向量的长度。
sample_rate: double类型，采样率。
NodeInfo: list类型，一个点属性字典的列表，表示点的元数据信息。
EdgeInfo: list类型，一个边属性字典的列表，表示边的元数据信息。
返回值: 无。' metadata={'Header 1': 'Sampling API', 'Header 2': '3. 图采样算子介绍', 'Header 3': '3.4.EdgeSampling算子：'}","page_content='Python Olap API

4. Olap API

图类OlapBase

- `NumVertices()-> size_t`：获取点数
- `NumEdges()-> size_t`：获取边数
- `OutDegree(size_t vid)-> size_t`：点vid的出度
- `InDegree(size_t vid)-> size_t`：点vid的入度  
- `AllocVertexArray[VertexData]() ->ParallelVector[VertexData]`：分配一个类型为VertexData的数组，大小为点个数
- `AllocVertexSubset()-> ParallelBitset`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `OutEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有出边集合
- `InEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有入边集合
- `Transpose()-> cython.void`：对有向图进行图反转
- `LoadFromArray(edge_array: cython.p_char, input_vertices: size_t, input_edges: size_t, edge_direction_policy: EdgeDirectionPolicy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。  
- `AcquireVertexLock(vid: size_t)-> cython.void`：对点vid加锁，禁止其它线程对该锁对应的点数据进行访存
- `void ReleaseVertexLock(vid: size_t)-> cython.void`：对点vid解锁，所有线程均可访存该锁对应的点数据  
TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程，在Python中与C++使用方法稍有不同。  
```python
# 函数名称:ProcessVertexInRange[ReducedSum, Algorithm](
#           work: (algo: Algorithm, vi: size_t)-> ReducedSum,
#           lower: size_t, upper: size_t,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#     函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
#     第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
#     具体实现请参考include/lgraph/olap_base.h中具体代码
#
#     使用示例:统计数组parent数组中有出边的点个数

import cython
from cython.cimports.olap_base import *


@cython.cclass
class CountCore:
graph: cython. pointer(OlapBase[Empty])
parent: ParallelVector[size_t]

@cython.cfunc
@cython.nogil
def Work(self, vi: size_t) -> size_t:
if self.graph.OutDegree(self.parent[vi]) > 0:
return 1
return 0

def run(self, pointer_g: cython' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}","page_content='Training

2. Mini-Batch训练

Mini-Batch训练需要使用TuGraph 图学习模块的采样算子，目前支持Neighbor Sampling、Edge Sampling、Random Walk Sampling和Negative Sampling。
TuGraph 图学习模块的采样算子进行采样后的结果以List的形式返回。
下面以Neighbor Sampling为例，介绍如何将采样后的结果，进行格式转换，送入到训练框架中进行训练。
用户需要提供一个Sample类：
```python
class TuGraphSample(object):
def __init__(self, args=None):
super(TuGraphSample, self).__init__()
self.args = args

def sample(self, g, seed_nodes):
args = self.args
# 1. 加载图数据
galaxy = PyGalaxy(args.db_path)
galaxy.SetCurrentUser(args.username, args.password)
db = galaxy.OpenGraph(args.graph_name, False)

sample_node = seed_nodes.tolist()
length = args.randomwalk_length
NodeInfo = []
EdgeInfo = []

# 2. 采样方法，结果存储在NodeInfo和EdgeInfo中
if args.sample_method == 'randomwalk':
randomwalk.Process(db, 100, sample_node, length, NodeInfo, EdgeInfo)
elif args.sample_method == 'negative':
negativesample.Process(db, 100)
else:
neighborsample(db, 100, sample_node, args.nbor_sample_num, NodeInfo, EdgeInfo)
del db
del galaxy

# 3. 对结果进行格式转换，使之符合训练格式
remap(EdgeInfo[0], EdgeInfo[1], NodeInfo[0])
g = dgl.graph((EdgeInfo[0], EdgeInfo[1]))
g.ndata['feat'] = torch.tensor(NodeInfo[1])
g.ndata['label'] = torch.tensor(NodeInfo[2])
return g
```
如代码所示，首先将图数据加载到内存中。然后使用采样算子对图数据进行采样，结果存储在NodeInfo和EdgeInfo中。NodeInfo和EdgeInfo是python list结果，其存储的信息结果如下：  
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |  
最后对结果进行格式转换，使之符合训练格式。这里我们使用的是DGL训练框架，因此使用结果数据构造了DGL Graph，最终将DGL Graph返回。
我们提供TuGraphSample类之后，就可以使用它进行Mini-Batch训练了。
令DGL的数据加载部分使用TuGraphSample的实例sampler：
```python
sampler = TugraphSample(args)
fake_g = construct_graph() # just make dgl happy
dataloader = dgl.dataloading.DataLoader(fake_g,
torch.arange(train_nids),
sampler,
batch_size=batch_size,
device=device,
use_ddp=True,
num_workers=0,
drop_last=False,
)
```
使用DGL进行模型训练：
```python
def train(dataloader, model):
optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)
model.tr' metadata={'Header 1': 'Training', 'Header 2': '2. Mini-Batch训练'}"
TuGraph-DB的主要功能是什么？,"page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}"
当Cypher请求的响应不包含正确的结果时，会抛出什么异常？,"page_content='RESTful API Legacy

4.查询

4.1.调用Cypher

- **URI**: `/cypher`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| graph | 数据库 | 字符串 |
| cypher | 查询语句 | 字符串 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| result | 运行结果 | 列表 |
| elapsed | 运行时间（秒） | 浮点数 |
| header | 返回结果的表头 | 列表 |
| size | 结果数 | 整型 |  
其中 header 是一个列表，每一元素格式如下：  
| 域名 | 说明                                        | 类型   |
| ---- | ------------------------------------------- | ------ |
| name | 列名                                        | 字符串 |
| type | 列数据类型，0 为标量，1 为点 id，2 为向量 |        |  
**Example request.**  
```
• POST http://localhost:7070/cypher
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""graph"": ""default"",
""script"": ""MATCH (n) RETURN n,n.name LIMIT 10""
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""elapsed"": 0.001224517822265625,
""header"": [
{
""name"": ""n"",
""type"": 1
},
{
""name"": ""n.name"",
""type"": 0
}
]
""result"": [
[
0,
""Rachel Kempson""
],
[
1,
""Michael Redgrave""
],
[
2,
""Vanessa Redgrave""
]
],
""size"": 3
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '4.查询', 'Header 3': '4.1.调用Cypher'}","page_content='TuGraph-Restful-Server

7.接口

7.4 执行cypher查询请求

用户通过此类请求发cypher给server端执行并获取执行结果，请求报文在http body 中将执行的cypher语句和目标子图发送给server，server执行完成后在响应报文的http body中返回执行结果
#### 7.4.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/cypher  
#### 7.4.2 REQUEST
| body参数 |    参数说明    |  参数类型  |  是否必填  |
|:------:|:----------:|:------:| :-----: |
| graph  |   查询目标子图   |  字符串  |  是  |
| script | cypher查询语句 |  字符串  |  是  |  
#### 7.4.3 RESPONSE
|    body参数     |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| result | 返回结果 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.4 执行cypher查询请求'}","page_content='Python客户端

3.RPC Client

3.3.向leader发送cypher请求

```python
ret, res = client.callCypherToLeader(""CALL db.edgeLabels()"", ""default"", 10)
```
```
callCypherToLeader(self: liblgraph_client_python.client, cypher: str, graph: str, json_format: bool, timeout: float) -> (bool, str)
```
本接口只支持在HA模式下使用，在HA模式下的client中，为防止向未同步数据的follower发送请求，
用户可以直接向leader发送请求，leader由集群选出。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.3.向leader发送cypher请求'}"
2024年度功能更新预计何时推出HA支持Witness角色和管理工具？,"page_content='技术规划

3. 2024年功能更新

在2024年度，我们计划的功能更新包括：  
| 版本号   | 功能                 | 计划时间    |
|-------|--------------------|---------|
| 4.2.x | HA支持Witness角色和管理工具 | 2024.3  |
| 4.2.x | Bolt支持流处理和参数化查询    | 2024.3  |
| x.x.x | GeaX支持Cypher       | 2024.6  |
| x.x.x | 支持组合索引             | 2024.6  |
| x.x.x | 数据导入功能优化           | 2024.6  |
| x.x.x | 【社区功能】支持地理数据类型使用   | 2024.6  |
| x.x.x | Cypher能力提升         | 2024.9  |
| x.x.x | 支持Schema快速变更       | 2024.9  |
| x.x.x | 向量化支持              | 2024.12 |
| x.x.x | RPQ支持              | 2024.12 |
| x.x.x | 【可选】查询引擎升级         | 2024.12 |
| x.x.x | 【社区功能】支持GraphAr    | 2024.12 |' metadata={'Header 1': '技术规划', 'Header 2': '3. 2024年功能更新'}","page_content='部署高可用模式

4.启动witness节点

4.2.允许witness节点成为leader

可以通过指定`ha_enable_witness_to_leader`参数为`true`，使得`witness`节点可以临时成为`leader`节点，在将新日志同步完成之后再主动切主  
启动允许成为`leader`节点的`witness`节点服务器的命令示例如下所示：  
```bash
$ ./lgraph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090 --ha_is_witness 1 --ha_enable_witness_to_leader 1
```  
注：尽管允许`witness`节点成为`leader`节点可以提高集群的可用性，但是在极端情况下可能会影响数据的一致性。因此一般应保证`witness`节点数量+1少于集群节点总数量的一半。' metadata={'Header 1': '部署高可用模式', 'Header 2': '4.启动witness节点', 'Header 3': '4.2.允许witness节点成为leader'}","page_content='部署高可用模式

1.原理

TuGraph 通过多机热备份来提供高可用（HA）模式。在高可用模式下，对数据库的写操作会被同步到所有服务器（非witness）上，这样即使有部分服务器宕机也不会影响服务的可用性。  
高可用模式启动时，多个 TuGraph 服务器组成一个备份组，即高可用集群。每个备份组由三个或更多 TuGraph 服务器组成，其中某台服务器会作为`leader`，而其他复制组服务器则作为`follower`。写入请求由`leader`
提供服务，该`leader`将每个请求复制同步到`follower`，并在请求同步到服务器后才能响应客户端。这样，如果任何服务器发生故障，其他服务器仍将具有到目前为止已写入的所有数据。如果`leader`
服务器发生故障，其他服务器将自动选择出新的`leader`。  
TuGraph的高可用模式提供两种类型的节点：`replica`节点和`witness`节点。其中，`replica`节点是普通节点，有日志有数据，可对外提供服务。
而`witness`节点是一种只接收心跳和日志但不保存数据的节点。根据部署需求，`leader`节点和`follower`节点可以灵活的部署为`replica`节点或`witness`节点。
基于此，TuGraph高可用模式的部署方式有两种：一是普通部署模式，二是带witness的简约部署模式。  
对于普通部署模式，`leader`和所有`follower`均为`replica`类型的节点。写入请求由`leader`提供服务，该`leader`将每个请求复制同步到`follower`，
并在请求同步到超过半数的服务器后才能响应客户端。这样，如果少于半数的服务器发生故障，其他服务器仍将具有到目前为止已写入的所有数据。如果`leader`
服务器发生故障，其他服务器将自动选举出新的`leader`，通过这种方式保证数据的一致性和服务的可用性。  
然而，在用户服务器资源不够或者发生网络分区时，不能建立正常的HA集群。此时，由于`witness`节点没有数据，对资源占用小，可以将`witness`节点和`replica`节点部署在一台机器上。
例如，当只有2台机器的情况下，可以在一台机器上部署`replica`节点，在另一台机器上部署`replica`节点和`witness`节点，不仅节省资源，而且不需要把日志应用到状态机上，
也不需要生成和安装快照，因此响应请求的速度很快，可以在集群崩溃或网络分区时协助快速选举出新的`leader`，这就是TuGraph HA集群的简约部署模式。
尽管`witness`节点有诸多好处，但是由于没有数据，集群实际上增加了一个不能成为`leader`的节点，因此可用性会略有降低。为提高集群的可用性，
可通过指定`ha_enable_witness_to_leader`参数为`true`，允许`witness`节点临时当主。`witness`节点在把新日志同步到其他节点之后，
会将leader角色主动切换到有最新日志的节点。  
v3.6及以上版本支持此功能。' metadata={'Header 1': '部署高可用模式', 'Header 2': '1.原理'}"
TuGraph-DB使用CMake作为编译工具，支持的C++标准为C++17,"page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='TuGraph产品架构

1.简介

![产品架构](../../../images/architecture.png)  
上图从功能模块的角度，以 TuGraph 为例，给出了企业级图数据库的整体架构，自下而上包括：  
- 软硬件环境。涉及图数据库的开发和使用环境。TuGraph 主要基于底层的 C++语言开发，能够兼容市面上大部分操作系统和 CPU。
- 存储层，包括 KV 存储层和图存储层。存储层需要支持计算层所需的各个功能。
- 计算层。计算层应包括图事务引擎、图分析引擎和图神经网络引擎，也包含了服务端提供的多种编程接口，包括描述式查询语言 Cypher，存储过程等。
- 客户端。客户端 SDK 应支持 Java、Python、C++ 等多种语言，也支持命令行的交互方式。Browser 和 Explorer 通过网页端交互的方式，降低了图数据库的使用门槛。
- 在生态工具方面，覆盖了企业级图数据库的开发、运维、管理等链路，提升可用性。' metadata={'Header 1': 'TuGraph产品架构', 'Header 2': '1.简介'}"
Cython.cimports.libcpp.unordered_map是什么？,"page_content='Python Olap API

6. 算法插件示例

下面为Python实现的BFS算法的代码示例：
```python
# cython: language_level=3, cpp_locals=True, boundscheck=False, wraparound=False, initializedcheck=False
# distutils: language = c++

# 注释作用如下：
# language_level=3: 使用Python3
# cpp_locals=True: 需要c++17，使用std::optional管理Python代码中的C++对象，可以避免C++对象的拷贝构造
# boundscheck=False: 关闭索引的边界检查
# wraparound=False: 关闭负数下标的处理（类似Python List）
# initializedcheck=False: 关闭检查内存是否初始化，关闭检查后运行性能更快
# language = c++: 将此py文件翻译为C++而不是C文件，TuGraph使用大量模板函数，所以都应该使用C++

import json

import cython
from cython.cimports.olap_base import *
from cython.cimports.lgraph_db import *
# 从procedures/algo_cython/ 中cimportolap_base.pxd与lgraph_db.pxd, 类似C++中#include ""xxx.h""

from cython.cimports.libc.stdio import printf
# 类似C++中#include <stdio.h>
# 其他常见的还有cython.cimports.libcpp.unordered_map等

import time


@cython.cclass
# cython.cclass 表示BFSCore为C类型的Class
class BFSCore:
graph: cython.pointer(OlapBase[Empty])
# cython.pointer(OlapBase[Empty])表示OlapBase[Empty]的指针，类似C++中OlapBase[Empty]*
# cython提供了常见类型的指针，如cython.p_int, cython.p_char等，表示int*, char*, ...
parent: ParallelVector[size_t]
active_in: ParallelBitset
active_out: ParallelBitset
root: size_t
# root: size_t 声明root为C++ size_t类型变量，等效于root = cython.declare(size_t)
# 不声明类型的变量为Python object类型
# 声明变量类型会大幅提高性能，同时在多线程部分，只有C/C++类型的变量可以访问

@cython.cfunc
# cython.cfunc 表示Work为C类型的函数，参数与返回值应声明
# cfunc性能好，能接受C/C++对象为参数、返回值，但是不能在其他python文件中调用
# 类似的有cython.ccall，如Standalone函数，可以在其他python文件中调用
@cython.nogil
# cython.nogil 表示释放Python全局解释锁，在nogil修饰的部分，不能访问Python对象
# 在多线程部分，都应有nogil修饰器
@cython.exceptval(check=False)
# cython.exceptval(check=False) 表示禁用异常传播，将忽略函数内部引发的Python异常
def Work(self, vi: size_t) -> size_t:
degree = cython.declare(size_t, self.graph.OutDegree(vi))
out_edges = cython.declare(AdjList[Empty], self.graph.OutEdges(vi))
i = cython.declare(size_t, 0)
local_num_activations = cython.declare(size_t, 0)
dst: size_t
for i in range(degree):
dst = out_edges[i].neighbour
if self.parent[dst] == cython.cast(size' metadata={'Header 1': 'Python Olap API', 'Header 2': '6. 算法插件示例'}","page_content='Python Olap API

3. Cython

Cython是一种高效的编程语言，是Python的超集。Cython能将py文件翻译为C/C++代码后编译为Python拓展类，在Python中通过import调用。在TuGraph中，所有的Python plugin都由Cython编译为Python拓展类后使用。  
Cython的Pure Python模式在保证Python语法的同时具有C/C++的性能，TuGraph Python接口均使用Cython实现。  
[Cython 文档](https://cython.readthedocs.io/en/latest/index.html)' metadata={'Header 1': 'Python Olap API', 'Header 2': '3. Cython'}","page_content='Python Olap API

4. Olap API

见procedures/algo_cython/olap_base.pxd文件，用法与功能基本与C++接口相同，olap_base.pxd中声明的接口都由C++实现，在py文件中必须通过`from cython.cimports.olap_base import *`的方式导入，由Cython编译py文件后才能运行。' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API'}"
TuGraph 数据预热命令需要指定哪两个选项？,"page_content='数据预热

1.数据预热命令

数据预热可以通过工具 `lgraph_warmup` 来进行。它的使用示例如下：  
```bash
$ lgraph_warmup -d {directory} -g {graph_list}
```  
其中：  
- `-d {db_dir}` 选项指定了 TuGraph 服务器的数据目录  
- `-g {graph_list}` 选项指定需要进行数据预热的图名称，用逗号分隔  
根据数据大小和所使用的磁盘类型不同，预热过程运行时间也不同。机械磁盘上预热一个大数据库可能耗时较长，请耐心等待。' metadata={'Header 1': '数据预热', 'Header 2': '1.数据预热命令'}","page_content='数据预热

1.简介

TuGraph 是基于磁盘的数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '数据预热', 'Header 2': '1.简介'}","page_content='功能概览

4.核心功能

4.5 数据预热

TuGraph 是基于磁盘的图数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.5 数据预热'}"
是否支持GQL语句？,"page_content='ISO GQL

1.GQL简介

Graph Query Language(GQL, 图查询语言)是一种国际标准语言，用于属性图查询，该语言建立在SQL的基础上，并整合了现有的[openCypher、PGQL、GSQL和G-CORE](https://gql.today/comparing-cypher-pgql-and-g-core/)语言的成熟思想。目前该标准仍然处于草稿阶段。  
TuGraph基于[ISO GQL (ISO/IEC 39075) Antlr4 语法文件](https://github.com/TuGraph-family/gql-grammar)实现了GQL，并做了一些扩展与改造。目前并未完全支持所有的GQL语法，我们会在未来逐步完善。' metadata={'Header 1': 'ISO GQL', 'Header 2': '1.GQL简介'}","page_content='ISO GQL

2.Clauses

2.1.MATCH

`MATCH`子句式是GQL最基础的子句，几乎所有查询都是通过 `MATCH`展开。  
`MATCH`子句用于指定在图中搜索的匹配模式，用来匹配满足一定条件的点或者路径。  
#### 点查询  
##### 查询所有点  
```
MATCH (n)
RETURN n
```  
##### 查询特定标签的点  
```
MATCH (n:Person)
RETURN n
```  
##### 通过属性匹配点  
```
MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
##### 通过过滤条件匹配点  
```
MATCH (n:Person WHERE n.birthyear > 1910)
RETURN n.name LIMIT 2
```  
返回结果
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```  
#### 边查询  
##### 出边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1970)-[e]->(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""BORN_IN"",""m.name"":""London"",""n.name"":""Christopher Nolan""},{""label(e)"":""DIRECTED"",""m.name"":null,""n.name"":""Christopher Nolan""}]
```  
##### 入边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1939)<-[e]-(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""HAS_CHILD"",""m.name"":""Rachel Kempson"",""n.name"":""Corin Redgrave""},{""label(e)"":""HAS_CHILD"",""m.name"":""Michael Redgrave"",""n.name"":""Corin Redgrave""}]
```  
##### 带过滤条件的边匹配  
```
MATCH (n:Person)-[e:BORN_IN WHERE e.weight > 20]->(m)
RETURN n.name, e.weight, m.name
```  
返回结果
```JSON
[{""e.weight"":20.549999237060547,""m.name"":""New York"",""n.name"":""John Williams""},{""e.weight"":20.6200008392334,""m.name"":""New York"",""n.name"":""Lindsay Lohan""}]
```  
#### 路径匹配  
##### 不定跳查询  
```
MATCH (n:Person)-[e]->{2,3}(m:Person)
RETURN m.name LIMIT 2
```  
返回结果
```JSON
[{""m.name"":""Liam Neeson""},{""m.name"":""Natasha Richardson""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.1.MATCH'}","page_content='Python客户端

3.RPC Client

3.4.调用GQL

```python
ret, res = client.callGql(""CALL db.edgeLabels()"", ""default"", 10)
```
```
callGql(self: liblgraph_client_python.client, gql: str, graph: str, json_format: bool, timeout: float, url: str) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.4.调用GQL'}"
在配置中提到的“log4j-core”和“guava”的版本号分别是多少？,"page_content='运维监控

2.部署方案

2.4.第四步

+ 下载符合您机器架构以及系统版本的Grafana安装包，下载地址: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)  
+ 安装Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 启动Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 配置Grafana，首先在数据源设置中配置Prometheus的IP地址，配置完成后可以通过测试连接功能，验证是否成功连接数据源。然后，导入如下模版，并在页面中根据实际情况，修改正确的接口IP和端口。最后可以根据实际情况设置刷新时间和监控时间范围  
```json
{
""annotations"": {
""list"": [
{
""builtIn"": 1,
""datasource"": {
""type"": ""grafana""
},
""enable"": true,
""hide"": true,
""iconColor"": ""rgba(0, 211, 255, 1)"",
""name"": ""Annotations & Alerts"",
""target"": {
""limit"": 100,
""matchAny"": false,
""tags"": [],
""type"": ""dashboard""
},
""type"": ""dashboard""
}
]
},
""editable"": true,
""fiscalYearStartMonth"": 0,
""graphTooltip"": 0,
""id"": 2,
""links"": [],
""liveNow"": false,
""panels"": [
{
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
}
},
""mappings"": [],
""unit"": ""kbytes""
},
""overrides"": [
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {__name__=\""resources_report\"", instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
},
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""others""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-blue"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}","page_content='安装指南

启动容器

本地启动GeaFlow Console平台服务，适用于minikube环境。（需要将${your.host.name}替换为本机对外IP地址）  
```shell
docker run -d --name geaflow-console -p 8888:8888 -p 3306:3306 -p 6379:6379 -p 8086:8086 -e geaflow.host=${your.host.name} geaflow-console:0.1
```  
启动对外GeaFlow Console平台服务，适用于K8S真实集群环境。（需要将${your.host.name}替换为本机内网IP地址，例如172.xx.xxx.xx；${your.public.ip} 替换为外部公网IP地址，才能从外部访问GeaFlow Console）
```shell
docker run -d --name geaflow-console -p 8888:8888 -p 3306:3306 -p 6379:6379 -p 8086:8086 -e geaflow.host=${your.host.name} geaflow-console:0.1
```  
容器默认以本地模式（local）启动，默认拉起本地的MySQL、Redis、InfluxDB。
```properties
# /opt/geaflow/config/application.properties
geaflow.deploy.mode=local
geaflow.host=127.0.0.1
geaflow.gateway.port=8888
geaflow.gateway.url=http://${geaflow.host}:${geaflow.gateway.port}

# Datasource
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://${geaflow.host}:3306/geaflow?useUnicode=true&characterEncoding=utf8
spring.datasource.username=geaflow
spring.datasource.password=geaflow
```  
进入容器等待geaflow-web进程启动完成后，访问[localhost:8888](http://localhost:8888)进入GeaFlow Console平台页面。
K8S集群环境这里为访问对外IP地址的8888端口。
```shell
> docker exec -it geaflow-console tailf /tmp/logs/geaflow/app-default.log

# wait the logs below and open url http://localhost:8888
GeaflowApplication:61   - Started GeaflowApplication in 11.437 seconds (JVM running for 13.475)
```  
若希望以集群模式（cluster）启动容器，需要调整datasource配置指向外部数据源，并设置对外的统一服务url地址。容器支持环境变量注入数据源配置和服务url，例如：
```shell
docker run -d --name geaflow-console -p 8888:8888 \
-e geaflow.deploy.mode=""cluster"" \
-e geaflow.host=${your.host.name} \
-e geaflow.gateway.port=8888 \
-e geaflow.gateway.url=${your.geaflow.gateway.url} \
-e spring.datasource.url=${your.datasource.url} \
-e spring.datasource.username=${your.datasource.username} \
-e spring.datasource.password=${your.datasource.password} \
geaflow-console:1.0
```  
如果希望Java进程端口号，只需设置geaflow.gateway.port环境变量，并重新映射端口号即可，如：
```shell
docker run -d --name geaflow-cons' metadata={'Header 1': '安装指南', 'Header 2': '启动容器'}","page_content='安装指南

一键安装

集群配置

配置GeaFlow作业的运行时集群，推荐使用Kubernates。本地模式下默认为本地的代理地址${your.host.name}:8000，请确保本地已经启动minikube并设置好代理地址。如果设置K8S集群地址，请确保集群地址的连通性正常。
![install_cluster_config](../../static/img/install_cluster_config.png)  
K8S集群模式添加以下配置
```
# 存储限制为10Gi
""kubernetes.resource.storage.limit.size"":""10Gi""
# 服务API配置为K8S服务地址，一般为6443端口
""kubernetes.master.url"":""https://${your.host.name}:6443""
# 在K8S集群找到 /etc/kubernetes/admin.conf 配置文件，从上到下分别配置以下三个字段
""kubernetes.ca.data"":""""
""kubernetes.cert.data"":""""
""kubernetes.cert.key"":""""
```' metadata={'Header 1': '安装指南', 'Header 2': '一键安装', 'Header 3': '集群配置'}"
类liblgraph_python_api.Galaxy的方法SetUserGraphAccess主要用于什么？,"page_content='Python Olap API

5. lgraph_db API

PyGalaxy:

- `PyGalaxy(self, dir_path: str)`: 构造函数，dir_path为db路径
- `SetCurrentUser(self, user: str password: str)-> void`: 设置用户
- `SetUser(self, user: std::string)-> void`: 设置用户
- `OpenGraph(self, graph: str, read_only: bool)-> PyGraphDB`: 创建PyGraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'PyGalaxy:'}","page_content='Python Olap API

5. lgraph_db API

Galaxy

- `Galaxy(dir_path: std::string)`: 构造函数，dir_path为db路径
- `SetCurrentUser(user: std::string, password: std::string)-> cython.void`: 设置用户
- `SetUser(user: std::string)-> cython.void`: 设置用户
- `OpenGraph(graph: std::string, read_only: bint)-> GraphDB`: 创建GraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Galaxy'}","page_content='用户权限

1.介绍

> TuGraph 的权限是基于角色的访问控制进行管理，定义访问控制的权限分配给角色，角色再分配给用户。' metadata={'Header 1': '用户权限', 'Header 2': '1.介绍'}"
TuGraph-DB如何在运行单元测试的过程中输出日志？,"page_content='日志信息

3.审计日志

审核日志记录每个请求和响应，以及发送请求的用户以及收到请求的时间。审核日志只能是打开或关闭状态。可以使用 TuGraph 可视化工具和 REST API 查询结果。  
开启审计日志需要在配置文件中将`enable_audit_log`参数设置为`true`。配置文件和配置参数说明详见：[数据库运行/服务配置](../../5.installation&running/7.tugraph-running.md)。' metadata={'Header 1': '日志信息', 'Header 2': '3.审计日志'}","page_content='日志信息

1.简介

TuGraph 保留两种类型的日志：服务器日志和审计日志。服务器日志记录人为可读的服务器状态信息，而审核日志维护服务器上执行的每个操作加密后的信息。' metadata={'Header 1': '日志信息', 'Header 2': '1.简介'}","page_content='集成测试

2.TuGraph集成测试框架

2.1.组件描述

| 组件名称            | 组件功能                       | 实现方式                                  |
|-----------------|----------------------------|---------------------------------------|
| server          | TuGraph单机服务                | 开启子进程并在子进程中启动服务                       |
| client          | TuGraph Rpc Client         | 当前进程中开启TuGraph Python Rpc Client发送请求  |
| importor        | TuGraph Importor           | 开启子进程并在子进程中处理导入请求                     |
| exportor        | TuGraph Exportor           | 开启子进程并在子进程中处理导出请求                     |
| backup_binlog   | TuGraph Backup Binlog      | 开启子进程并在子进程中处理备份binlog的请求              |
| backup_copy_dir | TuGraph Backup             | 开启子进程并在子进程中处理备份完整db的请求                |
| build_so        | 编译c++动态连接库的组件              | 开启子进程并在子进程中处理gcc编译逻辑                  |
| copy_snapshot   | TuGraph Copy Snapshot      | 当前进程中处理备份snapshot的请求                  |
| copydir         | 文件夹拷贝                      | 当前进程中处理文件夹拷贝请求                        |
| exec            | 执行c++/java可执行文件            | 开启子进程并在子进程中启动C++可执行文件                 |
| algo            | 执行算法                       | 开启子进程并在子进程中执行算法                       |
| bash            | 执行bash命令                   | 开启子进程并在子进程中执行bash命令                   |
| rest            | TuGraph Python Rest Client | 当前进程中开启TuGraph Python Rest Client发送请求 |' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.1.组件描述'}"
"GeaBase 查询中使用 ""Nav"" 语句的一种情况是什么?","page_content='GeaFlow支持**Case**和**If**条件函数。
* [Case](#Case)
* [If](#If)'","page_content='为什么使用图进行关联运算比表Join更具吸引力？

关系模型并不适合处理关系

痛点三：复杂关系查询难以描述

使用表建模的分析系统只支持SQL join一种方式进行关系分析，这在复杂场景中能力十分局限。 比如查询一个人4度以内所有好友，或者查询最短路径等，这些复杂关联关系通过SQL表的join方式很难描述。  
GeaFlow提供融合GQL和SQL样式的查询语言，这是一种图表一体的数据分析语言，继承自标准SQL+ISO/GQL，可以方便进行图表分析。  
![code_style](../../static/img/code_style.jpg)
<center>图3</center>  
**在融合DSL中，图计算的结果与表查询等价，都可以像表数据一样做关系运算处理。**这意味着图3中GQL和SQL两种描述都可以达到类似的效果，极大灵活了用户的查询表达能力。  
GeaFlow DSL引擎层还将支持SQL中的Join自动转化为GQL执行，用户可以自由混用SQL和GQL样式查询，同时做图匹配、图算法和表查询。' metadata={'Header 1': '为什么使用图进行关联运算比表Join更具吸引力？', 'Header 2': '关系模型并不适合处理关系', 'Header 3': '痛点三：复杂关系查询难以描述'}","page_content='GeaFlow Dashboard

其他功能

列表排序与查询

部分列表的列可以进行排序和查询。  
查询时，点击“搜索”标识，输入关键字，点击“搜索”按钮即可。  
重置时，点击“重置”按钮，列表会重新刷新。  
![dashboard_table_search.png](../static/img/dashboard_table_search.png)' metadata={'Header 1': 'GeaFlow Dashboard', 'Header 2': '其他功能', 'Header 3': '列表排序与查询'}"
我要快速定位到2个顶点间的某条关系边，通过pair unique索引查找关系边的接口有么，需求是根据pair_unique的值更新对应的边数据么,"page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}","page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}","page_content='Match

Syntax

Edge

匹配图上的边，类似Node节点可以指定边的类型以及对边的过滤条件。和Node不同的是,边需要指定方向，边的方向包括入边、出边和双向边。' metadata={'Header 1': 'Match', 'Header 2': 'Syntax', 'Header 3': 'Edge'}"
TuGraph Explorer 的功能现在在哪里可以找到？,"page_content='功能概览

6.生态工具

6.2.可视化交互

TuGraph Browser 是面向图数据库直接使用者的可视化交互界面，功能上覆盖了 TuGraph 的绝大部分能力，包括数据导入、图模型建立、数据增删查改、监控运维等操作链路。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.2.可视化交互'}","page_content='可视化操作手册（旧版）

作用

TuGraph Browser 的主要功能是为使用图数据库的开发人员，提供可视化的图数据开发，图数据管理和维护等功能。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '作用'}","page_content='可视化操作手册（旧版）

定义

TuGraph Browser 是 TuGraph 提供的可视化开发工具。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '定义'}"
SybilRank算法的执行过程中主要采用什么方式来进行计算？,"page_content='内置算法

扩展算法包

Sybil检测算法

Sybil检测算法实现了Sybil Rank算法。SybilRank算法从非Sybil节点开始进行提前终止的随机游走。算法内容请参考论文：“Aiding the Detection of Fake Accounts in Large Scale Social Online Services”。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': 'Sybil检测算法'}","page_content='内置算法

基础算法包

网页排序

网页排序程序实现了常用的Pagerank算法。该算法根据图中边和边权值计算所有点的重要性排名，PageRank值越高，表示该点在图中的重要性越高。计算时以点数量的倒数为各点初始Rank值，然后将点的Rank值按照出边平均传递到相邻点，重复该传递过程直到满足给定的收敛阈值或达到给定迭代轮数。每轮传递结束后，所有点的Rank值会有一定的的比例随机传递到任意点上。算法内容请参考 [https://en.wikipedia.org/wiki/PageRank](https://en.wikipedia.org/wiki/PageRank ""pagerank wiki"")。' metadata={'Header 1': '内置算法', 'Header 2': '基础算法包', 'Header 3': '网页排序'}","page_content='OlapOnDB API

3. 算法举例

3.2 PageRank算法流程

`pagerank`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关数据结构的初始化
1. 每个节点pagerank值的初始化
1. 每个节点pagerank值的计算，活跃点为所有点（意味着所有点都需要计算pagerank值）
1. 得到每个节点经过`num_iterations`次迭代后的pagerank值  
```C++
void PageRankCore(OlapBase<Empty>& graph, int num_iterations, ParallelVector<double>& curr) {

// 相关数据结构的初始化
auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
auto curr = olapondb.AllocVertexArray<double>();
auto next = olapondb.AllocVertexArray<double>();
size_t num_vertices = olapondb.NumVertices();
double one_over_n = (double)1 / num_vertices;

// 每个节点pagerank值的初始化，和该节点的出度成反比
double delta = graph.ProcessVertexActive<double>(
[&](size_t vi) {
curr[vi] = one_over_n;
if (olapondb.OutDegree(vi) > 0) {
curr[vi] /= olapondb.OutDegree(vi);
}
return one_over_n;
},
all_vertices);

// 总迭代过程
double d = (double)0.85;
for (int ii = 0;ii < num_iterations;ii ++) {
printf(""delta(%d)=%lf\n"", ii, delta);
next.Fill((double)0);

/*
函数用途：计算所有节点的pagerank值

函数流程描述：该函数用于计算所有节点的pagerank值，对all_vertices中所有为1的位对应的节点vi执行Func C，得到本轮迭代中vi的pagerank值，并返回vi节点的pagerank变化值，最终经过函数内部处理汇总所有活跃节点的总变化值并返回，该值被存储在delta变量中
*/
delta = graph.ProcessVertexActive<double>(
// Func C
[&](size_t vi) {
double sum = 0;

// 从邻居中获取当前节点的pagerank值
for (auto & edge : olapondb.InEdges(vi)) {
size_t src = edge.neighbour;
sum += curr[src];
}
next[vi] = sum;

// pagerank值计算核心公式
next[vi] = (1 - d) * one_over_n + d * next[vi];
if (ii == num_iterations - 1) {
return (double)0;
} else {

// 相关中间变量统计
if (olapondb.OutDegree(vi) > 0) {
next[vi] /= olapondb.OutDegree(vi);
return fabs(next[vi] - curr[vi]) * olapondb.OutDegree(vi);
} else {
return fabs(next[vi] - curr[vi]);
}
}
},
all_vertices
);

// 将本轮迭代得到的pagerank值输出作为下一轮迭代的输入
curr.Swap(next);
}
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.2 PageRank算法流程'}"
节点和边的属性在知识图谱中有什么作用？,"page_content='OlapBase API

6. 自定义数据结构

6.2 组合数据结构

为了便于计算，我们根据计算场景不同，定义了几种点和边数据的数据结构，分别是：  
- `EdgeUnit<EdgeData>`：表示权值类型为EdgeData的边，用于解析输入文件，包含三个成员变量：
- `size_t src`：边的起始点
- `size_t dst`：边的终点
- `EdgeData edge_data`：边的权值
- `AdjUnit<EdgeData>`：表示权值类型为EdgeData的边，用于批处理计算过程中，包含两个成员变量：
- `size_t neighbour`：边的邻居点
- `EdgeData edge_data`：边的权值
- `AdjList<EdgeData>`：权值类型为EdgeData的点的邻接表，常用于表示点的入边和出边集合，包含两个成员变量：
- `AdjUnit<T> * begin`：列表的起始指针
- `AdjUnit<T> * end`：列表的结束指针。begin和end的用法类似于vector容器的begin和end指针，可以使用这两个指针对邻接表进行循环访问。' metadata={'Header 1': 'OlapBase API', 'Header 2': '6. 自定义数据结构', 'Header 3': '6.2 组合数据结构'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

`图项目`提供可视化的图项目管理和图数据研发功能，它为用户提供了一系列便捷的图数据可视化操作，包括图项目的创建、修改、删除等管理操作，以及图数据的查询、点边统计等操作。此外，它也支持图模型的管理，使用户可以更加方便地进行图数据的管理和维护。  
#### 2.4.1.图项目管理  
在`图项目`界面，可以看到当前图数据库中的图项目。  
![图项目-首页](../../../images/browser/graphmanagement-homepage.png)  
##### 2.4.1.1.新建图项目  
在`图项目`界面，点击`新建图项目`按钮创建一个新的图项目。  
![图项目-新建图项目按钮](../../../images/browser/graphmanagement-creategraph.png)  
新建图项目需要通过`选择模板`和`填写配置`两个页面完成图项目的创建。  
- __选择模板__：产品提供空模板和demo模板两类模板。
- 空模板：全新的图项目，用户需要自己创建图模型和导入图数据，一般用于正式项目开发。
- demo模板：产品内置的demo数据，图项目创建成功后，系统会自动创建demo图模型并导入demo图数据，一般用于试用和学习。  
![图项目-选择模板](../../../images/browser/graphmanagement-selecttemplate.png)  
- __填写配置__：用户需要填写图项目基本信息，并点击`创建`按钮创建图项目。
- 图名称：新建图项目的名称，同时作为该图项目的唯一主键。支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图描述：新建图项目的描述，可用于详细说明该项目的背景和目标。
- 高级配置-最大存储空间：设置图项目最大可占用的存储空间，实际并不会提前占用物理存储空间，实际数据量达到最大存储空间阈值后不可再写入数据。  
![图项目-填写配置](../../../images/browser/graphmanagement-configure.png)  
创建成功后，可在`图项目`页面的图项目选项卡中查看。  
##### 2.4.1.2.编辑图项目  
在`图项目`界面，点击图项目选项卡中的`编辑`按钮（笔形图标），编辑对应图项目的基础信息。  
![图项目-编辑图项目按钮](../../../images/browser/graphmanagement-editgraph-button.png)  
编辑图项目功能可以修改`图描述`和`最大存储空间`。  
![图项目-编辑图项目](../../../images/browser/graphmanagement-editgraph.png)  
##### 2.4.1.3.删除图项目  
在`图项目`界面，点击图项目选项卡中的`删除`按钮（垃圾桶图标），删除对应的图项目。  
![图项目-删除图项目按钮](../../../images/browser/graphmanagement-deletegraph-button.png)  
_需要注意：图项目删除后无法恢复_。  
##### 2.4.1.4.点边统计  
在`图项目`界面，点击图项目选项卡中的`点边统计`按钮（刷新图标），统计对应图项目当前时间节点的点边数量。  
![图项目-点边统计按钮](../../../images/browser/graphmanagement-statistics-button.png)  
统计结果将展示在图项目选项卡上，已经统计过点边数据的图项目再次统计需要点击`刷新`按钮。  
![图项目-点边统计](../../../images/browser/graphmanagement-statistics.png)  
![图项目-刷新点边统计按钮](../../../images/browser/graphmanagement-statistics-refresh-button.png)  
##### 2.4.1.5.存储过程  
在`图项目`界面，点击图项目选项卡中的`存储过程`按钮（卡片最右侧图标），跳转到操作存储过程的图页面。  
![图项目-存储过程按钮](../../../images/browser/graphmanagement-procedure-button.png)  
在`存储过程`页面，可以新建存储过程，新建时需要填写""存储过程名称""、""存储过程类型""、""存储过程描述""，然后选择""版本""和""执行时是否修改数据库""  
![图项目-存储过程](../../../images/browser/graph' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='图算法介绍

1\. 图算法概述

在计算机科学中，图是一种表示实体（节点或顶点）以及实体之间关系（边）的数据结构。图模型可以天然地描述网络结构，能更清晰地表达复杂的数据关系和依赖，简化关联数据的理解和分析。在不同的场景下，图中点边具备不同的语义信息。比如在资金交易场景下，每个人可以抽象成一个点表示，人与人之间的转账关系可以抽象成一条边表示。通过图数据模型反映出各个实体之间的资金往来关系，让数据的关联分析更加直观和高效。  
在图数据模型上可以执行多种图算法，如社区检测，最短路径匹配，环路检测算法等。通过点边上的迭代计算，探索图模型中各个实体之间的关系。探索过程不依赖于数据的线性结构，从而便于识别隐藏的模式和关联关系。在主流迭代图算法中，节点通过消息传递的方式进行通信。每次迭代，节点可以接收来自它们邻居的消息，处理这些消息，然后决定是否发送新的消息给其他节点。迭代算法中，每个节点有一个状态，每次迭代它们都有可能更新这个状态直至收敛。例如，在PageRank算法中，每个节点的状态是其PageRank值，这个值在迭代过程中会随着邻居的值的更新而更新。  
图迭代算法解决了经典的图计算问题，但随着业务需求的复杂度提升，基于迭代的图算法存在着表达能力不足、自适应性能力差、异质图处理难度大等缺点。近年来随着深度学习的研究和应用的发展，以图神经网络（Graph Neural Networks，GNNs）为代表的一类神经网络算法，被设计用来捕获图中实体（节点）和关系（边）间的复杂模式。图神经网络能够结合节点特征和图的结构来学习节点和边的表示，相比之下，传统的迭代图算法通常不会直接从原始特征中学习，而更多地专注于结构特征。依赖于深度学习的天然优势，GNNs具有更强的表示学习能力，可以自动从数据中学习复杂的模式，这使得 GNNs 能够更好地处理多任务学习和迁移学习等问题。在社交网络分析、知识图谱、生物分子网络、推荐系统以及交通网络等领域，得到广泛应用。' metadata={'Header 1': '图算法介绍', 'Header 2': '1\\. 图算法概述'}"
在TuGraph项目中，为什么在提交代码前要先提交一个issue？,"page_content='如何贡献

4. 贡献代码流程

4.1. 提交issue

不论您是修复 TuGraph 的 bug 还是新增 TuGraph 的功能，在您提交代码之前，请在 TuGraph 的 GitHub 上提交一个 issue，描述您要修复的问题或者要增加的功能。这么做有几个好处:  
- 不会与其它开发者或是他们对这个项目的计划发生冲突，产生重复工作。
- TuGraph 的维护人员会对您提的 bug 或者新增功能进行相关讨论，确定该修改是不是必要，有没有提升的空间或更好的办法。
- 在达成一致后再开发，并提交代码，减少双方沟通成本，也减少 pull request 被拒绝的情况。' metadata={'Header 1': '如何贡献', 'Header 2': '4. 贡献代码流程', 'Header 3': '4.1. 提交issue'}","page_content='如何贡献

4. 贡献代码流程

4.2. 获取源码

要修改或新增功能，在提交 issue 后，fork一份 TuGraph  Master代码到您的代码仓库。' metadata={'Header 1': '如何贡献', 'Header 2': '4. 贡献代码流程', 'Header 3': '4.2. 获取源码'}","page_content='云部署

3.部署流程

3.3.申请试用

在正式试用前，需要申请试用，按照提示填写信息，在审核通过后就可以创建TuGraph服务。  
![申请试用](../../../images/cloud-deployment-2.png)' metadata={'Header 1': '云部署', 'Header 2': '3.部署流程', 'Header 3': '3.3.申请试用'}"
请问社区版本和企业版本，之间的差距在哪,"page_content='什么是TuGraph

4. TuGraph企业版

企业版对商业化功能支持更加完善，包括分布式集群架构，覆盖探索、研发、服务、运维管理全生命周期的一站式图平台，在线、近线、离线的图计算引擎，支持流式、大数据类数据源，多地多中心的部署形态，以及专家支持服务等。企业版是商业化解决方案的理想选择。  
如需商业支持，请联系我们：  
- 电话：400-903-0809
- 邮件：tugraph@service.alipay.com
- 官网：https://tugraph.antgroup.com' metadata={'Header 1': '什么是TuGraph', 'Header 2': '4. TuGraph企业版'}","page_content='什么是TuGraph

2. TuGraph社区版

2022年9月，TuGraph单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，支持TB级别的数据规模，为用户管理和分析复杂关联数据提供了高效、易用、可靠的平台。  
TuGraph社区版于2022年9月开源，提供了完整的图数据库基础功能和成熟的产品设计（如ACID兼容的事务、编程API和配套工具等），适用于单实例部署。社区版支持TB级别的数据规模，为用户管理和分析复杂关联数据提供了高效、易用、可靠的平台，是学习TuGraph和实现小型项目的理想选择。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '2. TuGraph社区版'}","page_content='环境和版本选择

1. 简介

TuGraph为不同需求的用户提供了差异化的系统环境和部署方式，来满足新手、系统开发者、生产运维人员、研究人员等不同用户的需求。' metadata={'Header 1': '环境和版本选择', 'Header 2': '1. 简介'}"
bfs_standalone程序的输出结果是什么？,"page_content='OLAP API

4. Standalone 编译与运行

该文件主要用于在终端处直接加载图数据，并运行打印输出结果。使用方法如下：
在tugraph-db/build目录下执行`make bfs_standalone` (需要在g++默认include路径中包含boost/sort/sort.hpp)即可得到bfs_standalone文件,该文件生成于tugraph-db/build/output/algo文件夹下。
运行方式：在tugraph-db/build目录下执行`./output/algo/bfs_standalone -–type [type] –-input_dir [input_dir] --id_mapping [id_mapping] -–vertices [vertices] --root [root] –-output_dir [output_dir]`即可运行。  
- `[type]`：表示输入图文件的类型来源，包含text文本文件、BINARY_FILE二进制文件和ODPS源。
- `[input_dir]`：表示输入图文件的文件夹路径，文件夹下可包含一个或多个输入文件。TuGraph在读取输入文件时会读取[input_dir]下的所有文件，要求[input_dir]下只能包含输入文件，不能包含其它文件。参数不可省略。
- `[id_mapping]`：当读入边表时，是否对输入数据做id映射，使达到符合算法运行的形式。1为需要做id映射，0为不需要做。该过程会消耗一定时间。参数可省略，默认值为0。
- `[vertices]`：表示图的点个数，为0时表示用户希望系统自动识别点数量；为非零值时表示用户希望自定义点个数，要求用户自定义点个数需大于最大的点ID。参数可省略，默认值为0。
- `[root]`：表示进行bfs的起始点id。参数不可省略。
- `[output_dir]`：表示输出数据保存的文件夹路径，将输出内容保存至该文件中，参数不可省略。  
示例：' metadata={'Header 1': 'OLAP API', 'Header 2': '4. Standalone 编译与运行'}","page_content='OLAP API

4. Standalone 编译与运行

Python:

Python语言的bfs拓展编译过程与embed模式无区别，在运行时通过`Standalone`接口调用，示例如下：
```python
# tugraph-db/procedures/run_standalone.py
import bfs as python_plugin

if __name__ == ""__main__"":
python_plugin.Standalone(input_dir=
""../test/integration/data/algo/fb_unweighted"",
root=0)
```  
通过如下命令执行  
```bash
python3 run_standalone.py
```  
至此，通过TuGraph对上图进行bfs运算的过程已经完成。' metadata={'Header 1': 'OLAP API', 'Header 2': '4. Standalone 编译与运行', 'Header 3': 'Python:'}","page_content='OLAP API

4. Standalone 编译与运行

C++:

在tugraph-db/build编译standalone算法程序  
```bash
make bfs_standalone
```  
在tugraph-db/build/output目录下运行text源文件  
```bash
./output/algo/bfs_standalone --type text --input_dir ../test/integration/data/algo/fb_unweighted --root 0
```  
得到运行结果：  
```text
prepare_cost = 0.10(s)
core_cost = 0.02(s)
found_vertices = 3829
output_cost = 0.00(s)
total_cost = 0.11(s)
DONE.
```  
结果参数解释同上。  
对于新的算法，运行时不了解该算法的所需参数时，可通过`./output/algo/bfs_standalone -h`进行查阅对应参数。' metadata={'Header 1': 'OLAP API', 'Header 2': '4. Standalone 编译与运行', 'Header 3': 'C++:'}"
Key_start和key_end相等于v时，VertexIndexIterator是如何工作的？,"page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void init(VertexCentricComputeFuncContext<K, VV, EV, M> vertexCentricFuncContext) | 迭代计算初始化接口 | vertexCentricFuncContext：静态图计算的上下文，K表示vertex id的类型，VV表示vertex value类型，EV表示edge value类型，M表示发送消息的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 迭代计算接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：迭代过程中所有发送给当前vertex的消息，其中M表示迭代计算过程中定义的发送消息类型。 |
| void finish() | 迭代计算完成接口 | 无 |  
- 详细接口  
```java
public interface VertexCentricComputeFunction<K, VV, EV, M> extends VertexCentricFunction<K, VV,
EV, M> {

void init(VertexCentricComputeFuncContext<K, VV, EV, M> vertexCentricFuncContext);

void compute(K vertex, Iterator<M> messageIterator);

void finish();

interface VertexCentricComputeFuncContext<K, VV, EV, M> extends VertexCentricFuncContext<K, VV,
EV, M> {
/** 设置vertex value */
void setNewVertexValue(VV value);

}

}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends Gra' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentric function进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |  
- 详细接口  
```java
public interface VertexCentricTraversalFunction<K, VV, EV, M, R> extends VertexCentricFunction<K, VV
, EV, M> {

void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);
/** 图遍历算法初始化方法 */
void init(ITraversalRequest<K> traversalRequest);
/** 实现图遍历逻辑 */
void compute(K vertexId, Iterator<M> messageIterator);

void finish();

void close();

interface VertexCentricTraversalFuncContext<K, VV, EV, M, R> extends VertexCentricFuncContext<K,
VV, EV, M> {
/** 获取图遍历结果 */
void takeResponse(ITraversalResponse<R> response);
/** 获取开始图遍历的点 */
TraversalVertexQuery<K, VV> vertex();
/** 获取开始图遍历的边 */
TraversalEdgeQuery<K, EV> edges();

void broadcast(IGraphMessage<K, M> message);
}

interface TraversalVertexQuery<K, VV> extends VertexQuery<K, VV> {
/** 获取图遍历中点的迭代器 */
Iterator<K> loadIdIterator();
}

interface TraversalEdgeQuery<K, EV> extends EdgeQuery<K, EV> {
/** 通过指定的点id，获取对应的图遍历起点 */
TraversalEdgeQuery<K, EV> withId(K vertexId);
}
}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}"
应该如何写入图数据库中的顶点数据？,"page_content='可视化操作手册

2.操作指南

2.4.图项目

`图项目`提供可视化的图项目管理和图数据研发功能，它为用户提供了一系列便捷的图数据可视化操作，包括图项目的创建、修改、删除等管理操作，以及图数据的查询、点边统计等操作。此外，它也支持图模型的管理，使用户可以更加方便地进行图数据的管理和维护。  
#### 2.4.1.图项目管理  
在`图项目`界面，可以看到当前图数据库中的图项目。  
![图项目-首页](../../../images/browser/graphmanagement-homepage.png)  
##### 2.4.1.1.新建图项目  
在`图项目`界面，点击`新建图项目`按钮创建一个新的图项目。  
![图项目-新建图项目按钮](../../../images/browser/graphmanagement-creategraph.png)  
新建图项目需要通过`选择模板`和`填写配置`两个页面完成图项目的创建。  
- __选择模板__：产品提供空模板和demo模板两类模板。
- 空模板：全新的图项目，用户需要自己创建图模型和导入图数据，一般用于正式项目开发。
- demo模板：产品内置的demo数据，图项目创建成功后，系统会自动创建demo图模型并导入demo图数据，一般用于试用和学习。  
![图项目-选择模板](../../../images/browser/graphmanagement-selecttemplate.png)  
- __填写配置__：用户需要填写图项目基本信息，并点击`创建`按钮创建图项目。
- 图名称：新建图项目的名称，同时作为该图项目的唯一主键。支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图描述：新建图项目的描述，可用于详细说明该项目的背景和目标。
- 高级配置-最大存储空间：设置图项目最大可占用的存储空间，实际并不会提前占用物理存储空间，实际数据量达到最大存储空间阈值后不可再写入数据。  
![图项目-填写配置](../../../images/browser/graphmanagement-configure.png)  
创建成功后，可在`图项目`页面的图项目选项卡中查看。  
##### 2.4.1.2.编辑图项目  
在`图项目`界面，点击图项目选项卡中的`编辑`按钮（笔形图标），编辑对应图项目的基础信息。  
![图项目-编辑图项目按钮](../../../images/browser/graphmanagement-editgraph-button.png)  
编辑图项目功能可以修改`图描述`和`最大存储空间`。  
![图项目-编辑图项目](../../../images/browser/graphmanagement-editgraph.png)  
##### 2.4.1.3.删除图项目  
在`图项目`界面，点击图项目选项卡中的`删除`按钮（垃圾桶图标），删除对应的图项目。  
![图项目-删除图项目按钮](../../../images/browser/graphmanagement-deletegraph-button.png)  
_需要注意：图项目删除后无法恢复_。  
##### 2.4.1.4.点边统计  
在`图项目`界面，点击图项目选项卡中的`点边统计`按钮（刷新图标），统计对应图项目当前时间节点的点边数量。  
![图项目-点边统计按钮](../../../images/browser/graphmanagement-statistics-button.png)  
统计结果将展示在图项目选项卡上，已经统计过点边数据的图项目再次统计需要点击`刷新`按钮。  
![图项目-点边统计](../../../images/browser/graphmanagement-statistics.png)  
![图项目-刷新点边统计按钮](../../../images/browser/graphmanagement-statistics-refresh-button.png)  
##### 2.4.1.5.存储过程  
在`图项目`界面，点击图项目选项卡中的`存储过程`按钮（卡片最右侧图标），跳转到操作存储过程的图页面。  
![图项目-存储过程按钮](../../../images/browser/graphmanagement-procedure-button.png)  
在`存储过程`页面，可以新建存储过程，新建时需要填写""存储过程名称""、""存储过程类型""、""存储过程描述""，然后选择""版本""和""执行时是否修改数据库""  
![图项目-存储过程](../../../images/browser/graph' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.2.构建采样器

训练过程中，首先使用GetDB算子从数据库中获取图数据并转换成所需数据结构，具体代码如下：
```python
GetDB.Process(db_: lgraph_db_python.PyGraphDB, olapondb: lgraph_db_python.PyOlapOnDB, feature_num: size_t, NodeInfo: list, EdgeInfo: list)
```
如代码所示，结果存储在NodeInfo和EdgeInfo中。NodeInfo和EdgeInfo是python list结果，其存储的信息结果如下：  
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |  
然后构建采样器
```python
batch_size = 5
count = 2708
sampler = TugraphSample(args)
dataloader = dgl.dataloading.DataLoader(fake_g,
torch.arange(count),
sampler,
batch_size=batch_size,
num_workers=0,
)
```' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.2.构建采样器'}","page_content='典型示例

PageRank动态图计算示例介绍

实例代码

```java

public class IncrGraphCompute {

private static final Logger LOGGER = LoggerFactory.getLogger(IncrGraphCompute.class);
// 计算结果路径
public static final String RESULT_FILE_PATH = ""./target/tmp/data/result/incr_graph"";
// 结果对比路径
public static final String REF_FILE_PATH = ""data/reference/incr_graph"";

public static void main(String[] args) {
// 获取执行环境
Environment environment = EnvironmentFactory.onLocalEnvironment();
// 执行作业提交
IPipelineResult result = submit(environment);
// 等待执行完成
result.get();
// 关闭执行环境
environment.shutdown();
}

public static IPipelineResult<?> submit(Environment environment) {
// 构建任务执行流
final Pipeline pipeline = PipelineFactory.buildPipeline(environment);
// 获取作业环境配置
Configuration envConfig = ((EnvironmentContext) environment.getEnvironmentContext()).getConfig();
// 指定保存计算结果的路径
envConfig.put(FileSink.OUTPUT_DIR, RESULT_FILE_PATH);

// graphview 名称
final String graphName = ""graph_view_name"";
// 创建增量图 graphview
GraphViewDesc graphViewDesc = GraphViewBuilder
.createGraphView(graphName)
// 设置 graphview 分片数, 可从配置中指定
.withShardNum(envConfig.getInteger(ExampleConfigKeys.ITERATOR_PARALLELISM))
// 设置 graphview backend 类型
.withBackend(BackendType.RocksDB)
// 指定 graphview 点边以及属性等schema信息
.withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class, Integer.class, ValueEdge.class, IntegerType.class))
.build();
// 将创建好的graphview信息添加到任务执行流
pipeline.withView(graphName, graphViewDesc);

// 提交任务并执行
pipeline.submit(new PipelineTask() {
@Override
public void execute(IPipelineTaskContext pipelineTaskCxt) {
Configuration conf = pipelineTaskCxt.getConfig();
// 1. 构建点数据输入源
PWindowSource<IVertex<Integer, Integer>> vertices =
// extract vertex from edge file
pipelineTaskCxt.buildSource(new RecoverableFileSource<>(""data/input/email_edge"",
// 指定每行数据的解析格式
line -> {
String[] fields = line.split("","");
IVertex<Integer, Integer> vertex1 = new ValueVertex<>(
Integer.valueOf(fields[0]), 1);
IVertex<Integer, Integer> vertex2 = new Value' metadata={'Header 1': '典型示例', 'Header 2': 'PageRank动态图计算示例介绍', 'Header 3': '实例代码'}"
lgraph_api::Transaction的作用是什么？,"page_content='Python Olap API

5. lgraph_db API

GraphDB：

- `CreateReadTxn()-> Transaction`: 创建只读事务
- `CreateWriteTxn()-> Transaction`: 创建写事务
- `ForkTxn(txn: Transaction)-> Transaction`: 复制事务，只能复制读事务' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'GraphDB：'}","page_content='Traversal API

1. 简介

TuGraph 强大的在线分析处理（OLAP）能力是其区别于其它图数据库的一个重要特性。
借助 C++ OLAP API（olap_on_db.h），用户可以快速地导出一个需要进行复杂分析的子图，然后在其上运行诸如 PageRank、连通分量、社区发现等迭代式图计算过程，最后根据结果做出相应决策。
导出和计算的过程都可以通过并行处理的方式进行加速，从而实现几乎实时的分析处理，避免了传统解决方案需要将数据导出、转换、再导入（ETL）到专门的分析系统进行离线处理的冗长步骤。  
TuGraph 内置了大量常用的图分析算法和丰富的辅助接口，因此用户几乎不需要自己来实现具体的图计算过程，只需在实现自己的存储过程时将相应算法库的头文件（.h 文件）包含到自己程序中，并在编译时链接相应的动态库文件（.so）即可。
一般情况下，用户需要自己实现的只有将需要分析的子图抽取出来的过程。  
目前 Traversal API 仅支持 C++。' metadata={'Header 1': 'Traversal API', 'Header 2': '1. 简介'}","page_content='Procedure API

1.简介

当用户需要表达的查询/更新逻辑较为复杂（例如 Cypher 无法描述，或是对性能要求较高）时，相比调用多个请求并在客户端完成整个处理流程的方式，TuGraph 提供的存储过程是更简洁和高效的选择。  
与传统数据库类似，TuGraph 的存储过程运行在服务器端，用户通过将处理逻辑（即多个操作）封装到一个过程单次调用，并且可以在实现时通过并行处理的方式（例如使用相关的 C++ OLAP 接口以及基于其实现的内置算法）进一步提升性能。  
存储过程中有一类特殊的API来进行数据的并行操作，我们叫 Traversal API，见[文档](2.traversal.md)。' metadata={'Header 1': 'Procedure API', 'Header 2': '1.简介'}"
在执行`ProcessVertexActive`函数时，如果运行时出现错误，会引发什么异常？,"page_content='动态图

示例

```java
public class IncrGraphTraversalAll {

private static final Logger LOGGER =
LoggerFactory.getLogger(IncrGraphTraversalAll.class);

public static void main(String[] args) {
Environment environment = EnvironmentFactory.onLocalEnvironment();
Pipeline pipeline = PipelineFactory.buildPipeline(environment);
String graphName = ""graph_view_name"";
GraphViewDesc graphViewDesc = GraphViewBuilder.createGraphView(graphName)
.withShardNum(2)
.withBackend(BackendType.RocksDB)
.withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class, Integer.class, ValueEdge.class, IntegerType.class))
.build();
pipeline.withView(graphName, graphViewDesc);
pipeline.submit(new PipelineTask() {
@Override
public void execute(IPipelineTaskContext pipelineTaskCxt) {
PWindowSource<IVertex<Integer, Integer>> vertices =
pipelineTaskCxt.buildSource(new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IVertex<Integer, Integer> vertex1 = new ValueVertex<>(
Integer.valueOf(fields[0]), 1);
IVertex<Integer, Integer> vertex2 = new ValueVertex<>(
Integer.valueOf(fields[1]), 1);
return Arrays.asList(vertex1, vertex2);
}), SizeTumblingWindow.of(10000));

PWindowSource<IEdge<Integer, Integer>> edges =
pipelineTaskCxt.buildSource( new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IEdge<Integer, Integer> edge = new ValueEdge<>(Integer.valueOf(fields[0]),
Integer.valueOf(fields[1]), 1);
return Collections.singletonList(edge);
}), SizeTumblingWindow.of(5000));

PGraphView<Integer, Integer, Integer> fundGraphView =
pipelineTaskCxt.getGraphView(graphName);
PIncGraphView<Integer, Integer, Integer> incGraphView =
fundGraphView.appendGraph(vertices, edges);
incGraphView.incrementalTraversal(new IncGraphTraversalAlgorithms(3))
.start()
.sink(v -> {});
}
});
IPipelineResult result = pipeline.execute();
result.get();
}

public static class IncGraphTraversalAlgorithms extends IncVertexCentricTraversal<Integer,
' metadata={'Header 1': '动态图', 'Header 2': '示例'}","page_content='OlapOnDB API

4. 其他常用函数功能描述

4.10 活跃点的描述

活跃点指的是在批处理函数中需要处理的点，在本例子中只是输出了活跃点的编号，并且汇总活跃点的数量：  
```C++
ParallelBitset temp = 000111;//当前活跃点为3，4，5号点

size_t delta = ForEachActiveVertex<double>(
//void c
[&](size_t vi) {
printf(""active_vertexId = %lu\n"",vi);
return 1;
},
all_vertices
);
```  
函数的运行结果显而易见，因为多线程的关系，一下输出顺序可能有所变化：  
```
active_vertexId = 3
active_vertexId = 4
active_vertexId = 5
```  
局部返回值均为1，该函数会在保证线程安全的情况下将所有的局部返回值累加得到最终的返回值，并存储在`delta`变量中，该值最终为3' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.10 活跃点的描述'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterato' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}"
如果在调用存储过程时，指定json_format参数为false，返回结果的格式是什么？,"page_content='Java客户端

2.使用示例

2.6.调用存储过程

```java
String result = client.callProcedure(""CPP"", ""khop"", kHopParamGen(), 1000, false, ""default"");
log.info(""testCallProcedure : "" + result);
```
```
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param param: the execution parameters
@param procedureTimeOut: Maximum execution time, overruns will be interrupted
@param inProcess: Running query or not
@param graph: the graph to query
@param jsonFormat: (Optional) Return format of calling stored procedure
@param url: (Optional) Node address of calling procedure
@return: the result of procedure execution
public String callProcedure(String procedureType, String procedureName, String param, double procedureTimeOut,
boolean inProcess, String graph, String url)
```
本接口支持在单机模式和HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}","page_content='RPC API

5.存储过程

5.2.调用存储过程

调用存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称
- param: 必要参数，存储过程参数
- result_in_json_format: 可选参数，调用结果是否以JSON格式返回
- in_process: 可选参数，未来支持
- timeout: 可选参数，调用存储过程的超时时间  
以C++为例，用户调用存储过程的方式如下所示：
```C++
LGraphRequest req;
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
lgraph::CallPluginRequest *cpRequest = pluginRequest->mutable_call_plugin_request();
cpRequest->set_name(procedure_name);
cpRequest->set_in_process(in_process);
cpRequest->set_param(param);
cpRequest->set_timeout(procedure_time_out);
cpRequest->set_result_in_json_format(json_format);
LGraphResponse res;
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
if (json_format) {
result = res.mutable_plugin_response()->mutable_call_plugin_response()->json_result();
} else {
result = res.mutable_plugin_response()->mutable_call_plugin_response()->reply();
}
```
调用存储过程的响应为以下两个参数之一：
- reply: ByteString格式的存储过程调用结果
- json_result: JSON格式的存储过程调用结果' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.2.调用存储过程'}","page_content='Python客户端

3.RPC Client

3.6.调用存储过程

```python
ret, res = client.callProcedure(""CPP"", ""test_plugin1"", ""bcefg"", 1000, False, ""default"")
```
```
callProcedure(self: liblgraph_client_python.client, procedure_type: str, procedure_name: str, param: str, procedure_time_out: float, in_process: bool, graph: str, json_format: bool, url: str) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.6.调用存储过程'}"
Prometheus的地址是什么？,"page_content='运维监控

1.设计思路

1.3.Prometheus

Prometheus是一个开源的监控平台，并配备有专属的时序数据库，它会定期通过http请求从TuGraph Monitor服务获取统计指标，并保存在自己的时序数据库中。详细信息请参考官网: [https://prometheus.io/docs/introduction/first_steps](https://prometheus.io/docs/introduction/first_steps)' metadata={'Header 1': '运维监控', 'Header 2': '1.设计思路', 'Header 3': '1.3.Prometheus'}","page_content='运维监控

2.部署方案

2.3.第三步

+ 下载符合您机器架构以及系统版本的Prometheus tar包，下载地址: [https://prometheus.io/download/](https://prometheus.io/download/)  
+ 解压tar包，命令如下  
```shell
tar -zxvf prometheus-2.37.5.linux-amd64.tar.gz
```  
+ 修改配置文件prometheus.yml，新增如下配置，使其可以抓取TuGraph Monitor包装好的性能数据  
```yaml
scrape_configs:
# The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
- job_name: ""tugraph""

# metrics_path defaults to '/metrics'
# scheme defaults to 'http'.

static_configs:
- targets: [""localhost:9111""]
```  
+ 启动prometheus，具体的启动参数可以通过如下命令获取  
```shell
./prometheus -h
```  
+ 验证prometheus服务是否正常，可以通过web端登陆prometheus服务，查询监控指标resources_report是否已经获取到，能成功查询到数据则正确' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.3.第三步'}","page_content='运维监控

2.部署方案

2.4.第四步

+ 下载符合您机器架构以及系统版本的Grafana安装包，下载地址: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)  
+ 安装Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 启动Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 配置Grafana，首先在数据源设置中配置Prometheus的IP地址，配置完成后可以通过测试连接功能，验证是否成功连接数据源。然后，导入如下模版，并在页面中根据实际情况，修改正确的接口IP和端口。最后可以根据实际情况设置刷新时间和监控时间范围  
```json
{
""annotations"": {
""list"": [
{
""builtIn"": 1,
""datasource"": {
""type"": ""grafana""
},
""enable"": true,
""hide"": true,
""iconColor"": ""rgba(0, 211, 255, 1)"",
""name"": ""Annotations & Alerts"",
""target"": {
""limit"": 100,
""matchAny"": false,
""tags"": [],
""type"": ""dashboard""
},
""type"": ""dashboard""
}
]
},
""editable"": true,
""fiscalYearStartMonth"": 0,
""graphTooltip"": 0,
""id"": 2,
""links"": [],
""liveNow"": false,
""panels"": [
{
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
}
},
""mappings"": [],
""unit"": ""kbytes""
},
""overrides"": [
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {__name__=\""resources_report\"", instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
},
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""others""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-blue"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}"
TuGraph图分析引擎主要面向哪类任务？,"page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。  
<table><tbody><tr><td>算法类型</td><td>中文算法名</td><td>英文算法名</td><td>程序名</td></tr><tr><td rowspan=""5"">路径查询</td><td>广度优先搜索</td><td>Breadth-First Search</td><td>bfs</td></tr><tr><td>单源最短路径</td><td>Single-Source Shortest Path</td><td>sssp</td></tr><tr><td>全对最短路径</td><td>All-Pair Shortest Path</td><td>apsp</td></tr><tr><td>多源最短路径</td><td>Multiple-source Shortest Paths</td><td>mssp</td></tr><tr><td>两点间最短路径</td><td>Single-Pair Shortest Path</td><td>spsp</td></tr><tr><td rowspan=""9"">重要性分析</td><td>网页排序</td><td>Pagerank</td><td>pagerank</td></tr><tr><td>介数中心度</td><td>Betweenness Centrality</td><td>bc</td></tr><tr><td>置信度传播</td><td>Belief Propagation</td><td>bp</td></tr><tr><td>距离中心度</td><td>Closeness Centrality</td><td>clce</td></tr><tr><td>个性化网页排序</td><td>Personalized PageRank</td><td>ppr</td></tr><tr><td>带权重的网页排序</td><td>Weighted Pagerank Algorithm</td><td>wpagerank</td></tr><tr><td>信任指数排名</td><td>Trustrank</td><td>trustrank</td></tr><tr><td>sybil检测算法</td><td>Sybil Rank</td><td>sybilrank</td></tr><tr><td>超链接主题搜索</td><td>Hyperlink-Induced Topic Search</td><td>hits</td></tr><tr><td rowspan=""4"">关联性分析</td><td>平均集聚系数</td><td>Local Clustering Coefficient</td><td>lcc</td></tr><tr><td>共同邻居</td><td>Common Neighborhood</td><td>cn</td></tr><tr><td>度数关联度</td><td>Degree Correlation</td><td>dc</td></tr><tr><td>杰卡德系数</td><td>Jaccard Index</td><td>ji</td></tr><tr><td rowspan=""5"">图结构</td><td>直径估计</td><' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}","page_content='OLAP API

1. TuGraph 图分析引擎介绍

TuGraph的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助TuGraph的 C++ / Python 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如PageRank、LPA、WCC等迭代式图算法，最后根据运行结果做出相应的对策。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph图计算系统社区版内置6个算法，商业版内置了25种算法，用户几乎不需要自己实现具体的图计算过程。其详细介绍可参考algorithms.md。  
根据数据来源及实现不同，可分为Procedure、Embed和Standalone三种运行方式，均继承于OlapBase API，OlapBase API接口文档可参考olapbase-api.md。  
其中Procedure和Embed的数据来源是图数据库中预加载的db数据，可以分别编译生成tugraph-web加载使用的.so文件和后台终端使用的embed文件，输入的图数据均通过db的加载形式，其接口文档可参考olapondb-api.md。
Standalone用于编译生成standalone文件，区别于前者，该文件的输入图数据通过txt、二进制、ODPS文件的形式加载，其接口文档可参考olapondisk-api.md。' metadata={'Header 1': 'OLAP API', 'Header 2': '1. TuGraph 图分析引擎介绍'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}"
在给定的XML配置中，如果表内属性字段名为id时，应该如何处理node_id字段以避免报错？,"page_content='业务开发指南

点类型操作

点类型添加字段

>该操作会同步变更所有该类型点的属性数据，数据量大的时候，有时间消耗。  
如下例子，对于点类型`node1`，一次添加了两个字段：`field1`，字符串类型，可选，默认值是 `null`; `field2`，`int64`类型，必选，默认值是0.
```
CALL db.alterLabelAddFields('vertex', 'node1', ['field1', string, null ,true], ['field2', int64, 0, false])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '点类型操作', 'Header 3': '点类型添加字段'}","page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

TuGraph 是一个具备多图能力的强模式属性图数据库。在每一张子图中，每种点和边都需要有预定义的数据格式。数据格式由 Label 决定，每种 Label 都有自己的数据格式。用户可以使用 REST API 添加，删除和查询 Label 及其对应的数据格式。  
Label 操作对应的 URI 格式为  
```
http://{host}:{port}/db/{graph_name}/label/{type}/{label_name}
```  
其中{type}可以是 node 或者 relationship。  
#### 6.6.1.创建Label  
创建 Label 的过程同时也是定义其数据类型的过程。只有创建了 Label 才能在图中插入相应类型的点或者边。  
- **URI**: `/db/{graph_name}/label`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | Label 名 | 字符串 |
| fields | 数据列定义 | 列表 |
| is_vertex | 是否是点 Label | 布尔值 |
| primary | 点的主键属性 | 字符串 |
| edge_constraints | 边的约束 | 列表 |  
`primary` 在 `is_vertex` 为 `true` 的时候设置，这个字段只有点才有, 创建点的时候必须设置。  
`edge_constraints` 在 `is_vertex` 为 `false` 的时候设置，这个字段只有边有。这个字段限制了该边的起点和终点只能是哪些点的组合，比如：`[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]`，限制了该边只能是从 `vertex_label1` 到 `vertex_label2` 和 从 `vertex_label3` 到 `vertex_label4`。如果不想有任何限制，不设置该字段即可。  
其中`fields`为一个数组，其中每个元素定义数据的一列，内容如下：  
| 域名     | 说明                                     | 类型                                                                                                |
| -------- | ---------------------------------------- | --------------------------------------------------------------------------------------------------- |
| name     | 列名                                     | 字符串                                                                                              |
| type     | 列数据类型                               | 字符串，有以下类型： int8, int16, int32, int64, float, double, string, date, datetime, binary, bool |
| optional | 数据是否可以为空（可选，缺省值为 false） | 布尔值                                                                                              |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/label
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""name"":""Actor"",
""fields"": [
{""name"":""uid"", ""type"":""int64' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}","page_content='业务开发指南

点类型操作

创建点类型

如下json定义了一个点类型，名字是`node1`。
```json
{
""label"": ""node1"",
""primary"": ""id"",
""type"": ""VERTEX"",
""detach_property"": true,
""properties"": [{
""name"": ""id"",
""type"": ""INT32"",
""optional"": false
}, {
""name"": ""name"",
""type"": ""STRING"",
""optional"": false,
""index"": true
}, {
""name"": ""num"",
""type"": ""INT32"",
""optional"": false,
""index"": true,
""unique"": true
}, {
""name"": ""desc"",
""type"": ""STRING"",
""optional"": true
}]
}

```
把上面这个json序列化成字符串，作为参数传入，建议使用驱动的参数化特性，避免自己拼接语句。
```
CALL db.createVertexLabelByJson($json_data)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '点类型操作', 'Header 3': '创建点类型'}"
"使用OGM进行创建节点和边的代码示例中，哪部分代码用于创建边标签""DIRECT""?","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.1 构建图对象**

首先需要通过注解标明图中的实体。  
@NodeEntity：该注解标明的类为节点类。  
@Relationship：用于标明边，同时@Relationship中可指定label与边的指向。  
@Id：用于标明identity，是OGM中数据的唯一标识。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.1 构建图对象**'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.3 通过OGM进行增操作**

OGM支持对TuGraph的实体执行CRUD 操作，同时支持发送任意TuGraph支持的Cypher语句，包括通过CALL调用存储过程。  
**CREATE**  
在完成图对象的构建后，即可通过类的实例化创建节点，当两个节点互相存储在对方的集合（该集合在构建时被标注为边）中，就形成了一条边，最后使用session.save方法将数据存入数据库。  
注意：TuGraph数据库为强schema类型数据库，在创建实体前需要该数据的label已经存在，且新建过程中需要提供唯一的主键。  
```
Movie jokes = new Movie（""Jokes""，1990）； // 新建Movie节点jokes session.save(jokes); // 将jokes存储在TuGraph中

Movie speed = new Movie(""Speed"", 2019);

Actor alice = new Actor(""Alice Neeves"");

alice.actsIn(speed);

session.save(speed);

/1 将speed节点与alice节点通过ACTS_IN进行连接 11 存储speed节点以及speed关联的边和alice节点
```' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.3 通过OGM进行增操作**'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.6 通过OGM进行查操作**

**MATCH**  
session.load方法用于根据节点id查找节点。 session.loadALL方法用于批量查找节点，支持通过多个节点id查找节点、查找某一类型的所有节点、带有filter的查询。 filter查询需要新建Filter，传入参数ComparisonOperatorx0;可选为：EQUALSx0;、GREATER\_THANx0;、LESS\_THAN  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*J3Z1TrA0BncAAAAAAAAAAAAADgOBAQ/original)  
**QUERY WITH CYPHER**  
OGM支持通过queryForObject、query方法向TuGraph发送Cypher查询，由于Cypher查询的灵活性，需要用户自行指定返回结果格式。  
session.queryForObject方法：需要在方法第一个参数处指定返回类型，可设定为某一实体类或数字类型。  
session.query方法：Cypher查询的返回结果被存储为Result类型，其内部数据需要用户自行解析，以下方代码为例，传入数据库的Cypher为CREATE查询，返回结果createResult可被解析为QueryStatistics，可获取到此次查询被创建的节点与边的数目。  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*lkxXS660eEgAAAAAAAAAAAAADgOBAQ/original)' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.6 通过OGM进行查操作**'}"
"return n 和 return p.name,p.age 的数据结构不一致。 能统一返回可视化页面的这种结构么？","page_content='Cypher API

2.Clauses

2.3.RETURN

- ✓ Return nodes  
```
MATCH (n {name: 'Carrie-Anne Moss'}) RETURN n
```  
- ✓ Return relationships  
```
MATCH (n {name: 'Carrie-Anne Moss'})-[r:acted_in]->(c)
RETURN r
```  
- ✓ Return property  
```
MATCH (n {name: 'Carrie-Anne Moss'}) RETURN n.born
```  
- ❏ Return all elements  
```
MATCH p = (a {name: 'A'})-[r]->(b)
RETURN *
```  
- ❏ Variable with uncommon characters  
```
MATCH (`This isn\'t a common variable`)
WHERE `This isn\'t a common variable`.name = 'A'
RETURN `This isn\'t a common variable`.happy
```  
- ✓ Aliasing a field  
```
MATCH (a {name: 'Carrie-Anne Moss'})
RETURN a.born AS SomethingTotallyDifferent
```  
- ✓ Optional properties  
```
MATCH (n)
RETURN n.age
```  
- ❏ Other expressions  
```
MATCH (a {name: 'Carrie-Anne Moss'})
RETURN a.born > 1900, ""I'm a literal"", (a)-[]->()
```  
`(a)-[]->()` not supported.  
- ✓ Unique results  
```
MATCH (a {name: 'Carrie-Anne Moss'})-[]->(b)
RETURN DISTINCT b
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.3.RETURN'}","page_content='ISO GQL

2.Clauses

2.3.RETURN

`RETURN`子句指定返回结果，包括返回点、边、路径、属性等。  
#### 返回点  
```
MATCH (n)
RETURN n LIMIT 2
```  
返回结果
```JSON
[{""n"":{""identity"":0,""label"":""Person"",""properties"":{""birthyear"":1910,""name"":""Rachel Kempson""}}},{""n"":{""identity"":1,""label"":""Person"",""properties"":{""birthyear"":1908,""name"":""Michael Redgrave""}}}]
```  
#### 返回边  
```
MATCH (n)-[e]->(m)
RETURN e LIMIT 2
```  
返回结果  
```JSON
[{""e"":{""dst"":2,""forward"":false,""identity"":0,""label"":""HAS_CHILD"",""label_id"":0,""src"":0,""temporal_id"":0}},{""e"":{""dst"":3,""forward"":false,""identity"":0,""label"":""HAS_CHILD"",""label_id"":0,""src"":0,""temporal_id"":0}}]
```  
#### 返回属性  
```
MATCH (n:Person)
RETURN n.name LIMIT 2
```  
返回结果  
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```  
#### 不常见字符串作为变量名  
```
MATCH (`/uncommon variable`:Person)
RETURN `/uncommon variable`.name LIMIT 3
```  
返回结果  
```JSON
[{""`/uncommon variable`.name"":""Christopher Nolan""},{""`/uncommon variable`.name"":""Corin Redgrave""},{""`/uncommon variable`.name"":""Dennis Quaid""}]
```  
#### 列别名  
```
MATCH (n:Person)
RETURN n.name AS nname LIMIT 2
```  
返回结果  
```JSON
[{""nname"":""Christopher Nolan""},{""nname"":""Corin Redgrave""}]
```  
#### 可选属性  
```
MATCH (n:Person)
RETURN n.age LIMIT 2
```  
返回结果  
```JSON
[{""n.age"":null},{""n.age"":null}]
```  
#### 其它表达式  
```
MATCH (n:Person)
RETURN n.birthyear > 1970, ""I'm a literal"", 1 + 2, abs(-2)
LIMIT 2
```  
返回结果  
```JSON
[{""\""I'm a literal\"""":""I'm a literal"",""1 + 2"":3,""abs(-2)"":2,""n.birthyear > 1970"":false},{""\""I'm a literal\"""":""I'm a literal"",""1 + 2"":3,""abs(-2)"":2,""n.birthyear > 1970"":false}]
```  
#### 结果唯一性  
```
MATCH (n)
RETURN DISTINCT label(n) AS label
```  
返回结果  
```JSON
[{""label"":""Person""},{""label"":""City""},{""label"":""Film""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.3.RETURN'}","page_content='Return

Example

```sql
MATCH (a:person WHERE a.id = '1')-[e:knows]->(b:person)
RETURN a.name as name, b.id as b_id

MATCH (a:person WHERE a.id = '1')-[e:knows]->(b:person)
RETURN a, b

-- GROUP BY
MATCH (a:person)-[e:knows where e.weight > 0.4]->(b:person)
RETURN a.id, SUM(e.weight) * 10 as amt GROUP BY a.id

-- ORDER BY
MATCH (a:person WHERE a.id = '1')-[e:knows]->(b:person)
RETURN a, b order by a.age DESC, b.age ASC

-- LIMIT
MATCH (a:person WHERE a.id = '1')-[e:knows]->(b:person)
RETURN a, b order by a.age DESC, b.age ASC LIMIT 10
```' metadata={'Header 1': 'Return', 'Header 2': 'Example'}"
编译TuGraph时如何为基于ARM的机器（如Mac M1）配置CMake？,"page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.3 通过OGM进行增操作**

OGM支持对TuGraph的实体执行CRUD 操作，同时支持发送任意TuGraph支持的Cypher语句，包括通过CALL调用存储过程。  
**CREATE**  
在完成图对象的构建后，即可通过类的实例化创建节点，当两个节点互相存储在对方的集合（该集合在构建时被标注为边）中，就形成了一条边，最后使用session.save方法将数据存入数据库。  
注意：TuGraph数据库为强schema类型数据库，在创建实体前需要该数据的label已经存在，且新建过程中需要提供唯一的主键。  
```
Movie jokes = new Movie（""Jokes""，1990）； // 新建Movie节点jokes session.save(jokes); // 将jokes存储在TuGraph中

Movie speed = new Movie(""Speed"", 2019);

Actor alice = new Actor(""Alice Neeves"");

alice.actsIn(speed);

session.save(speed);

/1 将speed节点与alice节点通过ACTS_IN进行连接 11 存储speed节点以及speed关联的边和alice节点
```' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.3 通过OGM进行增操作**'}","page_content='TuGraph与ARM架构

内容：

**背景介绍：**

在高速信息化的21世纪，计算机软硬件均经历着翻天覆地的变化，从Intel和AMD的x86 CPU架构到ARM RISC精简指令CPU，内存也演进出超高带宽内存HBM、非易失内存NVM。近年来基于ARM架构的CPU越来越普遍，在手机中ARM芯片已占90%以上份额，个人PC中苹果M1/M2均采用ARM架构，在服务器领域华为鲲鹏、飞腾等ARM架构CPU也逐步被接纳。本次测试使用的倚天710，是阿里基于ARMv9架构自研的CPU，已在阿里云服务中大规模部署，成为中国首个云上大规模应用的自研CPU。  
数据库作为底层系统软件，面对CPU的更新换代也迎来了更多的挑战和机遇。在ARM架构中，CPU通常拥有更多的核数、更低的能耗、更高的性价比。作为拥抱开源的图数据库产品，TuGraph不仅需要兼容新型硬件，更需要充分发挥出新硬件的功能和性能优势。适配和测试工作包括超多线程的支持、更加细致的负载均衡策略、并发读写性能优化等。  
**本次测试机构国际关联数据基准委员会LDBC是由高校、研究所、企业联合组成的非盈利组织，其中企业成员包括Intel、Oracle、Neo4j、蚂蚁集团等国内外知名图数据厂商，致力于推进图数据的规范标准化。**本次测试使用的图数据来自LDBC的社交网络运营场景SNB（Social Network Benchmark），LDBC SNB的图数据是一个包含14类顶点和20类边的属性图，用户可以指定scale factor生成不同规模的数据。LDBC SNB的交互式工作负载由14个复杂的只读查询、7个简单的只读查询和8个事务型更新查询组成。' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '内容：', 'Header 3': '**背景介绍：**'}"
单机的配置大致是什么情况？,"page_content='环境准备

3.典型配置推荐

| 硬件      | 最低配置   | 建议配置                   |
| -------- | --------- | ------------------------ |
| CPU      | 4 Cores   | 64 Cores                 |
| 内存      | 4GB       | 512GB                    |
| 外存      | 100GB     | 2TB NVMe SSD             |
| OS       | Linux 4.9 | CentOS 7.3               |' metadata={'Header 1': '环境准备', 'Header 2': '3.典型配置推荐'}","page_content='快速上手

1.简介

1.2.硬件要求

_目前我们建议用户使用 NVMe SSD 配合较大的内存配置以获取最佳性能。_  
| 硬件   | 最低配置      | 建议配置                     |
|------|-----------|--------------------------|
| CPU  | X86_64    | Xeon E5 2670 v4          |
| 内存   | 4GB       | 256GB                    |
| 硬盘   | 100GB     | 1TB NVMe SSD             |
| 操作系统 | Linux 2.6 | Ubuntu 18.04, CentOS 7.3 |' metadata={'Header 1': '快速上手', 'Header 2': '1.简介', 'Header 3': '1.2.硬件要求'}","page_content='运维监控

2.部署方案

2.4.第四步

+ 下载符合您机器架构以及系统版本的Grafana安装包，下载地址: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)  
+ 安装Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 启动Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 配置Grafana，首先在数据源设置中配置Prometheus的IP地址，配置完成后可以通过测试连接功能，验证是否成功连接数据源。然后，导入如下模版，并在页面中根据实际情况，修改正确的接口IP和端口。最后可以根据实际情况设置刷新时间和监控时间范围  
```json
{
""annotations"": {
""list"": [
{
""builtIn"": 1,
""datasource"": {
""type"": ""grafana""
},
""enable"": true,
""hide"": true,
""iconColor"": ""rgba(0, 211, 255, 1)"",
""name"": ""Annotations & Alerts"",
""target"": {
""limit"": 100,
""matchAny"": false,
""tags"": [],
""type"": ""dashboard""
},
""type"": ""dashboard""
}
]
},
""editable"": true,
""fiscalYearStartMonth"": 0,
""graphTooltip"": 0,
""id"": 2,
""links"": [],
""liveNow"": false,
""panels"": [
{
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
}
},
""mappings"": [],
""unit"": ""kbytes""
},
""overrides"": [
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {__name__=\""resources_report\"", instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
},
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""others""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-blue"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}"
如何查询两点间的一条通路？,"page_content='内置算法

扩展算法包

两点间最短路径

两点间最短路径程序实现了Bidirectional Breadth-First Search算法，在有向无权图上从起点沿着出边做正向宽度优先搜搜，从终点沿着入边做反向宽度优先搜索，通过起点和终点共同遍历到的点来确定从起点到终点的最短路径长度。算法内容请参考[https://en.wikipedia.org/wiki/Bidirectional_search](https://en.wikipedia.org/wiki/Bidirectional_search ""Bidirectional search"")。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': '两点间最短路径'}","page_content='快速上手(本地运行)

本地运行流图作业

下面介绍如何在本地环境运行一个实时环路查找的图计算作业。  
1. 启动流图作业  
在编译完 geaflow 代码后，在工程目录下执行以下命令，启动实时环路查找的计算作业：  
```shell
bin/gql_submit.sh --gql geaflow/geaflow-examples/gql/loop_detection.sql
```  
如果你想要在进程中使用火焰图进行进程分析，则需要自行下载解压async-profiler，
并将解压后的文件夹中的profiler.sh的路径加入到参数中。例如：  
```shell
bin/gql_submit.sh --gql geaflow/geaflow-examples/gql/loop_detection.sql --profiler /tmp/async-profiler/profiler.sh
```  
其中 loop_detection.sql 是一段实时查询图中所有四度环路的 DSL 计算作业，其内容如下：  
```sql
set geaflow.dsl.window.size = 1;
set geaflow.dsl.ignore.exception = true;

CREATE GRAPH IF NOT EXISTS dy_modern (
Vertex person (
id bigint ID,
name varchar
),
Edge knows (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
)
) WITH (
storeType='rocksdb',
shardCount = 1
);

CREATE TABLE IF NOT EXISTS tbl_source (
text varchar
) WITH (
type='socket',
`geaflow.dsl.column.separator` = '#',
`geaflow.dsl.socket.host` = 'localhost',
`geaflow.dsl.socket.port` = 9003
);

CREATE TABLE IF NOT EXISTS tbl_result (
a_id bigint,
b_id bigint,
c_id bigint,
d_id bigint,
a1_id bigint
) WITH (
type='socket',
`geaflow.dsl.column.separator` = ',',
`geaflow.dsl.socket.host` = 'localhost',
`geaflow.dsl.socket.port` = 9003
);

USE GRAPH dy_modern;

INSERT INTO dy_modern.person(id, name)
SELECT
cast(trim(split_ex(t1, ',', 0)) as bigint),
split_ex(t1, ',', 1)
FROM (
Select trim(substr(text, 2)) as t1
FROM tbl_source
WHERE substr(text, 1, 1) = '.'
);

INSERT INTO dy_modern.knows
SELECT
cast(split_ex(t1, ',', 0) as bigint),
cast(split_ex(t1, ',', 1) as bigint),
cast(split_ex(t1, ',', 2) as double)
FROM (
Select trim(substr(text, 2)) as t1
FROM tbl_source
WHERE substr(text, 1, 1) = '-'
);

INSERT INTO tbl_result
SELECT DISTINCT
a_id,
b_id,
c_id,
d_id,
a1_id
FROM (
MATCH (a:person) -[:knows]->(b:person) -[:knows]-> (c:person)
-[:knows]-> (d:person) -> (a:person)
RETURN a.id as a_id, b.id as b_id, c.id as c_id, d.id as d_id, a.id as a1_id
);
```  
该 DSL 实时读取 socket 服务 9003 端口数据，实时构图，然后计算图中所有的 4 度的环路, 并将环路上的点 i' metadata={'Header 1': '快速上手(本地运行)', 'Header 2': '本地运行流图作业'}","page_content='🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！

仅需 5 步，即可呈现 🎊

4. 演示

环路检测 Demo 提供了两种方式来进行交互：  
* 方式一 在输入框中输入点边信息
* 方式二 使用内置数据进行演示  
> 两种方式本质都是调用 Tugraph Analytics 进行实时计算，不过方式二省略了手动输入过程。  
这里我们使用内置数据进行快速演示，点击【选项】，选择`添加点`，画布中出现了 7 个点信息；接着选择`添加边`。我们可以在上方对话框中看到添加记录。  
<img width=""332"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/7ca76607-41a1-4afe-9427-cf7599de6889"">  
同样的，Tugraph Analytics 终端也会实时输出操作信息，并自动启动计算任务。  
<img width=""611"" alt=""image"" src=""https://github.com/TuGraph-family/tugraph-analytics/assets/25787943/d8d0d73a-4c07-4ecd-bcac-4633a742933a"">' metadata={'Header 1': '🌈 [G6VP](https://github.com/antvis/g6vp) 现在支持与 Tugraph 协作实现流图作业可视化了！', 'Header 2': '仅需 5 步，即可呈现 🎊', 'Header 3': '4. 演示'}"
tugraph 支持通过cypher 或者python的形式修改schema吗,"page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}","page_content='功能概览

4.核心功能

4.1.查询语言

TuGraph 提供 Cypher 图查询语言，遵循OpenCypher标准。
- __支持Procedure嵌入__  
- __可插拔优化框架__ 各类优化功能  
- __可扩展安全性检查框架__ 对于cypher进行' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.1.查询语言'}","page_content='Procedure API

2.存储过程的版本支持

目前TuGraph支持两个版本的存储过程，适用于不同的场景，v3.5版本只支持v1，可通过REST或RPC接口直接调用；从v3.5版本开始支持v2，能够在图查询语言（比如Cypher）中嵌入调用，我们称之为POG（Procedure On Graph query language，APOC）。  
|                        | Procedure v1                       | Procedure v2               |
| ---------------------- | ---------------------------------- | -------------------------- |
| 适用场景                 | 极致性能，或者复杂的多事务管理情形       | 一般情况，与Cypher高度联动 |
| 事务                    | 函数内部创建，可自由控制多事务          | 外部传入函数，单一事务     |
| 签名（参数定义）          | 无                                 | 有                    |
| 输入输出参数类型          | 不需要指定                           | 需要指定参数类型        |
| Cypher Standalone Call | 支持                                | 支持                  |
| Cypher Embeded Call    | 不支持                              | 支持                  |
| 语言                    | C++/Python/Rust                    | C++                  |
| 调用模式                 | 直接传字符串，一般为JSON               | 通过Cypher语句中的变量  |  
在TuGraph中，存储过程v1和v2单独管理，支持增删查，但仍不建议重名。' metadata={'Header 1': 'Procedure API', 'Header 2': '2.存储过程的版本支持'}"
TuGraph-Restful-Server 使用哪种框架支持其HTTP协议，并提供了哪些主要功能？,"page_content='TuGraph-Restful-Server

1.TuGraph-Restful-Server 简介

TuGraph Restful Server 使用brpc框架支持的http协议，提供restful接口查询功能，在实现中，restful server 与rpc server 使用同一个端口。目前restful接口提供文件上传，数据导入，导入进度查询，cypher查询，文件删除等功能' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '1.TuGraph-Restful-Server 简介'}","page_content='RESTful API Legacy

1.简介

TuGraph 提供遵从 REST 规范的 HTTP API，以供开发者通过 HTTP 请求远程调用 TuGraph 提供的服务。  
本文档描述 TuGraph 的 HTTP API 使用方式。  
**注意：除""登陆""、""查询""和""存储过程""外，其余接口自 **2023年4月30日** 起将不再提供支持，统一使用Cypher接口提供服务。**' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '1.简介'}","page_content='试用体验：TuGraph — 简单高效的图数据库

支持RESTful API

除了支持Cypher查询语言，TuGraph还提供了RESTful API接口。这使得我可以通过编程方式与图数据库进行交互，更好地将TuGraph集成到我的应用程序中。API设计合理，易于使用，为我提供了灵活性和自由度。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持RESTful API'}"
禁用角色后，具有该角色的用户会如何受影响？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='用户权限

4.常用权限操作

4.2.角色操作

- 创建角色  
```cypher
CALL dbms.security.createRole(role_name::STRING,desc::STRING)
```  
- 删除角色  
```cypher
CALL dbms.security.deleteRole(role_name::STRING
```  
- 列出所有角色  
```cypher
CALL dbms.security.listRoles()
```  
- 禁用/启用角色  
```cypher
CALL dbms.security.disableRole(role::STRING,disable::BOOLEAN)
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.2.角色操作'}","page_content='RESTful API Legacy

6.Deprecated

6.1.用户管理

系统默认创建一个管理员，管理员用户名为 _admin_，密码为 _73@TuGraph_。为了安全起见，请用户在第一次启动服务器后更改密码。  
#### 6.1.1.添加用户  
添加一个新的用户，并为其设置初始密码。只有管理员有权限进行此操作。其中用户名只能由字母，数字以及下划线构成，密码则可以包含任意字符。用户名和密码长度不能超过 64 字节。添加用户时还可以为用户增加一个描述，用户描述可以包含任意字符，最长不超过 512 字节。  
新用户默认拥有同名的角色，不具备任何图的权限。  
- **URI**: `/user`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |
| description | 用户描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""user"": ""USER1"",
""password"": ""AN_INITIAL_PASSWORD"",
""description"": ""This is a user""
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.1.2.列出所有用户  
列出数据库的所有用户。只有管理员拥有该操作权限。  
- **URI**: `/user/`
- **METHOD**: GET
- **RESPONSE**: 所有用户及其信息。  
**Example request.**  
```
• GET http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
Output:
{
""admin"": {
""disabled"": false,
""description"": ""Builtin admin user"",
""roles"": [""admin""]
},
""guest1"": {
""disabled"": true,
""description"": """",
""roles"": [""guest1"", ""some_other_role""]
}
}
```  
#### 6.1.3.获取用户信息  
列出给定用户的信息。  
- **URI**: `/user/{user_name}`
- **METHOD**: GET
- **RESPONSE**: 用户信息。  
**Example request.**  
```
• GET http://localhost:7070/user/guest1
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.1.用户管理'}"
如果您作为公司员工提交贡献内容，应如何保证合法授权？,"page_content='如何贡献

3. 准备工作

3.3. 许可协议

在贡献代码之前，请您稍微花一些时间了解为TuGraph贡献代码的流程，并阅读 [个人贡献者许可协议](3.individual-cla.md) 或 [公司贡献者许可协议](4.corporate-cla.md)，参与贡献则视为同意上述协议。' metadata={'Header 1': '如何贡献', 'Header 2': '3. 准备工作', 'Header 3': '3.3. 许可协议'}","page_content='如何贡献

2. 贡献什么

我们随时都欢迎任何贡献，无论是简单的错别字修正，BUG 修复还是增加新功能。请踊跃提出问题或发起 PR。我们同样重视文档以及与其它开源项目的整合，欢迎在这方面做出贡献。
对于任何修改，尤其是较为复杂的修改，建议新建一个issue ，按照BUG或者PR的模板填写。' metadata={'Header 1': '如何贡献', 'Header 2': '2. 贡献什么'}","page_content='如何贡献

4. 贡献代码流程

4.5. 配置 Github 信息

在您的机器执行 git config  --list ，查看 git 的全局用户名和邮箱。检查显示的 user.name 和 user.email 是不是与自己 github 的用户名和邮箱相匹配。  
如果公司内部有自己的 gitlab 或者使用了其他商业化的 gitlab，则可能会出现不匹配的情况。这时候，您需要为 TuGraph DB 项目单独设置用户名和邮箱。设置用户名和邮箱的方式请参考 github 官方文档。' metadata={'Header 1': '如何贡献', 'Header 2': '4. 贡献代码流程', 'Header 3': '4.5. 配置 Github 信息'}"
如何只清空数据，而保留schema？,"page_content='业务开发指南

子图操作

清空子图

#### 删除所有的点边数据和图schema
```
CALL db.dropDB()
```
#### 只删除所有点边数据, 保留图schema
```
CALL db.dropAllVertex()
```' metadata={'Header 1': '业务开发指南', 'Header 2': '子图操作', 'Header 3': '清空子图'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.4 通过OGM进行删操作**

**DELETE**  
使用session.delete方法删除节点，同时会删除与节点相关联的所有边。  
```java
session.delete(alice); // 删除alice节点以及相连的边

Movie m = session. load(Movie.class, jokes.getId); // EjokesTaMidsiXjokes# 点

session.delete(m);

// 清空数据库

session.deleteAll(Movie.class);

session.purgeDatabase ();

1/ 删除所有Movie节点

// 删除全部数据
```' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.4 通过OGM进行删操作**'}","page_content='RESTful API Legacy

5.存储过程

5.5.删除存储过程

- **URI**: `/db/{graph_name}/cpp_plugin|python_plugin/{plugin_name}`
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• DELETE http://localhost:7070/db/graph1/cpp_plugin/example_plugin
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程', 'Header 3': '5.5.删除存储过程'}"
OGM在哪些方面类似于MyBatis？,"page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.6 通过OGM进行查操作**

**MATCH**  
session.load方法用于根据节点id查找节点。 session.loadALL方法用于批量查找节点，支持通过多个节点id查找节点、查找某一类型的所有节点、带有filter的查询。 filter查询需要新建Filter，传入参数ComparisonOperatorx0;可选为：EQUALSx0;、GREATER\_THANx0;、LESS\_THAN  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*J3Z1TrA0BncAAAAAAAAAAAAADgOBAQ/original)  
**QUERY WITH CYPHER**  
OGM支持通过queryForObject、query方法向TuGraph发送Cypher查询，由于Cypher查询的灵活性，需要用户自行指定返回结果格式。  
session.queryForObject方法：需要在方法第一个参数处指定返回类型，可设定为某一实体类或数字类型。  
session.query方法：Cypher查询的返回结果被存储为Result类型，其内部数据需要用户自行解析，以下方代码为例，传入数据库的Cypher为CREATE查询，返回结果createResult可被解析为QueryStatistics，可获取到此次查询被创建的节点与边的数目。  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*lkxXS660eEgAAAAAAAAAAAAADgOBAQ/original)' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.6 通过OGM进行查操作**'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

简介

TuGraph 图数据库提供了 JAVA、C++、Python 等多种语言的 SDK 支持，方便客户在各种场景下使用。用户使用 SDK 向TuGraph服务器发送Cypher请求，服务器则以 JSON形式返回数据。近日，TuGraph 推出了一款面向 JAVA 客户端用户的开发工具 TuGraph-OGM (Object Graph Mapping)，为用户提供了对象操作接口，相较 Cypher/JSON 接口应用起来更加便捷。  
OGM 类似于关系数据库中的 ORM（Object Relational Model），可以将数据库返回的数据自动映射成 JAVA 中的对象，方便用户读取，而用户对这些对象的更新操作也可以被自动翻译成 Cypher 语句发送给服务器。这样即便是完全不懂 Cypher 的用户，也可以通过操作对象与数据库进行交互，大大降低了图数据库的使用门槛。  
TuGraph-OGM 同时也兼容其他开源产品 OGM 工具如 Neo4j-OGM，方便用户将工程在不同数据库与 TuGraph数据库间无缝迁移。本文将对 TuGraph-OGM 进行全面的介绍。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '简介'}","page_content='TuGraph-OGM

简介

TuGraph-OGM(Object Graph Mapping), 源自 `Neo4j-OGM` 项目，TuGraph-OGM
支持将JAVA对象（POJO）映射到TuGraph中，JAVA中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此JAVA开发人员可以在熟悉的生态中轻松地使用TuGraph数据库。同时TuGraph-OGM兼容Neo4j-OGM，Neo4j生态用户可以无缝迁移到TuGraph数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '简介'}"
BROWSER 有 docker 部署么？,"page_content='Docker部署

2.现有Docker Image

2.5. 运行服务

1. 拉取镜像
```shell
docker pull tugraph/tugraph-runtime-centos7:${VERSION}
```  
2. 启动docker  
```shell
docker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_demo ${REPOSITORY}:${VERSION}

# ${REPOSITORY}是镜像地址，${VERSION}是版本号。
# 7070是默认的http端口，访问tugraph-db-browser使用。
# 7687是bolt端口，bolt client访问使用。
# 9090是默认的rpc端口，rpc client访问使用。
# /var/lib/lgraph/data是容器内的默认数据目录，/var/log/lgraph_log是容器内的默认日志目录
# 命令将数据目录和日志目录挂载到了宿主机的/root/tugraph/上进行持久化，您可以根据实际情况修改。
```' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.5. 运行服务'}","page_content='Docker部署

2.现有Docker Image

2.1.镜像下载方式

镜像托管在[DockerHub]( https://hub.docker.com/u/tugraph )，可直接下载使用。  
最新版本的Docker地址参见 [文档地图](../../1.guide.md)的""TuGraph最新版本""章节。' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.1.镜像下载方式'}","page_content='Docker部署

2.现有Docker Image

2.3.常见Docker操作

Docker由Dockerfile生成，注意创建镜像需要下载依赖，因此网络问题可能会导致创建较慢或者创建失败。注意不要覆盖镜像，除非tag为 `latest`。  
创建Compile镜像
```bash
docker build -f tugraph-compile-centos7-Dockerfile -t tugraph/tugraph-compile-centos7:1.2.0 .
```  
创建Runtime / Mini Runtine镜像
```bash
docker build --build-arg FILEPATH=""${rpm_path_in_oss}"" --build-arg FILENAME=""${rpm_name}"" -f tugraph-compile-centos7-Dockerfile -t tugraph/tugraph-runtime-centos7:1.2.0 .
```  
修改镜像名称
```bash
docker tag ${image_name}:${image_tag} tugraph/tugraph-runtime-centos7:3.3.0
```  
上传镜像
```bash
docker push tugraph/tugraph-compile-centos7:1.2.0 .
```  
获取镜像
```bash
docker pull tugraph/tugraph-compile-centos7:1.2.0
```  
导出镜像
```bash
docker save ${image_name}:${image_tag} | gzip > lgraph_latest.tar.gz
```  
导入镜像
```bash
docker load --input lgraph_latest.tar.gz
```  
其他Docker操作请参考[docker官方文档](https://docs.docker.com/engine/reference/commandline/cli )' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.3.常见Docker操作'}"
TuGraph-DB是否有数据导入工具？相关代码在哪里？,"page_content='功能概览

6.生态工具

6.1.TuGraph DataX

![导入导出](../../../images/tugraph-datax.png)  
TuGraph 核心支持 CSV 和 JSON 合适的导入导出，提供空库导入和增量导入的模式。实际中会存在 MySQL、Kafka、Hive 等多数据源导入的需求，TuGraph 通过 DataX 做多数据源的对接。由于关系模型和图模型存在的差异，数据清洗的流程可以使用 SparkSQL 快速处理，TuGraph 本身仅关注 CSV 和 JSON 的简单场景导入可靠性和性能。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.1.TuGraph DataX'}","page_content='数据导入

1.简介

在图数据库服务安装成功后，您可以使用`lgraph_import`批量导入工具将现有数据导入 TuGraph。`lgraph_import`支持从 CSV 文件和 JSON 数据源导入数据。  
> CSV 格式  
```
[movies.csv]
id, name, year, rating
tt0188766,King of Comedy,1999,7.3
tt0286112,Shaolin Soccer,2001,7.3
tt4701660,The Mermaid,2016,6.3
```  
> jsonline 格式  
```json
[""tt0188766"",""King of Comedy"",1999,7.3]
[""tt0286112"",""Shaolin Soccer"",2001,7.3]
[""tt4701660"",""The Mermaid"",2016,6.3]
```  
TuGraph 支持两种导入模式：  
- _离线模式_：读取数据并将其导入指定服务器的数据文件，应仅在服务器离线时完成。
- _在线模式_：读取数据并将其发送到工作中的服务器，然后将数据导入其数据库。' metadata={'Header 1': '数据导入', 'Header 2': '1.简介'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}"
图数据库相比关系型数据库有哪些独特的优势？,"page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.1. 性能

在关联关系处理上，使用关系型数据库不可避免地要使用表的JOIN操作，这会对性能产生较大影响；而图数据库则直接跳转访问类指针，操作关联数据的效率更高，比关系型数据库提高2到4个数量级的性能。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.1. 性能'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

图数据库的功能是传统关系型数据库的扩展。与关系型数据库仅支持的“表结构”相比，图数据库所支持的“图结构”更为灵活。图数据库在基于图的增加、删除、查询和修改方面采用不同于其他数据库的设计。在图数据操作抽象上，采用基于点的视角，例如点通过其所有“出边”（从一个点出发，连接到其他点的边）访问其邻接点。这是图数据库系统设计的核心。  
图数据库的独特性体现在以下三个方面:' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势'}","page_content='什么是图数据库

2. 图数据库相比较于关系型数据库的优势

2.3. 直观性

使用图的方式表达现实世界的关系更直接和自然，在万物互联的时代尤为突出。如果使用关系型数据，先建立实体表，再建立关系表，最后映射数据，需要高度的抽象思维。在图数据上进行分析查询时，可以直观地通过点边连接的拓扑结构找到所需数据，无需任何专业知识。' metadata={'Header 1': '什么是图数据库', 'Header 2': '2. 图数据库相比较于关系型数据库的优势', 'Header 3': '2.3. 直观性'}"
TuGraph 产品架构中，客户端 SDK 支持哪些编程语言？,"page_content='Bolt客户端

客户端示例

在代码目录中的demo/Bolt下面有Golang、Java、JavaScript、Python、Rust 这几个语言的的例子。想要了解更多可见[客户端示例](https://github.com/TuGraph-family/tugraph-db/tree/master/demo)' metadata={'Header 1': 'Bolt客户端', 'Header 2': '客户端示例'}","page_content='功能概览

5.客户端工具

客户端主要分为各种编程语言的SDK，OGM以及命令行工具。  
客户端 SDK 主要用于二次开发，可以通过 RPC 或 REST 协议链接服务端。RPC 基于长链接有较好的性能，数据需要通过 protobuf 统一序列化。TuGraph 使用brpc，支持 Java、Python、C++ 的 rpc 客户端。REST 的协议比较宽泛，能够简单适配更加多样的环境，不同的编程语言能够简单对接。TuGraph 给出了 Python 的REST 客户端实例，命令行的交互也是用 REST 实现。  
OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。  
命令行工具`lgraph_cypher`是查询客户端，可用于向 TuGraph 服务器提交 OpenCypher 请求。`lgraph_cypher`客户端有两种执行模式：单命令模式和交互式模式。' metadata={'Header 1': '功能概览', 'Header 2': '5.客户端工具'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

简介

TuGraph 图数据库提供了 JAVA、C++、Python 等多种语言的 SDK 支持，方便客户在各种场景下使用。用户使用 SDK 向TuGraph服务器发送Cypher请求，服务器则以 JSON形式返回数据。近日，TuGraph 推出了一款面向 JAVA 客户端用户的开发工具 TuGraph-OGM (Object Graph Mapping)，为用户提供了对象操作接口，相较 Cypher/JSON 接口应用起来更加便捷。  
OGM 类似于关系数据库中的 ORM（Object Relational Model），可以将数据库返回的数据自动映射成 JAVA 中的对象，方便用户读取，而用户对这些对象的更新操作也可以被自动翻译成 Cypher 语句发送给服务器。这样即便是完全不懂 Cypher 的用户，也可以通过操作对象与数据库进行交互，大大降低了图数据库的使用门槛。  
TuGraph-OGM 同时也兼容其他开源产品 OGM 工具如 Neo4j-OGM，方便用户将工程在不同数据库与 TuGraph数据库间无缝迁移。本文将对 TuGraph-OGM 进行全面的介绍。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '简介'}"
OGC定义了哪些空间数据的标准表示格式？,"page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的实现

OGC(Open Geospatial Consortium) 定义了空间数据的标准表示格式，分别为EWKT(extended well known text)与EWKB(extended well known binary)格式，用于在不同系统和平台之间交换和存储空间数据，现已被广泛采用。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的实现'}","page_content='地理空间数据类型使用示例

2. 预备知识

2.3 数据存储格式

OGC(Open Geospatial Consortium) 定义了空间数据的标准表示格式，分别为WKT与WKB格式，用于在不同系统和平台之间交换和存储空间数据，现已被广泛采用。其中WKT(well-kown text)格式, 是一种文本标记语言,易于人类阅读和编写，而WKB(Well-Known Binary)格式采用一系列字节来编码空间数据，更适合在计算机中存储;  
**WKT:**  
```
POINT(<x> <y>)
LINESTRING(<x1> <y1>, <x2><y2>, ...)
```  
WKT格式的数据如上例所示，先指定空间数据类型，再在括号内指定具体的坐标，一个坐标对表示一个点，每个坐标对之间用逗号隔开。对于Polygon类型的数据，第一个坐标对需要与最后一个坐标对相同，形成闭合的面。  
**WKB:**  
![image.png](../../../images/spatail/WKB.png)  
针对EWKB格式的编码，说明如下:  
- 第0 - 1位: 编码方式;
- 第2 - 5位: 空间数据类型;
- 0100: point
- 0200: linestring
- 0300: polygon
- 第6 - 9位: 数据维度;
- 0020: 二维
- 0030: 三维
- 第10 - 17位: 坐标系的EPSG编码;
- 第18 - n位: double类型的坐标对的16进制表示。' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '2. 预备知识', 'Header 3': '2.3 数据存储格式'}","page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的表示

空间数据类型可以用不同的坐标系来表示，EPSG<sup>[1]</sup>是一个标准化的地理空间参考系统标识符集合， 用于标识不同的地理空间参考系统，包括坐标系统、地理坐标系、投影坐标系等。通常使用EPSG编码表示数据的坐标系。行业内一般采用  
-   •WGS84坐标系（没错，就是GPS系统的坐标系），标识符为EPSG 4326  
-   •Cartesian（笛卡尔）坐标系（没错，就是你高中数学学的直角坐标系），标识符为EPSG 7203  
WGS84是全球定位系统(GPS)的基础，允许全球的GPS接收器确定精确位置。几乎所有现代GPS设备都是基于WGS84坐标系来提供位置信息。在地图制作和GIS（地图制作和地理信息系统）领域，WGS84被广泛用于定义地球上的位置。这包括各种类型的地图创建、空间数据分析和管理等。  
Cartesian（笛卡尔）坐标系，又称直角坐标系，是一种最基本、最广泛应用的坐标系统。它通过两条数轴定义一个平面，三条数轴定义一个空间，这些轴互相垂直，在数学、物理、工程、天文和许多其他领域中有着广泛的应用。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的表示'}"
db.importor.dataImportor函数的目的是什么？,"page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}","page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

#### 2.3.1.rest  
样例代码中在test_get_info函数执行之前先启动server，server启动后启动了rest client，进入test_get_info函数后获取server的一些信息，并通过assert判断是否有获取到cpu的信息。  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7073 --rpc_port 9093"",
""cleanup_dir"":[""./testdb""]}
RESTTOPT = {""port"":""7073"", ""user"":""admin"", ""password"":""73@TuGraph""}
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""rest"", [RESTTOPT], indirect=True)
def test_get_info(self, server, rest):
res = rest.get_server_info()
log.info(""res : %s"", res)
assert('cpu' in res)
```  
#### 2.3.2.client  
样例代码中在test_flushdb函数执行之前先执行了数据离线导入逻辑，并启动server后，通过client创建链接，进入test_flushdb函数后，通过查询点的个数判断导入是否成功，导入成功后执行flushDB操作，再次通过assert判断是否能正常清空db  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}

CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}

IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}

@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_flushdb(self, importor, server, client):
ret = client.callCypher(""MATCH (n) RETURN n LIMIT 100"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert len(res) == 21
ret = client.callCypher(""CALL db.flushDB()"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```pytho' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}","page_content='Sampling API

3. 图采样算子介绍

3.5.GetDB算子：

从数据库中获取图数据并转换成所需数据结构。
```python
Process(db_: lgraph_db_python.PyGraphDB, olapondb:lgraph_db_python.PyOlapOnDB, feature_num: size_t, NodeInfo: list, EdgeInfo: list)
```
参数列表：
db_: 图数据库实例。
olapondb: 图分析类。
feature_num: size_t类型，feature特征向量的长度。
NodeInfo: list类型，一个点属性字典的列表，表示点的元数据信息。
EdgeInfo: list类型，一个边属性字典的列表，表示边的元数据信息。
返回值: 无。' metadata={'Header 1': 'Sampling API', 'Header 2': '3. 图采样算子介绍', 'Header 3': '3.5.GetDB算子：'}"
TuGraph企业版是什么？,"page_content='什么是TuGraph

4. TuGraph企业版

企业版对商业化功能支持更加完善，包括分布式集群架构，覆盖探索、研发、服务、运维管理全生命周期的一站式图平台，在线、近线、离线的图计算引擎，支持流式、大数据类数据源，多地多中心的部署形态，以及专家支持服务等。企业版是商业化解决方案的理想选择。  
如需商业支持，请联系我们：  
- 电话：400-903-0809
- 邮件：tugraph@service.alipay.com
- 官网：https://tugraph.antgroup.com' metadata={'Header 1': '什么是TuGraph', 'Header 2': '4. TuGraph企业版'}","page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}"
请求存储过程列表时，应该使用哪种HTTP方法和URI？,"page_content='RESTful API Legacy

5.存储过程

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/cpp_plugin|python_plugin
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程'}","page_content='Procedure API

4.2.如何使用存储过程

4.2.2.列出已加载的存储过程

在服务器运行过程中，用户可以随时获取存储过程列表。其调用如下：  
```python
>>> r = requests.get('http://127.0.0.1:7071/db/school/cpp_plugin')
>>> r.status_code
200
>>> r.text
'{""plugins"":[{""description"":""Custom Page Rank Procedure"", ""name"":""age_10"", ""read_only"":true}]}'
```' metadata={'Header 1': 'Procedure API', 'Header 2': '4.2.如何使用存储过程', 'Header 3': '4.2.2.列出已加载的存储过程'}","page_content='RESTful API Legacy

5.存储过程

5.4.调用存储过程

- **URI**: `/db/{graph_name}/cpp_plugin|python_plugin/{plugin_name}`
- **METHOD**: POST
- **REQUEST**: 字符串输入
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| data | 输入数据 | 字符串 |
| timeout | 超时长度（秒，可选，缺省值为 0） | 浮点 |
| in_process | 是否在本进程调用（可选，缺省值为 false） | 布尔值 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| result | 运行结果 | 字符串 |  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/python_plugin/echo
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
data : ""Hello!\n你好！\nKonichiwa!"",
timeout : 0,
in_process : true
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""result"": ""Hello!\n你好！\nKonichiwa!""
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '5.存储过程', 'Header 3': '5.4.调用存储过程'}"
TuGraph基础算法包包含哪些算法？,"page_content='内置算法

简介

TuGraph目前包含以下6个基础算法28种扩展算法，共34个图算法：' metadata={'Header 1': '内置算法', 'Header 2': '简介'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。  
<table><tbody><tr><td>算法类型</td><td>中文算法名</td><td>英文算法名</td><td>程序名</td></tr><tr><td rowspan=""5"">路径查询</td><td>广度优先搜索</td><td>Breadth-First Search</td><td>bfs</td></tr><tr><td>单源最短路径</td><td>Single-Source Shortest Path</td><td>sssp</td></tr><tr><td>全对最短路径</td><td>All-Pair Shortest Path</td><td>apsp</td></tr><tr><td>多源最短路径</td><td>Multiple-source Shortest Paths</td><td>mssp</td></tr><tr><td>两点间最短路径</td><td>Single-Pair Shortest Path</td><td>spsp</td></tr><tr><td rowspan=""9"">重要性分析</td><td>网页排序</td><td>Pagerank</td><td>pagerank</td></tr><tr><td>介数中心度</td><td>Betweenness Centrality</td><td>bc</td></tr><tr><td>置信度传播</td><td>Belief Propagation</td><td>bp</td></tr><tr><td>距离中心度</td><td>Closeness Centrality</td><td>clce</td></tr><tr><td>个性化网页排序</td><td>Personalized PageRank</td><td>ppr</td></tr><tr><td>带权重的网页排序</td><td>Weighted Pagerank Algorithm</td><td>wpagerank</td></tr><tr><td>信任指数排名</td><td>Trustrank</td><td>trustrank</td></tr><tr><td>sybil检测算法</td><td>Sybil Rank</td><td>sybilrank</td></tr><tr><td>超链接主题搜索</td><td>Hyperlink-Induced Topic Search</td><td>hits</td></tr><tr><td rowspan=""4"">关联性分析</td><td>平均集聚系数</td><td>Local Clustering Coefficient</td><td>lcc</td></tr><tr><td>共同邻居</td><td>Common Neighborhood</td><td>cn</td></tr><tr><td>度数关联度</td><td>Degree Correlation</td><td>dc</td></tr><tr><td>杰卡德系数</td><td>Jaccard Index</td><td>ji</td></tr><tr><td rowspan=""5"">图结构</td><td>直径估计</td><' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}"
REST 服务器的默认端口号是多少？,"page_content='RESTful API Legacy

3.登录

3.1.登录

用户通过用户名和密码发送登录请求。登录成功会收到带有签名的令牌(Json Web Token)和判断是否为默认密码的布尔型变量，客户端储存该令牌，并且用于以后的每次发送请求。如果登录失败会收到“Authentication failed”错误。  
- **URI**: `/login`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| jwt | 令牌 | 字符串 |
| default_password | 是否为默认密码 | 布尔值 |  
**Example request.**  
```
• POST http://localhost:7070/login
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""user"":""admin"",
""password"":""73@TuGraph""
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""jwt"": ""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek"",
""default_password"": true
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '3.登录', 'Header 3': '3.1.登录'}","page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='RESTful API Legacy

6.Deprecated

6.9.索引

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/index/{label}/{field}
```  
提供索引操作，接受 GET/POST 请求。  
#### 6.9.1.创建索引  
该操作会启动一个创建索引的后台任务，用户可以通过列出该 Label 相关的所有索引来检查新建索引的状态。  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: POST
- **REQUEST**:  
| 域名    | 说明     | 类型                                  |
|-------|--------|-------------------------------------|
| label | Label 名 | 字符串                                 |
| field | 域名     | 字符串                                 |
| type  | 索引类型   | int类型，0表示非唯一索引，1表示全局唯一索引，2表示两点间唯一索引 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"": ""Person"",
""field"": ""birthyear"",
""is_unique"" : false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.9.2.列出所有索引  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""field"": ""name"",
""label"": ""City"",
""is_unique"": false
},
{
""field"": ""title"",
""label"": ""Film"",
""is_unique"": false
},
{
""field"": ""name"",
""label"": ""Person"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
#### 6.9.3.列出所有与某个 Label 相关的索引  
- **URI**: `/db/{graph_name}/index/{label}`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index/Person
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""label"": ""Person"",
""field"": ""name"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
##' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.9.索引'}"
如果需要对一个角色进行禁用，调用何种函数，并且该函数在何种情况下返回true？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='用户权限

4.常用权限操作

4.2.角色操作

- 创建角色  
```cypher
CALL dbms.security.createRole(role_name::STRING,desc::STRING)
```  
- 删除角色  
```cypher
CALL dbms.security.deleteRole(role_name::STRING
```  
- 列出所有角色  
```cypher
CALL dbms.security.listRoles()
```  
- 禁用/启用角色  
```cypher
CALL dbms.security.disableRole(role::STRING,disable::BOOLEAN)
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.2.角色操作'}","page_content='RESTful API Legacy

6.Deprecated

6.1.用户管理

系统默认创建一个管理员，管理员用户名为 _admin_，密码为 _73@TuGraph_。为了安全起见，请用户在第一次启动服务器后更改密码。  
#### 6.1.1.添加用户  
添加一个新的用户，并为其设置初始密码。只有管理员有权限进行此操作。其中用户名只能由字母，数字以及下划线构成，密码则可以包含任意字符。用户名和密码长度不能超过 64 字节。添加用户时还可以为用户增加一个描述，用户描述可以包含任意字符，最长不超过 512 字节。  
新用户默认拥有同名的角色，不具备任何图的权限。  
- **URI**: `/user`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |
| description | 用户描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""user"": ""USER1"",
""password"": ""AN_INITIAL_PASSWORD"",
""description"": ""This is a user""
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.1.2.列出所有用户  
列出数据库的所有用户。只有管理员拥有该操作权限。  
- **URI**: `/user/`
- **METHOD**: GET
- **RESPONSE**: 所有用户及其信息。  
**Example request.**  
```
• GET http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
Output:
{
""admin"": {
""disabled"": false,
""description"": ""Builtin admin user"",
""roles"": [""admin""]
},
""guest1"": {
""disabled"": true,
""description"": """",
""roles"": [""guest1"", ""some_other_role""]
}
}
```  
#### 6.1.3.获取用户信息  
列出给定用户的信息。  
- **URI**: `/user/{user_name}`
- **METHOD**: GET
- **RESPONSE**: 用户信息。  
**Example request.**  
```
• GET http://localhost:7070/user/guest1
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.1.用户管理'}"
TuGraph更新之后，原库的数据会丢吗？,"page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}","page_content='Procedure API

4.2.如何使用存储过程

4.2.6.更新存储过程

更新存储过程需要执行如下两个步骤：  
1.  删除已存在的存储过程
2.  安装新的存储过程  
TuGraph 较为谨慎地管理存储过程操作的并发性，更新存储过程不会影响现有存储过程的运行。' metadata={'Header 1': 'Procedure API', 'Header 2': '4.2.如何使用存储过程', 'Header 3': '4.2.6.更新存储过程'}","page_content='技术规划

2. 已完成功能

TuGraph-DB于2022年9月1日开源，TuGraph-DB在社区的反馈声中，进行日常BUG修复，自身能力得到了完善。  
| 版本号   | 功能                               | 时间         |
|-------|----------------------------------|------------|
| 3.3.0 | 开源初版                             | 2022.9.1   |
| 3.3.1 | 图分析引擎重构，多模式支持                    | 2022.10.14 |
| 3.3.2 | OGM支持，UT覆盖率提升                    | 2022.11.21 |
| 3.3.3 | 链接认证机制迭代，加入英文文档                  | 2022.12.23 |
| 3.3.4 | 支持上云，梳理LDBC SNB Audit流程          | 2023.1.28  |
| 3.4.0 | 支持OLAP Python API, 离线导入升级        | 2023.3.11  |
| 3.5.0 | 支持POG，前端升级，文档梳理                  | 2023.6.5   |
| 3.5.1 | 图学习引擎，Procedure Rust API，存储属性分离  | 2023.7.14  |
| 3.6.0 | 高可用开源，日志系统升级                     | 2023.8.11  |
| 4.0.0 | ISO GQL支持，新增11个开源图算法，支持m1 Docker | 2023.9.6   |
| 4.0.1 | 支持时序边排序，新增5个开源图算法                | 2023.9.28  |
| 4.1.0 | 支持Bolt协议，支持快速在线全量导入，支持地理空间数据类型   | 2023.12.25 |  
除此之外，TuGraph-DB搭建了较为完善的质量体系，涵盖自动化的单元测试、集成测试、性能测试等。  
更详细的描述可以在源码目录在的 ""[root]/release/CHANGELOG.md"" 文件查看。' metadata={'Header 1': '技术规划', 'Header 2': '2. 已完成功能'}"
"如果节点中未包含属性""belt""，应该返回什么值？","page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/node/{vid}
```  
Nodes 提供节点（Vertex）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。  
#### 6.7.1.列出点数量和label数量  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| num_label | 点 label 数量 | 整数 |
| num_vertex | 点数量 | 整数 |  
_注意 num_vertex 返回的并不是准确的点数量，只是一个估计值。_  
#### 6.7.2.创建一个点  
向数据库中插入一个点。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 点属性 | 字典，其中 key 是列名，value 是相应值。value 必须是与列类型相应的类型，如列为 int32，则 value 只能是整数。 |  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新点 vid。该 ID 可用于后续的点操作中。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""property"" : {
""name"" : ""Passerby A"",
""birthyear"" : 1989
}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
21
}
```  
#### 6.7.3.批量创建点  
TuGraph 允许一次性插入多个点，以减少网络开销。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| fields | 点属性 | 列表 |
| values | 点数据 | 列表 |  
其中 fields 是一个字符串列表，列出一系列列名；values 是一个列表，其中每个元素是一个列表，列表中每个元素是列数据。  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新增加的点的 vid 列表，该列表中每一个 vid 按顺序对应请求中的每一个点。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""fields"" : [""name"", ""birthyear""],
""values"" : [[""alex"", 2000],
[""bob"", 1999]]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
22,
23
]
}
```  
#### 6.7.4.获取点  
- **URI**: `/db/{graph_name}/node/{vertex_id}`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelAddFields(label_type, label_name, field_value_spec...)

Adds specified fields to the label.  
**Parameters:**  
| parameter    | parameter type | description           |
| ---------------- | -------------- | ------------------------- |
| label_type       | string     | either 'vertex' or 'edge' |
| label_name       | string     | name of the label     |
| field_value_spec | list       | specification of a field  |  
in which each `field_value_spec` is a list of string in the form of `[field_name, field_type, field_value, optional]`, where: `field_value` is the default value of the field.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelAddFields(
'vertex',
'new_label',
['birth_date', DATE, '', true],
['img', BLOB, '', true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelAddFields(label_type, label_name, field_value_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.deleteLabel(label_type, label_name)

Delete a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |  
**Output:**  
| field_name | field_type | description              |
| ---------- | ---------- | -------------------------------- |
| affected   | integer    | number of vertexes/edges deleted |  
**Example input:**  
```
CALL db.deleteLabel('vertex', 'Person')
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.deleteLabel(label_type, label_name)'}"
磁盘IO警报是在什么情况下触发的？,"page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='RESTful API Legacy

6.Deprecated

6.3.服务器状态

#### 6.3.1.修改服务器配置  
修改服务器配置，配置修改后立即生效，并将影响所有服务器。这些配置的优先级高于配置文件以及命令行参数。  
- **URI**: `/config`
- **METHOD**: PUT
- **REQUEST**:  
请求为一个字典，使用 `{""opt1"":v1}` 可以将名为`opt1`的配置修改为`v1`。  
| 配置名               | 说明                   | 值类型 |
| -------------------- | ---------------------- | ------ |
| OPT_DB_ASYNC         | 是否启用异步模式       | 布尔值 |
| OPT_TXN_OPTIMISTIC   | 是否默认使用乐观事务锁 | 布尔值 |
| OPT_AUDIT_LOG_ENABLE | 是否启用审计日志       | 布尔值 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• PUT http://localhost:7070/config
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""OPT_DB_ASYNC"": true,
""OPT_AUDIT_LOG_ENABLE"": false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.3.2.当前服务器状态  
- **URI**: `/info`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| lgraph_version | 服务器版本号 | 字符串 |
| git_branch | 服务器代码分支 | 字符串 |
| git_commit | 服务器代码版本 | 字符串 |
| web_commit | 前端码版本 | 字符串 |
| cpp_id | CPP 编译器 ID | 字符串 |
| cpp_version | CPP 编译器版本 | 字符串 |
| python_version | PYTHON 版本 | 字符串 |
| node | 点 uri | 字符串 |
| relationship | 边 uri | 字符串 |
| cpu | cpu 信息 | 字典，格式参见[服务器 CPU 状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8CPU%E7%8A%B6%E6%80%81) |
| disk | 硬盘 IO 信息 | 字典，格式参见[服务器硬盘状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E7%9B%98%E7%8A%B6%E6%80%81) |
| memory | 内存信息 | 字典，格式参见[服务器内存状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%86%85%E5%AD%98%E7%8A%B6%E6%80%81) |
| db_space | 图数据库占用空间 | 字典，格式参见[图数据库占用空间](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4) |
| db_config | 图数据库配置信息 | 字典，格式参见[图数据库配置信息](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF) |
| up_time | 数据库在线时长（秒） | 整型 |  
**Example request.**  
```
• GET http://localhost:7070/info
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""lgraph_version"": ""1.2.0"",
""git_branch"": ""master"",
""git_commit"": ""9e2977d"",' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.3.服务器状态'}","page_content='Python Olap API

6. 算法插件示例

下面为Python实现的BFS算法的代码示例：
```python
# cython: language_level=3, cpp_locals=True, boundscheck=False, wraparound=False, initializedcheck=False
# distutils: language = c++

# 注释作用如下：
# language_level=3: 使用Python3
# cpp_locals=True: 需要c++17，使用std::optional管理Python代码中的C++对象，可以避免C++对象的拷贝构造
# boundscheck=False: 关闭索引的边界检查
# wraparound=False: 关闭负数下标的处理（类似Python List）
# initializedcheck=False: 关闭检查内存是否初始化，关闭检查后运行性能更快
# language = c++: 将此py文件翻译为C++而不是C文件，TuGraph使用大量模板函数，所以都应该使用C++

import json

import cython
from cython.cimports.olap_base import *
from cython.cimports.lgraph_db import *
# 从procedures/algo_cython/ 中cimportolap_base.pxd与lgraph_db.pxd, 类似C++中#include ""xxx.h""

from cython.cimports.libc.stdio import printf
# 类似C++中#include <stdio.h>
# 其他常见的还有cython.cimports.libcpp.unordered_map等

import time


@cython.cclass
# cython.cclass 表示BFSCore为C类型的Class
class BFSCore:
graph: cython.pointer(OlapBase[Empty])
# cython.pointer(OlapBase[Empty])表示OlapBase[Empty]的指针，类似C++中OlapBase[Empty]*
# cython提供了常见类型的指针，如cython.p_int, cython.p_char等，表示int*, char*, ...
parent: ParallelVector[size_t]
active_in: ParallelBitset
active_out: ParallelBitset
root: size_t
# root: size_t 声明root为C++ size_t类型变量，等效于root = cython.declare(size_t)
# 不声明类型的变量为Python object类型
# 声明变量类型会大幅提高性能，同时在多线程部分，只有C/C++类型的变量可以访问

@cython.cfunc
# cython.cfunc 表示Work为C类型的函数，参数与返回值应声明
# cfunc性能好，能接受C/C++对象为参数、返回值，但是不能在其他python文件中调用
# 类似的有cython.ccall，如Standalone函数，可以在其他python文件中调用
@cython.nogil
# cython.nogil 表示释放Python全局解释锁，在nogil修饰的部分，不能访问Python对象
# 在多线程部分，都应有nogil修饰器
@cython.exceptval(check=False)
# cython.exceptval(check=False) 表示禁用异常传播，将忽略函数内部引发的Python异常
def Work(self, vi: size_t) -> size_t:
degree = cython.declare(size_t, self.graph.OutDegree(vi))
out_edges = cython.declare(AdjList[Empty], self.graph.OutEdges(vi))
i = cython.declare(size_t, 0)
local_num_activations = cython.declare(size_t, 0)
dst: size_t
for i in range(degree):
dst = out_edges[i].neighbour
if self.parent[dst] == cython.cast(size' metadata={'Header 1': 'Python Olap API', 'Header 2': '6. 算法插件示例'}"
调用 Close() 函数后 InEdgeIterator 的状态是怎样的？,"page_content='动态图

示例

```java
public class IncrGraphTraversalAll {

private static final Logger LOGGER =
LoggerFactory.getLogger(IncrGraphTraversalAll.class);

public static void main(String[] args) {
Environment environment = EnvironmentFactory.onLocalEnvironment();
Pipeline pipeline = PipelineFactory.buildPipeline(environment);
String graphName = ""graph_view_name"";
GraphViewDesc graphViewDesc = GraphViewBuilder.createGraphView(graphName)
.withShardNum(2)
.withBackend(BackendType.RocksDB)
.withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class, Integer.class, ValueEdge.class, IntegerType.class))
.build();
pipeline.withView(graphName, graphViewDesc);
pipeline.submit(new PipelineTask() {
@Override
public void execute(IPipelineTaskContext pipelineTaskCxt) {
PWindowSource<IVertex<Integer, Integer>> vertices =
pipelineTaskCxt.buildSource(new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IVertex<Integer, Integer> vertex1 = new ValueVertex<>(
Integer.valueOf(fields[0]), 1);
IVertex<Integer, Integer> vertex2 = new ValueVertex<>(
Integer.valueOf(fields[1]), 1);
return Arrays.asList(vertex1, vertex2);
}), SizeTumblingWindow.of(10000));

PWindowSource<IEdge<Integer, Integer>> edges =
pipelineTaskCxt.buildSource( new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IEdge<Integer, Integer> edge = new ValueEdge<>(Integer.valueOf(fields[0]),
Integer.valueOf(fields[1]), 1);
return Collections.singletonList(edge);
}), SizeTumblingWindow.of(5000));

PGraphView<Integer, Integer, Integer> fundGraphView =
pipelineTaskCxt.getGraphView(graphName);
PIncGraphView<Integer, Integer, Integer> incGraphView =
fundGraphView.appendGraph(vertices, edges);
incGraphView.incrementalTraversal(new IncGraphTraversalAlgorithms(3))
.start()
.sink(v -> {});
}
});
IPipelineResult result = pipeline.execute();
result.get();
}

public static class IncGraphTraversalAlgorithms extends IncVertexCentricTraversal<Integer,
' metadata={'Header 1': '动态图', 'Header 2': '示例'}","page_content='动态图

示例

```java
public class IncrGraphCompute {

private static final Logger LOGGER = LoggerFactory.getLogger(IncrGraphCompute.class);

public static void main(String[] args) {
Environment environment = EnvironmentFactory.onLocalEnvironment();
IPipelineResult result = submit(environment);
result.get();
environment.shutdown();
}

public static IPipelineResult<?> submit(Environment environment) {
final Pipeline pipeline = PipelineFactory.buildPipeline(environment);
final String graphName = ""graph_view_name"";
GraphViewDesc graphViewDesc = GraphViewBuilder.createGraphView(graphName)
.withShardNum(4)
.withBackend(BackendType.RocksDB)
.withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class, Integer.class, ValueEdge.class, IntegerType.class))
.build();
pipeline.withView(graphName, graphViewDesc);
pipeline.submit(new PipelineTask() {
@Override
public void execute(IPipelineTaskContext pipelineTaskCxt) {
Configuration conf = pipelineTaskCxt.getConfig();
PWindowSource<IVertex<Integer, Integer>> vertices =
// extract vertex from edge file
pipelineTaskCxt.buildSource(new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IVertex<Integer, Integer> vertex1 = new ValueVertex<>(
Integer.valueOf(fields[0]), 1);
IVertex<Integer, Integer> vertex2 = new ValueVertex<>(
Integer.valueOf(fields[1]), 1);
return Arrays.asList(vertex1, vertex2);
}), SizeTumblingWindow.of(10000));

PWindowSource<IEdge<Integer, Integer>> edges =
pipelineTaskCxt.buildSource( new RecoverableFileSource<>(""data/input/email_edge"",
line -> {
String[] fields = line.split("","");
IEdge<Integer, Integer> edge = new ValueEdge<>(Integer.valueOf(fields[0]),
Integer.valueOf(fields[1]), 1);
return Collections.singletonList(edge);
}), SizeTumblingWindow.of(5000));

PGraphView<Integer, Integer, Integer> fundGraphView = pipelineTaskCxt.getGraphView(graphName);

PIncGraphView<Integer, Integer, Integer> incGraphView = fundGraphView.appendGraph(vertices, edges);
incGraphView.i' metadata={'Header 1': '动态图', 'Header 2': '示例'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends Gra' metadata={'Header 1': '动态图', 'Header 2': '接口'}"
DUAL_DIRECTION表示什么？,"page_content='内置算法

扩展算法包

两点间最短路径

两点间最短路径程序实现了Bidirectional Breadth-First Search算法，在有向无权图上从起点沿着出边做正向宽度优先搜搜，从终点沿着入边做反向宽度优先搜索，通过起点和终点共同遍历到的点来确定从起点到终点的最短路径长度。算法内容请参考[https://en.wikipedia.org/wiki/Bidirectional_search](https://en.wikipedia.org/wiki/Bidirectional_search ""Bidirectional search"")。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': '两点间最短路径'}","page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}","page_content='DSL原理介绍

两级DAG物理执行计划

和传统的分布式表数据处理引擎Storm、Flink和Spark的系统不同，GeaFlow是一个流图一体的分布式计算系统。其物理执行计划采用图表两级DAG结构，如下图所示：
![DSl DAG结构](../../static/img/dsl_twice_level_dag.png)
外层DAG包含表处理相关的算子以及图处理的迭代算子，为物理执行逻辑的主体部分，将图表的计算逻辑链接起来。内层DAG则将图计算的逻辑通过DAG方式展开，代表了图迭代计算具体执行方式.' metadata={'Header 1': 'DSL原理介绍', 'Header 2': '两级DAG物理执行计划'}"
当指定的顶点ID不存在，并且nearest参数为true时，Goto函数将如何处理？,"page_content='RESTful API

2.请求与响应格式

2.2请求类型

#### 2.2.1. 用户登陆
用户在登陆请求中携带用户名和密码发送到服务端。登录成功会收到带有签名的令牌(Json Web Token)和判断是否为默认密码的布尔型变量，客户端储存该令牌，在后续的请求中将令牌加入请求头的Authorization域中。如果登录失败会收到“Authentication failed”错误。  
- **URI**:     /login
- **METHOD**:  POST
- **REQUEST**:  
| body参数  | 参数说明 | 参数类型  | 是否必填       |
| ------- |------|-------|------------|
| userName   | 用户名  | 字符串类型   | 是          |
| password   | 用户密码 | 字符串类型 | 是          |  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data中包含令牌  
| body参数  | 参数说明 | 参数类型  | 是否必填       |
| ------- |------|-------|------------|
| authorization   | 令牌  | 字符串类型   | 是          |
| default_password  | 默认密码 | 布尔类型 | 是          |  
**Example request.**  
```
{""userName"" : ""test"", ""password"" : ""123456""}
```  
#### 2.2.2. 用户登出
用户登出，同时删除已经认证的token，用户后续发送请求时，需要重新登陆，并获取新的token。  
- **URI**:     /logout
- **METHOD**:  POST
- **REQUEST**:
http request header中携带调用login接口时返回的token，body中没有参数  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data为空  
#### 2.2.3. 身份刷新
已下发的token失效后，需要调用本接口重新认证。后端验证token合法性。token在初次登录后，1小时内有效，过期需要刷新  
- **URI**:     /refresh
- **METHOD**:  POST
- **REQUEST**:
http request header中携带调用login接口时返回的token，body中没有参数  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data中包含令牌  
| body参数  | 参数说明 | 参数类型  | 是否必填       |
| ------- |------|-------|------------|
| authorization   | 令牌  | 字符串类型   | 是          |  
#### 2.2.4. 调用cypher
用户对TuGraph的增删改查请求需要调用cypher接口，并通过标准的cypher查询语言发起  
- **URI**:     /cypher
- **METHOD**:  POST
- **REQUEST**:  
| body参数  | 参数说明     | 参数类型  | 是否必填       |
| ------- |----------|-------|------------|
| graph   | 查询的子图名称  | 字符串类型   | 是          |
| script   | cypher语句 | 字符串类型 | 是          |  
- **RESPONSE**:
如果成功，返回的响应信息中success为00，data中包含查询结果  
| body参数  | 参数说明 | 参数类型    | 是否必填       |
| ------- |------|---------|------------|
| result   | 查询结果 | json字符串 | 是          |  
**Example request.**  
```
{""script"" : ""Match (n) return n"", ""graph"" : ""default""}
```  
#### 2.2.5. 上传文件
接口用于将本地文件上传至TuGraph所在机器。可以上传文本文件，二进制文件，可以上传大文件，也可以上传小文件' metadata={'Header 1': 'RESTful API', 'Header 2': '2.请求与响应格式', 'Header 3': '2.2请求类型'}","page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}","page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}"
在BFS算法中，最终返回的结果是什么？,"page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

`bfs`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关定义、数据结构的初始化
2. 使用批处理函数对每个节点进行循环计算，每一轮找到与当前节点相邻的全部节点，并在该轮次终止时进行交换。
3. 直到找到全部节点，返回节点个数discovered_vertices。  
```C++
size_t BFSCore(Graph<Empty>& graph, size_t root_vid, ParallelVector<size_t>& parent){

size_t root = root_vid;
auto active_in = graph.AllocVertexSubset();   //分配数组，active_in用于存放上一循环阶段已找到的节点
active_in.Add(root);            //把跟节点加入数组中
auto active_out = graph.AllocVertexSubset();  //分配数组active_out用于存放当前循环阶段找到的节点
parent.Fill((size_t)-1);               //将parent数组中的节点赋值为-1，-1表示未被找到
parent[root] = root;
size_t num_activations = 1;       //表示当前循环阶段找到的节点个数
size_t discovered_vertices = 0;    //表示当前循环阶段找到节点的总个数

for (int ii = 0; num_activations != 0; ii++) {       //num_activations表示当前循环阶段找到的节点个数
printf(""activates(%d) <= %lu\n"", ii, num_activations);
discovered_vertices += num_activations;         //discovered_vertices表示当前循环阶段找到节点的总个数
active_out.Clear();
num_activations = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t num_activations = 0;
for (auto& edge : graph.OutEdges(vi)) {   //每一次循环从根节点出发，查找邻近的相邻节点，对其parent值改变，并num_activations+1操作
size_t dst = edge.neighbour;
if (parent[dst] == (size_t)-1) {
auto lock = graph.GuardVertexLock(dst);
if (parent[dst] == (size_t)-1) {
parent[dst] = vi;
num_activations += 1;
active_out.Add(dst);       //存放当前循环阶段找到的节点
}
}
}
return num_activations;
},
active_in);
active_in.Swap(active_out);
}
// 返回全部节点数
return discovered_vertices;
}
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}","page_content='OlapOnDisk API

2. 算法举例

在这里对BFS算法分块做解释，大体上分为主函数`main`、BFS算法流程`BFSCore`函数和配置类MyConfig。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例'}","page_content='内置算法

基础算法包

广度优先搜索

广度优先搜索实现了Breadth-first Search算法，从根点开始，沿着图的宽度遍历所有可访问点。返回结果为遍历点个数。算法内容请参考 [https://en.wikipedia.org/wiki/Breadth-first_search](https://en.wikipedia.org/wiki/Breadth-first_search ""bfs wiki"")。' metadata={'Header 1': '内置算法', 'Header 2': '基础算法包', 'Header 3': '广度优先搜索'}"
TuGraph“refresh_time”的默认设置是什么？,"page_content='功能概览

4.核心功能

4.5 数据预热

TuGraph 是基于磁盘的图数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.5 数据预热'}","page_content='数据预热

1.简介

TuGraph 是基于磁盘的数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '数据预热', 'Header 2': '1.简介'}","page_content='可视化操作手册（旧版）

操作详情

3.工作台

#### 3.1 快速上手  
- 首次登录，系统会默认创建 default 空图  
![alt 快速上手](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/2.tugraph-browser-quickstart-01.png)  
- 用户点击帮助选项，并选择快速上手  
![alt 帮助](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/3.tugraph-browser-quickstart-02.png)  
- 然后点击“一键创建模型”——>""一键创建数据""，就可以完成内置的 Movie 数据图谱的构建  
#### 3.2 创建子图和示例  
##### 3.2.1 创建子图  
- 点击新建子图
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/4.tugraph-browser-create-subgraph-01.png)
- 填写表单信息
![alt 填写表单](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/5.tugraph-browser-create-subgraph-02.png)
- 子图名称
- 子图描述
- 配置信息
- 点击确认，提示创建成功
- 切换子图
![alt 切换子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/6.tugraph-browser-use-graph-01.png)  
- 点击新建示例
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/create-scene-01.png)
- 选择示例并点击创建
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/select-scene.png)  
#### 3.3 查询  
![alt 查询](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/7.tugraph-browser-query-01.png)  
##### 3.3.1 页面组成  
- cypher 输入框
- 结果集展示区域  
##### 3.3.2 结果集展示区域功能详情  
- 结果集标签展示及功能
![alt 结果集标签](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/tugraph-browser-result.png)
- 这里展示了结果集的所有类型统计
- 点击不同的“label（标签）”，可以进行以下修改操作
- 修改展示颜色
- 修改节点大小或边的粗细
- 修改默认展示属性或系统属性
- 布局修改
- 力导布局
- 网格布局
- 树形布局
- 环境布局
- 边聚合
- 相同类型，方向的边可以进行合并
- 创建节点
- 点击创建节点按钮
- 选择节点类型
- 添写节点内容
- 创建关系
- 在画布中选择起点和终点
- 选择可以匹配的类型
- 填写节点信息
- 停止布局
- 当数据量过大，导致浏览器页面卡顿时候，可以点击这个停止布局的按钮，能够提高体验的流畅度
- 鼠标悬停
- 开启此功能，可以高亮显示鼠标悬停节点的一度邻居节点
- 结果集导出
- 可以将结果集导出为 png，json，csv 三种不同的文件形式
- 刷新
- 点击刷新按钮，会重新执行当前页面的初始 cypher 语句，并刷新结果集
- 最大化
- 点击最大化，结果集展示区域将全屏展示
- 结果集展示形式切换
- 支持图谱、表格、文本三种形式  
###' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '3.工作台'}"
GetEdgeProp命令中，如果要查找特定的时间戳的边属性，该如何指定timestamp字段？,"page_content='业务开发指南

边类型操作

查看边类型schema

```
CALL db.getEdgeSchema('edge1')
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '查看边类型schema'}","page_content='图相关DDL

Create Graph

**Syntax**
一个图至少包含一对点边，点表必须包含一个id字段作为主键，边表必须包含srcId和targetId作为主键，边表还可以有一个时间戳字段标识时间。  
```
CREATE GRAPH <graph name>
(
<graph vertex>
[ { , <graph vertex> } ... ]
, <graph edge>
[ { , <graph edge> } ... ]
) WITH （
storeType = <graph store type>
[ { , <config key> = <config value> } ... ]
);

<graph vertex>  ::=
VERTEX <vertex name>
(
<column name> <data type> ID
[ {, <column name> <data type> } ... ]
)

<graph edge>  ::=
Edge <edge name>
(
<column name> <data type> SOURCE ID
, <column name> <data type> DESTINATION ID
[ , <column name> <data type> TIMESTAMP ]
[ {, <column name> <data type> } ... ]
)

```  
**Example**
```sql
CREATE GRAPH dy_modern (
Vertex person (
id bigint ID,
name varchar,
age int
),
Vertex software (
id bigint ID,
name varchar,
lang varchar
),
Edge knows (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
),
Edge created (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
)
) WITH (
storeType = 'rocksdb',
shardCount = 2
);
```
这个例子创建了一张包含2个点2个边的图，存储类型为rocksdb, 分片数2个。' metadata={'Header 1': '图相关DDL', 'Header 2': 'Create Graph'}","page_content='Python Olap API

4. Olap API

自定义数据结构

- `Empty`：内容为空的特殊数据类型。
- `EdgeUnit[EdgeData]`：表示权值类型为EdgeData的边，用于解析输入文件，包含三个成员变量：
- `src: size_t`：边的起始点
- `dst: size_t`：边的终点
- `edge_data: EdgeData`：边的权值
- `AdjUnit[EdgeData]`：表示权值类型为EdgeData的边，用于批处理计算过程中，包含两个成员变量：
- `neighbour: size_t`：边的邻居点
- `edge_data: EdgeData`：边的权值
- `AdjList[EdgeData]`：权值类型为EdgeData的点的邻接表，常用于表示点的入边和出边集合，包含两个成员变量：
- `begin()-> cython.pointer(AdjUnit[T])`：列表的起始指针
- `end()-> cython.pointer(AdjUnit[T])`：列表的结束指针。
- `operator[](i: size_t)-> AdjUnit[EdgeData]`: 下标为i的数据' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '自定义数据结构'}"
使用TuGraph Browser时，默认的端口号是多少？,"page_content='可视化操作手册

2.操作指南

2.1.访问

当用户完成图数据库的安装后，可以通过浏览器访问Browser。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7070。  
- 例如：127.0.0.1:7070。
- 推荐使用Chrome。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.1.访问'}","page_content='可视化操作手册（旧版）

操作详情

1.连接数据库

当用户完成图数据库的安装后，可以通过浏览器进行访问，TuGraph Browser 工具。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7090。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '1.连接数据库'}","page_content='可视化操作手册

2.操作指南

2.2.登录

![login](../../../images/browser/login.png)  
- 浏览器成功访问Browser后，首先进入的是登录页面（如上图所示），用户需要填写账号和密码进行登录。
- 数据库地址格式为：ip:bolt_port。
- 默认账号：admin。
- 默认密码：73@TuGraph。
- 用户首次登录后，会跳转至修改密码页面，密码修改成功后，使用新密码重新登录即可使用。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.2.登录'}"
TuGraph-DB是否支持运行图算法？是否有示例图算法可以参考？,"page_content='TuGraph Management

简介

TuGraph Management 是一款为TuGraph开发的算法任务管理工具。采用了sofastack与brpc作为通信框架，并使用sqlite进行持久化存储。  
主要功能：  
- 算法任务状态持久化存储  
- 算法任务结果持久化存储  
- 延时触发与定时触发算法任务支持' metadata={'Header 1': 'TuGraph Management', 'Header 2': '简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}","page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。  
蚂蚁集团 2015 年开始自主研发分布式图数据库、流式图计算等图相关技术，2016 年发布自研分布式图数据库，并应用于支付宝。至今 TuGraph 已应用于蚂蚁内部 150 多个场景，包括在线支付的实时链路，以支付宝风险识别能力提升近 10 倍、风险审理分析效率提升 90%的成绩，验证了其高可靠性。  
LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，TuGraph 在功能完整性、吞吐率、响应速度等层面全球领先。  
目前，蚂蚁集团已形成了一套以图数据库为底座、同时包含流式图计算，离线图学习的大规模图计算系统。  
蚂蚁集团图数据库负责人洪春涛表示，图技术是未来大数据、人工智能和高性能计算产业发展的关键所在，它很有可能会成为下一代的数据底座。蚂蚁集团愿意通过开源持续输出核心技术优势，推动图数据库更广泛的应用生态，携手行业抢占技术高地，不断探索技术的可能性。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}"
Python存储过程接口包含哪些重要组件和功能？,"page_content='Procedure API

4.1.编写存储过程

4.1.2.编写Python存储过程

与 C++类似，Python 存储过程也可以调用 core API，一个简单的例子如下：  
```python
def Process(db, input):
txn = db.CreateReadTxn()
it = txn.GetVertexIterator()
n = 0
while it.IsValid():
if it.GetLabel() == 'student' and it['age'] and it['age'] == 10:
n = n + 1
it.Next()
return (True, str(nv))
```  
Python 存储过程返回的是一个 tuple，其中第一个元素是一个布尔值，表示该存储过程是否成功执行；第二个元素是一个`str`，里面是需要返回的结果。  
Python 存储过程不需要编译，可以直接加载。' metadata={'Header 1': 'Procedure API', 'Header 2': '4.1.编写存储过程', 'Header 3': '4.1.2.编写Python存储过程'}","page_content='Python客户端

3.RPC Client

3.9.列举存储过程

```python
ret, res = client.listProcedures(""CPP"", ""any"", ""default"")
```
```
listProcedures(self: liblgraph_client_python.client, procedure_type: str, version: str, graph: str, url: str) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.9.列举存储过程'}","page_content='Python客户端

3.RPC Client

3.6.调用存储过程

```python
ret, res = client.callProcedure(""CPP"", ""test_plugin1"", ""bcefg"", 1000, False, ""default"")
```
```
callProcedure(self: liblgraph_client_python.client, procedure_type: str, procedure_name: str, param: str, procedure_time_out: float, in_process: bool, graph: str, json_format: bool, url: str) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.6.调用存储过程'}"
当执行 CallGql 函数时，如果操作成功和失败分别返回什么？,"page_content='C++客户端

2.使用示例

2.4.调用GQL

```C++
std::string str;
bool ret = client.CallGql(str,
""CALL db.createVertexLabel('actor', 'name', 'name', string, false, 'age', int8, true)"");
```
```
bool CallGql(std::string& result, const std::string& gql,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0, const std::string& url = """");
@param [out] result      The result.
@param [in]  gql         inquire statement.
@param [in]  graph       (Optional) the graph to query.
@param [in]  json_format (Optional) Returns the format， true is json，Otherwise, binary
format.
@param [in]  timeout     (Optional) Maximum execution time, overruns will be interrupted.
@param [in]  url         (Optional) Node address of calling gql.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.4.调用GQL'}","page_content='Geaflow支持以下逻辑运算：  
操作|描述
----------------------|------
boolean1 OR boolean2 | 如果boolean1为true或boolean2为true，则返回true。
boolean1 AND boolean2 | 仅在boolean1为true和boolean2为true时才返回true。
NOT boolean | 返回给定布尔变量的NOT操作的结果。
boolean IS FALSE | 如果布尔变量为false，则返回true。如果布尔变量是UNKNOWN，则返回false。
boolean IS NOT FALSE | 如果布尔变量为true，则返回true。如果布尔变量是UNKNOWN，则返回true。
boolean IS TRUE | 如果布尔变量为true，则返回true。如果布尔变量是UNKNOWN，则返回false。
boolean IS NOT TRUE | 如果布尔变量为false，则返回true。如果布尔变量是UNKNOWN，则返回true。
value1 = value2 | 如果value1等于value2，则返回true。
value1 <> value2 | 如果value1不等于value2，则返回true。
value1 > value2 | 如果value1大于value2，则返回true。
value1 >= value2 | 如果value1大于或等于value2，则返回true。
value1 < value2 | 如果value1小于value2，则返回true。
value1 <= value2 | 如果value1小于或等于value2，则返回true。
value IS NULL | 如果value为null，则返回true。
value IS NOT NULL | 如果value不为null，则返回true。
value1 IS DISTINCT FROM value2 | 如果value1与value2不同，则返回true。如果value1和value2都为null，则它们被视为相等。
value1 IS NOT DISTINCT FROM value2 | 如果value1等于value2，则返回true。如果value1和value2都为null，则它们被视为相等。
value1 BETWEEN value2 AND value3 | 如果value1大于或等于value2且小于value3，则返回true。
value1 NOT BETWEEN value2 AND value3 | 如果value1小于value2或大于或等于value3，则返回true。
string1 LIKE string2 [ ESCAPE string3 ] | 对字符串string1进行模糊匹配，如果匹配到模式string2则返回true，如果不匹配则返回false。
string1 NOT LIKE string2 [ ESCAPE string3 ] | 对字符串string1进行模糊匹配，如果匹配到模式string2则返回false，如果不匹配则返回true。
value IN (value [, value]* ) | 如果value等于列表中的任何一个值，则返回true。
value NOT IN (value [, value]* ) | 如果value不等于列表中的任何一个值，则返回true。'","page_content='C++客户端

2.使用示例

2.5.向leader发送GQL请求

```C++
std::string str;
bool ret = client.CallGqlToLeader(str,
""CALL db.createVertexLabel('actor', 'name', 'name', string, false, 'age', int8, true)"");
```
```
bool CallGqlToLeader(std::string& result, const std::string& gql,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0);
@param [out] result      The result.
@param [in]  gql         inquire statement.
@param [in]  graph       (Optional) the graph to query.
@param [in]  json_format (Optional) Returns the format， true is json，Otherwise, binary
format.
@param [in]  timeout     (Optional) Maximum execution time, overruns will be interrupted.
@returns True if it succeeds, false if it fails.
```
本接口只支持在HA模式下使用，在HA模式下的client中，为防止向未同步数据的follower发送请求，
用户可以直接向leader发送请求，leader由集群选出。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.5.向leader发送GQL请求'}"
TuGraph 中复杂图分析操作如何执行？,"page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。  
<table><tbody><tr><td>算法类型</td><td>中文算法名</td><td>英文算法名</td><td>程序名</td></tr><tr><td rowspan=""5"">路径查询</td><td>广度优先搜索</td><td>Breadth-First Search</td><td>bfs</td></tr><tr><td>单源最短路径</td><td>Single-Source Shortest Path</td><td>sssp</td></tr><tr><td>全对最短路径</td><td>All-Pair Shortest Path</td><td>apsp</td></tr><tr><td>多源最短路径</td><td>Multiple-source Shortest Paths</td><td>mssp</td></tr><tr><td>两点间最短路径</td><td>Single-Pair Shortest Path</td><td>spsp</td></tr><tr><td rowspan=""9"">重要性分析</td><td>网页排序</td><td>Pagerank</td><td>pagerank</td></tr><tr><td>介数中心度</td><td>Betweenness Centrality</td><td>bc</td></tr><tr><td>置信度传播</td><td>Belief Propagation</td><td>bp</td></tr><tr><td>距离中心度</td><td>Closeness Centrality</td><td>clce</td></tr><tr><td>个性化网页排序</td><td>Personalized PageRank</td><td>ppr</td></tr><tr><td>带权重的网页排序</td><td>Weighted Pagerank Algorithm</td><td>wpagerank</td></tr><tr><td>信任指数排名</td><td>Trustrank</td><td>trustrank</td></tr><tr><td>sybil检测算法</td><td>Sybil Rank</td><td>sybilrank</td></tr><tr><td>超链接主题搜索</td><td>Hyperlink-Induced Topic Search</td><td>hits</td></tr><tr><td rowspan=""4"">关联性分析</td><td>平均集聚系数</td><td>Local Clustering Coefficient</td><td>lcc</td></tr><tr><td>共同邻居</td><td>Common Neighborhood</td><td>cn</td></tr><tr><td>度数关联度</td><td>Degree Correlation</td><td>dc</td></tr><tr><td>杰卡德系数</td><td>Jaccard Index</td><td>ji</td></tr><tr><td rowspan=""5"">图结构</td><td>直径估计</td><' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}","page_content='OlapBase API

7. 图类OlapBase

7.4 批处理操作

TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程。分别是：  
```c++
/*
函数名称:ReducedSum ProcessVertexInRange(std::function<ReducedSum(size_t)> work, size_t lower, size_t upper,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考include/lgraph/olap_base.h中具体代码

使用示例:统计数组parent数组中有出边的点个数
*/

auto vertex_num = graph.ProcessVertexInRange<size_t>(
[&](size_t i) {
if (graph.OutDegree(parent[i]) > 0) {
return 1;
}
},
0, parent.Size()
);
printf(""the number is %lu\n"",vertex_num);
```  
其中graph为图类OlapBase的实例化对象  
```C++
/*
函数名称:ReducedSum ProcessVertexActive(std::function<ReducedSum(size_t)> work, ParallelBitset &active_vertices,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对active_vertices中对应为1的节点执行work函数，第三个参数表示累加的基数，默认为0；
第四个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考/include/lgraph/olap_base.h中具体代码

使用示例:输出Graph中节点1，2，3的所有出度邻居，并统计这三个节点的总出度
*/

auto active_in = graph.AllocVertexSubset();
active_in.Add(1);
active_in.Add(2);
active_in.Add(3);
auto total_outdegree = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t local_outdegree = 0;
for (auto & edge : graph.OutEdges(vi)) {
size_t dst = edge.neighbour;
printf(""node %lu has neighbour %lu\n"",vi,dst);
local_outdegree += 1;
}
return local_outdegree;
},
active_in
);
printf(""total outdegree of node1,2,3 is %lu\n"",total_outdegree);
```' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.4 批处理操作'}","page_content='OLAP API

1. TuGraph 图分析引擎介绍

TuGraph的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助TuGraph的 C++ / Python 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如PageRank、LPA、WCC等迭代式图算法，最后根据运行结果做出相应的对策。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph图计算系统社区版内置6个算法，商业版内置了25种算法，用户几乎不需要自己实现具体的图计算过程。其详细介绍可参考algorithms.md。  
根据数据来源及实现不同，可分为Procedure、Embed和Standalone三种运行方式，均继承于OlapBase API，OlapBase API接口文档可参考olapbase-api.md。  
其中Procedure和Embed的数据来源是图数据库中预加载的db数据，可以分别编译生成tugraph-web加载使用的.so文件和后台终端使用的embed文件，输入的图数据均通过db的加载形式，其接口文档可参考olapondb-api.md。
Standalone用于编译生成standalone文件，区别于前者，该文件的输入图数据通过txt、二进制、ODPS文件的形式加载，其接口文档可参考olapondisk-api.md。' metadata={'Header 1': 'OLAP API', 'Header 2': '1. TuGraph 图分析引擎介绍'}"
filter_output_default函数的主要作用是什么？,"page_content='OlapOnDisk API

3. 其他常用函数功能描述

3.2 图写入

- `void Write(ConfigBase<EdgeData> & config, ParallelVector<VertexData>& array, size_t array_size, std::string name, std::function<bool(VertexData &)> filter_output = filter_output_default<VertexData&>)`：把array中数据写回文件中，各参数表示意义分别是：
- `config`：需要加载的配置参数。该参数内保存了该图的一般信息（如数据来源，算法名称，数据输入、输出路径，点个数等）以及根据不同数据来源、不同算法所配置的不同信息参数。
- `array`：待写入数据的数组
- `array_size`：待写入数据的数字长度
- `name`：算法名称
- `filter_output`：写入数据规则函数，待写入数据需要满足该函数的要求。' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '3. 其他常用函数功能描述', 'Header 3': '3.2 图写入'}","page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='OlapOnDisk API

2. 算法举例

2.2 配置类MyConfig

MyConfig配置类函数用于提供算法逻辑计算时所需的配置信息，继承于ConfigBase<EdgeData>,其中EdgeDate可根据加载图类型不同选择Empty（无权图）、int（带权图权重为整数）或者double（带权图权重为double）类型。  
MyConfig配置类一般根据算法不同，需要额外配置信息如下：  
1.算法所需参数
2.算法名称
3.配置类内Print函数
其余公用成员继承与ConfigBase，可参考src/olap/olap_config.h查阅。  
```C++
class MyConfig : public ConfigBase<Empty> {
public:

// 算法所需参数初始化
size_t root = 0;
std::string name = std::string(""bfs"");
void AddParameter(fma_common::Configuration & config) {
ConfigBase<Empty>::AddParameter(config);
config.Add(root, ""root"", true)
.Comment(""the root of bfs"");
}
void Print() {
ConfigBase<Empty>::Print();
std::cout << ""  name: "" << name << std::endl;
if (root != size_t(-1)) {
std::cout << ""  root: "" << root << std::endl;
} else {
std::cout << ""  root: UNSET"" << std::endl;
}
}
// 配置文件接受命令行参数，该用例会顺次读取命令行调用算法时的参数，优先使用用户指定数值，若用户并未指定则选择默认参数。
MyConfig(int &argc, char** &argv): ConfigBase<Empty>(argc, argv) {
fma_common::Configuration config;
AddParameter(config);
config.ExitAfterHelp(true);
config.ParseAndFinalize(argc, argv);
Print();
}
};
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.2 配置类MyConfig'}"
在Java运行时，MyBatis Generator的XML配置文件应如何配置targetProject？,"page_content='可视化操作手册

2.操作指南

2.4.图项目

`图项目`提供可视化的图项目管理和图数据研发功能，它为用户提供了一系列便捷的图数据可视化操作，包括图项目的创建、修改、删除等管理操作，以及图数据的查询、点边统计等操作。此外，它也支持图模型的管理，使用户可以更加方便地进行图数据的管理和维护。  
#### 2.4.1.图项目管理  
在`图项目`界面，可以看到当前图数据库中的图项目。  
![图项目-首页](../../../images/browser/graphmanagement-homepage.png)  
##### 2.4.1.1.新建图项目  
在`图项目`界面，点击`新建图项目`按钮创建一个新的图项目。  
![图项目-新建图项目按钮](../../../images/browser/graphmanagement-creategraph.png)  
新建图项目需要通过`选择模板`和`填写配置`两个页面完成图项目的创建。  
- __选择模板__：产品提供空模板和demo模板两类模板。
- 空模板：全新的图项目，用户需要自己创建图模型和导入图数据，一般用于正式项目开发。
- demo模板：产品内置的demo数据，图项目创建成功后，系统会自动创建demo图模型并导入demo图数据，一般用于试用和学习。  
![图项目-选择模板](../../../images/browser/graphmanagement-selecttemplate.png)  
- __填写配置__：用户需要填写图项目基本信息，并点击`创建`按钮创建图项目。
- 图名称：新建图项目的名称，同时作为该图项目的唯一主键。支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图描述：新建图项目的描述，可用于详细说明该项目的背景和目标。
- 高级配置-最大存储空间：设置图项目最大可占用的存储空间，实际并不会提前占用物理存储空间，实际数据量达到最大存储空间阈值后不可再写入数据。  
![图项目-填写配置](../../../images/browser/graphmanagement-configure.png)  
创建成功后，可在`图项目`页面的图项目选项卡中查看。  
##### 2.4.1.2.编辑图项目  
在`图项目`界面，点击图项目选项卡中的`编辑`按钮（笔形图标），编辑对应图项目的基础信息。  
![图项目-编辑图项目按钮](../../../images/browser/graphmanagement-editgraph-button.png)  
编辑图项目功能可以修改`图描述`和`最大存储空间`。  
![图项目-编辑图项目](../../../images/browser/graphmanagement-editgraph.png)  
##### 2.4.1.3.删除图项目  
在`图项目`界面，点击图项目选项卡中的`删除`按钮（垃圾桶图标），删除对应的图项目。  
![图项目-删除图项目按钮](../../../images/browser/graphmanagement-deletegraph-button.png)  
_需要注意：图项目删除后无法恢复_。  
##### 2.4.1.4.点边统计  
在`图项目`界面，点击图项目选项卡中的`点边统计`按钮（刷新图标），统计对应图项目当前时间节点的点边数量。  
![图项目-点边统计按钮](../../../images/browser/graphmanagement-statistics-button.png)  
统计结果将展示在图项目选项卡上，已经统计过点边数据的图项目再次统计需要点击`刷新`按钮。  
![图项目-点边统计](../../../images/browser/graphmanagement-statistics.png)  
![图项目-刷新点边统计按钮](../../../images/browser/graphmanagement-statistics-refresh-button.png)  
##### 2.4.1.5.存储过程  
在`图项目`界面，点击图项目选项卡中的`存储过程`按钮（卡片最右侧图标），跳转到操作存储过程的图页面。  
![图项目-存储过程按钮](../../../images/browser/graphmanagement-procedure-button.png)  
在`存储过程`页面，可以新建存储过程，新建时需要填写""存储过程名称""、""存储过程类型""、""存储过程描述""，然后选择""版本""和""执行时是否修改数据库""  
![图项目-存储过程](../../../images/browser/graph' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='运维监控

2.部署方案

2.4.第四步

+ 下载符合您机器架构以及系统版本的Grafana安装包，下载地址: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)  
+ 安装Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 启动Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 配置Grafana，首先在数据源设置中配置Prometheus的IP地址，配置完成后可以通过测试连接功能，验证是否成功连接数据源。然后，导入如下模版，并在页面中根据实际情况，修改正确的接口IP和端口。最后可以根据实际情况设置刷新时间和监控时间范围  
```json
{
""annotations"": {
""list"": [
{
""builtIn"": 1,
""datasource"": {
""type"": ""grafana""
},
""enable"": true,
""hide"": true,
""iconColor"": ""rgba(0, 211, 255, 1)"",
""name"": ""Annotations & Alerts"",
""target"": {
""limit"": 100,
""matchAny"": false,
""tags"": [],
""type"": ""dashboard""
},
""type"": ""dashboard""
}
]
},
""editable"": true,
""fiscalYearStartMonth"": 0,
""graphTooltip"": 0,
""id"": 2,
""links"": [],
""liveNow"": false,
""panels"": [
{
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
}
},
""mappings"": [],
""unit"": ""kbytes""
},
""overrides"": [
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {__name__=\""resources_report\"", instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
},
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""others""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-blue"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}","page_content='安装指南

一键安装

集群配置

配置GeaFlow作业的运行时集群，推荐使用Kubernates。本地模式下默认为本地的代理地址${your.host.name}:8000，请确保本地已经启动minikube并设置好代理地址。如果设置K8S集群地址，请确保集群地址的连通性正常。
![install_cluster_config](../../static/img/install_cluster_config.png)  
K8S集群模式添加以下配置
```
# 存储限制为10Gi
""kubernetes.resource.storage.limit.size"":""10Gi""
# 服务API配置为K8S服务地址，一般为6443端口
""kubernetes.master.url"":""https://${your.host.name}:6443""
# 在K8S集群找到 /etc/kubernetes/admin.conf 配置文件，从上到下分别配置以下三个字段
""kubernetes.ca.data"":""""
""kubernetes.cert.data"":""""
""kubernetes.cert.key"":""""
```' metadata={'Header 1': '安装指南', 'Header 2': '一键安装', 'Header 3': '集群配置'}"
"在给定的代码中，`@Property(""class"")`注解指定了什么数据库字段名？","page_content='Cypher API

5.附录2. 内置procedures列表

* db.subgraph()

**Scope:** whole instance.  
**Parameters:**  
| parameter  | parameter type | description                                                           |
| ---------- | -------------- | --------------------------------------------------------------------- |
| vids       | list           | list of vertex id                                                     |  
**Output:**  
Get a json containing all the properties of nodes and relationships.  
**Example input:**  
```
CALL db.subgraph([3937,4126,4066,4010])
```  
**Example output**  
| subgraph |
| -------- |
| {""nodes"":[{""identity"":3937,""label"":""movie"",""properties"":{""duration"":136,""id"":1,""poster_image"":""http://image.tmdb.org/t/p/w185/gynBNzwyaHKtXqlEKKLioNkjKgN.jpg"",""rated"":""R"",""summary"":""Thomas A. Anderson is a man living two lives. By day he is an average computer programmer and by night a malevolent hacker known as Neo who finds himself targeted by the police when he is contacted by Morpheus a legendary computer hacker who reveals the shocking truth about our reality."",""tagline"":""Welcome to the Real World."",""title"":""The Matrix""}},{""identity"":4010,""label"":""user"",""properties"":{""id"":44,""login"":""Howard""}},{""identity"":4066,""label"":""user"",""properties"":{""id"":202,""login"":""Enoch""}},{""identity"":4126,""label"":""user"",""properties"":{""id"":464,""login"":""Wilburn""}}],""relationships"":[{""dst"":4126,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4010,""temporal_id"":0},{""dst"":4010,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4066,""temporal_id"":0},{""dst"":4066,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4126,""temporal_id"":0}]} |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.subgraph()'}","page_content='RESTful API Legacy

6.Deprecated

6.9.索引

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/index/{label}/{field}
```  
提供索引操作，接受 GET/POST 请求。  
#### 6.9.1.创建索引  
该操作会启动一个创建索引的后台任务，用户可以通过列出该 Label 相关的所有索引来检查新建索引的状态。  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: POST
- **REQUEST**:  
| 域名    | 说明     | 类型                                  |
|-------|--------|-------------------------------------|
| label | Label 名 | 字符串                                 |
| field | 域名     | 字符串                                 |
| type  | 索引类型   | int类型，0表示非唯一索引，1表示全局唯一索引，2表示两点间唯一索引 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"": ""Person"",
""field"": ""birthyear"",
""is_unique"" : false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.9.2.列出所有索引  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""field"": ""name"",
""label"": ""City"",
""is_unique"": false
},
{
""field"": ""title"",
""label"": ""Film"",
""is_unique"": false
},
{
""field"": ""name"",
""label"": ""Person"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
#### 6.9.3.列出所有与某个 Label 相关的索引  
- **URI**: `/db/{graph_name}/index/{label}`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index/Person
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""label"": ""Person"",
""field"": ""name"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
##' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.9.索引'}","page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

#### 6.10.1.指定文件内容导入  
- **URI**: `/db/{graph_name}/import/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |
| data | 要导入的文件内容（建议最大在 16MB 左右，最长不超过 17MB） | 字符串 / 数组 / 对象 |
| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""description"": ""{\\""files\\"":[{\\""columns\\"":[\\""SRC_ID\\"",\\""role\\"",\\""DST_ID\\""],\\""format\\"":\\""CSV\\"",\\""label\\"":\\""role\\"",\\""SRC_ID\\"":\\""actor\\"",\\""DST_ID\\"":\\""movie\\""}]}""}"",
""data"": ""1,Role1,2\n3,Role2,4\n"",
""continue_on_error"": true,
""delimiter"": "",""
}
```  
上述 description 的值是如下 json 序列化后的字符串  
```json
{
""files"": [
{
""format"": ""CSV"",
""label"": ""role"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""log"": ""Missing src uid 1\n""
}
```  
由于请求中指定了在出错时继续，该返回信息说明 SRC_ID 为 1 的边没有被导入，而其他信息导入成功。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}"
在tugraph中是否能通过cypher语句删除图中的重复关系？,"page_content='Cypher API

4.附录1. 语法扩充及不同

TuGraph查询语言与OpenCypher的不同点如下：  
- Label数量
- TuGraph: Each node/relationship must have one and only one label. So error occurs when there is no label, and the 1st label will be picked as the label if there are more than one label.
- OpenCypher: One node/relationship may have 0 to many labels.
- Schema.
- TuGraph: TuGraph has strong schema
- OpenCypher: schema-less' metadata={'Header 1': 'Cypher API', 'Header 2': '4.附录1. 语法扩充及不同'}","page_content='Cypher API

2.Clauses

2.7.CREATE

- Create nodes  
> **Note**
> TuGraph不支持创建空的nodes，不支持多labels。  
- ☒ Create single node  
```
CREATE (n)
```  
- ☒ Create multiple nodes  
```
CREATE (n), (m)
```  
- ☒ Create a node with a label  
```
CREATE (n:person)
```  
- ☒ Create a node with multiple labels  
```
CREATE (n:Person:Swedish)
```  
- ✓ Create node and add labels and properties  
```
CREATE (n:person {id:2001, name: 'Andres'})
```  
- ✓ Return created node  
```
CREATE (n:person {id:2002, name: 'Andres'})
RETURN n
```  
- Create relationships
- ✓ Create a relationship between two nodes  
```
MATCH (n:person), (m:movie)
WHERE n.name = 'Jada Pinkett Smith' AND m.title = 'The Matrix'
CREATE (n)-[r:write]->(m)
```  
- ✓ Create a relationship and set properties  
```
MATCH (n:person), (m:movie)
WHERE n.name = 'Jada Pinkett Smith' AND m.title = 'The Matrix'
CREATE (n)-[r:acted_in{role: 'Trinity'}]->(m)
```  
- ❏ Create a full path  
```
CREATE p = (andres:person {id: 2005, name:'Andres'})-[:acted_in {role: 'Trinity'}]->
(m:movie {id: 2006})<-[:acted_in {role: 'Trinity'}]-(michael {id: 2006, name:'Michael'})
RETURN p
```  
- Use parameters with CREATE
- ❏ Create node with a parameter for the properties  
```
CREATE (n:Person $props)
RETURN n
```  
- ☒ Create multiple nodes with a parameter for their properties  
```
UNWIND $props AS map
CREATE (n)
SET n = map
```
cannot create vertex without label.' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.7.CREATE'}","page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}"
在默认情况下，第一次快照的时间如何设置？,"page_content='图算法介绍

5.4 配置参数

配置相关参数，启动运行作业即可。  
```
""geaflow.infer.env.enable"":""true"",
// 初始化虚拟环境等待时间
""geaflow.infer.env.init.timeout.sec"":120,
// 是否接收日志
""geaflow.infer.env.suppress.log.enable"":""true""

```' metadata={'Header 1': '图算法介绍', 'Header 2': '5.4 配置参数'}","page_content='安装指南

注册登录

首位注册用户将默认被设置为管理员，以管理员身份登录，通过一键安装功能开始系统初始化。
![welcome](../../static/img/install_welcome.png)' metadata={'Header 1': '安装指南', 'Header 2': '注册登录'}","page_content='运维监控

2.部署方案

2.4.第四步

+ 下载符合您机器架构以及系统版本的Grafana安装包，下载地址: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)  
+ 安装Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 启动Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 配置Grafana，首先在数据源设置中配置Prometheus的IP地址，配置完成后可以通过测试连接功能，验证是否成功连接数据源。然后，导入如下模版，并在页面中根据实际情况，修改正确的接口IP和端口。最后可以根据实际情况设置刷新时间和监控时间范围  
```json
{
""annotations"": {
""list"": [
{
""builtIn"": 1,
""datasource"": {
""type"": ""grafana""
},
""enable"": true,
""hide"": true,
""iconColor"": ""rgba(0, 211, 255, 1)"",
""name"": ""Annotations & Alerts"",
""target"": {
""limit"": 100,
""matchAny"": false,
""tags"": [],
""type"": ""dashboard""
},
""type"": ""dashboard""
}
]
},
""editable"": true,
""fiscalYearStartMonth"": 0,
""graphTooltip"": 0,
""id"": 2,
""links"": [],
""liveNow"": false,
""panels"": [
{
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
}
},
""mappings"": [],
""unit"": ""kbytes""
},
""overrides"": [
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {__name__=\""resources_report\"", instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
},
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""others""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-blue"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}"
如果您想提交非原创作品给蚂蚁集团，您需要标注哪些信息？,"page_content='如何贡献

3. 准备工作

3.3. 许可协议

在贡献代码之前，请您稍微花一些时间了解为TuGraph贡献代码的流程，并阅读 [个人贡献者许可协议](3.individual-cla.md) 或 [公司贡献者许可协议](4.corporate-cla.md)，参与贡献则视为同意上述协议。' metadata={'Header 1': '如何贡献', 'Header 2': '3. 准备工作', 'Header 3': '3.3. 许可协议'}","page_content='社区角色

5. PMC

5.1. 要求

- 暂不开放，如有强烈愿望请联系PMC' metadata={'Header 1': '社区角色', 'Header 2': '5. PMC', 'Header 3': '5.1. 要求'}","page_content='如何贡献

2. 贡献什么

我们随时都欢迎任何贡献，无论是简单的错别字修正，BUG 修复还是增加新功能。请踊跃提出问题或发起 PR。我们同样重视文档以及与其它开源项目的整合，欢迎在这方面做出贡献。
对于任何修改，尤其是较为复杂的修改，建议新建一个issue ，按照BUG或者PR的模板填写。' metadata={'Header 1': '如何贡献', 'Header 2': '2. 贡献什么'}"
web端导入点数据后，不同的方式查询得到结果不同,"page_content='业务开发指南

导入数据

批量upsert点数据

如果不存在就插入点，如果存在就更新点的属性，根据点的主键字段值判断是否存在。  
第二个参数是一个`list`类型，每个`list`里面的元素是个`map`类型，每个`map`里面是点的字段和对应的值。  
推荐使用driver里面的参数化特性，第二个参数直接传入一个 `list`结构体，避免自己构造语句。
```
CALL db.upsertVertex('node1', [{id:1, name:'name1'},{id:2, name:'name2'}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert点数据'}","page_content='内置算法

扩展算法包

个性化网页排序

个性化网页排序程序实现了Personalized PageRank算法。该算法根据给定的源点，基于该源点个性化计算所有点对于源点的重要性排名。Rank值越高，表示该点对于源点越重要。与PageRank不同的是，初始化时源点Rank值为1，其余点Rank值为0；并且每轮传递结束后，Rank值会有一定的比例随即传递回源点。算法内容请参考 [https://cs.stanford.edu/people/plofgren/Fast-PPR_KDD_Talk.pdf](https://cs.stanford.edu/people/plofgren/Fast-PPR_KDD_Talk.pdf)。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': '个性化网页排序'}","page_content='TuGraph-Restful-Server

7.接口

7.8 数据导入请求

用户通过此类请求导入已经上传的数据文件。导入不论成功或失败，都将删除已上传文件。数据导入请求在server中实现为一个异步任务，响应返回并不意味着导入已完成，返回的是任务id，后续可以通过此任务id查询导入进度
#### 7.8.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_data
#### 7.8.2 REQUEST
|  body参数  |          参数说明           |  参数类型  | 是否必填 |
|:--------:|:-----------------------:|:------:|:----:|
| graph |         导入目标子图          |  字符串  |  是   |
| schema |       导入schema描述        | json字符串  |  是   |
| delimiter |           分隔符           |  字符串  |  是   |
| continueOnError |     单行数据出错是否跳过错误并继续     |  boolean  |  否   |
| skipPackages |         跳过的包个数          |  字符串  |  否   |
| taskId |  任务id   |  字符串  |  否   |
| other | 其他参数 |  json字符串  |  否   |  
#### 7.8.3 RESPONSE
|    body参数     |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| taskId | 任务编号 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.8 数据导入请求'}"
对象图映射（OGM）支持什么？,"page_content='TuGraph-OGM

简介

TuGraph-OGM(Object Graph Mapping), 源自 `Neo4j-OGM` 项目，TuGraph-OGM
支持将JAVA对象（POJO）映射到TuGraph中，JAVA中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此JAVA开发人员可以在熟悉的生态中轻松地使用TuGraph数据库。同时TuGraph-OGM兼容Neo4j-OGM，Neo4j生态用户可以无缝迁移到TuGraph数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '简介'}","page_content='TuGraph-OGM

1.简介

> TuGraph-OGM 项目在其他仓库开源。  
TuGraph-OGM(Object Graph Mapping)为面向 TuGraph 的图对象映射工具，支持将 JAVA 对象（POJO）映射到 TuGraph 中，JAVA 中的类映射为图中的节点、类中的集合映射为边、类的属性映射为图对象的属性，并提供了对应的函数操作图数据库，因此 JAVA 开发人员可以在熟悉的生态中轻松地使用 TuGraph 数据库。同时 TuGraph-OGM 兼容 Neo4j-OGM，Neo4j 生态用户可以无缝迁移到 TuGraph 数据库上。' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '1.简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

0 映射原理

TuGraph-OGM 将 JAVA 对象映射为图的对象，类映射为点，类的属性映射为图中的属性，类中的方法映射为操作 TuGraph 的查询语句。  
以电影场景为例，对演员、电影、导演之间的关系进行数据化，就形成了非常典型的图数据。举一个简单的示例，演员Alice在1990年和2019年分别出演了两部电影《Jokes》和《Speed》，其中《Jokes》的导演是Frank Darabont。  
以图的思维来看，演员、导演、电影可以被映射为三种不同的节点，而出演、执导可以被映射为两种边，映射结果如上图所示，将数据存入图数据库后，相关的开发人员就可以使用各类图查询语言对数据进行查询。  
但对非图数据库相关的开发人员来说，这个例子中的演员、导演、电影作为实体，同样可以映射为类中的对象，而与实体相关联的对象可以通过集合存储，这是大多数开发人员熟悉的领域。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '0 映射原理'}"
如何在单节点模式下实例化liblgraph_client_python.client对象？,"page_content='Python客户端

3.RPC Client

3.1.实例化client对象

#### 3.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
```python
client = liblgraph_client_python.client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, url: str, user: str, password: str)
```  
#### 3.1.2.实例化HA集群直连连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化。
```python
client = liblgraph_client_python.client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, url: str, user: str, password: str)
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 3.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化
```python
client = liblgraph_client_python.client([""189.33.97.23:9091"",""189.33.97.24:9091"", ""189.33.97.25:9091""], ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, urls: list, user: str, password: str)
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.1.实例化client对象'}","page_content='C++客户端

2.使用示例

2.1.实例化client对象

引入依赖并实例化  
#### 2.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
``` C++
RpcClient client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
RpcClient(const std::string& url, const std::string& user, const std::string& password);
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```  
#### 2.1.2.实例化HA集群直接连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化
``` C++
RpcClient client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
RpcClient(const std::string& url, const std::string& user, const std::string& password);
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 2.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化。
```java
std::vector<std::string> urls = {""189.33.97.23:9091"", ""189.33.97.24:9091"", ""189.33.97.25:9091""};
TuGraphDbRpcClient client = new TuGraphDbRpcClient(urls, ""admin"", ""73@TuGraph"");
```
```
RpcClient(std::vector<std::string>& urls, std::string user, std::string password)
@param urls: tugraph host list
@param user: login user name
@param password: login password
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.1.实例化client对象'}","page_content='Java客户端

2.使用示例

2.1.实例化client对象

添加maven依赖  
```xml
<dependency>
<groupId>com.antgroup.tugraph</groupId>
<artifactId>tugraph-db-java-rpc-client</artifactId>
<version>1.4.1</version>
</dependency>
```  
引入依赖
```java
import com.antgroup.tugraph.TuGraphDbRpcClient;
```  
#### 2.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
```java
TuGraphDbRpcClient client = new TuGraphDbRpcClient(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(String url, String user, String pass)
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```  
#### 2.1.2.实例化HA集群直连连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化。
```java
TuGraphDbRpcClient client = new TuGraphDbRpcClient(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(String url, String user, String pass)
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 2.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化
```java
List<String> urls = new ArrayList<>();
urls.add(""189.33.97.23:9091"");
urls.add(""189.33.97.24:9091"");
urls.add(""189.33.97.25:9091"");
TuGraphDbRpcClient client = new TuGraphDbRpcClient(urls, ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(List<String> urls, String user, String password)
@param urls: tugraph host list
@param user: login user name
@param password: login password
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.1.实例化client对象'}"
如果传递给 `GetRoleInfo` 函数的角色名非法，会抛出哪种异常？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='用户权限

4.常用权限操作

4.2.角色操作

- 创建角色  
```cypher
CALL dbms.security.createRole(role_name::STRING,desc::STRING)
```  
- 删除角色  
```cypher
CALL dbms.security.deleteRole(role_name::STRING
```  
- 列出所有角色  
```cypher
CALL dbms.security.listRoles()
```  
- 禁用/启用角色  
```cypher
CALL dbms.security.disableRole(role::STRING,disable::BOOLEAN)
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.2.角色操作'}","page_content='用户权限

4.常用权限操作

4.4.角色赋权

- 修改角色对指定图的访问权限  
```cypher
CALL dbms.security.modRoleAccessLevel(role::STRING,access_level::MAP)
```  
示例  
```cypher
CALL dbms.security.modRoleAccessLevel(""test_role"", {test_graph1:""FULL"", test_graph2:""NONE""})
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.4.角色赋权'}"
TuGraph 的部署方式有哪些？,"page_content='功能概览

1.1.部署方式

TuGraph目前提供云部署、Docker部署以及安装包部署三种部署方式，用户可根据实际情况选择适合的部署方式。' metadata={'Header 1': '功能概览', 'Header 2': '1.1.部署方式'}","page_content='环境和版本选择

3. 部署方式选择

TuGraph部署仅需一台服务器（高可用模式需要多台），可根据实际资源情况和使用场景，选择适合的部署方式。  
| 部署方式     | 描述                   | 备注                                                                                      |
|----------|----------------------|-----------------------------------------------------------------------------------------|
| 云部署      | 阿里云计算巢一键部署，免费试用      | 新手适用，流程参考 [链接](../5.installation&running/5.cloud-deployment.md)              |
| Docker部署 | 通过预先准备的Docker镜像跨平台部署 | 对硬件有要求的用户，比如性能测试，流程参考 [链接](../5.installation&running/3.docker-deployment.md) |
| 本地部署     | 在现有系统紧耦合部署           | 指定生产环境适用，流程参考 [链接](../5.installation&running/4.local-package-deployment.md)  |' metadata={'Header 1': '环境和版本选择', 'Header 2': '3. 部署方式选择'}","page_content='云部署

1.简介

TuGraph（tugraph.antgroup.com）是蚂蚁集团研发的高性能图数据库（Graph Database）。TuGraph在计算巢上提供了社区版服务，您无需自行购置云主机，即可在计算巢上快速部署TuGraph服务、实现运维监控，从而搭建您自己的图应用。本文向您介绍如何开通计算巢上的TuGraph社区版服务，以及部署流程和使用说明。' metadata={'Header 1': '云部署', 'Header 2': '1.简介'}"
根据使用MATCH和SKIP语句的查询结果，跳过第一行后返回的第一位人物的名字是什么？,"page_content='Cypher API

2.Clauses

2.5.SKIP

- ✓ Skip first three records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 3
```  
- ✓ Return middle two records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP 1
LIMIT 2
```  
- ❏ Using an expression with SKIP to return a subset of the records  
```
MATCH (n:person)
RETURN n.name
ORDER BY n.name
SKIP toInteger(3*rand())+ 1
```' metadata={'Header 1': 'Cypher API', 'Header 2': '2.Clauses', 'Header 3': '2.5.SKIP'}","page_content='ISO GQL

2.Clauses

2.7.SKIP

`SKIP`指定结果偏移行数。  
#### 未使用SKIP  
```
MATCH (n:Person)
RETURN n.name LIMIT 3
```  
返回结果  
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""},{""n.name"":""Dennis Quaid""}]
```  
#### 使用SKIP  
```
MATCH (n:Person)
RETURN n.name SKIP 1 LIMIT 2
```  
返回结果
```JSON
[{""n.name"":""Corin Redgrave""},{""n.name"":""Dennis Quaid""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.7.SKIP'}","page_content='ISO GQL

2.Clauses

2.1.MATCH

`MATCH`子句式是GQL最基础的子句，几乎所有查询都是通过 `MATCH`展开。  
`MATCH`子句用于指定在图中搜索的匹配模式，用来匹配满足一定条件的点或者路径。  
#### 点查询  
##### 查询所有点  
```
MATCH (n)
RETURN n
```  
##### 查询特定标签的点  
```
MATCH (n:Person)
RETURN n
```  
##### 通过属性匹配点  
```
MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
##### 通过过滤条件匹配点  
```
MATCH (n:Person WHERE n.birthyear > 1910)
RETURN n.name LIMIT 2
```  
返回结果
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```  
#### 边查询  
##### 出边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1970)-[e]->(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""BORN_IN"",""m.name"":""London"",""n.name"":""Christopher Nolan""},{""label(e)"":""DIRECTED"",""m.name"":null,""n.name"":""Christopher Nolan""}]
```  
##### 入边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1939)<-[e]-(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""HAS_CHILD"",""m.name"":""Rachel Kempson"",""n.name"":""Corin Redgrave""},{""label(e)"":""HAS_CHILD"",""m.name"":""Michael Redgrave"",""n.name"":""Corin Redgrave""}]
```  
##### 带过滤条件的边匹配  
```
MATCH (n:Person)-[e:BORN_IN WHERE e.weight > 20]->(m)
RETURN n.name, e.weight, m.name
```  
返回结果
```JSON
[{""e.weight"":20.549999237060547,""m.name"":""New York"",""n.name"":""John Williams""},{""e.weight"":20.6200008392334,""m.name"":""New York"",""n.name"":""Lindsay Lohan""}]
```  
#### 路径匹配  
##### 不定跳查询  
```
MATCH (n:Person)-[e]->{2,3}(m:Person)
RETURN m.name LIMIT 2
```  
返回结果
```JSON
[{""m.name"":""Liam Neeson""},{""m.name"":""Natasha Richardson""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.1.MATCH'}"
导入数据时，如果操作失败，是否可以继续导入？,"page_content='TuGraph-Restful-Server

7.接口

7.8 数据导入请求

用户通过此类请求导入已经上传的数据文件。导入不论成功或失败，都将删除已上传文件。数据导入请求在server中实现为一个异步任务，响应返回并不意味着导入已完成，返回的是任务id，后续可以通过此任务id查询导入进度
#### 7.8.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_data
#### 7.8.2 REQUEST
|  body参数  |          参数说明           |  参数类型  | 是否必填 |
|:--------:|:-----------------------:|:------:|:----:|
| graph |         导入目标子图          |  字符串  |  是   |
| schema |       导入schema描述        | json字符串  |  是   |
| delimiter |           分隔符           |  字符串  |  是   |
| continueOnError |     单行数据出错是否跳过错误并继续     |  boolean  |  否   |
| skipPackages |         跳过的包个数          |  字符串  |  否   |
| taskId |  任务id   |  字符串  |  否   |
| other | 其他参数 |  json字符串  |  否   |  
#### 7.8.3 RESPONSE
|    body参数     |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| taskId | 任务编号 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.8 数据导入请求'}","page_content='数据导入

5.在线增量导入

在线导入模式可用于将一批文件导入已在运行中的 TuGraph 实例中。这对于处理通常以固定的时间间隔进行的增量批处理更新非常便利。`lgraph_import --online true`选项使导入工具能够在线模式工作。与`离线模式`一样，在线模式有自己的命令行选项集，可以使用`-h，--help`选项进行打印输出：  
```shell
$ lgraph_import --online true -h
Available command line options:
--online            Whether to import online.
-h, --help          Print this help message. Default=0.

Available command line options:
--log               Log file to use, empty means stderr. Default="""".
-v, --verbose       Verbose level to use, higher means more verbose.
Default=1.
-c, --config_file   Config file path.
-r, --url           DB REST API address.
-u, --username      DB username.
-p, --password      DB password.
-i, --continue_on_error
When we hit a duplicate uid or missing uid, should we
continue or abort. Default=0.
-g, --graph         The name of the graph to import into. Default=default.
--skip_packages     How many packages should we skip. Default=0.
--delimiter         Delimiter used in the CSV files
--breakpoint_continue
When the transmission process is interrupted,whether
to re-transmit from zero package next time. Default=false
-h, --help          Print this help message. Default=0.
```  
文件的相关配置在配置文件中指定，其格式与`离线模式`完全相同。但是，我们现在不是将数据导入本地数据库，而是将数据发送到正在运行的 TuGraph 实例中，该实例通常运行在与运行导入工具的客户端计算机不同的计算机上。因此，我们需要指定远程计算机的 HTTP 地址的URL、DB用户和密码。  
如果用户和密码有效，并且指定的图存在，导入工具将将数据发送到服务器，服务器随后解析数据并将其写入指定的图。数据将以大约 16MB 大小的包发送，在最近的换行符处中断。每个包都是以原子方式导入的，这意味着如果成功导入包，则成功导入所有数据，否则，任何数据都不会进入数据库。如果指定了`--continue_on_error true`，则忽略数据完整性错误，并忽略违规行。否则，导入将在第一个错误包处停止，并打印出已导入的包数。在这种情况下，用户可以修改数据以消除错误，然后使用`--skip_packages N`重做导入以跳过已导入的包。' metadata={'Header 1': '数据导入', 'Header 2': '5.在线增量导入'}","page_content='数据导入

4.离线全量导入

离线模式只能在离线状态的服务器使用。离线导入会创建一张新图，因此更适合新安装的 TuGraph 服务器上的第一次数据导入。
要在离线模式下使用`lgraph_import`工具，可以指定`lgraph_import --online false`选项。要了解可用的命令行选项，请使用`lgraph_import --online false --help`：  
```shell
$ ./lgraph_import --online false -help
Available command line options:
--log               Log file to use, empty means stderr. Default="""".
-v, --verbose       Verbose level to use, higher means more verbose.
Default=1.
...
-h, --help          Print this help message. Default=0.
```  
命令行参数：  
- **-c, --config_file** `config_file`: 导入配置文件名，其格式要求见下述。
- **--log** `log_dir`: 日志目录。默认为空字符串，此时将日志信息输出到控制台。
- **--verbose** `0/1/2`: 日志等级，等级越高输出信息越详细。默认为 1。
- **-i, --continue_on_error** `true/false`: 在碰到错误时跳过错误并继续，默认为 false，碰到错误立即退出。
- **-d, --dir** `{diretory}`: 数据库目录，导入工具会将数据写到这个目录。默认为`./db`。
- **--delimiter** `{delimiter}`: 数据文件分隔符。只在数据源是 CSV 格式时使用，默认为`"",""`。
- **-u, --username** `{user}`: 数据库用户名。需要是管理员用户才能执行离线导入。
- **-p, --password** `{password}`: 指定的数据库用户的密码
- **--overwrite** `true/false`: 是否覆盖数据。设为 true 时，如果数据目录已经存在，则覆盖数据。默认为`false`。
- **-g, --graph** `{graph_name}`: 指定需要导入的图种类。
- **-h, --help**: 输出帮助信息。' metadata={'Header 1': '数据导入', 'Header 2': '4.离线全量导入'}"
如果不定义表头并使用空的Result()初始化表，你接下来应该使用什么方法为表设置表头？,"page_content='可视化操作手册（旧版）

操作详情

3.工作台

#### 3.1 快速上手  
- 首次登录，系统会默认创建 default 空图  
![alt 快速上手](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/2.tugraph-browser-quickstart-01.png)  
- 用户点击帮助选项，并选择快速上手  
![alt 帮助](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/3.tugraph-browser-quickstart-02.png)  
- 然后点击“一键创建模型”——>""一键创建数据""，就可以完成内置的 Movie 数据图谱的构建  
#### 3.2 创建子图和示例  
##### 3.2.1 创建子图  
- 点击新建子图
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/4.tugraph-browser-create-subgraph-01.png)
- 填写表单信息
![alt 填写表单](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/5.tugraph-browser-create-subgraph-02.png)
- 子图名称
- 子图描述
- 配置信息
- 点击确认，提示创建成功
- 切换子图
![alt 切换子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/6.tugraph-browser-use-graph-01.png)  
- 点击新建示例
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/create-scene-01.png)
- 选择示例并点击创建
![alt 创建子图](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/select-scene.png)  
#### 3.3 查询  
![alt 查询](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/2.Operating/7.tugraph-browser-query-01.png)  
##### 3.3.1 页面组成  
- cypher 输入框
- 结果集展示区域  
##### 3.3.2 结果集展示区域功能详情  
- 结果集标签展示及功能
![alt 结果集标签](https://tugraph-web-static.oss-cn-beijing.aliyuncs.com/%E6%96%87%E6%A1%A3/3.3.0-image/tugraph-browser-result.png)
- 这里展示了结果集的所有类型统计
- 点击不同的“label（标签）”，可以进行以下修改操作
- 修改展示颜色
- 修改节点大小或边的粗细
- 修改默认展示属性或系统属性
- 布局修改
- 力导布局
- 网格布局
- 树形布局
- 环境布局
- 边聚合
- 相同类型，方向的边可以进行合并
- 创建节点
- 点击创建节点按钮
- 选择节点类型
- 添写节点内容
- 创建关系
- 在画布中选择起点和终点
- 选择可以匹配的类型
- 填写节点信息
- 停止布局
- 当数据量过大，导致浏览器页面卡顿时候，可以点击这个停止布局的按钮，能够提高体验的流畅度
- 鼠标悬停
- 开启此功能，可以高亮显示鼠标悬停节点的一度邻居节点
- 结果集导出
- 可以将结果集导出为 png，json，csv 三种不同的文件形式
- 刷新
- 点击刷新按钮，会重新执行当前页面的初始 cypher 语句，并刷新结果集
- 最大化
- 点击最大化，结果集展示区域将全屏展示
- 结果集展示形式切换
- 支持图谱、表格、文本三种形式  
###' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '操作详情', 'Header 3': '3.工作台'}","page_content='业务开发指南

导入数据

批量upsert点数据

如果不存在就插入点，如果存在就更新点的属性，根据点的主键字段值判断是否存在。  
第二个参数是一个`list`类型，每个`list`里面的元素是个`map`类型，每个`map`里面是点的字段和对应的值。  
推荐使用driver里面的参数化特性，第二个参数直接传入一个 `list`结构体，避免自己构造语句。
```
CALL db.upsertVertex('node1', [{id:1, name:'name1'},{id:2, name:'name2'}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert点数据'}","page_content='RESTful API Legacy

6.Deprecated

6.9.索引

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/index/{label}/{field}
```  
提供索引操作，接受 GET/POST 请求。  
#### 6.9.1.创建索引  
该操作会启动一个创建索引的后台任务，用户可以通过列出该 Label 相关的所有索引来检查新建索引的状态。  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: POST
- **REQUEST**:  
| 域名    | 说明     | 类型                                  |
|-------|--------|-------------------------------------|
| label | Label 名 | 字符串                                 |
| field | 域名     | 字符串                                 |
| type  | 索引类型   | int类型，0表示非唯一索引，1表示全局唯一索引，2表示两点间唯一索引 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"": ""Person"",
""field"": ""birthyear"",
""is_unique"" : false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.9.2.列出所有索引  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""field"": ""name"",
""label"": ""City"",
""is_unique"": false
},
{
""field"": ""title"",
""label"": ""Film"",
""is_unique"": false
},
{
""field"": ""name"",
""label"": ""Person"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
#### 6.9.3.列出所有与某个 Label 相关的索引  
- **URI**: `/db/{graph_name}/index/{label}`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index/Person
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""label"": ""Person"",
""field"": ""name"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
##' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.9.索引'}"
蚂蚁集团的个人贡献者许可协议主要目的是什么？,"page_content='如何贡献

3. 准备工作

3.3. 许可协议

在贡献代码之前，请您稍微花一些时间了解为TuGraph贡献代码的流程，并阅读 [个人贡献者许可协议](3.individual-cla.md) 或 [公司贡献者许可协议](4.corporate-cla.md)，参与贡献则视为同意上述协议。' metadata={'Header 1': '如何贡献', 'Header 2': '3. 准备工作', 'Header 3': '3.3. 许可协议'}","page_content='社区角色

5. PMC

5.2. 职责

- 积极参与社区讨论，对社区重大决策给予指导
- 负责保证开源项目的社区活动都能运转良好' metadata={'Header 1': '社区角色', 'Header 2': '5. PMC', 'Header 3': '5.2. 职责'}","page_content='如何贡献

3. 准备工作

3.2. 准备环境

对于文档贡献，可以直接通过[文档](https://tugraph-db.readthedocs.io/zh_CN/latest)，点击右上角的""在GitHub上编译""直接修改并提PR。  
对于代码贡献，通常需要在搭建编译执行的环境，可以采用[Docker部署](../5.installation&running/3.docker-deployment.md)或[本地部署](../5.installation&running/4.local-package-deployment.md)。' metadata={'Header 1': '如何贡献', 'Header 2': '3. 准备工作', 'Header 3': '3.2. 准备环境'}"
TuGraph Mini Runtime Image 不包含哪些功能？,"page_content='Docker部署

1.简介

- TuGraph Compile Image：提供编译环境，可以用于TuGraph的编译，测试；
- TuGraph Runtime Image：提供二进制可运行环境，附带TuGraph库和可执行文件；
- TuGraph Mini Runtime Image: 提供二进制可运行环境，不包含TuGraph中Java、Python相关的功能，无C++ plugin编译运行，仅so上传。' metadata={'Header 1': 'Docker部署', 'Header 2': '1.简介'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='Docker部署

2.现有Docker Image

2.2.命名规范

#### 2.2.1.TuGraph Compile Image  
提供编译环境，可以用于TuGraph的编译。  
`tugraph/tugraph-compile-[os name & version]:[tugraph compile version]`  
例如： `tugraph/tugraph-compile-centos7:1.2.0`  
#### 2.2.2.TuGraph Runtime Image  
提供二进制可运行环境，附带TuGraph库和可执行文件。  
`tugraph/tugraph-runtime-[os name & version]:[tugraph-runtime version]`  
例如：`tugraph/tugraph-runtime-centos7:3.4.0`  
#### 2.2.3.TuGraph Mini Runtime Image  
提供二进制可运行环境，不包含TuGraph种Java、Python相关的功能，无C++ plugin编译运行，仅so上传。  
`tugraph/tugraph-mini-runtime-[os name & version]:[tugraph-runtime version]`  
例如： `tugraph/tugraph-mini-runtime-centos7:3.4.0`' metadata={'Header 1': 'Docker部署', 'Header 2': '2.现有Docker Image', 'Header 3': '2.2.命名规范'}"
OlapOnDB API文档中介绍的Procedure及Embed主要使用了哪些辅助函数？,"page_content='OlapOnDB API

1. 简介

一般用户需要自己实现的只是将需要分析的子图抽取出来的过程。用户也可以通过使用TuGraph中丰富的辅助接口实现自己的图分析算法。  
该文档主要介绍Procedure及Embed的接口设计，并介绍部分常用接口，具体的接口信息参见include/lgraph/olap_on_db.h文件。' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '1. 简介'}","page_content='OlapOnDB API

3. 算法举例

3.1 主函数

主函数输入有三个参数，`TuGraph`数据库参数`db`，从网页端获取的请求`request`，给网页端的返回值`response`，整体流程可以分为一下几步：  
1. 相关参数的获取
2. 快照类的创建
3. PageRank算法主流程
4. 网页端返回值的获取和发送  
```C++
extern ""C"" bool Process(GraphDB & db, const std::string & request, std::string & response) {

// 从网页端请求中获取迭代次数（num_iterations），
int num_iterations = 20;
try {
json input = json::parse(request);
num_iterations = input[""num_iterations""].get<int>();
} catch (std::exception & e) {
throw std::runtime_error(""json parse error"");
return false;
}

// 读事务的创建以及快照类的创建
auto txn = db.CreateReadTxn();
OlapOnDB<Empty> olapondb(
db,
txn,
SNAPSHOT_PARALLEL
);

// 创建pr数组用于存储每个节点的pr值
ParallelVector<double> pr = olapondb.AllocVertexArray<double>();
// pagerank算法主流程，获取每个节点的pagerank值
PageRankCore(olapondb, num_iterations, pr);

auto all_vertices = olapondb.AllocVertexSubset();
all_vertices.Fill();
/*
函数用途：从所有节点中获取pagerank值最大的节点编号

函数流程描述：该函数对点集合all_vertices中所有为1的位对应的节点vi（又称为活跃点）执行Func A，再将Func A的返回值作为Func B的第二个输入参数，得到局部最大值（因为第一个输入参数为0，因此实际上返回值就是每个节点的pagerank值），最后再将所有线程的返回值汇总，再次 执行Func B得到全局返回值，并存入max_pr_vi变量中
*/
size_t max_pr_vi = olapondb.ProcessVertexActive<size_t>(

//Func A
[&](size_t vi) {
return vi;
},
all_vertices,
0,

//Func B
[&](size_t a, size_t b) {
return pr[a] > pr[b] ? a : b;
}
);

// 网页端返回值的获取和发送
json output;
output[""max_pr_vid""] = olapondb.OriginalVid(max_pr_vi);
output[""max_pr_val""] = pr[max_pr_vi];
response = output.dump();
return true;
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '3. 算法举例', 'Header 3': '3.1 主函数'}","page_content='OLAP API

3. Embed 编译与运行

该种方式主要用于TuGraph在后台程序中对预加载的db图数据进行算法分析。其使用方法如下：
在tugraph-db/procedures 目录下对embed_main.cpp文件完善，补充数据名称、输入参数、数据路径等信息，示例如下：' metadata={'Header 1': 'OLAP API', 'Header 2': '3. Embed 编译与运行'}"
在尝试为用户设置新密码时，哪些异常可能会被抛出？,"page_content='云部署

4.常见FAQ

问题三: 登录时的用户名密码不正确

请注意检查，登录时使用的密码应为详情页面展示的密码。' metadata={'Header 1': '云部署', 'Header 2': '4.常见FAQ', 'Header 3': '问题三: 登录时的用户名密码不正确'}","page_content='RESTful API Legacy

6.Deprecated

6.1.用户管理

系统默认创建一个管理员，管理员用户名为 _admin_，密码为 _73@TuGraph_。为了安全起见，请用户在第一次启动服务器后更改密码。  
#### 6.1.1.添加用户  
添加一个新的用户，并为其设置初始密码。只有管理员有权限进行此操作。其中用户名只能由字母，数字以及下划线构成，密码则可以包含任意字符。用户名和密码长度不能超过 64 字节。添加用户时还可以为用户增加一个描述，用户描述可以包含任意字符，最长不超过 512 字节。  
新用户默认拥有同名的角色，不具备任何图的权限。  
- **URI**: `/user`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |
| description | 用户描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""user"": ""USER1"",
""password"": ""AN_INITIAL_PASSWORD"",
""description"": ""This is a user""
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.1.2.列出所有用户  
列出数据库的所有用户。只有管理员拥有该操作权限。  
- **URI**: `/user/`
- **METHOD**: GET
- **RESPONSE**: 所有用户及其信息。  
**Example request.**  
```
• GET http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
Output:
{
""admin"": {
""disabled"": false,
""description"": ""Builtin admin user"",
""roles"": [""admin""]
},
""guest1"": {
""disabled"": true,
""description"": """",
""roles"": [""guest1"", ""some_other_role""]
}
}
```  
#### 6.1.3.获取用户信息  
列出给定用户的信息。  
- **URI**: `/user/{user_name}`
- **METHOD**: GET
- **RESPONSE**: 用户信息。  
**Example request.**  
```
• GET http://localhost:7070/user/guest1
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.1.用户管理'}","page_content='RESTful API Legacy

3.登录

3.1.登录

用户通过用户名和密码发送登录请求。登录成功会收到带有签名的令牌(Json Web Token)和判断是否为默认密码的布尔型变量，客户端储存该令牌，并且用于以后的每次发送请求。如果登录失败会收到“Authentication failed”错误。  
- **URI**: `/login`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| jwt | 令牌 | 字符串 |
| default_password | 是否为默认密码 | 布尔值 |  
**Example request.**  
```
• POST http://localhost:7070/login
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""user"":""admin"",
""password"":""73@TuGraph""
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""jwt"": ""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek"",
""default_password"": true
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '3.登录', 'Header 3': '3.1.登录'}"
如何使用 liblgraph_python_api.Galaxy 类创建一个新的用户账户？,"page_content='Python Olap API

5. lgraph_db API

PyGalaxy:

- `PyGalaxy(self, dir_path: str)`: 构造函数，dir_path为db路径
- `SetCurrentUser(self, user: str password: str)-> void`: 设置用户
- `SetUser(self, user: std::string)-> void`: 设置用户
- `OpenGraph(self, graph: str, read_only: bool)-> PyGraphDB`: 创建PyGraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'PyGalaxy:'}","page_content='Python Olap API

5. lgraph_db API

Galaxy

- `Galaxy(dir_path: std::string)`: 构造函数，dir_path为db路径
- `SetCurrentUser(user: std::string, password: std::string)-> cython.void`: 设置用户
- `SetUser(user: std::string)-> cython.void`: 设置用户
- `OpenGraph(graph: std::string, read_only: bint)-> GraphDB`: 创建GraphDB' metadata={'Header 1': 'Python Olap API', 'Header 2': '5. lgraph_db API', 'Header 3': 'Galaxy'}","page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.1.数据加载

```python
galaxy = PyGalaxy(args.db_path)
galaxy.SetCurrentUser(args.username, args.password)
db = galaxy.OpenGraph(args.graph_name, False)
```
如代码所示，根据图数据路径、用户名、密码和子图名称将数据加载到内存中。TuGraph可以载入多个子图用于图训练，在此处我们只载入一个子图。' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.1.数据加载'}"
调用liblgraph_python_api.GraphDB的哪个方法可以删除一个顶点标签？,"page_content='Cypher API

5.附录2. 内置procedures列表

* dbms.graph.modGraph(graph_name, config)

delete a subgraph in this graph database .  
**Parameters:**  
| parameter  | parameter type | description              |
| ---------- | -------------- | ------------------------------------ |
| graph_name | string     | the name of subgraph to been deleted |
| config     | map        | the configuration to be modified     |  
**Output:**  
if successful , it will return true.  
**Example input:**  
```
CALL dbms.graph.modGraph('graph1',{description:'this graph', max_size_GB:20})
```  
**Example output:**  
| success |
| ------- |
| true    |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* dbms.graph.modGraph(graph_name, config)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* dbms.graph.deleteGraph(graph_name)

delete a subgraph in this graph database .  
| parameter  | parameter type | description              |
| ---------- | -------------- | ------------------------------------ |
| graph_name | string     | the name of subgraph to been deleted |  
**Output:**  
if successful , it will return true.  
**Example input:**  
```
CALL dbms.graph.deleteGraph('graph1')
```  
**Example output:**  
| success |
| ------- |
| true    |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* dbms.graph.deleteGraph(graph_name)'}","page_content='业务开发指南

子图操作

删除子图

```
CALL dbms.graph.deleteGraph('graph1')
```' metadata={'Header 1': '业务开发指南', 'Header 2': '子图操作', 'Header 3': '删除子图'}"
角色被禁用后，用户将从该角色中获得什么权限？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='用户权限

4.常用权限操作

4.3.赋予用户角色

- 新增用户与角色的联系  
```cypher
CALL dbms.security.addUserRoles(user::STRING,roles::LIST)
```  
- 删除用户与角色的联系  
CALL dbms.security.deleteUserRoles(user::STRING,roles::LIST)  
- 清空用户角色的关系并重建  
```cypher
CALL dbms.security.rebuildUserRoles(user::STRING,roles::LIST)
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.3.赋予用户角色'}","page_content='用户权限

4.常用权限操作

4.2.角色操作

- 创建角色  
```cypher
CALL dbms.security.createRole(role_name::STRING,desc::STRING)
```  
- 删除角色  
```cypher
CALL dbms.security.deleteRole(role_name::STRING
```  
- 列出所有角色  
```cypher
CALL dbms.security.listRoles()
```  
- 禁用/启用角色  
```cypher
CALL dbms.security.disableRole(role::STRING,disable::BOOLEAN)
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.2.角色操作'}"
TuGraph的可视化监控主要使用了哪些软件？,"page_content='运维监控

1.设计思路

可视化监控并不是TuGraph自身不可或缺的一部分，因此在设计时将可视化监控作为TuGraph周边生态中的一个应用，来减少和TuGraph数据库的耦合度，以及对于TuGraph自身的影响。TuGraph可视化监控采用目前最火热的开源解决方案，TuGraph Monitor + Prometheus + Grafana来实现。其中TuGraph Monitor作为TuGraph服务的客户端，通过TCP链接向TuGraph服务发起Procedure请求，TuGraph服务在接收到请求后收集自身所在机器的cpu，memory，disk，io，以及请求数量等指标的统计结果进行响应。TuGraph Monitor在接收到TuGraph响应的指标数据后，将数据包装成prometheus需要的格式，保存在内存中，等待Prometheus服务通过http请求获取。Prometheus服务会定期通过http请求从TuGraph Monitor获取封装好的请求数据，按照获取的时间保存在自己的时序数据库中。Grafana可以根据用户的配置，从Prometheus处获取某个时间段内的统计数据，并在web界面上绘制浅显易懂的图形来展示最终结果。整个请求链路中，都采用了主动获取，即PULL的模型，好处之一是它能最大限度的避免数据生产者和数据消费者之间的耦合度，使得开发更简单，好处之二是数据生产者不需要考虑数据消费者的数据处理能力，即使某个消费者的数据处理能力较弱，也不会因为生产者生产数据过快而压垮消费者。主动拉取模型的不足之处在于数据的实时性不够，但在这个场景中，数据并没有很高的实时性要求。' metadata={'Header 1': '运维监控', 'Header 2': '1.设计思路'}","page_content='功能概览

6.生态工具

6.3.运维监控

TuGraph 使用 Prometheus 加 Grafana 的监控框架，采用松耦合的方式。Prometheus 从 TuGraph 的监控接口获取监控信息，存储在本地时序数据库中，然后通过 Grafana 在网页端交互展示。  
TuGraph 提供的监控的状态包括图数据库的状态和服务器的状态，前者包括读写负载、点边数量等数据库端的状态，后者包括内存、CPU、硬盘等服务器的实时状态。如果某些监控状态超过了预期的阈值，就需要主动告警，通常需要对接其他运维管控系统，比如群消息、邮件告警等。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.3.运维监控'}","page_content='功能概览

6.生态工具

6.2.可视化交互

TuGraph Browser 是面向图数据库直接使用者的可视化交互界面，功能上覆盖了 TuGraph 的绝大部分能力，包括数据导入、图模型建立、数据增删查改、监控运维等操作链路。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.2.可视化交互'}"
TuGraph 服务在哪个文件中读取其配置？,"page_content='数据库运行

4.服务配置

4.2.服务器配置文件

TuGraph 的配置文件以 JSON 格式存储。建议将大多数配置存储在配置文件中，并且仅在需要时使用命令行选项临时修改某些配置参数。
一个典型的配置文件如下：  
```json
{
""directory"" : ""/var/lib/lgraph/data"",
""host"" : ""0.0.0.0"",
""port"" : 7070,
""rpc_port"" : 9090,
""enable_rpc"" : true,
""bolt_port"": 7687,
""enable_ha"" : false,
""verbose"" : 1,
""log_dir"" : ""/var/log/lgraph_log"",
""disable_auth"" : false,
""ssl_auth"" : false,
""server_key"" : ""/usr/local/etc/lgraph/server-key.pem"",
""server_cert"" : ""/usr/local/etc/lgraph/server-cert.pem"",
""web"" : ""/usr/local/share/lgraph/browser-resource""
}
```' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.2.服务器配置文件'}","page_content='TuGraph-DataX

4.导出TuGraph

4.1.配置样例

TuGraph支持使用DataX导出数据，使用如下配置即可将数据导出到文本数据中  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"":1
}
},
""content"": [
{
""reader"": {
""name"": ""tugraphreader"",
""parameter"": {
""username"": ""admin"",
""password"": ""73@TuGraph"",
""graphName"": ""Movie_8C5C"",
""queryCypher"": ""match (n:person) return n.id,n.name,n.born;"",
""url"": ""bolt://127.0.0.1:27687""
}
},
""writer"": {
""name"": ""txtfilewriter"",
""parameter"": {
""path"": ""./result"",
""fileName"": ""luohw"",
""writeMode"": ""truncate""
}
}
}
]
}
}
```  
使用这个配置文件，可以把TuGraph Movie_8C5C子图中person节点的id,name和born属性全部导出出来，
导出到当前目录下的result目录中，文件名称为luohw+随机后缀。' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '4.导出TuGraph', 'Header 3': '4.1.配置样例'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}"
该接口`StudentMapper`中`selectVertex`方法的超时设置是多少毫秒？,"page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends Gra' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void init(IncGraphComputeContext<K, VV, EV, M> incGraphContext) | 图计算初始化接口 | incGraphContext： 增量动态图计算的上下文，K表示vertex id的类型，VV表示vertex value类型，EV表示edge value类型，M表示发送消息的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮迭代对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 迭代计算接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 迭代计算完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型 |  
- 详细接口  
```java
public interface IncVertexCentricFunction<K, VV, EV, M> extends Function {

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncGraphContext<K, VV, EV, M> {
/** 获取job id */
long getJobId();

/** 获取当前迭代 id */
long getIterationId();

/** 获取运行时上下文 */
RuntimeContext getRuntimeContext();

/** 获取可变图 */
MutableGraph<K, VV, EV> getMutableGraph();

/** 获取增量图 */
TemporaryGraph<K, VV, EV> getTemporaryGraph();

/** 获取图存储上的历史图 */
HistoricalGraph<K, VV, EV> getHistoricalGraph();

/** 给指定vertex发送消息 */
void sendMessage(K vertexId, M message);

/** 给当前vertex邻居节点发送消息 */
void sendMessageToNeighbors(M message);

}

interface TemporaryGraph<K, VV, EV> {
/** 从增量图中获取vertex */
IVertex<K, VV> getVertex();

/** 从增量图中获取edges */
List<IEdge<K, EV>> getEdges();

/** 更新vertex value */
void updateVertexValue(VV value);

}

interface HistoricalGraph<K, VV, EV> {
/** 获取图数据最新版本id */
Long getLatestVersionId();

/** 获取图数据所有版本 */
List<Long> getAllVersionIds();

/** 获取图数据所有vertex */
Map<Long, IVertex<K, VV>> getAllVertex();

/** 获取图数据指定版本的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions);

/** 获取图数据指定版本并满足过滤条件的ve' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void init(VertexCentricComputeFuncContext<K, VV, EV, M> vertexCentricFuncContext) | 迭代计算初始化接口 | vertexCentricFuncContext：静态图计算的上下文，K表示vertex id的类型，VV表示vertex value类型，EV表示edge value类型，M表示发送消息的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 迭代计算接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：迭代过程中所有发送给当前vertex的消息，其中M表示迭代计算过程中定义的发送消息类型。 |
| void finish() | 迭代计算完成接口 | 无 |  
- 详细接口  
```java
public interface VertexCentricComputeFunction<K, VV, EV, M> extends VertexCentricFunction<K, VV,
EV, M> {

void init(VertexCentricComputeFuncContext<K, VV, EV, M> vertexCentricFuncContext);

void compute(K vertex, Iterator<M> messageIterator);

void finish();

interface VertexCentricComputeFuncContext<K, VV, EV, M> extends VertexCentricFuncContext<K, VV,
EV, M> {
/** 设置vertex value */
void setNewVertexValue(VV value);

}

}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}"
PathTraversal 类中展开当前前沿的操作可以使用哪些类型的过滤函数？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterato' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='Traversal API

2. 接口说明

2.1. Snapshot

C++ OLAP API 中的 Snapshot 模版类用于表示抽取出来的静态子图，其中 EdgeData 用来表示该子图上每条边所用权值的数据类型（如果边不需要权值，使用 Empty 作为 EdgeData 即可）。  
抽取的子图通过 Snapshot 类的构造函数来描述：  
```c
Snapshot::Snapshot(
GraphDB & db,
Transaction & txn,
size_t flags = 0,
std::function<bool(VertexIterator &)> vertex_filter = nullptr,
std::function<bool(OutEdgeIterator &, EdgeData &)> out_edge_filter = nullptr
);
```  
其中，db 为数据库句柄，txn 为事务句柄，flags 为生成时使用的选项，可选值包括以下的组合：SNAPSHOT_PARALLEL 表示导出时使用多个线程进行并行；SNAPSHOT_UNDIRECTED 表示需要将导出的图变为无向图。
vertex_filter 是面向点的用户自定义过滤函数，返回值为 true 表示该点需要被包含到待抽取的子图中，反之则表示需要被排除。
out_edge_filter 是面向边的用户自定义过滤函数，返回值为 true 表示该边需要被包含到待抽取的子图中，反之则表示需要被排除。
当过滤函数为缺省值时，则表示需要将所有点/边都包含进来。  
Snapshot 类提供的其它方法请参考详细的 C++ API 文档（olap_on_db.h）。' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.1. Snapshot'}","page_content='Traversal API

1. 简介

TuGraph 强大的在线分析处理（OLAP）能力是其区别于其它图数据库的一个重要特性。
借助 C++ OLAP API（olap_on_db.h），用户可以快速地导出一个需要进行复杂分析的子图，然后在其上运行诸如 PageRank、连通分量、社区发现等迭代式图计算过程，最后根据结果做出相应决策。
导出和计算的过程都可以通过并行处理的方式进行加速，从而实现几乎实时的分析处理，避免了传统解决方案需要将数据导出、转换、再导入（ETL）到专门的分析系统进行离线处理的冗长步骤。  
TuGraph 内置了大量常用的图分析算法和丰富的辅助接口，因此用户几乎不需要自己来实现具体的图计算过程，只需在实现自己的存储过程时将相应算法库的头文件（.h 文件）包含到自己程序中，并在编译时链接相应的动态库文件（.so）即可。
一般情况下，用户需要自己实现的只有将需要分析的子图抽取出来的过程。  
目前 Traversal API 仅支持 C++。' metadata={'Header 1': 'Traversal API', 'Header 2': '1. 简介'}"
当在只读交易中调用函数时，会抛出哪种异常？,"page_content='Java客户端

2.使用示例

2.8.加载存储过程

```java
boolean result = client.loadProcedure(""./test/procedure/khop.so"", ""CPP"", ""khop"", ""SO"", ""test loadprocedure"", true, ""v1"", ""default"");
log.info(""loadProcedure : "" + result);
```
```
@param sourceFile: the source_file contain procedure code
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param codeType: code type, currently supported PY, SO, CPP, ZIP
@param procedureDescription: procedure description
@param readOnly: procedure is read only or not
@param version: The version of procedure
@param graph: the graph to query.
@return: the result of procedure execution
public boolean loadProcedure(String sourceFile, String procedureType, String procedureName, String codeType,
String procedureDescription, boolean readOnly, String version, String graph) throws Exception
```
本接口支持在单机模式和HA模式下使用。其中，由于加载存储过程是写请求，HA模式下的client只能向leader发送加载存储过程请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.8.加载存储过程'}","page_content='QA汇总

数据导入QA

读取oracle数据报错

Q：读取oracle数据报错
""error_message"":""Error parsing file memory_file_stream\n\tError occurred at offset 0, exception detail:\n\tjson reading failed, error msg : std::bad_cast\n>Error line....""，如何解决？
A：看起来像在处理数据的时候遇到特使符号导致报错的，建议用相对较小的表以及数据可以尝试测一下' metadata={'Header 1': 'QA汇总', 'Header 2': '数据导入QA', 'Header 3': '读取oracle数据报错'}","page_content='C++客户端

2.使用示例

2.6.调用存储过程

```C++
std::string str;
bool ret = client.CallProcedure(str, ""CPP"", ""test_plugin1"", ""bcefg"");
```
```
bool CallProcedure(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& param,
double procedure_time_out = 0.0, bool in_process = false,
const std::string& graph = ""default"", bool json_format = true,
const std::string& url = """");
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  url                 (Optional) Node address of calling procedure.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}"
UDF的支持中，如果开发的函数的语言是Python，模块通常放在什么位置？,"page_content='Framework原理介绍

计算引擎

GeaFlow计算引擎核心模块主要包括执行计划生成和优化、统一Cycle调度以及Worker运行时执行。下面就这几个核心模块进行介绍说明。' metadata={'Header 1': 'Framework原理介绍', 'Header 2': '计算引擎'}","page_content='Python Olap API

6. 算法插件示例

下面为Python实现的BFS算法的代码示例：
```python
# cython: language_level=3, cpp_locals=True, boundscheck=False, wraparound=False, initializedcheck=False
# distutils: language = c++

# 注释作用如下：
# language_level=3: 使用Python3
# cpp_locals=True: 需要c++17，使用std::optional管理Python代码中的C++对象，可以避免C++对象的拷贝构造
# boundscheck=False: 关闭索引的边界检查
# wraparound=False: 关闭负数下标的处理（类似Python List）
# initializedcheck=False: 关闭检查内存是否初始化，关闭检查后运行性能更快
# language = c++: 将此py文件翻译为C++而不是C文件，TuGraph使用大量模板函数，所以都应该使用C++

import json

import cython
from cython.cimports.olap_base import *
from cython.cimports.lgraph_db import *
# 从procedures/algo_cython/ 中cimportolap_base.pxd与lgraph_db.pxd, 类似C++中#include ""xxx.h""

from cython.cimports.libc.stdio import printf
# 类似C++中#include <stdio.h>
# 其他常见的还有cython.cimports.libcpp.unordered_map等

import time


@cython.cclass
# cython.cclass 表示BFSCore为C类型的Class
class BFSCore:
graph: cython.pointer(OlapBase[Empty])
# cython.pointer(OlapBase[Empty])表示OlapBase[Empty]的指针，类似C++中OlapBase[Empty]*
# cython提供了常见类型的指针，如cython.p_int, cython.p_char等，表示int*, char*, ...
parent: ParallelVector[size_t]
active_in: ParallelBitset
active_out: ParallelBitset
root: size_t
# root: size_t 声明root为C++ size_t类型变量，等效于root = cython.declare(size_t)
# 不声明类型的变量为Python object类型
# 声明变量类型会大幅提高性能，同时在多线程部分，只有C/C++类型的变量可以访问

@cython.cfunc
# cython.cfunc 表示Work为C类型的函数，参数与返回值应声明
# cfunc性能好，能接受C/C++对象为参数、返回值，但是不能在其他python文件中调用
# 类似的有cython.ccall，如Standalone函数，可以在其他python文件中调用
@cython.nogil
# cython.nogil 表示释放Python全局解释锁，在nogil修饰的部分，不能访问Python对象
# 在多线程部分，都应有nogil修饰器
@cython.exceptval(check=False)
# cython.exceptval(check=False) 表示禁用异常传播，将忽略函数内部引发的Python异常
def Work(self, vi: size_t) -> size_t:
degree = cython.declare(size_t, self.graph.OutDegree(vi))
out_edges = cython.declare(AdjList[Empty], self.graph.OutEdges(vi))
i = cython.declare(size_t, 0)
local_num_activations = cython.declare(size_t, 0)
dst: size_t
for i in range(degree):
dst = out_edges[i].neighbour
if self.parent[dst] == cython.cast(size' metadata={'Header 1': 'Python Olap API', 'Header 2': '6. 算法插件示例'}","page_content='Python Olap API

3. Cython

Cython是一种高效的编程语言，是Python的超集。Cython能将py文件翻译为C/C++代码后编译为Python拓展类，在Python中通过import调用。在TuGraph中，所有的Python plugin都由Cython编译为Python拓展类后使用。  
Cython的Pure Python模式在保证Python语法的同时具有C/C++的性能，TuGraph Python接口均使用Cython实现。  
[Cython 文档](https://cython.readthedocs.io/en/latest/index.html)' metadata={'Header 1': 'Python Olap API', 'Header 2': '3. Cython'}"
在文本中，哪种资源名称对应的颜色设置为固定的“light-orange”？,"page_content='RESTful API Legacy

6.Deprecated

6.11.其他

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/misc
```  
#### 6.11.1.提取子图  
给出点 id 集合，返回包含该集合的最小子图。  
- **URI**: `/db/{graph_name}/misc/sub_graph`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| vertex_ids | 点 id 集合 | 列表 |  
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| nodes | 点数据 | 列表，每元素包含 vid, label, 以及属性 |
| relationships | 边数据 | 列表，每元素包含 src, dst, euid, label, 以及属性 |  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/misc/sub_graph
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""vertex_ids"": [2, 5, 14, 20]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""nodes"": [
{
""label"": ""Person"",
""properties"": {
""birthyear"": 1937,
""name"": ""Vanessa Redgrave""
},
""vid"": 2
},
{
""label"": ""Person"",
""properties"": {
""birthyear"": 1963,
""name"": ""Natasha Richardson""
},
""vid"": 5
},
{
""label"": ""City"",
""properties"": {
""name"": ""London""
},
""vid"": 14
},
{
""label"": ""Film"",
""properties"": {
""title"": ""Camelot""
},
""vid"": 20
}
],
""relationships"": [
{
""destination"": 5,
""label"": ""HAS_CHILD"",
""properties"": {
""birthyear"": 1937,
""name"": ""Vanessa Redgrave""
},
""source"": 2
},
{
""destination"": 14,
""label"": ""BORN_IN"",
""properties"": {
""birthyear"": 1937,
""name"": ""Vanessa Redgrave""
},
""source"": 2
},
{
""destination"": 20,
""label"": ""ACTED_IN"",
""properties"": {
""birthyear"": 1937,
""charactername"": ""Guenevere"",
""name"": ""Vanessa Redgrave""
},
""source"": 2
},
{
""destination"": 14,
""label"": ""BORN_IN"",
""properties"": {
""birthyear"": 1963,
""name"": ""Natasha Richardson""
},
""source"": 5
}
]
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.11.其他'}","page_content='运维监控

2.部署方案

2.4.第四步

+ 下载符合您机器架构以及系统版本的Grafana安装包，下载地址: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)  
+ 安装Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 启动Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 配置Grafana，首先在数据源设置中配置Prometheus的IP地址，配置完成后可以通过测试连接功能，验证是否成功连接数据源。然后，导入如下模版，并在页面中根据实际情况，修改正确的接口IP和端口。最后可以根据实际情况设置刷新时间和监控时间范围  
```json
{
""annotations"": {
""list"": [
{
""builtIn"": 1,
""datasource"": {
""type"": ""grafana""
},
""enable"": true,
""hide"": true,
""iconColor"": ""rgba(0, 211, 255, 1)"",
""name"": ""Annotations & Alerts"",
""target"": {
""limit"": 100,
""matchAny"": false,
""tags"": [],
""type"": ""dashboard""
},
""type"": ""dashboard""
}
]
},
""editable"": true,
""fiscalYearStartMonth"": 0,
""graphTooltip"": 0,
""id"": 2,
""links"": [],
""liveNow"": false,
""panels"": [
{
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
}
},
""mappings"": [],
""unit"": ""kbytes""
},
""overrides"": [
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {__name__=\""resources_report\"", instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
},
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""others""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-blue"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}","page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

#### 6.10.1.指定文件内容导入  
- **URI**: `/db/{graph_name}/import/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |
| data | 要导入的文件内容（建议最大在 16MB 左右，最长不超过 17MB） | 字符串 / 数组 / 对象 |
| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""description"": ""{\\""files\\"":[{\\""columns\\"":[\\""SRC_ID\\"",\\""role\\"",\\""DST_ID\\""],\\""format\\"":\\""CSV\\"",\\""label\\"":\\""role\\"",\\""SRC_ID\\"":\\""actor\\"",\\""DST_ID\\"":\\""movie\\""}]}""}"",
""data"": ""1,Role1,2\n3,Role2,4\n"",
""continue_on_error"": true,
""delimiter"": "",""
}
```  
上述 description 的值是如下 json 序列化后的字符串  
```json
{
""files"": [
{
""format"": ""CSV"",
""label"": ""role"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""log"": ""Missing src uid 1\n""
}
```  
由于请求中指定了在出错时继续，该返回信息说明 SRC_ID 为 1 的边没有被导入，而其他信息导入成功。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}"
导入图库的数据如何删除,"page_content='业务开发指南

子图操作

清空子图

#### 删除所有的点边数据和图schema
```
CALL db.dropDB()
```
#### 只删除所有点边数据, 保留图schema
```
CALL db.dropAllVertex()
```' metadata={'Header 1': '业务开发指南', 'Header 2': '子图操作', 'Header 3': '清空子图'}","page_content='业务开发指南

子图操作

删除子图

```
CALL dbms.graph.deleteGraph('graph1')
```' metadata={'Header 1': '业务开发指南', 'Header 2': '子图操作', 'Header 3': '删除子图'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.4 通过OGM进行删操作**

**DELETE**  
使用session.delete方法删除节点，同时会删除与节点相关联的所有边。  
```java
session.delete(alice); // 删除alice节点以及相连的边

Movie m = session. load(Movie.class, jokes.getId); // EjokesTaMidsiXjokes# 点

session.delete(m);

// 清空数据库

session.deleteAll(Movie.class);

session.purgeDatabase ();

1/ 删除所有Movie节点

// 删除全部数据
```' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.4 通过OGM进行删操作**'}"
当使用 TuGraph 批量创建边时，如果请求成功，响应中将返回什么内容？,"page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='TuGraph-Restful-Server

7.接口

7.7 批量创建schema请求

用户通过此类请求批量创建schema，请求报文在http body 中将创建schema的目标子图和schema信息发送给server，如果拿到返回errorCode为200的响应报文即为正常创建
#### 7.7.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_schema
#### 7.7.2 REQUEST
|  body参数  |    参数说明    |  参数类型  |  是否必填  |
|:--------:|:----------:|:------:| :-----: |
| graph |   创建目标子图   |  字符串  |  是  |
| schema | schema描述信息 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.7 批量创建schema请求'}","page_content='TuGraph-Restful-Server

5.返回值

通用返回格式  
|  body参数  | 参数说明  |  参数类型  |  是否必填  |
|:--------:|:-----:|:------:| :-----: |
| errorCode |  状态码  |  字符串  |  是  |
| errorMessage | 错误信息  |  字符串  |  是  |
| data | 返回的数据 |  字符串  |  是  |  
TuGraph 返回的 HTTP 状态码包含以下四种：  
- 200 OK: 操作成功
- 400 Bad Request: 输入有误，例如 URI 错误，或者请求中的 JSON 参数错误
- 401 Unauthorized: 未通过鉴权认证，例如用户名密码错误，token超过有效期等
- 500 Internal Server Error: 服务器端错误
当操作成功时，返回的 data 中包含操作的返回值。
当发生输入错误或者服务器错误时，返回的 errorMessage 中包含错误提示。' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '5.返回值'}"
TuGraph为什么选择使用B+树作为其底层存储数据结构？,"page_content='性能优先

3.存储数据结构

TuGraph底层采用B+树来支持实时的增删查改事务。  
在排序树的数据结构中，B+树和LSM树为主要代表。B+树在树节点中使用拆分和合并式来更新排序数据，而 LSM 树在日志中追加更新，以进行延迟数据合并。B+ 早期用在文件系统的实现中，通过将数据保存 在自适应长度的叶子节点中，解决硬盘顺序操作和随机操作性能存在数据量级差别的问题，有较均衡的读写性能。LSM 树的主要优势使用 WAL(Write Ahead Log) 进行更新，将更新操作变成顺序操作，在键值较小时性能优势尤为突出。WAL 意味着将数据的更新合并推迟，批量更新能提升综合效率，也使得系统的调度变得复杂。如果更新合并完成前，恰好对其中的数据继续读取，LSM 树就需要读取几个层级局部合并的日志，会导致读取放大和空间放大，从而影响读效率。  
总结来说，B+ 树有较好的顺序读写性能，而 LSM 树在数据随机写方面占优。此外 LSM 树采用后台合并的方式，使得性能的波动难以预期，性能波动和上层存储和计算的关联性较弱，增加了整体设计的成本。综上考虑，TuGraph 选用 B+ 树作为读性能优先的实现。' metadata={'Header 1': '性能优先', 'Header 2': '3.存储数据结构'}","page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}","page_content='TuGraph在图计算系统建设中的作用

TuGraph 技术优势

蚂蚁自己开发了一套图计算系统 TuGraph，既能解决图数据的存储问题，也能解决流式计算、离线计算和图学习的问题。目前，超过 100 个业务线和 300 多个场景都在使用这套系统。这套系统在 2021 年获得了世界互联网大会领先科技成果奖。  
在 TuGraph 中，性能是一个重要的因素，因为图数据集的体积很大，如果性能不佳就会浪费机器资源，导致许多情况下无法完成任务。比如，希望业务的查询能在几十毫秒内返回结果，但是如果做的性能不好，几秒钟才能返回结果，就无法作为在线查询使用。因此，我们是非常对性能是很重视的，其中在 LDBC-SNB 标准测试中（类似于数据库领域性能标准测试 TPC-C），TuGraph 仍然是世界纪录的保持者。  
TuGraph 的整个图存储是建立在完美哈希的基础上的，这是我们与其他图系统的一个重要区别。目前，大多数图系统使用的是基于数的存储，但数的问题在于永远存在一个 LogN 的查找操作。然而，在图中可以看到，不同的顶点之间实际上是无序的，不需要有顺序，所以顶点这个级别实际上是基于哈希的，理论上，顶点的读取是最优的。  
此外，TuGraph 还参与了许多标准的定制，整个系统在尽量往标准化的方向去做。  
除了为内部提供服务，我们还向外提供服务，主要是因为，作为一个系统，如果只为有限的客户提供服务，就很容易构建成一个专有系统。我们希望这是一个标准化、开放的系统，所以我们也在对外提供图计算系统的产品和服务。目前，我们也有很多外部客户，包括金融、工业、互联网以及政企领域。  
开源开放，共建发展  
整个图计算系统目前仍处于较早期的阶段，我们认为还有很多工作要做，包括提升应用性、性能和降低成本。所有的系统都会有这些问题。但是，如果希望普及，我们认为最重要的是有健康的生态，来推动图计算系统的发展，需要有更多的用户和更多的场景使用这个系统。  
所有的计算机系统都需要去有一个更开放、更大的生态才能促进发展。蚂蚁有一句话叫做“成熟一个、开放一个”，一个系统成熟以后，我们就会试着开放出去，让更多的人去用。今年 9 月，我们已经在 GitHub 上开源了 TuGraph 中的单机版图数据库，以及一个离线图分析引擎 TuGraph Compute。分布式图数据库和流式图计算现在已经包含在我们的商业化版本中，包括一站式图研发平台。我们计划在未来迭代更多更丰富的系统功能，希望能做得更好。' metadata={'Header 1': 'TuGraph在图计算系统建设中的作用', 'Header 2': 'TuGraph 技术优势'}"
"接口 ""CallProcedureToLeader"" 支持哪些参数设置以改变返回结果的格式？","page_content='Java客户端

2.使用示例

2.7.向leader调用存储过程

```java
String result = client.callProcedureToLeader(""CPP"", ""khop"", kHopParamGen(), 1000, false, ""default"");
log.info(""testCallProcedureToLeader : "" + result);
```
```
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param param: the execution parameters
@param procedureTimeOut: Maximum execution time, overruns will be interrupted
@param inProcess: Running query or not
@param graph: the graph to query
@param jsonFormat: (Optional) Return format of calling stored procedure
@return: the result of procedure execution
public String callProcedureToLeader(String procedureType, String procedureName, String param, double procedureTimeOut,
boolean inProcess, String graph)
```
本接口支持在HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.7.向leader调用存储过程'}","page_content='Python客户端

3.RPC Client

3.7.向leader调用存储过程

```python
ret, res = client.callProcedureToLeader(""CPP"", ""khop"", kHopParamGen(), 1000, false, ""default"")
```
```
callProcedureToLeader(self: liblgraph_client_python.client, procedure_type: str, procedure_name: str, param: str, procedure_time_out: float, in_process: bool, graph: str, json_format: bool) -> (bool, str)
```
本接口支持在HA模式下使用，默认以字符串格式直接返回存储过程的执行结果，指定jsonFormat为true可以返回json格式的执行结果。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.7.向leader调用存储过程'}","page_content='C++客户端

2.使用示例

2.7.向leader调用存储过程

```C++
std::string str;
bool ret = client.CallProcedureToLeader(str, ""CPP"", ""test_plugin1"", ""bcefg"");
```
```
bool CallProcedureToLeader(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& param,
double procedure_time_out = 0.0, bool in_process = false,
const std::string& graph = ""default"", bool json_format = true);
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@returns True if it succeeds, false if it fails.
```
本接口支持在HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.7.向leader调用存储过程'}"
如何提高查询效率？,"page_content='QA汇总

Cypher QA

拼接查询慢

Q：查询语句 Where 后使用 and 进行拼接查询速度较慢，语句应如何优化改进？
示例：  
```
MATCH (n1),(n2) CALL algo.allShortestPaths(n1,n2)
YIELD nodeIds,relationshipIds,cost
WHERE id(n1) IN [0] AND id(n2) IN [3938]
RETURN nodeIds,relationshipIds,cost
```  
A：目前 cypher 查询引擎正在优化中。现阶段语句改写可以通过 with 向下传递进行优化。
示例：  
```
MATCH (n1) where id(n1) in [0] with n1
MATCH (n2) where id(n2) in [3938] with n1, n2
CALL algo.allShortestPaths(n1,n2) YIELD nodeIds,relationshipIds,cost
RETURN nodeIds,relationshipIds,cost
```' metadata={'Header 1': 'QA汇总', 'Header 2': 'Cypher QA', 'Header 3': '拼接查询慢'}","page_content='GeaFlow Dashboard

其他功能

列表排序与查询

部分列表的列可以进行排序和查询。  
查询时，点击“搜索”标识，输入关键字，点击“搜索”按钮即可。  
重置时，点击“重置”按钮，列表会重新刷新。  
![dashboard_table_search.png](../static/img/dashboard_table_search.png)' metadata={'Header 1': 'GeaFlow Dashboard', 'Header 2': '其他功能', 'Header 3': '列表排序与查询'}","page_content='性能优先

4.数据编码

对于属性图模型而言，除了图拓扑编码外，属性数据也会很大程度影响功能和性能，我们先讨论属性数据如何与拓扑数据共存的编码格式。从目前的调研来看，属性编码有两种方式，我们称之为基于指针索引将属性数据单独存储的离散编码，和将属性数据和拓扑数据打包在一起的紧凑编码。离散编码根据程度的不同，可以每个属性都单独存储，或者每条边的属性打包后各自存储，下面的讨论对两种情况都适用。  
点查询。属性编码主要针对边，不涉及点查询。  
单边查询。离散编码通过指针定位边，紧凑编码则需要二分查找定位边的位置，离散编码有略微的优势。  
边遍历。离散编码在边遍历过程需要不断地进行指针跳转进行随机数据访问，而紧凑编码提前把数据排列在一起，顺序访问的特性使得效率大大提升。 由规律三知对边的遍历操作很普遍，紧凑编码在边遍历的优势明显。  
单边更新。离散编码对边的更新仅需找到对应的指针位置，插入数据后修改前后指针指向。紧凑编码则需要对紧凑排列的数据进行重编码，对整个边值进行重新写入，开销显著大于离散编码的情形。  
批量边更新。批量更新可以在内存中预先构建点的所有边属性，一次性编码写入，离散编码和紧凑编码相当。但紧凑编码不需要存储指针变量，更少的存储空间效率也会更高。  
以上离散编码和紧凑编码在某一类的查询的性能问题，可以通过优化的来缓解。整体上说，由于图负载读写 20:1 的特性，读性能在整体性能中占比更高。以及规律三所揭示的对属性访问的特征，TuGraph 更倾向于采用紧凑编码来保证读性能。其主要弱势为单边更新时重编码的开销，可以用自适应映射的技术来解决。' metadata={'Header 1': '性能优先', 'Header 2': '4.数据编码'}"
FieldData 类中的 integer() 方法在什么情况下会抛出 std::bad_cast 异常？,"page_content='QA汇总

数据导入QA

读取oracle数据报错

Q：读取oracle数据报错
""error_message"":""Error parsing file memory_file_stream\n\tError occurred at offset 0, exception detail:\n\tjson reading failed, error msg : std::bad_cast\n>Error line....""，如何解决？
A：看起来像在处理数据的时候遇到特使符号导致报错的，建议用相对较小的表以及数据可以尝试测一下' metadata={'Header 1': 'QA汇总', 'Header 2': '数据导入QA', 'Header 3': '读取oracle数据报错'}","page_content='Java客户端

2.使用示例

2.12.从字节流中导入点边数据

```java
boolean ret = client.importDataFromContent(personDesc, person, "","", true, 16, ""default"", 1000);
log.info(""importDataFromContent : "" + ret);
```
```
@param desc: data format description
@param data: the data to be imported
@param delimiter: data separator
@param continueOnError: whether to continue when importing data fails
@param threadNums: maximum number of threads
@param graph: the graph to query.
@param timeout: Maximum execution time, overruns will be interrupted
@return: the result of import data
public boolean importDataFromContent(String desc, String data, String delimiter, boolean continueOnError,
int threadNums, String graph, double timeout) throws UnsupportedEncodingException
```
本接口支持在单机模式和HA模式下使用。其中，由于导入点边数据是写请求，HA模式下的client只能向leader发送导入点边数据请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.12.从字节流中导入点边数据'}","page_content='C++客户端

2.使用示例

2.6.调用存储过程

```C++
std::string str;
bool ret = client.CallProcedure(str, ""CPP"", ""test_plugin1"", ""bcefg"");
```
```
bool CallProcedure(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& param,
double procedure_time_out = 0.0, bool in_process = false,
const std::string& graph = ""default"", bool json_format = true,
const std::string& url = """");
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  param               the execution parameters.
@param [in]  procedure_time_out  (Optional) Maximum execution time, overruns will be
interrupted.
@param [in]  in_process          (Optional) support in future.
@param [in]  graph               (Optional) the graph to query.
@param [in]  json_format         (Optional) Returns the format， true is json，Otherwise,
binary format.
@param [in]  url                 (Optional) Node address of calling procedure.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用，默认以json格式直接返回存储过程的执行结果，指定jsonFormat为false可以返回字符串格式的执行结果。
其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.6.调用存储过程'}"
TuGraph-DB的存储引擎用了kv数据库么？如果是，基于什么kv数据库构建的？,"page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}","page_content='TuGraph产品架构

1.简介

![产品架构](../../../images/architecture.png)  
上图从功能模块的角度，以 TuGraph 为例，给出了企业级图数据库的整体架构，自下而上包括：  
- 软硬件环境。涉及图数据库的开发和使用环境。TuGraph 主要基于底层的 C++语言开发，能够兼容市面上大部分操作系统和 CPU。
- 存储层，包括 KV 存储层和图存储层。存储层需要支持计算层所需的各个功能。
- 计算层。计算层应包括图事务引擎、图分析引擎和图神经网络引擎，也包含了服务端提供的多种编程接口，包括描述式查询语言 Cypher，存储过程等。
- 客户端。客户端 SDK 应支持 Java、Python、C++ 等多种语言，也支持命令行的交互方式。Browser 和 Explorer 通过网页端交互的方式，降低了图数据库的使用门槛。
- 在生态工具方面，覆盖了企业级图数据库的开发、运维、管理等链路，提升可用性。' metadata={'Header 1': 'TuGraph产品架构', 'Header 2': '1.简介'}"
请问下怎么没找到新版的browser-resource，怎么进行新旧版本的web切换呢,"page_content='快速上手

2.安装

2.2.新旧前端说明

进入容器，可以通过修改配置文件""/usr/local/etc/lgraph.json""中的""web""参数来选择使用老版本或新版本的前端。对于老版本，可以将""web""的值设为""/usr/local/share/lgraph/resource""；对于新版本，可以将""web""的值设为""/usr/local/share/lgraph/browser-resource""。完成配置文件的修改后，请执行命令 `docker restart tugraph` 以使更改生效。需要注意的是，新版本是默认选项。' metadata={'Header 1': '快速上手', 'Header 2': '2.安装', 'Header 3': '2.2.新旧前端说明'}","page_content='数据库运行

3.服务操作

3.4.新旧前端切换

进入容器，可以通过修改配置文件""/usr/local/etc/lgraph.json""中的""web""参数来选择使用老版本或新版本的前端。对于老版本，可以将""web""的值设为""/usr/local/share/lgraph/resource""；对于新版本，可以将""web""的值设为""/usr/local/share/lgraph/browser-resource""。完成配置文件的修改后，请执行命令 `docker restart tugraph` 以使更改生效。需要注意的是，新版本是默认选项。' metadata={'Header 1': '数据库运行', 'Header 2': '3.服务操作', 'Header 3': '3.4.新旧前端切换'}","page_content='安装指南

启动容器

本地启动GeaFlow Console平台服务，适用于minikube环境。（需要将${your.host.name}替换为本机对外IP地址）  
```shell
docker run -d --name geaflow-console -p 8888:8888 -p 3306:3306 -p 6379:6379 -p 8086:8086 -e geaflow.host=${your.host.name} geaflow-console:0.1
```  
启动对外GeaFlow Console平台服务，适用于K8S真实集群环境。（需要将${your.host.name}替换为本机内网IP地址，例如172.xx.xxx.xx；${your.public.ip} 替换为外部公网IP地址，才能从外部访问GeaFlow Console）
```shell
docker run -d --name geaflow-console -p 8888:8888 -p 3306:3306 -p 6379:6379 -p 8086:8086 -e geaflow.host=${your.host.name} geaflow-console:0.1
```  
容器默认以本地模式（local）启动，默认拉起本地的MySQL、Redis、InfluxDB。
```properties
# /opt/geaflow/config/application.properties
geaflow.deploy.mode=local
geaflow.host=127.0.0.1
geaflow.gateway.port=8888
geaflow.gateway.url=http://${geaflow.host}:${geaflow.gateway.port}

# Datasource
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://${geaflow.host}:3306/geaflow?useUnicode=true&characterEncoding=utf8
spring.datasource.username=geaflow
spring.datasource.password=geaflow
```  
进入容器等待geaflow-web进程启动完成后，访问[localhost:8888](http://localhost:8888)进入GeaFlow Console平台页面。
K8S集群环境这里为访问对外IP地址的8888端口。
```shell
> docker exec -it geaflow-console tailf /tmp/logs/geaflow/app-default.log

# wait the logs below and open url http://localhost:8888
GeaflowApplication:61   - Started GeaflowApplication in 11.437 seconds (JVM running for 13.475)
```  
若希望以集群模式（cluster）启动容器，需要调整datasource配置指向外部数据源，并设置对外的统一服务url地址。容器支持环境变量注入数据源配置和服务url，例如：
```shell
docker run -d --name geaflow-console -p 8888:8888 \
-e geaflow.deploy.mode=""cluster"" \
-e geaflow.host=${your.host.name} \
-e geaflow.gateway.port=8888 \
-e geaflow.gateway.url=${your.geaflow.gateway.url} \
-e spring.datasource.url=${your.datasource.url} \
-e spring.datasource.username=${your.datasource.username} \
-e spring.datasource.password=${your.datasource.password} \
geaflow-console:1.0
```  
如果希望Java进程端口号，只需设置geaflow.gateway.port环境变量，并重新映射端口号即可，如：
```shell
docker run -d --name geaflow-cons' metadata={'Header 1': '安装指南', 'Header 2': '启动容器'}"
tugraph进行大规模数据查询时是否对图数据进行了压缩？,"page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}","page_content='功能概览

4.核心功能

4.5 数据预热

TuGraph 是基于磁盘的图数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.5 数据预热'}","page_content='TuGraph与ARM架构

内容：

**测试介绍：**

TuGraph在测试中使用Client/Server分离的模式，来模拟真实的用户使用场景。在结果中，TuGraph在不同规模的数据集下均表现优异，在大规模100GB的数据集（2.8亿个点，18亿条边）上，TuGraph的吞吐率较上一次官方纪录提升了31%。在300GB数据集上，TuGraph测试了超过内存容量的数据吞吐量，虽然较100GB的性能有所下降，但考虑内存和硬盘的读写性能鸿沟，该结果也在预期之内。**除了性能测试，TuGraph在****系统事务性、可恢复性、正确性、稳定性等方面均达到官方标准，体现了TuGraph高并发低延迟的强大性能优势。**  
在性能测试中，我们发现并解决了一些值得注意的问题。其一是有的系统页大小默认为64KB，这个对图系统随机数据读写并不友好，调整为X86更普遍的4KB有助于提升性能。其二是在云上使用云盘，会比本地硬盘的读写带宽和稳定性差很多，如果能够在测试前进行数据预热和及时的硬盘性能监控，更有助于获得理想的结果。' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '内容：', 'Header 3': '**测试介绍：**'}"
TuGraph选择使用哪一种树结构作为其存储数据结构，并简述选择这种结构的主要原因是什么？,"page_content='性能优先

3.存储数据结构

TuGraph底层采用B+树来支持实时的增删查改事务。  
在排序树的数据结构中，B+树和LSM树为主要代表。B+树在树节点中使用拆分和合并式来更新排序数据，而 LSM 树在日志中追加更新，以进行延迟数据合并。B+ 早期用在文件系统的实现中，通过将数据保存 在自适应长度的叶子节点中，解决硬盘顺序操作和随机操作性能存在数据量级差别的问题，有较均衡的读写性能。LSM 树的主要优势使用 WAL(Write Ahead Log) 进行更新，将更新操作变成顺序操作，在键值较小时性能优势尤为突出。WAL 意味着将数据的更新合并推迟，批量更新能提升综合效率，也使得系统的调度变得复杂。如果更新合并完成前，恰好对其中的数据继续读取，LSM 树就需要读取几个层级局部合并的日志，会导致读取放大和空间放大，从而影响读效率。  
总结来说，B+ 树有较好的顺序读写性能，而 LSM 树在数据随机写方面占优。此外 LSM 树采用后台合并的方式，使得性能的波动难以预期，性能波动和上层存储和计算的关联性较弱，增加了整体设计的成本。综上考虑，TuGraph 选用 B+ 树作为读性能优先的实现。' metadata={'Header 1': '性能优先', 'Header 2': '3.存储数据结构'}","page_content='技术规划

1. 简介

该文档是 TuGraph-DB 未来开发的规划，包括正在开发中、不在开发计划里、已经开发完成但不在开源版本里的功能等。  
TuGraph-DB定位开源高性能图数据库，图数据采用集中存储的方式，短期 **不会** 考虑基于分片（Sharding）的数据切分，
而将支持主备复制的模式来解决高并发读的场景，采用云上存储解决存储容量的问题。' metadata={'Header 1': '技术规划', 'Header 2': '1. 简介'}","page_content='TuGraph产品架构

1.简介

![产品架构](../../../images/architecture.png)  
上图从功能模块的角度，以 TuGraph 为例，给出了企业级图数据库的整体架构，自下而上包括：  
- 软硬件环境。涉及图数据库的开发和使用环境。TuGraph 主要基于底层的 C++语言开发，能够兼容市面上大部分操作系统和 CPU。
- 存储层，包括 KV 存储层和图存储层。存储层需要支持计算层所需的各个功能。
- 计算层。计算层应包括图事务引擎、图分析引擎和图神经网络引擎，也包含了服务端提供的多种编程接口，包括描述式查询语言 Cypher，存储过程等。
- 客户端。客户端 SDK 应支持 Java、Python、C++ 等多种语言，也支持命令行的交互方式。Browser 和 Explorer 通过网页端交互的方式，降低了图数据库的使用门槛。
- 在生态工具方面，覆盖了企业级图数据库的开发、运维、管理等链路，提升可用性。' metadata={'Header 1': 'TuGraph产品架构', 'Header 2': '1.简介'}"
TuGraph-DB使用的boost库是什么版本？,"page_content='技术规划

2. 已完成功能

TuGraph-DB于2022年9月1日开源，TuGraph-DB在社区的反馈声中，进行日常BUG修复，自身能力得到了完善。  
| 版本号   | 功能                               | 时间         |
|-------|----------------------------------|------------|
| 3.3.0 | 开源初版                             | 2022.9.1   |
| 3.3.1 | 图分析引擎重构，多模式支持                    | 2022.10.14 |
| 3.3.2 | OGM支持，UT覆盖率提升                    | 2022.11.21 |
| 3.3.3 | 链接认证机制迭代，加入英文文档                  | 2022.12.23 |
| 3.3.4 | 支持上云，梳理LDBC SNB Audit流程          | 2023.1.28  |
| 3.4.0 | 支持OLAP Python API, 离线导入升级        | 2023.3.11  |
| 3.5.0 | 支持POG，前端升级，文档梳理                  | 2023.6.5   |
| 3.5.1 | 图学习引擎，Procedure Rust API，存储属性分离  | 2023.7.14  |
| 3.6.0 | 高可用开源，日志系统升级                     | 2023.8.11  |
| 4.0.0 | ISO GQL支持，新增11个开源图算法，支持m1 Docker | 2023.9.6   |
| 4.0.1 | 支持时序边排序，新增5个开源图算法                | 2023.9.28  |
| 4.1.0 | 支持Bolt协议，支持快速在线全量导入，支持地理空间数据类型   | 2023.12.25 |  
除此之外，TuGraph-DB搭建了较为完善的质量体系，涵盖自动化的单元测试、集成测试、性能测试等。  
更详细的描述可以在源码目录在的 ""[root]/release/CHANGELOG.md"" 文件查看。' metadata={'Header 1': '技术规划', 'Header 2': '2. 已完成功能'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}","page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。  
蚂蚁集团 2015 年开始自主研发分布式图数据库、流式图计算等图相关技术，2016 年发布自研分布式图数据库，并应用于支付宝。至今 TuGraph 已应用于蚂蚁内部 150 多个场景，包括在线支付的实时链路，以支付宝风险识别能力提升近 10 倍、风险审理分析效率提升 90%的成绩，验证了其高可靠性。  
LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，TuGraph 在功能完整性、吞吐率、响应速度等层面全球领先。  
目前，蚂蚁集团已形成了一套以图数据库为底座、同时包含流式图计算，离线图学习的大规模图计算系统。  
蚂蚁集团图数据库负责人洪春涛表示，图技术是未来大数据、人工智能和高性能计算产业发展的关键所在，它很有可能会成为下一代的数据底座。蚂蚁集团愿意通过开源持续输出核心技术优势，推动图数据库更广泛的应用生态，携手行业抢占技术高地，不断探索技术的可能性。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}"
TuGraph适合哪些类型的用户？,"page_content='环境和版本选择

1. 简介

TuGraph为不同需求的用户提供了差异化的系统环境和部署方式，来满足新手、系统开发者、生产运维人员、研究人员等不同用户的需求。' metadata={'Header 1': '环境和版本选择', 'Header 2': '1. 简介'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='快速上手

1.简介

1.1.支持的平台

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的的平台。' metadata={'Header 1': '快速上手', 'Header 2': '1.简介', 'Header 3': '1.1.支持的平台'}"
TuGraph的REST API中，POST请求主要用途是什么？,"page_content='RESTful API Legacy

2.请求与数据格式

2.1请求

TuGraph 支持 HTTP GET/POST/PUT/DELETE 请求。其中：  
- GET 请求用于只读请求，如读取点属性，边属性等操作；
- POST 请求用于创建实体，提交 Cypher，以及加载和调用存储过程；
- PUT 请求用于修改已有实体，如修改点属性，边属性等；
- DELETE 请求用于删除已有实体，如删除点，边等。  
在高可用模式下，用户可以在请求的报头(request header)中设置 `server_version` 来保证请求的服务器有足够新的数据。
当前的 `server_version` 可以从服务器返回的报头中获取。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '2.请求与数据格式', 'Header 3': '2.1请求'}","page_content='RESTful API Legacy

1.简介

TuGraph 提供遵从 REST 规范的 HTTP API，以供开发者通过 HTTP 请求远程调用 TuGraph 提供的服务。  
本文档描述 TuGraph 的 HTTP API 使用方式。  
**注意：除""登陆""、""查询""和""存储过程""外，其余接口自 **2023年4月30日** 起将不再提供支持，统一使用Cypher接口提供服务。**' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '1.简介'}","page_content='RESTful API Legacy

2.请求与数据格式

2.4.URI格式

TuGraph REST API 提供以下功能：Service Root, login, info, label, index, node, relationship, cypher, cpp_plugin, 以及 python_plugin。
各功能使用的 URI 格式如下：  
| URI     | 说明                 |
| ------- | -------------------- |
| /web    | web 可视化界面       |
| /cypher | cypher 请求          |
| /acl    | 权限控制             |
| /user   | 用户管理             |
| /login  | 用户登录             |
| /info   | 数据库状态及提示信息 |
| /task   | 任务管理             |
| /db     | 子图操作             |  
其中子图操作又分为：  
| URI                              | 说明                 |
| -------------------------------- | -------------------- |
| /db                              | 子图的创建，删除     |
| /db/_{graph_name}_/node          | 点操作             |
| /db/_{graph_name}_/relationship  | 边操作               |
| /db/_{graph_name}_/label         | Label 相关操作       |
| /db/_{graph_name}_/index         | 索引相关操作         |
| /db/_{graph_name}_/cypher        | 子图相关 cypher 操作 |
| /db/_{graph_name}_/cpp_plugin    | C++存储过程          |
| /db/_{graph_name}_/python_plugin | Python 存储过程      |
| /db/_{graph_name}_/import        | 在线导入             |
| /db/_{graph_name}_/misc          | 其它操作             |' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '2.请求与数据格式', 'Header 3': '2.4.URI格式'}"
安装部署TuGraph外存配置的最低和建议分别是多少？,"page_content='环境准备

1.硬件环境

1.3. 外存

我们强烈建议用户使用 NVMe SSD 作为外存，数据库有大量的写操作需要同步的外存，通常为随机写，外存的读写性能很容易成为整体数据库运行的性能瓶颈。因此，高IOPS、低延迟的 NVMe SSD 是最优的选择。  
如果现实条件只能使用 SATA接口的SSD，或者云上的网盘，性能虽然会受到影响，但 TuGraph 依然能正确的运行。  
外存大小建议为实际数据大小的4倍，比如数据为1TB，则准备4TB的硬盘会比较稳妥。' metadata={'Header 1': '环境准备', 'Header 2': '1.硬件环境', 'Header 3': '1.3. 外存'}","page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='云部署

2.实例说明

TuGraph部署的为社区开源版本，源码参考Github Repo，目前可以选择的实例规格如下：  
| 规格族         | vCPU与内存                 | 系统盘              | 公网带宽      |
|----------------|-------------------------|-------------------|-----------|
| ecs.r7a.xlarge | AMD 内存型 r7a，4vCPU 32GiB | ESSD云盘 200GiB PL0 | 固定带宽1Mbps |
| ecs.r6.xlarge  | 内存型r6，4vCPU 32GiB       | ESSD云盘 200GiB PL0 | 固定带宽1Mbps |  
预估费用在创建实例时可实时看到（目前为免费）。 如需更多规格、其他服务（如集群高可用性要求、企业级支持服务等），请联系我们 tugraph@service.alipay.com。' metadata={'Header 1': '云部署', 'Header 2': '2.实例说明'}"
在创建一个TuGraph数据库时，如果指定的目录不存在，构造函数会如何处理？,"page_content='数据库运行

1.前置条件

TuGraph 运行的前置条件为 TuGraph 正确安装，参考[安装流程](1.environment.md)。  
TuGraph 运行需要保证库文件 liblgraph.so 的文件位置在环境变量 LD_LIBRARY_PATH。  
运行 TuGraph 进程的用户不需要超级权限，但需要对配置文件（一般为lgraph.json）及文件中涉及的文件有读权限，并且对数据文件夹、日志文件夹等有写权限。' metadata={'Header 1': '数据库运行', 'Header 2': '1.前置条件'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='Learn Tutorial

3.TuGraph编译及数据准备

TuGraph编译请参考：[编译](../../5.installation&running/6.compile.md)
在build/output目录下执行：
```bash
cp -r ../../test/integration/data/ ./ && cp -r ../../learn/examples/* ./
```  
该指令将数据集相关文件拷贝到build/output目录下。' metadata={'Header 1': 'Learn Tutorial', 'Header 2': '3.TuGraph编译及数据准备'}"
VertexIterator 的 GetNumOutEdges 方法默认的 n_limit 参数值是多少？,"page_content='Cypher API

5.附录2. 内置procedures列表

* algo.algo.native.extract(id, config))

get the field values of a list of vertexes or edges.  
**Parameters:**  
| parameter | parameter type | description                        |
| --------- | -------------- | ---------------------------------------------------------- |
| id    | ANY        | the id of vertexes or edges , the id must be variable      |
| config    | MAP        | the configuration of  this extraction of vertexes or edges |  
in which each `config` is a map in the form of `{isNode:true, filed:'HAS_CHILD'}`, if `isNode` is specified true, the `id` is a vertex id, or  it is an edge id.  
**Output:**  
If successful, it returns a list of the value of vertexes or edges specified field .  
**Example input:**  
```
with [2,3] as vids CALL algo.native.extract(vids,{isNode:true, field:'id'})
YIELD value  RETURN value
```  
**Example output:**  
| value |
| ----- |
| [4,5] |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* algo.algo.native.extract(id, config))'}","page_content='Python Olap API

4. Olap API

图类OlapBase

- `NumVertices()-> size_t`：获取点数
- `NumEdges()-> size_t`：获取边数
- `OutDegree(size_t vid)-> size_t`：点vid的出度
- `InDegree(size_t vid)-> size_t`：点vid的入度  
- `AllocVertexArray[VertexData]() ->ParallelVector[VertexData]`：分配一个类型为VertexData的数组，大小为点个数
- `AllocVertexSubset()-> ParallelBitset`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `OutEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有出边集合
- `InEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有入边集合
- `Transpose()-> cython.void`：对有向图进行图反转
- `LoadFromArray(edge_array: cython.p_char, input_vertices: size_t, input_edges: size_t, edge_direction_policy: EdgeDirectionPolicy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。  
- `AcquireVertexLock(vid: size_t)-> cython.void`：对点vid加锁，禁止其它线程对该锁对应的点数据进行访存
- `void ReleaseVertexLock(vid: size_t)-> cython.void`：对点vid解锁，所有线程均可访存该锁对应的点数据  
TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程，在Python中与C++使用方法稍有不同。  
```python
# 函数名称:ProcessVertexInRange[ReducedSum, Algorithm](
#           work: (algo: Algorithm, vi: size_t)-> ReducedSum,
#           lower: size_t, upper: size_t,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#     函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
#     第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
#     具体实现请参考include/lgraph/olap_base.h中具体代码
#
#     使用示例:统计数组parent数组中有出边的点个数

import cython
from cython.cimports.olap_base import *


@cython.cclass
class CountCore:
graph: cython. pointer(OlapBase[Empty])
parent: ParallelVector[size_t]

@cython.cfunc
@cython.nogil
def Work(self, vi: size_t) -> size_t:
if self.graph.OutDegree(self.parent[vi]) > 0:
return 1
return 0

def run(self, pointer_g: cython' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}","page_content='OlapBase API

7. 图类OlapBase

7.1 基本信息

- `size_t NumVertices()`：获取点数
- `size_t NumEdges()`：获取边数
- `size_t OutDegree(size_t vid)`：点vid的出度
- `size_t InDegree(size_t vid)`：点vid的入度' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.1 基本信息'}"
试图加入高可用集群时节点的默认等待秒数是多少？,"page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

二、TuGraph-DB高可用架构与规划

1.Server架构设计—启动集群

上面是我们选择的一个基础算法，下面介绍 TuGraph-DB 具体的高可用架构是怎样设计的。通过一个 CASE 来进行讲解。  
首先建立一个集群，启动集群的方式跟单机版几乎是一致的，只不过要加上 enable\_ha 参数和 ha\_conf 参数去指定集群里面所有节点的 URL，并且要保证三个或者五个节点是可以进行通信的。在三个节点同时启动后，最先启动的节点的计时器会超时，把自己选成一个候选者，之后向其它节点发送一个投票请求，其它节点接收到请求之后，会返回给候选者一个 success 的 response，当超过半数之后，这个 leader 就当选了。一般来说，在同城的情况下，延迟不会超过 2 毫秒，在两地的情况下，比如上海到深圳，最高延迟不会超过 30 毫秒，所以集群建立的时间和选举的时间是非常快的。' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '二、TuGraph-DB高可用架构与规划', 'Header 3': '1.Server架构设计—启动集群'}","page_content='部署高可用模式

1.原理

TuGraph 通过多机热备份来提供高可用（HA）模式。在高可用模式下，对数据库的写操作会被同步到所有服务器（非witness）上，这样即使有部分服务器宕机也不会影响服务的可用性。  
高可用模式启动时，多个 TuGraph 服务器组成一个备份组，即高可用集群。每个备份组由三个或更多 TuGraph 服务器组成，其中某台服务器会作为`leader`，而其他复制组服务器则作为`follower`。写入请求由`leader`
提供服务，该`leader`将每个请求复制同步到`follower`，并在请求同步到服务器后才能响应客户端。这样，如果任何服务器发生故障，其他服务器仍将具有到目前为止已写入的所有数据。如果`leader`
服务器发生故障，其他服务器将自动选择出新的`leader`。  
TuGraph的高可用模式提供两种类型的节点：`replica`节点和`witness`节点。其中，`replica`节点是普通节点，有日志有数据，可对外提供服务。
而`witness`节点是一种只接收心跳和日志但不保存数据的节点。根据部署需求，`leader`节点和`follower`节点可以灵活的部署为`replica`节点或`witness`节点。
基于此，TuGraph高可用模式的部署方式有两种：一是普通部署模式，二是带witness的简约部署模式。  
对于普通部署模式，`leader`和所有`follower`均为`replica`类型的节点。写入请求由`leader`提供服务，该`leader`将每个请求复制同步到`follower`，
并在请求同步到超过半数的服务器后才能响应客户端。这样，如果少于半数的服务器发生故障，其他服务器仍将具有到目前为止已写入的所有数据。如果`leader`
服务器发生故障，其他服务器将自动选举出新的`leader`，通过这种方式保证数据的一致性和服务的可用性。  
然而，在用户服务器资源不够或者发生网络分区时，不能建立正常的HA集群。此时，由于`witness`节点没有数据，对资源占用小，可以将`witness`节点和`replica`节点部署在一台机器上。
例如，当只有2台机器的情况下，可以在一台机器上部署`replica`节点，在另一台机器上部署`replica`节点和`witness`节点，不仅节省资源，而且不需要把日志应用到状态机上，
也不需要生成和安装快照，因此响应请求的速度很快，可以在集群崩溃或网络分区时协助快速选举出新的`leader`，这就是TuGraph HA集群的简约部署模式。
尽管`witness`节点有诸多好处，但是由于没有数据，集群实际上增加了一个不能成为`leader`的节点，因此可用性会略有降低。为提高集群的可用性，
可通过指定`ha_enable_witness_to_leader`参数为`true`，允许`witness`节点临时当主。`witness`节点在把新日志同步到其他节点之后，
会将leader角色主动切换到有最新日志的节点。  
v3.6及以上版本支持此功能。' metadata={'Header 1': '部署高可用模式', 'Header 2': '1.原理'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

三、TuGraph-DB高可用集群部署与应用

2.高可用集群部署

当原始数据一致的时候，可以直接指定 HA configure 参数启动集群。当初始数据不一致的时候，假如有一个节点有数据，其它节点没有数据，需要把数据同步到其它节点，但是又不能通过 SCP 传，那么就可以通过初始数据不一致的方式去启动。有数据的节点用 bootstrap 方式启动，预先生成一个快照，然后其它节点以 follower 的身份加入集群，加入集群时会安装快照，安装快照之后才会进行选举和 follower 身份的确认。  
初始数据一致:  
• 所有节点数据相同或没有数据时，可以直接指定ha_conf参数启动集群  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true \ --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090`  
初始数据不一致:  
• 有数据的节点使用bootstrap方式启动，预先生成快照  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090 --ha_bootstrap_role 1`  
• 无数据的节点直接以follower的身份加入安装快照，无需再选举  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090 —-ha_bootstrap_role 2`' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '三、TuGraph-DB高可用集群部署与应用', 'Header 3': '2.高可用集群部署'}"
生成Mapper接口的时候，XMLMAPPER类型将如何实现接口方法？,"page_content='多层级接口

3.服务端接口

服务端接口包括描述式图查询语言 Cypher、过程式图查询语言 Procedure API、图分析编程框架 OLAP API 和图神经网络编程框架 GNN PI，为图事务引擎、图分析引擎、图神经网络引擎提供服务，下面先展开介绍各个接口的特点。  
> __描述式图查询语言__ 是对查询逻辑的抽象描述，而与执行逻辑无关，对图数据库应用者比较友好，类比关系型数据库的 SQL 语言。TuGraph 的 Cypher 语言主要依照 Neo4j 开源的 OpenCypher 查询标准，同时对运维管理等辅助功能进行了扩展，在功能上囊括了 TuGraph 的大部分操作。描述式图查询语言会成为图数据库的主要数据操作方式，但由于描述到执行之间需要生成执行计划（Execution Plan），生成最优执行计划在学术界和工业界均有很长的路要走。  
> __过程式图查询语言__ 是为了解决描述式图查询语言与最优性能间的鸿沟。TuGraph的 Procedure API 是在 Core API 上做了一层简单的封装，C++ Procedure API的灵活性和高效性能够充分发挥存储的极致性能，也是 Cypher 优化的上限性能。Python Procedure API 是 C++ Procedure API 上的一层跨语言封装，翻译过程中值的拷贝会带来一定的性能损失，优势则主要是 python 语言本身的易用性。raversal API 是并行执行的 Procedure 接口，描述上更接近于集合的操作，比如扩展点集合所有出度邻居，获得一个新的点集。  
> __图分析编程框架__ 属于 ‘图计算系统’ 的范畴，会将图数据从支持增删改查的存储中导出快照，以更紧凑的数据存储格式来支持只读的复杂图分析，这里叫做OLAP API。OLAP API 封装了高并发执行的数据结构，包括 Vector、Bitmap等，以及基于 CSR 格式的图快照数据结构，然后提供一套并发的快速点边操作框架。在图分析任务完成后，数据可以通过接口写回图数据库。  
> __图神经网络编程框架__ 主要提供了图神经网络应用编程所需要的接口，能够对接PyTorch 等机器学习框架。TuGraph 的图神经网络编程框架主要集成了 DGL，在 Python 的语言环境中完成从图存储到图神经网络应用的完整流程。  
除了 Cypher 是解释执行外，其余服务端接口都是编译执行，即需要将对应代码传到服务端后，进行编译（可能会有时间开销），再在服务端执行。所以通常需要先加载，然后再已加载的应用列表中找到程序，传输入参数后执行。' metadata={'Header 1': '多层级接口', 'Header 2': '3.服务端接口'}","page_content='多层级接口

2.客户端接口

客户端接口指在客户端执行的接口，通常用于集成到软件应用中。TuGraph 的客户端的接口比较简单，包括登录登出、数据导入导出、存储过程加载调用、Cypher操作等。其中 Cypher 中集成了大部分的功能，包括数据操作、图模型操作、运维管理、账户管理等。  
由于 Cypher 的参数和返回值都是字符串，JAVA OGM 是对 Cypher 的结构化封装，即查询结果能够被封装为一个有类型的对象，方便使用。' metadata={'Header 1': '多层级接口', 'Header 2': '2.客户端接口'}","page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterato' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}"
GCN模型的主要组成部分是什么？,"page_content='使用 TuGraph 图学习模块进行点分类

6. 模型训练及保存

6.4.构建GCN模型

```python
class GCN(nn.Module):
def __init__(self, in_size, hid_size, out_size):
super().__init__()
self.layers = nn.ModuleList()
# two-layer GCN
self.layers.append(dgl.nn.GraphConv(in_size, hid_size, activation=F.relu))
self.layers.append(dgl.nn.GraphConv(hid_size, out_size))
self.dropout = nn.Dropout(0.5)

def forward(self, g, features):
h = features
for i, layer in enumerate(self.layers):
if i != 0:
h = self.dropout(h)
h = layer(g, h)
return h

def build_model():
in_size = feature_len  #feature_len为feature的长度，在此处为1433
out_size = classes  #classes为类别数，在此处为7
model = GCN(in_size, 16, out_size)  #16为隐藏层大小
return model
```
本教程将构建一个两层图卷积网络（GCN）。每层通过聚合邻居信息来计算新的点表示。' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '6. 模型训练及保存', 'Header 3': '6.4.构建GCN模型'}","page_content='使用 TuGraph 图学习模块进行点分类

1.简介

GNN 是许多图上机器学习任务的强大工具。在本介绍性教程中，您将学习使用 GNN 进行点分类的基本工作流程，即预测图中点的类别。  
此文档将展示如何构建一个 GNN 用于在 Cora 数据集上仅使用少量标签进行半监督点分类，这是一个以论文为点、引文为边的引文网络。任务是预测给定论文的类别。  
通过完成本教程，您可以  
使用 TuGraph 加载 cora 数据集。  
使用 TuGraph 提供的采样算子采样，并构建 GNN 模型。  
在 CPU 或 GPU 上训练用于点分类的 GNN 模型。  
此文档需要对图神经网络、DGL等使用有一定经验。' metadata={'Header 1': '使用 TuGraph 图学习模块进行点分类', 'Header 2': '1.简介'}","page_content='Training

3. 全图训练

GNN（图神经网络）的全图训练是一种涉及一次处理整个训练数据集的训练。它是 GNN 最简单、最直接的训练方法之一，整个图被视为单个实例。 在全图训练中，整个数据集被加载到内存中，模型在整个图上进行训练。这种类型的训练对于中小型图特别有用，并且主要用于不随时间变化的静态图。
在算子调用时，使用以下方式：
```python
getdb.Process(db, olapondb, feature_len, NodeInfo, EdgeInfo)
```
获取全图数据，然后将全图送入训练框架中进行训练。
完整代码：请参考learn/examples/train_full_cora.py。' metadata={'Header 1': 'Training', 'Header 2': '3. 全图训练'}"
TuGraph-DB的单元测试使用的是什么框架？,"page_content='TuGraph与ARM架构

内容：

TuGraph作为蚂蚁集团开源的高性能图数据库，近期在完成多平台认证的基础上，在ARM架构上发挥出极致的性能，获得了国际权威图数据库基准测试LDBC SNB的官方认证，并基于ARM架构打破了官方记录。  
**本次测试，验证了TuGraph对于ARM架构的兼容性，成为对x86和ARM架构均完整适配的图数据库；同时充分发挥出了新硬件的功能和性能优势，性能数据****较上一次官方纪录提升了31%，云端机器开销降低40%****。**  
评测流程和相关文件已同步发布在Github（https://github.com/TuGraph-family/tugraph-snb-interactive），开发者可参照来复现评测结果，**也可以通过阿里云轻松一键部署，以可视化方式试用TuGraph丰富的功能（****https://aliyun-computenest.github.io/quickstart-tugraph/****）。**该测试流程也适用于x86等其他软硬件环境。' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '内容：'}","page_content='TuGraph由LDBC认定全球领先

基本介绍

TuGraph 由蚂蚁集团和清华大学共同研发，是图数据库权威测试世界纪录保持者，也是世界上有测试纪录的“最快”的图数据库。  
**随着 TuGraph 的开源，图数据领域将迎来一款性能卓越、功能丰富、生态完备的开源产品**。  
开发者可以聚焦应用层，轻松打造属于自己的图数据，从而提升行业整体技术应用水位。TuGraph 开源采用 Apache2.0 协议，在 Github 和 Gitee 上进行托管。  
图数据库区别于关系型数据库，基于图模型，使用点边来表示、存储、处理数据，拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。  
蚂蚁 TuGraph 是一套分布式图数据库系统，可以支持万亿级边上的实时查询。此次开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可以轻松支持 TB 级别数据和百亿级别大图，足以满足大多数业务场景需求。相较于市场上常见的开源产品，TuGraph 单机版的性能高 10 倍以上。  
蚂蚁集团 2015 年开始自主研发分布式图数据库、流式图计算等图相关技术，2016 年发布自研分布式图数据库，并应用于支付宝。至今 TuGraph 已应用于蚂蚁内部 150 多个场景，包括在线支付的实时链路，以支付宝风险识别能力提升近 10 倍、风险审理分析效率提升 90%的成绩，验证了其高可靠性。  
LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，TuGraph 在功能完整性、吞吐率、响应速度等层面全球领先。  
目前，蚂蚁集团已形成了一套以图数据库为底座、同时包含流式图计算，离线图学习的大规模图计算系统。  
蚂蚁集团图数据库负责人洪春涛表示，图技术是未来大数据、人工智能和高性能计算产业发展的关键所在，它很有可能会成为下一代的数据底座。蚂蚁集团愿意通过开源持续输出核心技术优势，推动图数据库更广泛的应用生态，携手行业抢占技术高地，不断探索技术的可能性。' metadata={'Header 1': 'TuGraph由LDBC认定全球领先', 'Header 2': '基本介绍'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}"
tugraph-db可以先用cypher找一个子图，然后在这个子图上跑图分析吗？例如pagerank、kcore什么的！,"page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}","page_content='场景：流浪地球

4.Cypher查询

参考cypher文档，在TuGraph的Web页面前端输入Cypher进行查询' metadata={'Header 1': '场景：流浪地球', 'Header 2': '4.Cypher查询'}","page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。  
<table><tbody><tr><td>算法类型</td><td>中文算法名</td><td>英文算法名</td><td>程序名</td></tr><tr><td rowspan=""5"">路径查询</td><td>广度优先搜索</td><td>Breadth-First Search</td><td>bfs</td></tr><tr><td>单源最短路径</td><td>Single-Source Shortest Path</td><td>sssp</td></tr><tr><td>全对最短路径</td><td>All-Pair Shortest Path</td><td>apsp</td></tr><tr><td>多源最短路径</td><td>Multiple-source Shortest Paths</td><td>mssp</td></tr><tr><td>两点间最短路径</td><td>Single-Pair Shortest Path</td><td>spsp</td></tr><tr><td rowspan=""9"">重要性分析</td><td>网页排序</td><td>Pagerank</td><td>pagerank</td></tr><tr><td>介数中心度</td><td>Betweenness Centrality</td><td>bc</td></tr><tr><td>置信度传播</td><td>Belief Propagation</td><td>bp</td></tr><tr><td>距离中心度</td><td>Closeness Centrality</td><td>clce</td></tr><tr><td>个性化网页排序</td><td>Personalized PageRank</td><td>ppr</td></tr><tr><td>带权重的网页排序</td><td>Weighted Pagerank Algorithm</td><td>wpagerank</td></tr><tr><td>信任指数排名</td><td>Trustrank</td><td>trustrank</td></tr><tr><td>sybil检测算法</td><td>Sybil Rank</td><td>sybilrank</td></tr><tr><td>超链接主题搜索</td><td>Hyperlink-Induced Topic Search</td><td>hits</td></tr><tr><td rowspan=""4"">关联性分析</td><td>平均集聚系数</td><td>Local Clustering Coefficient</td><td>lcc</td></tr><tr><td>共同邻居</td><td>Common Neighborhood</td><td>cn</td></tr><tr><td>度数关联度</td><td>Degree Correlation</td><td>dc</td></tr><tr><td>杰卡德系数</td><td>Jaccard Index</td><td>ji</td></tr><tr><td rowspan=""5"">图结构</td><td>直径估计</td><' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}"
HA集群的snapshot何时删除？,"page_content='集群管理

1. 简介

HA集群启动之后，可以使用`lgraph_peer`工具进行集群管理，可以执行删除节点，转移leader和生成snapshot等功能。' metadata={'Header 1': '集群管理', 'Header 2': '1. 简介'}","page_content='集群管理

4. 生成snapshot

出于节点启动时设置ha_snapshot_interval_s为-1以默认不打snapshot或其他原因，
当需要让某个节点手动生成snapshot时，可以使用`lgraph_peer`的`snapshot`命令。命令示例如下所示：  
```shell
$ lgraph_peer --command snapshot --peer {peer_id}
```  
其中：  
- `--command snapshot` 指定要执行的操作为snapshot，即生成快照。
- `--peer {peer_id}` 指定要生成快照的节点的rpc网络地址，如 `127.0.0.1:9092`。' metadata={'Header 1': '集群管理', 'Header 2': '4. 生成snapshot'}","page_content='集群管理

2. 删除节点

对于TuGraph HA集群中长期离线或者产生网络分区的节点，可以使用`lgraph_peer`的`remove_peer`命令删除节点。命令示例如下所示：
```shell
$ lgraph_peer --command remove_peer --peer {peer_id} --conf {group_conf}
```  
其中：  
- `--command remove_peer` 指定要执行的操作为remove_peer，即删除节点。
- `--peer {peer_id}` 指定要删除节点的rpc网络地址，如 `127.0.0.1:9092`。
- `--conf {group_conf}` 指定HA集群的成员配置（可连通主节点即可），如 `127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094` 。' metadata={'Header 1': '集群管理', 'Header 2': '2. 删除节点'}"
TuGraph-DB目前支持哪种查询语言，并计划在将来支持哪种查询语言？,"page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}","page_content='功能概览

4.核心功能

4.1.查询语言

TuGraph 提供 Cypher 图查询语言，遵循OpenCypher标准。
- __支持Procedure嵌入__  
- __可插拔优化框架__ 各类优化功能  
- __可扩展安全性检查框架__ 对于cypher进行' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.1.查询语言'}","page_content='技术规划

2. 已完成功能

TuGraph-DB于2022年9月1日开源，TuGraph-DB在社区的反馈声中，进行日常BUG修复，自身能力得到了完善。  
| 版本号   | 功能                               | 时间         |
|-------|----------------------------------|------------|
| 3.3.0 | 开源初版                             | 2022.9.1   |
| 3.3.1 | 图分析引擎重构，多模式支持                    | 2022.10.14 |
| 3.3.2 | OGM支持，UT覆盖率提升                    | 2022.11.21 |
| 3.3.3 | 链接认证机制迭代，加入英文文档                  | 2022.12.23 |
| 3.3.4 | 支持上云，梳理LDBC SNB Audit流程          | 2023.1.28  |
| 3.4.0 | 支持OLAP Python API, 离线导入升级        | 2023.3.11  |
| 3.5.0 | 支持POG，前端升级，文档梳理                  | 2023.6.5   |
| 3.5.1 | 图学习引擎，Procedure Rust API，存储属性分离  | 2023.7.14  |
| 3.6.0 | 高可用开源，日志系统升级                     | 2023.8.11  |
| 4.0.0 | ISO GQL支持，新增11个开源图算法，支持m1 Docker | 2023.9.6   |
| 4.0.1 | 支持时序边排序，新增5个开源图算法                | 2023.9.28  |
| 4.1.0 | 支持Bolt协议，支持快速在线全量导入，支持地理空间数据类型   | 2023.12.25 |  
除此之外，TuGraph-DB搭建了较为完善的质量体系，涵盖自动化的单元测试、集成测试、性能测试等。  
更详细的描述可以在源码目录在的 ""[root]/release/CHANGELOG.md"" 文件查看。' metadata={'Header 1': '技术规划', 'Header 2': '2. 已完成功能'}"
语句里面有没有开启事务和结束事务的关键字,"page_content='Cypher API

5.附录2. 内置procedures列表

5.2.内置procedures完整列表

| Name                                  | Description                           | Signature                                                                                                                                                                               |
|---------------------------------------|---------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| db.subgraph                           | 列出点的子图                                | db.subgraph(vids::LIST) :: (subgraph::STRING)                                                                                                                                           |
| db.vertexLabels                       | 列出所有Vertex Label                      | db.vertexLabels() :: (label::STRING)                                                                                                                                                    |
| db.edgeLabels                         | 列出所有Edge Label                        | db.edgeLabels() :: (edgeLabels::STRING)                                                                                                                                                 |
| db.indexes                            | 列出所有索引                                | db.indexes() :: (label::STRING,field::STRING,label_type:STRING,unique::BOOLEAN,pair_unique::BOOLEAN)                                                                                    |
| db.listLabelIndexes                   | 列出所有与某个Label相关的索引                     | db.listLabelIndexes(label_name:STRING,label_type:STRING) :: (label::STRING,field::STRING,unique::BOOLEAN,pair_unique::BOOLEAN)                                                          |
| db.warmup                             | 预热数据                     ' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '5.2.内置procedures完整列表'}","page_content='RESTful API Legacy

6.Deprecated

6.3.服务器状态

#### 6.3.1.修改服务器配置  
修改服务器配置，配置修改后立即生效，并将影响所有服务器。这些配置的优先级高于配置文件以及命令行参数。  
- **URI**: `/config`
- **METHOD**: PUT
- **REQUEST**:  
请求为一个字典，使用 `{""opt1"":v1}` 可以将名为`opt1`的配置修改为`v1`。  
| 配置名               | 说明                   | 值类型 |
| -------------------- | ---------------------- | ------ |
| OPT_DB_ASYNC         | 是否启用异步模式       | 布尔值 |
| OPT_TXN_OPTIMISTIC   | 是否默认使用乐观事务锁 | 布尔值 |
| OPT_AUDIT_LOG_ENABLE | 是否启用审计日志       | 布尔值 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• PUT http://localhost:7070/config
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""OPT_DB_ASYNC"": true,
""OPT_AUDIT_LOG_ENABLE"": false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.3.2.当前服务器状态  
- **URI**: `/info`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| lgraph_version | 服务器版本号 | 字符串 |
| git_branch | 服务器代码分支 | 字符串 |
| git_commit | 服务器代码版本 | 字符串 |
| web_commit | 前端码版本 | 字符串 |
| cpp_id | CPP 编译器 ID | 字符串 |
| cpp_version | CPP 编译器版本 | 字符串 |
| python_version | PYTHON 版本 | 字符串 |
| node | 点 uri | 字符串 |
| relationship | 边 uri | 字符串 |
| cpu | cpu 信息 | 字典，格式参见[服务器 CPU 状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8CPU%E7%8A%B6%E6%80%81) |
| disk | 硬盘 IO 信息 | 字典，格式参见[服务器硬盘状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E7%9B%98%E7%8A%B6%E6%80%81) |
| memory | 内存信息 | 字典，格式参见[服务器内存状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%86%85%E5%AD%98%E7%8A%B6%E6%80%81) |
| db_space | 图数据库占用空间 | 字典，格式参见[图数据库占用空间](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4) |
| db_config | 图数据库配置信息 | 字典，格式参见[图数据库配置信息](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF) |
| up_time | 数据库在线时长（秒） | 整型 |  
**Example request.**  
```
• GET http://localhost:7070/info
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""lgraph_version"": ""1.2.0"",
""git_branch"": ""master"",
""git_commit"": ""9e2977d"",' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.3.服务器状态'}","page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}"
如何使用命令创建一个新的角色，并为其提供描述信息？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.1.用户管理

系统默认创建一个管理员，管理员用户名为 _admin_，密码为 _73@TuGraph_。为了安全起见，请用户在第一次启动服务器后更改密码。  
#### 6.1.1.添加用户  
添加一个新的用户，并为其设置初始密码。只有管理员有权限进行此操作。其中用户名只能由字母，数字以及下划线构成，密码则可以包含任意字符。用户名和密码长度不能超过 64 字节。添加用户时还可以为用户增加一个描述，用户描述可以包含任意字符，最长不超过 512 字节。  
新用户默认拥有同名的角色，不具备任何图的权限。  
- **URI**: `/user`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |
| description | 用户描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""user"": ""USER1"",
""password"": ""AN_INITIAL_PASSWORD"",
""description"": ""This is a user""
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.1.2.列出所有用户  
列出数据库的所有用户。只有管理员拥有该操作权限。  
- **URI**: `/user/`
- **METHOD**: GET
- **RESPONSE**: 所有用户及其信息。  
**Example request.**  
```
• GET http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
Output:
{
""admin"": {
""disabled"": false,
""description"": ""Builtin admin user"",
""roles"": [""admin""]
},
""guest1"": {
""disabled"": true,
""description"": """",
""roles"": [""guest1"", ""some_other_role""]
}
}
```  
#### 6.1.3.获取用户信息  
列出给定用户的信息。  
- **URI**: `/user/{user_name}`
- **METHOD**: GET
- **RESPONSE**: 用户信息。  
**Example request.**  
```
• GET http://localhost:7070/user/guest1
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.1.用户管理'}","page_content='用户权限

4.常用权限操作

4.2.角色操作

- 创建角色  
```cypher
CALL dbms.security.createRole(role_name::STRING,desc::STRING)
```  
- 删除角色  
```cypher
CALL dbms.security.deleteRole(role_name::STRING
```  
- 列出所有角色  
```cypher
CALL dbms.security.listRoles()
```  
- 禁用/启用角色  
```cypher
CALL dbms.security.disableRole(role::STRING,disable::BOOLEAN)
```' metadata={'Header 1': '用户权限', 'Header 2': '4.常用权限操作', 'Header 3': '4.2.角色操作'}"
TuGraph查询语句不支持任意长度路径吧？,"page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='TuGraph图模型说明

1. 数据模型

1.2. 数据类型

TuGraph支持多种可用于属性的数据类型。具体支持的数据类型如下：  
| **数据类型** | **最小值**          | **最大值**          | **描述**                            |
| ------------ | ------------------- | ------------------- | ----------------------------------- |
| BOOL         | false               | true                | 布尔值                              |
| INT8         | -128                | 127                 | 8位整型                          |
| INT16        | -32768              | 32767               | 16位整型                         |
| INT32        | - 2^31              | 2^31 - 1            | 32位整型                         |
| INT64        | - 2^63              | 2^63 - 1            | 64位整型                         |
| DATE         | 0000-00-00          | 9999-12-31          | ""YYYY-MM-DD"" 格式的日期             |
| DATETIME     | 0000-00-00 00:00:00.000000 | 9999-12-31 23:59:59.999999 | ""YYYY-MM-DD HH:mm:ss[.ffffff]"" 格式的日期时间 |
| FLOAT        |                     |                     | 32位浮点数                       |
| DOUBLE       |                     |                     | 64位浮点数                       |
| STRING       |                     |                     | 不定长度的字符串                    |
| BLOB         |                     |                     | 二进制数据（在输入输出时使用Base64编码） |
| POINT        |                     |                     | EWKB格式数据，表示点              |
| LINESTRING   |                     |                     | EWKB格式数据，表示线              |
| POLYGON      |                     |                     | EWKB格式数据，表示面(多边形)       |
| FLOAT_VECTOR |                     |                     | 包含32位浮点数的动态向量               |' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.2. 数据类型'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.6 通过OGM进行查操作**

**MATCH**  
session.load方法用于根据节点id查找节点。 session.loadALL方法用于批量查找节点，支持通过多个节点id查找节点、查找某一类型的所有节点、带有filter的查询。 filter查询需要新建Filter，传入参数ComparisonOperatorx0;可选为：EQUALSx0;、GREATER\_THANx0;、LESS\_THAN  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*J3Z1TrA0BncAAAAAAAAAAAAADgOBAQ/original)  
**QUERY WITH CYPHER**  
OGM支持通过queryForObject、query方法向TuGraph发送Cypher查询，由于Cypher查询的灵活性，需要用户自行指定返回结果格式。  
session.queryForObject方法：需要在方法第一个参数处指定返回类型，可设定为某一实体类或数字类型。  
session.query方法：Cypher查询的返回结果被存储为Result类型，其内部数据需要用户自行解析，以下方代码为例，传入数据库的Cypher为CREATE查询，返回结果createResult可被解析为QueryStatistics，可获取到此次查询被创建的节点与边的数目。  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*lkxXS660eEgAAAAAAAAAAAAADgOBAQ/original)' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.6 通过OGM进行查操作**'}"
如果在Java运行时，targetProject在xml配置文件中应如何配置？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.6 通过OGM进行查操作**

**MATCH**  
session.load方法用于根据节点id查找节点。 session.loadALL方法用于批量查找节点，支持通过多个节点id查找节点、查找某一类型的所有节点、带有filter的查询。 filter查询需要新建Filter，传入参数ComparisonOperatorx0;可选为：EQUALSx0;、GREATER\_THANx0;、LESS\_THAN  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*J3Z1TrA0BncAAAAAAAAAAAAADgOBAQ/original)  
**QUERY WITH CYPHER**  
OGM支持通过queryForObject、query方法向TuGraph发送Cypher查询，由于Cypher查询的灵活性，需要用户自行指定返回结果格式。  
session.queryForObject方法：需要在方法第一个参数处指定返回类型，可设定为某一实体类或数字类型。  
session.query方法：Cypher查询的返回结果被存储为Result类型，其内部数据需要用户自行解析，以下方代码为例，传入数据库的Cypher为CREATE查询，返回结果createResult可被解析为QueryStatistics，可获取到此次查询被创建的节点与边的数目。  
![](https://mdn.alipayobjects.com/huamei_qcdryc/afts/img/A*lkxXS660eEgAAAAAAAAAAAAADgOBAQ/original)' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.6 通过OGM进行查操作**'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.1 构建图对象**

首先需要通过注解标明图中的实体。  
@NodeEntity：该注解标明的类为节点类。  
@Relationship：用于标明边，同时@Relationship中可指定label与边的指向。  
@Id：用于标明identity，是OGM中数据的唯一标识。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.1 构建图对象**'}"
2024年功能更新计划中支持什么角色和工具？,"page_content='技术规划

3. 2024年功能更新

在2024年度，我们计划的功能更新包括：  
| 版本号   | 功能                 | 计划时间    |
|-------|--------------------|---------|
| 4.2.x | HA支持Witness角色和管理工具 | 2024.3  |
| 4.2.x | Bolt支持流处理和参数化查询    | 2024.3  |
| x.x.x | GeaX支持Cypher       | 2024.6  |
| x.x.x | 支持组合索引             | 2024.6  |
| x.x.x | 数据导入功能优化           | 2024.6  |
| x.x.x | 【社区功能】支持地理数据类型使用   | 2024.6  |
| x.x.x | Cypher能力提升         | 2024.9  |
| x.x.x | 支持Schema快速变更       | 2024.9  |
| x.x.x | 向量化支持              | 2024.12 |
| x.x.x | RPQ支持              | 2024.12 |
| x.x.x | 【可选】查询引擎升级         | 2024.12 |
| x.x.x | 【社区功能】支持GraphAr    | 2024.12 |' metadata={'Header 1': '技术规划', 'Header 2': '3. 2024年功能更新'}","page_content='技术规划

4. 期望社区共创的功能

目前团队研发精力并不能实现我们对TuGraph-DB的全部期望，在功能的梳理中，我们发现有一系列值得挖掘的想法，
团队也有一些初步的探索，期望下面功能能够在社区中共同研发。  
| 版本号   | 功能                      | 计划时间   |
|-------|-------------------------|--------|
| x.x.x | 图算法库丰富                  | 2024.x |
| x.x.x | 属性默认值支持                 | 2024.x |
| x.x.x | Embedded TuGraph-DB最佳实践 | 2024.x |
| x.x.x | Bolt显式事务支持              | 2024.x |
| x.x.x | List、Map和Decimal等数据类型扩展 | 2024.x |
| x.x.x | 探索多存储引擎                 | 2024.x |  
一些更加简单的功能，我们会在github的issue中打上 good first issue 的标签，欢迎对图数据库感兴趣的技术爱好者共同研讨。' metadata={'Header 1': '技术规划', 'Header 2': '4. 期望社区共创的功能'}","page_content='技术规划

2. 已完成功能

TuGraph-DB于2022年9月1日开源，TuGraph-DB在社区的反馈声中，进行日常BUG修复，自身能力得到了完善。  
| 版本号   | 功能                               | 时间         |
|-------|----------------------------------|------------|
| 3.3.0 | 开源初版                             | 2022.9.1   |
| 3.3.1 | 图分析引擎重构，多模式支持                    | 2022.10.14 |
| 3.3.2 | OGM支持，UT覆盖率提升                    | 2022.11.21 |
| 3.3.3 | 链接认证机制迭代，加入英文文档                  | 2022.12.23 |
| 3.3.4 | 支持上云，梳理LDBC SNB Audit流程          | 2023.1.28  |
| 3.4.0 | 支持OLAP Python API, 离线导入升级        | 2023.3.11  |
| 3.5.0 | 支持POG，前端升级，文档梳理                  | 2023.6.5   |
| 3.5.1 | 图学习引擎，Procedure Rust API，存储属性分离  | 2023.7.14  |
| 3.6.0 | 高可用开源，日志系统升级                     | 2023.8.11  |
| 4.0.0 | ISO GQL支持，新增11个开源图算法，支持m1 Docker | 2023.9.6   |
| 4.0.1 | 支持时序边排序，新增5个开源图算法                | 2023.9.28  |
| 4.1.0 | 支持Bolt协议，支持快速在线全量导入，支持地理空间数据类型   | 2023.12.25 |  
除此之外，TuGraph-DB搭建了较为完善的质量体系，涵盖自动化的单元测试、集成测试、性能测试等。  
更详细的描述可以在源码目录在的 ""[root]/release/CHANGELOG.md"" 文件查看。' metadata={'Header 1': '技术规划', 'Header 2': '2. 已完成功能'}"
"调用 ""CallGql"" 接口时，如何指定要查询的图的名称？","page_content='ISO GQL

1.GQL简介

Graph Query Language(GQL, 图查询语言)是一种国际标准语言，用于属性图查询，该语言建立在SQL的基础上，并整合了现有的[openCypher、PGQL、GSQL和G-CORE](https://gql.today/comparing-cypher-pgql-and-g-core/)语言的成熟思想。目前该标准仍然处于草稿阶段。  
TuGraph基于[ISO GQL (ISO/IEC 39075) Antlr4 语法文件](https://github.com/TuGraph-family/gql-grammar)实现了GQL，并做了一些扩展与改造。目前并未完全支持所有的GQL语法，我们会在未来逐步完善。' metadata={'Header 1': 'ISO GQL', 'Header 2': '1.GQL简介'}","page_content='Python客户端

3.RPC Client

3.4.调用GQL

```python
ret, res = client.callGql(""CALL db.edgeLabels()"", ""default"", 10)
```
```
callGql(self: liblgraph_client_python.client, gql: str, graph: str, json_format: bool, timeout: float, url: str) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.4.调用GQL'}","page_content='C++客户端

2.使用示例

2.4.调用GQL

```C++
std::string str;
bool ret = client.CallGql(str,
""CALL db.createVertexLabel('actor', 'name', 'name', string, false, 'age', int8, true)"");
```
```
bool CallGql(std::string& result, const std::string& gql,
const std::string& graph = ""default"", bool json_format = true,
double timeout = 0, const std::string& url = """");
@param [out] result      The result.
@param [in]  gql         inquire statement.
@param [in]  graph       (Optional) the graph to query.
@param [in]  json_format (Optional) Returns the format， true is json，Otherwise, binary
format.
@param [in]  timeout     (Optional) Maximum execution time, overruns will be interrupted.
@param [in]  url         (Optional) Node address of calling gql.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，在HA模式下的client中，通过指定url参数可以定向向某个server发送读请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.4.调用GQL'}"
图中能把属性值展示出来吗？,"page_content='可视化操作手册

2.操作指南

2.4.图项目

`图项目`提供可视化的图项目管理和图数据研发功能，它为用户提供了一系列便捷的图数据可视化操作，包括图项目的创建、修改、删除等管理操作，以及图数据的查询、点边统计等操作。此外，它也支持图模型的管理，使用户可以更加方便地进行图数据的管理和维护。  
#### 2.4.1.图项目管理  
在`图项目`界面，可以看到当前图数据库中的图项目。  
![图项目-首页](../../../images/browser/graphmanagement-homepage.png)  
##### 2.4.1.1.新建图项目  
在`图项目`界面，点击`新建图项目`按钮创建一个新的图项目。  
![图项目-新建图项目按钮](../../../images/browser/graphmanagement-creategraph.png)  
新建图项目需要通过`选择模板`和`填写配置`两个页面完成图项目的创建。  
- __选择模板__：产品提供空模板和demo模板两类模板。
- 空模板：全新的图项目，用户需要自己创建图模型和导入图数据，一般用于正式项目开发。
- demo模板：产品内置的demo数据，图项目创建成功后，系统会自动创建demo图模型并导入demo图数据，一般用于试用和学习。  
![图项目-选择模板](../../../images/browser/graphmanagement-selecttemplate.png)  
- __填写配置__：用户需要填写图项目基本信息，并点击`创建`按钮创建图项目。
- 图名称：新建图项目的名称，同时作为该图项目的唯一主键。支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图描述：新建图项目的描述，可用于详细说明该项目的背景和目标。
- 高级配置-最大存储空间：设置图项目最大可占用的存储空间，实际并不会提前占用物理存储空间，实际数据量达到最大存储空间阈值后不可再写入数据。  
![图项目-填写配置](../../../images/browser/graphmanagement-configure.png)  
创建成功后，可在`图项目`页面的图项目选项卡中查看。  
##### 2.4.1.2.编辑图项目  
在`图项目`界面，点击图项目选项卡中的`编辑`按钮（笔形图标），编辑对应图项目的基础信息。  
![图项目-编辑图项目按钮](../../../images/browser/graphmanagement-editgraph-button.png)  
编辑图项目功能可以修改`图描述`和`最大存储空间`。  
![图项目-编辑图项目](../../../images/browser/graphmanagement-editgraph.png)  
##### 2.4.1.3.删除图项目  
在`图项目`界面，点击图项目选项卡中的`删除`按钮（垃圾桶图标），删除对应的图项目。  
![图项目-删除图项目按钮](../../../images/browser/graphmanagement-deletegraph-button.png)  
_需要注意：图项目删除后无法恢复_。  
##### 2.4.1.4.点边统计  
在`图项目`界面，点击图项目选项卡中的`点边统计`按钮（刷新图标），统计对应图项目当前时间节点的点边数量。  
![图项目-点边统计按钮](../../../images/browser/graphmanagement-statistics-button.png)  
统计结果将展示在图项目选项卡上，已经统计过点边数据的图项目再次统计需要点击`刷新`按钮。  
![图项目-点边统计](../../../images/browser/graphmanagement-statistics.png)  
![图项目-刷新点边统计按钮](../../../images/browser/graphmanagement-statistics-refresh-button.png)  
##### 2.4.1.5.存储过程  
在`图项目`界面，点击图项目选项卡中的`存储过程`按钮（卡片最右侧图标），跳转到操作存储过程的图页面。  
![图项目-存储过程按钮](../../../images/browser/graphmanagement-procedure-button.png)  
在`存储过程`页面，可以新建存储过程，新建时需要填写""存储过程名称""、""存储过程类型""、""存储过程描述""，然后选择""版本""和""执行时是否修改数据库""  
![图项目-存储过程](../../../images/browser/graph' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}","page_content='TuGraph图模型说明

2. 图项目、点、边、属性命名规则和建议

2.1 命名规则

图项目、点、边和属性是识别符。该节描述了在TuGraph中识别符的允许的语法。
下面的表描述了每类识别符的最大长度和允许的字符。  
|**识别符** |**长度** |**允许的字符**|
|---------  |---------  |---------  |
|用户、角色、图项目|1-64字符|允许中文、字母、数字、下划线，且首字符不为数字|
|点类型、边类型、属性|1~256字符|允许中文、字母、数字、下划线，且首字符不为数字|' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '2. 图项目、点、边、属性命名规则和建议', 'Header 3': '2.1 命名规则'}"
tugraph-db如何与neo4j驱动连接？,"page_content='业务开发指南

连接tugraph-db

驱动连接

tugraph-db兼容neo4j的通讯协议，因此可以使用neo4j的驱动连接tugraph-db的server。  
[bolt driver 使用介绍](./7.client-tools/5.bolt-client.md)  
[bolt driver 使用例子](https://github.com/TuGraph-family/tugraph-db/tree/master/demo/Bolt)' metadata={'Header 1': '业务开发指南', 'Header 2': '连接tugraph-db', 'Header 3': '驱动连接'}","page_content='TuGraph-OGM

使用TuGraph-OGM

与TuGraph建立连接

使用Tugraph-ogm 建立连接  
```java
// 配置
String databaseUri = ""list://ip:port"";
String username = ""admin"";
String password = ""password"";
//启动driver
Driver driver = new RpcDriver();
Configuration.Builder baseConfigurationBuilder = new Configuration.Builder()
.uri(databaseUri)
.verifyConnection(true)
.credentials(username, password);
driver.configure(baseConfigurationBuilder.build());
driver.configure(baseConfigurationBuilder.build());
// 开启session
SessionFactory sessionFactory = new SessionFactory(driver, ""entity_path"");
Session session = sessionFactory.openSession();
```' metadata={'Header 1': 'TuGraph-OGM', 'Header 2': '使用TuGraph-OGM', 'Header 3': '与TuGraph建立连接'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

2 使用示例

**2.2 与TuGraph建立连接**

当前TuGraph-OGM提供了RPC driver用于连接TuGraph，具体配置如下所示：  
```java
// 配置

String databaseUri = ""list://ip:port"";

String username = ""username"";

String password = ""password"";

//启动driver

Driver driver = new RpcDriver();

Configuration.Builder baseConfigurationBuilder = new Configuration.Builder()

•uri(databaseUri)

• verifyConnection (true)

•credentials (username, password);

driver.configure(baseConfigurationBuilder.build());

// 开启session

SessionFactory sessionFactory = new SessionFactory(driver, ""entity_path"");

Session session = sessionFactory.openSession();
```' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '2 使用示例', 'Header 3': '**2.2 与TuGraph建立连接**'}"
图模型中某些边设置了属性，这些有属性的边在导入数据之后进行查询，发现查不到这些边数据,"page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}","page_content='Heterogeneous Graph

3. 异质图查询接口

3.2 边类型查询接口

```python
olapondb.etypes()
```
返回值为边类型列表，如['edge1', 'edge2', 'edge3']。' metadata={'Header 1': 'Heterogeneous Graph', 'Header 2': '3. 异质图查询接口', 'Header 3': '3.2 边类型查询接口'}","page_content='业务开发指南

边类型操作

查看边类型schema

```
CALL db.getEdgeSchema('edge1')
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '查看边类型schema'}"
"在""TuGraph-DataX""项目中如何通过job配置文件将""actors.csv""导入到TuGraph？","page_content='TuGraph-DataX

3. 导入TuGraph

3.1.文本数据通过DataX导入TuGraph

我们以 TuGraph 手册中导入工具 lgraph_import 章节举的数据为例子，有三个 csv 数据文件，如下：
`actors.csv`  
```
nm015950,Stephen Chow
nm0628806,Man-Tat Ng
nm0156444,Cecilia Cheung
nm2514879,Yuqi Zhang
```  
`movies.csv`  
```
tt0188766,King of Comedy,1999,7.3
tt0286112,Shaolin Soccer,2001,7.3
tt4701660,The Mermaid,2016,6.3
```  
`roles.csv`  
```
nm015950,Tianchou Yin,tt0188766
nm015950,Steel Leg,tt0286112
nm0628806,,tt0188766
nm0628806,coach,tt0286112
nm0156444,PiaoPiao Liu,tt0188766
nm2514879,Ruolan Li,tt4701660
```  
然后建三个 DataX 的 job 配置文件：
`job_actors.json`  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"": 1
}
},
""content"": [
{
""reader"": {
""name"": ""txtfilereader"",
""parameter"": {
""path"": [""actors.csv""],
""encoding"": ""UTF-8"",
""column"": [
{
""index"": 0,
""type"": ""string""
},
{
""index"": 1,
""type"": ""string""
}
],
""fieldDelimiter"": "",""
}
},
""writer"": {
""name"": ""tugraphwriter"",
""parameter"": {
""url"": ""bolt://127.0.0.1:27687"",
""username"": ""admin"",
""password"": ""73@TuGraph"",
""graphName"": ""default"",
""labelType"": ""VERTEX"",
""labelName"": ""actor"",
""batchNum"": 1000,
""properties"": [""aid"", ""name""]
}
}
}
]
}
}
```  
`job_movies.json`  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"": 1
}
},
""content"": [
{
""reader"": {
""name"": ""txtfilereader"",
""parameter"": {
""path"": [""movies.csv""],
""encoding"": ""UTF-8"",
""column"": [
{
""index"": 0,
""type"": ""string""
},
{
""index"": 1,
""type"": ""string""
},
{
""index"": 2,
""type"": ""string""
},
{
""index"": 3,
""type"": ""string""
}
],
""fieldDelimiter"": "",""
}
},
""writer"": {
""name"": ""tugraphwriter"",
""parameter"": {
""url"": ""bolt://127.0.0.1:27687"",
""username"": ""admin"",
""password"": ""73@TuGraph"",
""graphName"": ""default"",
""labelType"": ""VERTEX"",
""labelName"": ""movie"",
""batchNum"": 1000,
""properties"": [""mid"", ""name"", ""year"", ""rate""]
}
}
}
]
}
}
```  
`job_roles.json`  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"": 1
}
},
""content"": [
{
""reader"": {
""name"": ""txtfilereader"",
""parameter"": {
""path"": [""roles.csv""],
""encoding"": ""UTF-8"",
""column"": [
{
' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '3. 导入TuGraph', 'Header 3': '3.1.文本数据通过DataX导入TuGraph'}","page_content='TuGraph-DataX

4.导出TuGraph

4.1.配置样例

TuGraph支持使用DataX导出数据，使用如下配置即可将数据导出到文本数据中  
```json
{
""job"": {
""setting"": {
""speed"": {
""channel"":1
}
},
""content"": [
{
""reader"": {
""name"": ""tugraphreader"",
""parameter"": {
""username"": ""admin"",
""password"": ""73@TuGraph"",
""graphName"": ""Movie_8C5C"",
""queryCypher"": ""match (n:person) return n.id,n.name,n.born;"",
""url"": ""bolt://127.0.0.1:27687""
}
},
""writer"": {
""name"": ""txtfilewriter"",
""parameter"": {
""path"": ""./result"",
""fileName"": ""luohw"",
""writeMode"": ""truncate""
}
}
}
]
}
}
```  
使用这个配置文件，可以把TuGraph Movie_8C5C子图中person节点的id,name和born属性全部导出出来，
导出到当前目录下的result目录中，文件名称为luohw+随机后缀。' metadata={'Header 1': 'TuGraph-DataX', 'Header 2': '4.导出TuGraph', 'Header 3': '4.1.配置样例'}","page_content='数据导入

3.配置文件

3.2.配置文件示例

```json
{
""schema"": [
{
""label"": ""actor"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""aid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" }
],
""primary"": ""aid""
},
{
""label"": ""movie"",
""type"": ""VERTEX"",
""properties"": [
{ ""name"": ""mid"", ""type"": ""STRING"" },
{ ""name"": ""name"", ""type"": ""STRING"" },
{ ""name"": ""year"", ""type"": ""INT16"" },
{ ""name"": ""rate"", ""type"": ""FLOAT"", ""optional"": true }
],
""primary"": ""mid"",
""detach_property"": false
},
{
""label"": ""play_in"",
""type"": ""EDGE"",
""properties"": [{ ""name"": ""role"", ""type"": ""STRING"", ""optional"": true }],
""constraints"": [[""actor"", ""movie""]]
}
],
""files"": [
{
""path"": ""actors.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""actor"",
""columns"": [""aid"", ""name""]
},
{
""path"": ""movies.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""movie"",
""columns"": [""mid"", ""name"", ""year"", ""rate""]
},
{
""path"": ""roles.csv"",
""header"": 2,
""format"": ""CSV"",
""label"": ""play_in"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
对于上述配置文件，定义了三个 label：两个点类型`actor`和`movie`，一个边类型`role`。每个 label 都描述了：label 的名字、类型（点还是边）、属性字段有哪些以及每个字段的类型。对于点，另外定义了 primary 字段是哪个；对于边，另外定义了 constraints 字段，用来限制边的起点和终点只能是哪些组合。  
还描述了三个数据文件，两个点的数据文件`actors.csv`和`movies.csv`，一个边的数据文件`roles.csv`。每个部分都描述了：文件的路径（path）、数据类型（format）、信息头占开头几行（header）、是哪个 label 的数据（label）、文件中每行数据中的每个列对应的字段是哪个。  
对于上述配置文件，import 工具在执行的过程中会先在 TuGraph 中创建`actor`、`movie`、`role`这三个 label，然后再执行三个文件的数据导入。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.2.配置文件示例'}"
创建新子图时需要哪些参数？,"page_content='图相关DDL

Create Graph

**Syntax**
一个图至少包含一对点边，点表必须包含一个id字段作为主键，边表必须包含srcId和targetId作为主键，边表还可以有一个时间戳字段标识时间。  
```
CREATE GRAPH <graph name>
(
<graph vertex>
[ { , <graph vertex> } ... ]
, <graph edge>
[ { , <graph edge> } ... ]
) WITH （
storeType = <graph store type>
[ { , <config key> = <config value> } ... ]
);

<graph vertex>  ::=
VERTEX <vertex name>
(
<column name> <data type> ID
[ {, <column name> <data type> } ... ]
)

<graph edge>  ::=
Edge <edge name>
(
<column name> <data type> SOURCE ID
, <column name> <data type> DESTINATION ID
[ , <column name> <data type> TIMESTAMP ]
[ {, <column name> <data type> } ... ]
)

```  
**Example**
```sql
CREATE GRAPH dy_modern (
Vertex person (
id bigint ID,
name varchar,
age int
),
Vertex software (
id bigint ID,
name varchar,
lang varchar
),
Edge knows (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
),
Edge created (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
)
) WITH (
storeType = 'rocksdb',
shardCount = 2
);
```
这个例子创建了一张包含2个点2个边的图，存储类型为rocksdb, 分片数2个。' metadata={'Header 1': '图相关DDL', 'Header 2': 'Create Graph'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

`图项目`提供可视化的图项目管理和图数据研发功能，它为用户提供了一系列便捷的图数据可视化操作，包括图项目的创建、修改、删除等管理操作，以及图数据的查询、点边统计等操作。此外，它也支持图模型的管理，使用户可以更加方便地进行图数据的管理和维护。  
#### 2.4.1.图项目管理  
在`图项目`界面，可以看到当前图数据库中的图项目。  
![图项目-首页](../../../images/browser/graphmanagement-homepage.png)  
##### 2.4.1.1.新建图项目  
在`图项目`界面，点击`新建图项目`按钮创建一个新的图项目。  
![图项目-新建图项目按钮](../../../images/browser/graphmanagement-creategraph.png)  
新建图项目需要通过`选择模板`和`填写配置`两个页面完成图项目的创建。  
- __选择模板__：产品提供空模板和demo模板两类模板。
- 空模板：全新的图项目，用户需要自己创建图模型和导入图数据，一般用于正式项目开发。
- demo模板：产品内置的demo数据，图项目创建成功后，系统会自动创建demo图模型并导入demo图数据，一般用于试用和学习。  
![图项目-选择模板](../../../images/browser/graphmanagement-selecttemplate.png)  
- __填写配置__：用户需要填写图项目基本信息，并点击`创建`按钮创建图项目。
- 图名称：新建图项目的名称，同时作为该图项目的唯一主键。支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图描述：新建图项目的描述，可用于详细说明该项目的背景和目标。
- 高级配置-最大存储空间：设置图项目最大可占用的存储空间，实际并不会提前占用物理存储空间，实际数据量达到最大存储空间阈值后不可再写入数据。  
![图项目-填写配置](../../../images/browser/graphmanagement-configure.png)  
创建成功后，可在`图项目`页面的图项目选项卡中查看。  
##### 2.4.1.2.编辑图项目  
在`图项目`界面，点击图项目选项卡中的`编辑`按钮（笔形图标），编辑对应图项目的基础信息。  
![图项目-编辑图项目按钮](../../../images/browser/graphmanagement-editgraph-button.png)  
编辑图项目功能可以修改`图描述`和`最大存储空间`。  
![图项目-编辑图项目](../../../images/browser/graphmanagement-editgraph.png)  
##### 2.4.1.3.删除图项目  
在`图项目`界面，点击图项目选项卡中的`删除`按钮（垃圾桶图标），删除对应的图项目。  
![图项目-删除图项目按钮](../../../images/browser/graphmanagement-deletegraph-button.png)  
_需要注意：图项目删除后无法恢复_。  
##### 2.4.1.4.点边统计  
在`图项目`界面，点击图项目选项卡中的`点边统计`按钮（刷新图标），统计对应图项目当前时间节点的点边数量。  
![图项目-点边统计按钮](../../../images/browser/graphmanagement-statistics-button.png)  
统计结果将展示在图项目选项卡上，已经统计过点边数据的图项目再次统计需要点击`刷新`按钮。  
![图项目-点边统计](../../../images/browser/graphmanagement-statistics.png)  
![图项目-刷新点边统计按钮](../../../images/browser/graphmanagement-statistics-refresh-button.png)  
##### 2.4.1.5.存储过程  
在`图项目`界面，点击图项目选项卡中的`存储过程`按钮（卡片最右侧图标），跳转到操作存储过程的图页面。  
![图项目-存储过程按钮](../../../images/browser/graphmanagement-procedure-button.png)  
在`存储过程`页面，可以新建存储过程，新建时需要填写""存储过程名称""、""存储过程类型""、""存储过程描述""，然后选择""版本""和""执行时是否修改数据库""  
![图项目-存储过程](../../../images/browser/graph' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='RESTful API Legacy

6.Deprecated

6.5.子图管理

TuGraph 支持多子图，子图之间完全独立，不同的子图可以对不同用户开放不同权限。管理员可以添加和删除子图。  
#### 6.5.1.创建新子图  
- **URI**: `/db`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | 子图名 | 字符串 |
| config | 配置 | 字典，格式为 { {列名 1}:{列值 1},... } |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""name"":""graph1"",
""config"" : {
""max_size_GB"":2048,
""description"": ""description of graph1""
}
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.5.2.删除子图  
- **URI**: `/db/{graph_name}`
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• DELETE http://localhost:7070/db/graph1
```  
**Example response.**  
```
• 200: OK
```  
#### 6.5.3.列出所有子图  
- **URI**: `/db`
- **METHOD**: GET
- **RESPONSE**: 子图列表  
**Example request.**  
```
• GET http://localhost:7070/db
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""graph1"": {
""max_size_GB"":1024,
""description"":""description of graph1""
}
}
```  
#### 6.5.4.获取子图信息  
- **URI**: `/db/{graph_name}`
- **METHOD**: GET
- **RESPONSE**: 子图列表  
**Example request.**  
```
• GET http://localhost:7070/db/graph1
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""max_size_GB"":1024,
""description"":""description of graph1""
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.5.子图管理'}"
在test_export_default函数中，如何验证导出后再次导入的数据是否与原始数据一致？,"page_content='数据导出

2.导出命令

该工具的命令示例如下：  
```bash
$ lgraph_export -d {database_dir} -e {export_destination_dir} -g {graph_to_use} -u {username} -p {password} -f {output_format}
```  
其中：  
- `-d {database_dir}` 指定需要进行数据导出的数据库所在目录，默认值为 `./testdb`。
- `-e {export_destination_dir}` 指定导出文件存放的目录，默认值为 `./exportdir`。
- `-g {graph_to_use}` 指定图数据库的种类，默认为 `default` 。
- `-u {username}` 指定进行该导出操作的用户的用户名。
- `-p {password}` 指定进行该导出操作的用户的用户密码。
- `-s {field_separator}` 指定导出文件的分隔符，默认为逗号。
- `-f {output_format}` 指定导出数据的格式，`json`或者`csv`，默认为`csv`。
- `-h` 除上述指定参数外，也可以使用该参数查看该工具的使用帮助。' metadata={'Header 1': '数据导出', 'Header 2': '2.导出命令'}","page_content='集成测试

2.TuGraph集成测试框架

2.3.测试样例

#### 2.3.1.rest  
样例代码中在test_get_info函数执行之前先启动server，server启动后启动了rest client，进入test_get_info函数后获取server的一些信息，并通过assert判断是否有获取到cpu的信息。  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7073 --rpc_port 9093"",
""cleanup_dir"":[""./testdb""]}
RESTTOPT = {""port"":""7073"", ""user"":""admin"", ""password"":""73@TuGraph""}
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""rest"", [RESTTOPT], indirect=True)
def test_get_info(self, server, rest):
res = rest.get_server_info()
log.info(""res : %s"", res)
assert('cpu' in res)
```  
#### 2.3.2.client  
样例代码中在test_flushdb函数执行之前先执行了数据离线导入逻辑，并启动server后，通过client创建链接，进入test_flushdb函数后，通过查询点的个数判断导入是否成功，导入成功后执行flushDB操作，再次通过assert判断是否能正常清空db  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}

CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}

IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}

@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_flushdb(self, importor, server, client):
ret = client.callCypher(""MATCH (n) RETURN n LIMIT 100"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert len(res) == 21
ret = client.callCypher(""CALL db.flushDB()"", ""default"")
assert ret[0]
res = json.loads(ret[1])
assert res == None
```  
#### 2.3.3.exportor/importor  
样例代码中在test_export_default函数执行之前先执行了数据离线导入逻辑，导入成功后将当前db的数据导出，然后再次通过离线导入逻辑将exportor导出的数据导入到新的目录中，以新导入的数据启动db，并且创建链接。在test_export_default函数主体中判断导出后再次导入的数据是否与原始数据一致  
```pytho' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.3.测试样例'}","page_content='集成测试

2.TuGraph集成测试框架

2.2.组件用法

#### 2.2.1.server  
##### 2.2.1.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
SERVEROPT = {""cmd"":""./lgraph_server -c lgraph_standalone.json --directory ./testdb --license _FMA_IGNORE_LICENSE_CHECK_SALTED_ --port 7072 --rpc_port 9092"",
""cleanup_dir"":[""./testdb""]}
```  
##### 2.2.1.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动server，函数执行完成后会停止server，并清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
def test_server(self, server):
pass
```  
#### 2.2.2.client  
##### 2.2.2.1.启动参数
采用python字典传入
+ host是TuGraph Server的ip和端口
+ user是TuGraph Server的用户名
+ password是TuGraph Server 中user对应的密码  
```python
CLIENTOPT = {""host"":""127.0.0.1:9092"", ""user"":""admin"", ""password"":""73@TuGraph""}
```  
##### 2.2.2.2.启动命令
通过fixtures组件引入工具，并通过启动参数来控制不同的处理逻辑，函数开始执行前会启动客户端，函数执行结束后会结束客户端  
```python
@pytest.mark.parametrize(""server"", [SERVEROPT], indirect=True)
@pytest.mark.parametrize(""client"", [CLIENTOPT], indirect=True)
def test_client(self, server, client):
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0]
ret = client.callCypher(""CALL db.createEdgeLabel('followed', '[]', 'address', string, false, 'date', int32, false)"", ""default"")
assert ret[0] == False
```  
#### 2.2.3.importor  
##### 2.2.3.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是执行完成后需要清理的目录，可以是多个，通过python列表传入  
```python
IMPORTOPT = {""cmd"":""./lgraph_import --config_file ./data/yago/yago.conf --dir ./testdb --user admin --password 73@TuGraph --graph default --overwrite 1"",
""cleanup_dir"":[""./testdb"", ""./.import_tmp""]}
```  
##### 2.2.3.2.启动命令  
通过fixtures组件引入工具，并通过启动参数来控制导入不同的数据，函数开始执行前会导入数据到指定的目录，函数执行完成后会清理cleanup_dir指定的目录  
```python
@pytest.mark.parametrize(""importor"", [IMPORTOPT], indirect=True)
def test_importor(self, importor):
pass
```  
#### 2.2.4.exportor  
##### 2.2.4.1.启动参数
采用python字典传入
+ cmd是启动命令
+ cleanup_dir是' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.2.组件用法'}"
Work函数在处理节点vi时，返回值代表什么？,"page_content='OlapOnDB API

4. 其他常用函数功能描述

4.10 活跃点的描述

活跃点指的是在批处理函数中需要处理的点，在本例子中只是输出了活跃点的编号，并且汇总活跃点的数量：  
```C++
ParallelBitset temp = 000111;//当前活跃点为3，4，5号点

size_t delta = ForEachActiveVertex<double>(
//void c
[&](size_t vi) {
printf(""active_vertexId = %lu\n"",vi);
return 1;
},
all_vertices
);
```  
函数的运行结果显而易见，因为多线程的关系，一下输出顺序可能有所变化：  
```
active_vertexId = 3
active_vertexId = 4
active_vertexId = 5
```  
局部返回值均为1，该函数会在保证线程安全的情况下将所有的局部返回值累加得到最终的返回值，并存储在`delta`变量中，该值最终为3' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.10 活跃点的描述'}","page_content='Python Olap API

4. Olap API

图类OlapBase

- `NumVertices()-> size_t`：获取点数
- `NumEdges()-> size_t`：获取边数
- `OutDegree(size_t vid)-> size_t`：点vid的出度
- `InDegree(size_t vid)-> size_t`：点vid的入度  
- `AllocVertexArray[VertexData]() ->ParallelVector[VertexData]`：分配一个类型为VertexData的数组，大小为点个数
- `AllocVertexSubset()-> ParallelBitset`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `OutEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有出边集合
- `InEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有入边集合
- `Transpose()-> cython.void`：对有向图进行图反转
- `LoadFromArray(edge_array: cython.p_char, input_vertices: size_t, input_edges: size_t, edge_direction_policy: EdgeDirectionPolicy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。  
- `AcquireVertexLock(vid: size_t)-> cython.void`：对点vid加锁，禁止其它线程对该锁对应的点数据进行访存
- `void ReleaseVertexLock(vid: size_t)-> cython.void`：对点vid解锁，所有线程均可访存该锁对应的点数据  
TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程，在Python中与C++使用方法稍有不同。  
```python
# 函数名称:ProcessVertexInRange[ReducedSum, Algorithm](
#           work: (algo: Algorithm, vi: size_t)-> ReducedSum,
#           lower: size_t, upper: size_t,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#     函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
#     第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
#     具体实现请参考include/lgraph/olap_base.h中具体代码
#
#     使用示例:统计数组parent数组中有出边的点个数

import cython
from cython.cimports.olap_base import *


@cython.cclass
class CountCore:
graph: cython. pointer(OlapBase[Empty])
parent: ParallelVector[size_t]

@cython.cfunc
@cython.nogil
def Work(self, vi: size_t) -> size_t:
if self.graph.OutDegree(self.parent[vi]) > 0:
return 1
return 0

def run(self, pointer_g: cython' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}","page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void init(VertexCentricComputeFuncContext<K, VV, EV, M> vertexCentricFuncContext) | 迭代计算初始化接口 | vertexCentricFuncContext：静态图计算的上下文，K表示vertex id的类型，VV表示vertex value类型，EV表示edge value类型，M表示发送消息的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 迭代计算接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：迭代过程中所有发送给当前vertex的消息，其中M表示迭代计算过程中定义的发送消息类型。 |
| void finish() | 迭代计算完成接口 | 无 |  
- 详细接口  
```java
public interface VertexCentricComputeFunction<K, VV, EV, M> extends VertexCentricFunction<K, VV,
EV, M> {

void init(VertexCentricComputeFuncContext<K, VV, EV, M> vertexCentricFuncContext);

void compute(K vertex, Iterator<M> messageIterator);

void finish();

interface VertexCentricComputeFuncContext<K, VV, EV, M> extends VertexCentricFuncContext<K, VV,
EV, M> {
/** 设置vertex value */
void setNewVertexValue(VV value);

}

}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}"
TuGraph Explorer 的功能现在在哪里可以找到？,"page_content='功能概览

6.生态工具

6.2.可视化交互

TuGraph Browser 是面向图数据库直接使用者的可视化交互界面，功能上覆盖了 TuGraph 的绝大部分能力，包括数据导入、图模型建立、数据增删查改、监控运维等操作链路。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.2.可视化交互'}","page_content='可视化操作手册（旧版）

作用

TuGraph Browser 的主要功能是为使用图数据库的开发人员，提供可视化的图数据开发，图数据管理和维护等功能。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '作用'}","page_content='可视化操作手册（旧版）

定义

TuGraph Browser 是 TuGraph 提供的可视化开发工具。' metadata={'Header 1': '可视化操作手册（旧版）', 'Header 2': '定义'}"
在批量创建点的操作中，如果请求成功，TuGraph 会返回什么？,"page_content='TuGraph-Restful-Server

7.接口

7.7 批量创建schema请求

用户通过此类请求批量创建schema，请求报文在http body 中将创建schema的目标子图和schema信息发送给server，如果拿到返回errorCode为200的响应报文即为正常创建
#### 7.7.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_schema
#### 7.7.2 REQUEST
|  body参数  |    参数说明    |  参数类型  |  是否必填  |
|:--------:|:----------:|:------:| :-----: |
| graph |   创建目标子图   |  字符串  |  是  |
| schema | schema描述信息 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.7 批量创建schema请求'}","page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

二、TuGraph-DB高可用架构与规划

2.Server架构设计—请求同步

集群建立好之后，可以向其发送读写请求。发送读请求非常简单，client 发送一个读请求给 TuGraph server，server 接到读请求之后，去进行处理。图中给出的一个 cypher 语句，是查询图中边的 label 的数量。在 server 端，会对 cypher 语句进行解析，辨别它是一个只读的请求，一旦确定就会直接发送给 TuGraph-DB，由 TuGraph-DB 进行响应。  
写请求会涉及到 DB 数据的变化。Client 发送给 server 之后，server 会通过一些自有的逻辑去判断，如果是一个写请求，那么它会传给内部的一个 raft node，这个 raft node 可以看作是一个 client。因为是三个节点，每个节点持有其它节点的一个 client，每个节点既是 server，也是 client。当收到这个请求之后，只有 leader 节点会处理写请求。它并不会直接应用到 TuGraph-DB 上面，而是先调用客户端把日志去发送给其它节点，当超过半数的节点响应之后，才会应用到 TuGraph-DB 内部，保证写请求日志的一致性。  
在高可用集群使用过程中，有很多不可预知的情况，比如正好在应用日志的时候，集群突然挂了或者突然重启了。即使这种情况发生的概率非常低，但在大规模应用中仍然有可能发生。因此，写请求必须是幂等的，请求的 log index 必须是一致的，当它应用到 DB 里时，不能产生重复的提交。所以我们在 DB 内部持有 log 的 index，当 client 由于超时重发或节点的状态发生变化而重复提交时，都不会对 DB 状态产生污染。' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '二、TuGraph-DB高可用架构与规划', 'Header 3': '2.Server架构设计—请求同步'}"
tugraph能否支持混合检索 vector+知识图谱？,"page_content='功能概览

6.生态工具

6.1.TuGraph DataX

![导入导出](../../../images/tugraph-datax.png)  
TuGraph 核心支持 CSV 和 JSON 合适的导入导出，提供空库导入和增量导入的模式。实际中会存在 MySQL、Kafka、Hive 等多数据源导入的需求，TuGraph 通过 DataX 做多数据源的对接。由于关系模型和图模型存在的差异，数据清洗的流程可以使用 SparkSQL 快速处理，TuGraph 本身仅关注 CSV 和 JSON 的简单场景导入可靠性和性能。' metadata={'Header 1': '功能概览', 'Header 2': '6.生态工具', 'Header 3': '6.1.TuGraph DataX'}","page_content='试用体验：TuGraph — 简单高效的图数据库

配套的可视化试用工具

TuGraph提供了一款配套的可视化试用工具，使得对图数据库的操作更加直观和方便。我可以通过可视化工具轻松浏览图数据、执行查询和分析结果。这对我理解数据结构和发现潜在关联非常有帮助。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '配套的可视化试用工具'}","page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}"
TuGraph 数据预热的主要目的是什么？,"page_content='数据预热

1.简介

TuGraph 是基于磁盘的数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '数据预热', 'Header 2': '1.简介'}","page_content='功能概览

4.核心功能

4.5 数据预热

TuGraph 是基于磁盘的图数据库，仅当访问数据时，数据才会加载到内存中。因此在服务器刚开启后的一段时间内，系统性能可能会由于频繁的 IO 操作而变差。此时我们可以通过事先进行数据预热来改善这一问题。' metadata={'Header 1': '功能概览', 'Header 2': '4.核心功能', 'Header 3': '4.5 数据预热'}","page_content='数据预热

1.数据预热命令

数据预热可以通过工具 `lgraph_warmup` 来进行。它的使用示例如下：  
```bash
$ lgraph_warmup -d {directory} -g {graph_list}
```  
其中：  
- `-d {db_dir}` 选项指定了 TuGraph 服务器的数据目录  
- `-g {graph_list}` 选项指定需要进行数据预热的图名称，用逗号分隔  
根据数据大小和所使用的磁盘类型不同，预热过程运行时间也不同。机械磁盘上预热一个大数据库可能耗时较长，请耐心等待。' metadata={'Header 1': '数据预热', 'Header 2': '1.数据预热命令'}"
InEdgeIterator 类的 GetSrc 方法返回什么信息？,"page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void init(IncGraphComputeContext<K, VV, EV, M> incGraphContext) | 图计算初始化接口 | incGraphContext： 增量动态图计算的上下文，K表示vertex id的类型，VV表示vertex value类型，EV表示edge value类型，M表示发送消息的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮迭代对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 迭代计算接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 迭代计算完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型 |  
- 详细接口  
```java
public interface IncVertexCentricFunction<K, VV, EV, M> extends Function {

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncGraphContext<K, VV, EV, M> {
/** 获取job id */
long getJobId();

/** 获取当前迭代 id */
long getIterationId();

/** 获取运行时上下文 */
RuntimeContext getRuntimeContext();

/** 获取可变图 */
MutableGraph<K, VV, EV> getMutableGraph();

/** 获取增量图 */
TemporaryGraph<K, VV, EV> getTemporaryGraph();

/** 获取图存储上的历史图 */
HistoricalGraph<K, VV, EV> getHistoricalGraph();

/** 给指定vertex发送消息 */
void sendMessage(K vertexId, M message);

/** 给当前vertex邻居节点发送消息 */
void sendMessageToNeighbors(M message);

}

interface TemporaryGraph<K, VV, EV> {
/** 从增量图中获取vertex */
IVertex<K, VV> getVertex();

/** 从增量图中获取edges */
List<IEdge<K, EV>> getEdges();

/** 更新vertex value */
void updateVertexValue(VV value);

}

interface HistoricalGraph<K, VV, EV> {
/** 获取图数据最新版本id */
Long getLatestVersionId();

/** 获取图数据所有版本 */
List<Long> getAllVersionIds();

/** 获取图数据所有vertex */
Map<Long, IVertex<K, VV>> getAllVertex();

/** 获取图数据指定版本的vertex */
Map<Long, IVertex<K, VV>> getAllVertex(List<Long> versions);

/** 获取图数据指定版本并满足过滤条件的ve' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends Gra' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentric function进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |  
- 详细接口  
```java
public interface VertexCentricTraversalFunction<K, VV, EV, M, R> extends VertexCentricFunction<K, VV
, EV, M> {

void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);
/** 图遍历算法初始化方法 */
void init(ITraversalRequest<K> traversalRequest);
/** 实现图遍历逻辑 */
void compute(K vertexId, Iterator<M> messageIterator);

void finish();

void close();

interface VertexCentricTraversalFuncContext<K, VV, EV, M, R> extends VertexCentricFuncContext<K,
VV, EV, M> {
/** 获取图遍历结果 */
void takeResponse(ITraversalResponse<R> response);
/** 获取开始图遍历的点 */
TraversalVertexQuery<K, VV> vertex();
/** 获取开始图遍历的边 */
TraversalEdgeQuery<K, EV> edges();

void broadcast(IGraphMessage<K, M> message);
}

interface TraversalVertexQuery<K, VV> extends VertexQuery<K, VV> {
/** 获取图遍历中点的迭代器 */
Iterator<K> loadIdIterator();
}

interface TraversalEdgeQuery<K, EV> extends EdgeQuery<K, EV> {
/** 通过指定的点id，获取对应的图遍历起点 */
TraversalEdgeQuery<K, EV> withId(K vertexId);
}
}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}"
可选匹配子句OPTIONAL MATCH在查询中有什么作用？,"page_content='ISO GQL

2.Clauses

2.1.MATCH

`MATCH`子句式是GQL最基础的子句，几乎所有查询都是通过 `MATCH`展开。  
`MATCH`子句用于指定在图中搜索的匹配模式，用来匹配满足一定条件的点或者路径。  
#### 点查询  
##### 查询所有点  
```
MATCH (n)
RETURN n
```  
##### 查询特定标签的点  
```
MATCH (n:Person)
RETURN n
```  
##### 通过属性匹配点  
```
MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
##### 通过过滤条件匹配点  
```
MATCH (n:Person WHERE n.birthyear > 1910)
RETURN n.name LIMIT 2
```  
返回结果
```JSON
[{""n.name"":""Christopher Nolan""},{""n.name"":""Corin Redgrave""}]
```  
#### 边查询  
##### 出边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1970)-[e]->(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""BORN_IN"",""m.name"":""London"",""n.name"":""Christopher Nolan""},{""label(e)"":""DIRECTED"",""m.name"":null,""n.name"":""Christopher Nolan""}]
```  
##### 入边匹配  
```
MATCH (n:Person WHERE n.birthyear = 1939)<-[e]-(m)
RETURN n.name, label(e), m.name
```  
返回结果
```JSON
[{""label(e)"":""HAS_CHILD"",""m.name"":""Rachel Kempson"",""n.name"":""Corin Redgrave""},{""label(e)"":""HAS_CHILD"",""m.name"":""Michael Redgrave"",""n.name"":""Corin Redgrave""}]
```  
##### 带过滤条件的边匹配  
```
MATCH (n:Person)-[e:BORN_IN WHERE e.weight > 20]->(m)
RETURN n.name, e.weight, m.name
```  
返回结果
```JSON
[{""e.weight"":20.549999237060547,""m.name"":""New York"",""n.name"":""John Williams""},{""e.weight"":20.6200008392334,""m.name"":""New York"",""n.name"":""Lindsay Lohan""}]
```  
#### 路径匹配  
##### 不定跳查询  
```
MATCH (n:Person)-[e]->{2,3}(m:Person)
RETURN m.name LIMIT 2
```  
返回结果
```JSON
[{""m.name"":""Liam Neeson""},{""m.name"":""Natasha Richardson""}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.1.MATCH'}","page_content='ISO GQL

2.Clauses

2.2.OPTIONAL MATCH

`OPTIONAL MATCH`匹配图模式，如果未命中，则返回`null`。  
#### 查询命中  
```
OPTIONAL MATCH (n:Person{name:'Michael Redgrave'})
RETURN n.birthyear
```  
返回结果
```JSON
[{""n.birthyear"":1908}]
```  
#### 查询未命中  
```
OPTIONAL MATCH (n:Person{name:'Redgrave Michael'})
RETURN n.birthyear
```  
返回结果  
```JSON
[{""n.birthyear"":null}]
```' metadata={'Header 1': 'ISO GQL', 'Header 2': '2.Clauses', 'Header 3': '2.2.OPTIONAL MATCH'}","page_content='Match

Syntax

Node

匹配图上的点,可以指定点的类型以及对点的过滤条件。' metadata={'Header 1': 'Match', 'Header 2': 'Syntax', 'Header 3': 'Node'}"
GraphDB 实例无法使用的情况是什么？,"page_content='Use Graph

Syntax

```sql
USE GRAPH Identifier
```' metadata={'Header 1': 'Use Graph', 'Header 2': 'Syntax'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

一、高可用架构介绍

4.TuGraph-DB高可用架构—Raft 共识算法

针对上述缺点，我们选用了 Raft 算法来实现高可用架构。Raft 算法的优点包括：  
-   首先，它保持了一主多备的易用性。它有一个强leader可以对外提供服务。
-   第二是一致性。一主多备的模式是通过定期复制的方式去进行数据备份。但是Raft算法采用的是日志复制方式，复制的是日志并不是数据，当写请求的日志到来之后，会逐个按顺序发送给每一个节点，当超过半数的节点达成一致之后才会提交，所以它不仅不会丢失数据，甚至也不会存在日志空洞或乱序的情况。
-   有了一致性的保证后，安全性也就有了保证，当超过半数的节点达成一致之后，才应用日志，这样就能解决网络分区延迟、丢包、冗余和乱序的错误。
-   基于一致性和安全性，它的可用性也就得到了保证，只要少于半数的节点宕机，即使主机宕机，也可以快速恢复应用，通过一次选举的时间就可以重新选出一个leader对外提供服务。  
国标对于高可用系统的指标评估，RTO 和 RPO 分别是恢复时间指标和恢复点目标，有 6 个等级，TuGraph-DB 已经达到了最高等级。当少量节点故障时，RPO 是 0，也就是没有数据损失，数据恢复时间点指标是小于 15 秒。即使是在部署的时候，无论是在同城的两中心、三中心，还是多地的多中心，都可以达成 RTO 小于 15 秒的标准。  
Raft算法优点:  
• 易用性：状态简单，强Leader  
• 一致性：日志逐个复制，超过半数节点达成一致才提交，不存在日志空洞  
• 安全性：超半数节点达成一致才应用日志，能解决网络延迟、分区、丢包、冗余和乱序等错误  
• 可用性：能容忍少于半数的节点宕机，主机宕机时自动触发选举流程，选出Leader后快速恢复应用用户价值  
• 支持多地多中心部署，容灾和恢复能力强  
• RPO=0（少数节点故障），RTO<15S，超越国标恢复能力6级' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '一、高可用架构介绍', 'Header 3': '4.TuGraph-DB高可用架构—Raft 共识算法'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

三、TuGraph-DB高可用集群部署与应用

2.高可用集群部署

当原始数据一致的时候，可以直接指定 HA configure 参数启动集群。当初始数据不一致的时候，假如有一个节点有数据，其它节点没有数据，需要把数据同步到其它节点，但是又不能通过 SCP 传，那么就可以通过初始数据不一致的方式去启动。有数据的节点用 bootstrap 方式启动，预先生成一个快照，然后其它节点以 follower 的身份加入集群，加入集群时会安装快照，安装快照之后才会进行选举和 follower 身份的确认。  
初始数据一致:  
• 所有节点数据相同或没有数据时，可以直接指定ha_conf参数启动集群  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true \ --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090`  
初始数据不一致:  
• 有数据的节点使用bootstrap方式启动，预先生成快照  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090 --ha_bootstrap_role 1`  
• 无数据的节点直接以follower的身份加入安装快照，无需再选举  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090 —-ha_bootstrap_role 2`' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '三、TuGraph-DB高可用集群部署与应用', 'Header 3': '2.高可用集群部署'}"
TuGraph 运行需要保证哪个库文件的位置在环境变量 LD_LIBRARY_PATH 中？,"page_content='数据库运行

1.前置条件

TuGraph 运行的前置条件为 TuGraph 正确安装，参考[安装流程](1.environment.md)。  
TuGraph 运行需要保证库文件 liblgraph.so 的文件位置在环境变量 LD_LIBRARY_PATH。  
运行 TuGraph 进程的用户不需要超级权限，但需要对配置文件（一般为lgraph.json）及文件中涉及的文件有读权限，并且对数据文件夹、日志文件夹等有写权限。' metadata={'Header 1': '数据库运行', 'Header 2': '1.前置条件'}","page_content='场景：流浪地球

2.使用说明

前置条件：TuGraph已安装' metadata={'Header 1': '场景：流浪地球', 'Header 2': '2.使用说明'}","page_content='环境分类

2.依赖系统库

针对三种环境，除去TuGraph的运行包，所需要的系统库如下：
* 编译环境，包括gcc、python、java等编译器，也包含antlr4、pybind11等，具体参见tugraph-db源码目录 ci/images/tugraph-compile-*-Dockerfile。
* 运行环境，主要由存储过程引入，包括gcc、boost、cmake等，具体参见tugraph-db源码目录 ci/images/tugraph-runtime-*-Dockerfile。
* 精简运行环境，无，可以参见tugraph-db源码目录 ci/images/ tugraph-mini-runtime-*-Dockerfile。' metadata={'Header 1': '环境分类', 'Header 2': '2.依赖系统库'}"
GetNumOutEdges函数如何在达到限制时响应？,"page_content='Python Olap API

4. Olap API

图类OlapBase

- `NumVertices()-> size_t`：获取点数
- `NumEdges()-> size_t`：获取边数
- `OutDegree(size_t vid)-> size_t`：点vid的出度
- `InDegree(size_t vid)-> size_t`：点vid的入度  
- `AllocVertexArray[VertexData]() ->ParallelVector[VertexData]`：分配一个类型为VertexData的数组，大小为点个数
- `AllocVertexSubset()-> ParallelBitset`：分配一个ParallelBitset集合，用于表示所有点的状态是否激活
- `OutEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有出边集合
- `InEdges(vid: size_t)-> AdjList[EdgeData]`：获取点v的所有入边集合
- `Transpose()-> cython.void`：对有向图进行图反转
- `LoadFromArray(edge_array: cython.p_char, input_vertices: size_t, input_edges: size_t, edge_direction_policy: EdgeDirectionPolicy)`：从数组中加载图数据，包含四个参数，其含义分别表示：
- `edge_array`：将该数组中的数据读入图，一般情况下该数组包含多条边。
- `input_vertices`：指定数组读入图的点个数。
- `input_edges`：指定数组读入图的边的条数。
- `edge_direction_policy`：指定图为有向或无向，包含三种模式，分别为DUAL_DIRECTION、MAKE_SYMMETRIC以及INPUT_SYMMETRIC。对应的详细介绍见include/lgraph/olap_base.h文件的`enum EdgeDirectionPolicy`。  
- `AcquireVertexLock(vid: size_t)-> cython.void`：对点vid加锁，禁止其它线程对该锁对应的点数据进行访存
- `void ReleaseVertexLock(vid: size_t)-> cython.void`：对点vid解锁，所有线程均可访存该锁对应的点数据  
TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程，在Python中与C++使用方法稍有不同。  
```python
# 函数名称:ProcessVertexInRange[ReducedSum, Algorithm](
#           work: (algo: Algorithm, vi: size_t)-> ReducedSum,
#           lower: size_t, upper: size_t,
#           algo: Algorithm,
#           zero: ReducedSum = 0,
#           reduce: (a: ReducedSum, b: ReducedSum)-> ReducedSum = reduce_plus[ReducedSum])
#
#     函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
#     第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
#     具体实现请参考include/lgraph/olap_base.h中具体代码
#
#     使用示例:统计数组parent数组中有出边的点个数

import cython
from cython.cimports.olap_base import *


@cython.cclass
class CountCore:
graph: cython. pointer(OlapBase[Empty])
parent: ParallelVector[size_t]

@cython.cfunc
@cython.nogil
def Work(self, vi: size_t) -> size_t:
if self.graph.OutDegree(self.parent[vi]) > 0:
return 1
return 0

def run(self, pointer_g: cython' metadata={'Header 1': 'Python Olap API', 'Header 2': '4. Olap API', 'Header 3': '图类OlapBase'}","page_content='OlapOnDB API

4. 其他常用函数功能描述

4.6 获取出边集合

```C++
/*
函数名称：AdjList<EdgeData> OutEdges(size_t vid)
数据结构:
AdjList 可以理解为类型为AdjUnit结构体的数组
AdjUnit 有两个成员变量： 1. size_t neighbour 2. edge_data，其中neighbour表示该出边指向的目标节点编号，如果为有权图，则edge_data数据类型和输入文件中边的权重值相同，否则数据类型为Empty

使用示例：输出节点vid的所有出度邻居
*/
for (auto & edge : olapondb.OutEdges(vid)) {
size_t dst = edge.neighbour;
printf(""src = %lu,dst = %lu\n"",vid,dst);
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.6 获取出边集合'}","page_content='OlapOnDB API

4. 其他常用函数功能描述

4.7 获取入边集合

```C++
AdjList<EdgeData> InEdges(size_t vid)

// 使用示例：输出节点vid的所有入度邻居
for (auto & edge : olapondb.InEdges(vid)) {
size_t dst = edge.neighbour;
printf(""src = %lu,dst = %lu\n"",vid,dst);
}
```' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.7 获取入边集合'}"
文本中的 BFS 算法在每次迭代中怎样更新活跃顶点数量？,"page_content='OlapOnDisk API

2. 算法举例

2.4 bfs算法流程

`bfs`主流程有两个输入参数，快照类（子图）还有迭代次数，整体流程可以分为以下几步：  
1. 相关定义、数据结构的初始化
2. 使用批处理函数对每个节点进行循环计算，每一轮找到与当前节点相邻的全部节点，并在该轮次终止时进行交换。
3. 直到找到全部节点，返回节点个数discovered_vertices。  
```C++
size_t BFSCore(Graph<Empty>& graph, size_t root_vid, ParallelVector<size_t>& parent){

size_t root = root_vid;
auto active_in = graph.AllocVertexSubset();   //分配数组，active_in用于存放上一循环阶段已找到的节点
active_in.Add(root);            //把跟节点加入数组中
auto active_out = graph.AllocVertexSubset();  //分配数组active_out用于存放当前循环阶段找到的节点
parent.Fill((size_t)-1);               //将parent数组中的节点赋值为-1，-1表示未被找到
parent[root] = root;
size_t num_activations = 1;       //表示当前循环阶段找到的节点个数
size_t discovered_vertices = 0;    //表示当前循环阶段找到节点的总个数

for (int ii = 0; num_activations != 0; ii++) {       //num_activations表示当前循环阶段找到的节点个数
printf(""activates(%d) <= %lu\n"", ii, num_activations);
discovered_vertices += num_activations;         //discovered_vertices表示当前循环阶段找到节点的总个数
active_out.Clear();
num_activations = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t num_activations = 0;
for (auto& edge : graph.OutEdges(vi)) {   //每一次循环从根节点出发，查找邻近的相邻节点，对其parent值改变，并num_activations+1操作
size_t dst = edge.neighbour;
if (parent[dst] == (size_t)-1) {
auto lock = graph.GuardVertexLock(dst);
if (parent[dst] == (size_t)-1) {
parent[dst] = vi;
num_activations += 1;
active_out.Add(dst);       //存放当前循环阶段找到的节点
}
}
}
return num_activations;
},
active_in);
active_in.Swap(active_out);
}
// 返回全部节点数
return discovered_vertices;
}
```' metadata={'Header 1': 'OlapOnDisk API', 'Header 2': '2. 算法举例', 'Header 3': '2.4 bfs算法流程'}","page_content='OlapOnDB API

4. 其他常用函数功能描述

4.10 活跃点的描述

活跃点指的是在批处理函数中需要处理的点，在本例子中只是输出了活跃点的编号，并且汇总活跃点的数量：  
```C++
ParallelBitset temp = 000111;//当前活跃点为3，4，5号点

size_t delta = ForEachActiveVertex<double>(
//void c
[&](size_t vi) {
printf(""active_vertexId = %lu\n"",vi);
return 1;
},
all_vertices
);
```  
函数的运行结果显而易见，因为多线程的关系，一下输出顺序可能有所变化：  
```
active_vertexId = 3
active_vertexId = 4
active_vertexId = 5
```  
局部返回值均为1，该函数会在保证线程安全的情况下将所有的局部返回值累加得到最终的返回值，并存储在`delta`变量中，该值最终为3' metadata={'Header 1': 'OlapOnDB API', 'Header 2': '4. 其他常用函数功能描述', 'Header 3': '4.10 活跃点的描述'}","page_content='性能优先

3.存储数据结构

TuGraph底层采用B+树来支持实时的增删查改事务。  
在排序树的数据结构中，B+树和LSM树为主要代表。B+树在树节点中使用拆分和合并式来更新排序数据，而 LSM 树在日志中追加更新，以进行延迟数据合并。B+ 早期用在文件系统的实现中，通过将数据保存 在自适应长度的叶子节点中，解决硬盘顺序操作和随机操作性能存在数据量级差别的问题，有较均衡的读写性能。LSM 树的主要优势使用 WAL(Write Ahead Log) 进行更新，将更新操作变成顺序操作，在键值较小时性能优势尤为突出。WAL 意味着将数据的更新合并推迟，批量更新能提升综合效率，也使得系统的调度变得复杂。如果更新合并完成前，恰好对其中的数据继续读取，LSM 树就需要读取几个层级局部合并的日志，会导致读取放大和空间放大，从而影响读效率。  
总结来说，B+ 树有较好的顺序读写性能，而 LSM 树在数据随机写方面占优。此外 LSM 树采用后台合并的方式，使得性能的波动难以预期，性能波动和上层存储和计算的关联性较弱，增加了整体设计的成本。综上考虑，TuGraph 选用 B+ 树作为读性能优先的实现。' metadata={'Header 1': '性能优先', 'Header 2': '3.存储数据结构'}"
角色名的允许的最大长度是多少字节？,"page_content='TuGraph图模型说明

2. 图项目、点、边、属性命名规则和建议

2.1 命名规则

图项目、点、边和属性是识别符。该节描述了在TuGraph中识别符的允许的语法。
下面的表描述了每类识别符的最大长度和允许的字符。  
|**识别符** |**长度** |**允许的字符**|
|---------  |---------  |---------  |
|用户、角色、图项目|1-64字符|允许中文、字母、数字、下划线，且首字符不为数字|
|点类型、边类型、属性|1~256字符|允许中文、字母、数字、下划线，且首字符不为数字|' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '2. 图项目、点、边、属性命名规则和建议', 'Header 3': '2.1 命名规则'}","page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='TuGraph图模型说明

2. 图项目、点、边、属性命名规则和建议

2.2 使用限制

|**描述**|**最大个数**|
|-------- |--------- |
|用户数、角色数|65536|
|图项目的个数|4096|
|每个图项目的点和边类型数量之和|4096|
|每个点或边类型的属性数量|1024|  
注：
1、特殊字符和关键字说明：使用特殊字符或非保留关键字时，需要使用反单引号/backquote（``）进行引用；  
示例： ```match (`match`:match) return `match`.id limit 1```  
2、大小写敏感性：TuGraph大小写敏感；  
3、图项目、点/边、属性名称之间可以重复使用，同一点或边下的属性名称不可以重复；  
4、属性名字保留关键字：SRC_ID / DST_ID / SKIP' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '2. 图项目、点、边、属性命名规则和建议', 'Header 3': '2.2 使用限制'}"
URIs 用于修改和启用角色的 HTTP 方法是什么？,"page_content='RESTful API Legacy

6.Deprecated

6.2.角色管理

TuGraph 使用基于角色的权限管理。  
同一用户可以拥有多个角色。新用户默认拥有与其同名的角色。删除用户时，同名角色也会被删除。如果新建用户时同名角色已经存在，则创建失败。  
同一角色可以对多个图有不同的权限。用户对某张图的权限由其所有角色对该图的最高权限决定。  
TuGraph 使用四级权限，不用的用户对不同的子图可以有不同的权限，四种权限及其说明如下：  
| 权限  | 说明                                                                             |
| ----- | -------------------------------------------------------------------------------- |
| NONE  | 无权限                                                                           |
| READ  | 只读                                                                             |
| WRITE | 可读写子图中的点和边                                                           |
| FULL  | 完全权限，包括更改元数据（label, index），管理存储过程，以及删除子图中的所有数据 |  
管理员对所有子图都有完全权限，新建的用户对所有子图都没有权限。将用户加入管理员角色中可以将用户提升为管理员。  
#### 6.2.1.添加角色  
添加一个新的角色，并设置其描述。只有管理员有权限进行此操作。  
角色名只能由字母，数字以及下划线构成，密码则可以包含任意字符。角色名长度不能超过 64 字节。  
角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| role | 角色名 | 字符串 |
| description | 角色描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""role"": ""new_role"",
""description"": ""This is a new role."",
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.2.2.修改角色描述  
修改角色的描述。只有管理员有权限进行此操作。角色描述可以是任意字符串，长度不超过 512 字节。  
- **URI**: `/role/{role_name}/description`
- **METHOD**: PUT
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 新描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/role/role1/description
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.2.角色管理'}","page_content='RESTful API Legacy

6.Deprecated

6.1.用户管理

系统默认创建一个管理员，管理员用户名为 _admin_，密码为 _73@TuGraph_。为了安全起见，请用户在第一次启动服务器后更改密码。  
#### 6.1.1.添加用户  
添加一个新的用户，并为其设置初始密码。只有管理员有权限进行此操作。其中用户名只能由字母，数字以及下划线构成，密码则可以包含任意字符。用户名和密码长度不能超过 64 字节。添加用户时还可以为用户增加一个描述，用户描述可以包含任意字符，最长不超过 512 字节。  
新用户默认拥有同名的角色，不具备任何图的权限。  
- **URI**: `/user`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |
| description | 用户描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""user"": ""USER1"",
""password"": ""AN_INITIAL_PASSWORD"",
""description"": ""This is a user""
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.1.2.列出所有用户  
列出数据库的所有用户。只有管理员拥有该操作权限。  
- **URI**: `/user/`
- **METHOD**: GET
- **RESPONSE**: 所有用户及其信息。  
**Example request.**  
```
• GET http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
Output:
{
""admin"": {
""disabled"": false,
""description"": ""Builtin admin user"",
""roles"": [""admin""]
},
""guest1"": {
""disabled"": true,
""description"": """",
""roles"": [""guest1"", ""some_other_role""]
}
}
```  
#### 6.1.3.获取用户信息  
列出给定用户的信息。  
- **URI**: `/user/{user_name}`
- **METHOD**: GET
- **RESPONSE**: 用户信息。  
**Example request.**  
```
• GET http://localhost:7070/user/guest1
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.1.用户管理'}","page_content='RESTful API Legacy

2.请求与数据格式

2.4.URI格式

TuGraph REST API 提供以下功能：Service Root, login, info, label, index, node, relationship, cypher, cpp_plugin, 以及 python_plugin。
各功能使用的 URI 格式如下：  
| URI     | 说明                 |
| ------- | -------------------- |
| /web    | web 可视化界面       |
| /cypher | cypher 请求          |
| /acl    | 权限控制             |
| /user   | 用户管理             |
| /login  | 用户登录             |
| /info   | 数据库状态及提示信息 |
| /task   | 任务管理             |
| /db     | 子图操作             |  
其中子图操作又分为：  
| URI                              | 说明                 |
| -------------------------------- | -------------------- |
| /db                              | 子图的创建，删除     |
| /db/_{graph_name}_/node          | 点操作             |
| /db/_{graph_name}_/relationship  | 边操作               |
| /db/_{graph_name}_/label         | Label 相关操作       |
| /db/_{graph_name}_/index         | 索引相关操作         |
| /db/_{graph_name}_/cypher        | 子图相关 cypher 操作 |
| /db/_{graph_name}_/cpp_plugin    | C++存储过程          |
| /db/_{graph_name}_/python_plugin | Python 存储过程      |
| /db/_{graph_name}_/import        | 在线导入             |
| /db/_{graph_name}_/misc          | 其它操作             |' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '2.请求与数据格式', 'Header 3': '2.4.URI格式'}"
