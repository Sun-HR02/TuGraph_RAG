Q,K1,K2,K3
RPC 及 HA 服务中，verbose 参数的设置有几个级别？,"page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客户端端口。默认端口为 7687。                                                                                                                                                            |
| enable_ha                    | 布尔值                   | 是否启动高可用模式。默认值为 false。                                                ' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='日志信息

2.服务器日志

2.1.服务器日志配置项

服务器日志的输出位置可以通过`log_dir`配置指定。服务器日志详细程度可通过`verbose`配置项指定。  
`log_dir`配置项默认为空。若`log_dir`配置项为空，则所有日志会输出到控制台(daemon模式下若log_dir配置项为空则不会向console输出任何日志)；若手动指定`log_dir`配置项，则日志文件会生成在对应的路径下面。单个日志文件最大大小为256MB。  
`verbose`配置项控制日志的详细程度，从粗到细分为`0, 1, 2`三个等级，默认等级为`1`。等级为`2`时，日志记录最详细，服务器将打印`DEBUG`及以上等级的全部日志信息；等级为`1`时，服务器将仅打印`INFO`等级及以上的主要事件的日志；等级为`0`时，服务器将仅打印`ERROR`等级及以上的错误日志。' metadata={'Header 1': '日志信息', 'Header 2': '2.服务器日志', 'Header 3': '2.1.服务器日志配置项'}","page_content='RPC API

5.存储过程

5.2.调用存储过程

调用存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称
- param: 必要参数，存储过程参数
- result_in_json_format: 可选参数，调用结果是否以JSON格式返回
- in_process: 可选参数，未来支持
- timeout: 可选参数，调用存储过程的超时时间  
以C++为例，用户调用存储过程的方式如下所示：
```C++
LGraphRequest req;
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
lgraph::CallPluginRequest *cpRequest = pluginRequest->mutable_call_plugin_request();
cpRequest->set_name(procedure_name);
cpRequest->set_in_process(in_process);
cpRequest->set_param(param);
cpRequest->set_timeout(procedure_time_out);
cpRequest->set_result_in_json_format(json_format);
LGraphResponse res;
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
if (json_format) {
result = res.mutable_plugin_response()->mutable_call_plugin_response()->json_result();
} else {
result = res.mutable_plugin_response()->mutable_call_plugin_response()->reply();
}
```
调用存储过程的响应为以下两个参数之一：
- reply: ByteString格式的存储过程调用结果
- json_result: JSON格式的存储过程调用结果' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.2.调用存储过程'}"
在磁盘IO监控的配置中，当哪个值大于10000时会触发危急颜色模式？,"page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客户端端口。默认端口为 7687。                                                                                                                                                            |
| enable_ha                    | 布尔值                   | 是否启动高可用模式。默认值为 false。                                                ' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='运维监控

2.部署方案

2.4.第四步

+ 下载符合您机器架构以及系统版本的Grafana安装包，下载地址: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)  
+ 安装Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 启动Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 配置Grafana，首先在数据源设置中配置Prometheus的IP地址，配置完成后可以通过测试连接功能，验证是否成功连接数据源。然后，导入如下模版，并在页面中根据实际情况，修改正确的接口IP和端口。最后可以根据实际情况设置刷新时间和监控时间范围  
```json
{
""annotations"": {
""list"": [
{
""builtIn"": 1,
""datasource"": {
""type"": ""grafana""
},
""enable"": true,
""hide"": true,
""iconColor"": ""rgba(0, 211, 255, 1)"",
""name"": ""Annotations & Alerts"",
""target"": {
""limit"": 100,
""matchAny"": false,
""tags"": [],
""type"": ""dashboard""
},
""type"": ""dashboard""
}
]
},
""editable"": true,
""fiscalYearStartMonth"": 0,
""graphTooltip"": 0,
""id"": 2,
""links"": [],
""liveNow"": false,
""panels"": [
{
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
}
},
""mappings"": [],
""unit"": ""kbytes""
},
""overrides"": [
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {__name__=\""resources_report\"", instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
},
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""others""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-blue"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
}
}
]
}
]
},
""gridPos"": {
""h"": 16,
""w"": 6,
""x"": 0,
""y"": 0
},
""id"": 14,
""options"": {
""displayLabels"": [
""name"",
""value""
],
""legend"": {
""displayMode"": ""table"",
""placement"": ""bottom"",
""values"": [
""percent"",
""value""
]
},
""pieType"": ""pie"",
""reduceOptions"": {
""calcs"": [
""lastNotNull""
],
""fields"": """",
""val' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}","page_content='RESTful API Legacy

6.Deprecated

6.3.服务器状态

#### 6.3.1.修改服务器配置  
修改服务器配置，配置修改后立即生效，并将影响所有服务器。这些配置的优先级高于配置文件以及命令行参数。  
- **URI**: `/config`
- **METHOD**: PUT
- **REQUEST**:  
请求为一个字典，使用 `{""opt1"":v1}` 可以将名为`opt1`的配置修改为`v1`。  
| 配置名               | 说明                   | 值类型 |
| -------------------- | ---------------------- | ------ |
| OPT_DB_ASYNC         | 是否启用异步模式       | 布尔值 |
| OPT_TXN_OPTIMISTIC   | 是否默认使用乐观事务锁 | 布尔值 |
| OPT_AUDIT_LOG_ENABLE | 是否启用审计日志       | 布尔值 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• PUT http://localhost:7070/config
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""OPT_DB_ASYNC"": true,
""OPT_AUDIT_LOG_ENABLE"": false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.3.2.当前服务器状态  
- **URI**: `/info`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| lgraph_version | 服务器版本号 | 字符串 |
| git_branch | 服务器代码分支 | 字符串 |
| git_commit | 服务器代码版本 | 字符串 |
| web_commit | 前端码版本 | 字符串 |
| cpp_id | CPP 编译器 ID | 字符串 |
| cpp_version | CPP 编译器版本 | 字符串 |
| python_version | PYTHON 版本 | 字符串 |
| node | 点 uri | 字符串 |
| relationship | 边 uri | 字符串 |
| cpu | cpu 信息 | 字典，格式参见[服务器 CPU 状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8CPU%E7%8A%B6%E6%80%81) |
| disk | 硬盘 IO 信息 | 字典，格式参见[服务器硬盘状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E7%9B%98%E7%8A%B6%E6%80%81) |
| memory | 内存信息 | 字典，格式参见[服务器内存状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%86%85%E5%AD%98%E7%8A%B6%E6%80%81) |
| db_space | 图数据库占用空间 | 字典，格式参见[图数据库占用空间](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4) |
| db_config | 图数据库配置信息 | 字典，格式参见[图数据库配置信息](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF) |
| up_time | 数据库在线时长（秒） | 整型 |  
**Example request.**  
```
• GET http://localhost:7070/info
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""lgraph_version"": ""1.2.0"",
""git_branch"": ""master"",
""git_commit"": ""9e2977d"",
""web_commit"": ""1e2823d"",
""cpu_id"": ""GUN"",
""cpu_version"": ""4.8.5"",
""python_version"": ""3.2"",
""node"": ""/node"",
""relationship"": ""/relationship"",
""cpu"": {
""self"": 25,
""server"": 35,
""unit"": ""%""
},
""disk"": {
""read"": 2000,
""write"": 2000,
""unit"": ""B/s""
},
""memory"": {
""self"": 25016,
""server_avail"": 46865636,' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.3.服务器状态'}"
`FieldData` 类中的函数 `IsReal()` 是用来查询什么类型的数据？,"page_content='空间数据类型在TuGraph-DB中的实现

相关函数介绍

创建空间数据相关函数，以Point为例：  
| **函数名** | **描述** | **输入参数** | **返回值类型** |
| --- | --- | --- | --- |
| Point() | 根据坐标或EWKB创建Point | 坐标对(double, double) / EWKB format(string) | point |
| PointWKB() | 根据WKB与指定SRID创建Point | WKB format(string) , SRID(int) | point |
| PointWKT() | 根据WKT与指定SRID创建Point | WKT format(string) , SRID(int) | point |  
查询用相关函数：  
| **函数名** | **描述** | **输入参数** | **返回值类型** |
| --- | --- | --- | --- |
| Distance() | 计算两个空间数据间的距离 |
|
|
| 注：要求坐标系相同 | Spatial data1, Spatial data2 | double |
|
| Disjoint() | 判断两个空间数据是否相交 |
|
|
| 注：开发中 | Spatial data1, Spatial data2 | bool |
|
| WithinBBox() | 判断某个空间数据是否在给定的长方形区域内 |
|
|
| 注：开发中 | Spatial data, Point1 | bool |
|  
使用实例如下：  
```
#创建包含空间数据类型的点模型
CALLdb.createVertexLabel('food','id','id',int64,false,'name',string,true,'pointTest',point,true)

#插入标记美食点的数据
CREATE(n:food{id:10001,name:'acoBell',pointTest:point(3.0,4.0,7203)})RETURNn

#创建具有折线属性的点模型
CALLdb.createVertexLabel('lineTest','id','id',int64,false,'name',string,true,'linestringTest',linestring,true)

#插入具有折线属性的点数据
CREATE(n:lineTest{id:102,name:'Tom',linestringTest:linestringwkt('LINESTRING(02,11,20)',7203)})RETURNn

#创建具有多边型属性的点模型
CALLdb.createVertexLabel('polygonTest','id','id',int64,false,'name',string,true,'polygonTest',polygon,true)

#插入具有多边型属性的点数据
CREATE(n:polygonTest{id:103,name:'polygonTest',polygonTest:polygonwkt('POLYGON((00,07,42,20,00))',7203)})RETURNn



```' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '相关函数介绍'}","page_content='业务开发指南

实时查看当前点边数据量

如下例子返回所有的点边类型，以及每种类型当前的数据量是多少。  
读的是统计数据，轻操作。
```
CALL dbms.meta.countDetail()
```' metadata={'Header 1': '业务开发指南', 'Header 2': '实时查看当前点边数据量'}","page_content='地理空间数据类型使用示例

4. 函数介绍

| 函数名  | 描述 | 输入参数                         | 返回值类型 |
| --- | --- |------------------------------| --- |
| Distance() | 计算两个空间数据间的距离(要求坐标系相同) | Spatial data1, Spatial data2 | double |
| Disjoint()  |  判断两个空间数据是否相交（开发中） | Spatial data1, Spatial data2 | bool |
| WithinBBox() | 判断某个空间数据是否在给定的长方形区域内（开发中） | Spatial data, Point1         | bool |' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '4. 函数介绍'}"
如果成功修改一个用户的描述，应返回什么状态码？  ,"page_content='RESTful API Legacy

6.Deprecated

6.1.用户管理

系统默认创建一个管理员，管理员用户名为 _admin_，密码为 _73@TuGraph_。为了安全起见，请用户在第一次启动服务器后更改密码。  
#### 6.1.1.添加用户  
添加一个新的用户，并为其设置初始密码。只有管理员有权限进行此操作。其中用户名只能由字母，数字以及下划线构成，密码则可以包含任意字符。用户名和密码长度不能超过 64 字节。添加用户时还可以为用户增加一个描述，用户描述可以包含任意字符，最长不超过 512 字节。  
新用户默认拥有同名的角色，不具备任何图的权限。  
- **URI**: `/user`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| user | 用户名 | 字符串 |
| password | 密码 | 字符串 |
| description | 用户描述 | 字符串 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
Input:
{
""user"": ""USER1"",
""password"": ""AN_INITIAL_PASSWORD"",
""description"": ""This is a user""
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.1.2.列出所有用户  
列出数据库的所有用户。只有管理员拥有该操作权限。  
- **URI**: `/user/`
- **METHOD**: GET
- **RESPONSE**: 所有用户及其信息。  
**Example request.**  
```
• GET http://localhost:7070/user
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
Output:
{
""admin"": {
""disabled"": false,
""description"": ""Builtin admin user"",
""roles"": [""admin""]
},
""guest1"": {
""disabled"": true,
""description"": """",
""roles"": [""guest1"", ""some_other_role""]
}
}
```  
#### 6.1.3.获取用户信息  
列出给定用户的信息。  
- **URI**: `/user/{user_name}`
- **METHOD**: GET
- **RESPONSE**: 用户信息。  
**Example request.**  
```
• GET http://localhost:7070/user/guest1
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
• Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6dHJ1ZSwiaXNzIjoiZm1hLmFpIiwidXNlcl9pZCI6ImFkbWluIn0.SHaqrjKLaI4byjbEYVAH4D88dOTD_zYQ_uAvdizTMek
```  
**Example response.**  
```
• 200: OK
Output:
{
""disabled"": true,
""description"": ""A guest user""
""roles"": [""guest1"", ""some_other_role""]
}
```  
#### 6.1.4.列出用户权限  
列出给定用户有权限访问的所有图及相应权限。  
- **URI**: `/user/{user_name}/graph`
- **METH' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.1.用户管理'}","page_content='RESTful API Legacy

6.Deprecated

6.3.服务器状态

#### 6.3.1.修改服务器配置  
修改服务器配置，配置修改后立即生效，并将影响所有服务器。这些配置的优先级高于配置文件以及命令行参数。  
- **URI**: `/config`
- **METHOD**: PUT
- **REQUEST**:  
请求为一个字典，使用 `{""opt1"":v1}` 可以将名为`opt1`的配置修改为`v1`。  
| 配置名               | 说明                   | 值类型 |
| -------------------- | ---------------------- | ------ |
| OPT_DB_ASYNC         | 是否启用异步模式       | 布尔值 |
| OPT_TXN_OPTIMISTIC   | 是否默认使用乐观事务锁 | 布尔值 |
| OPT_AUDIT_LOG_ENABLE | 是否启用审计日志       | 布尔值 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• PUT http://localhost:7070/config
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""OPT_DB_ASYNC"": true,
""OPT_AUDIT_LOG_ENABLE"": false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.3.2.当前服务器状态  
- **URI**: `/info`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| lgraph_version | 服务器版本号 | 字符串 |
| git_branch | 服务器代码分支 | 字符串 |
| git_commit | 服务器代码版本 | 字符串 |
| web_commit | 前端码版本 | 字符串 |
| cpp_id | CPP 编译器 ID | 字符串 |
| cpp_version | CPP 编译器版本 | 字符串 |
| python_version | PYTHON 版本 | 字符串 |
| node | 点 uri | 字符串 |
| relationship | 边 uri | 字符串 |
| cpu | cpu 信息 | 字典，格式参见[服务器 CPU 状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8CPU%E7%8A%B6%E6%80%81) |
| disk | 硬盘 IO 信息 | 字典，格式参见[服务器硬盘状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E7%9B%98%E7%8A%B6%E6%80%81) |
| memory | 内存信息 | 字典，格式参见[服务器内存状态](#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%86%85%E5%AD%98%E7%8A%B6%E6%80%81) |
| db_space | 图数据库占用空间 | 字典，格式参见[图数据库占用空间](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4) |
| db_config | 图数据库配置信息 | 字典，格式参见[图数据库配置信息](#%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF) |
| up_time | 数据库在线时长（秒） | 整型 |  
**Example request.**  
```
• GET http://localhost:7070/info
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""lgraph_version"": ""1.2.0"",
""git_branch"": ""master"",
""git_commit"": ""9e2977d"",
""web_commit"": ""1e2823d"",
""cpu_id"": ""GUN"",
""cpu_version"": ""4.8.5"",
""python_version"": ""3.2"",
""node"": ""/node"",
""relationship"": ""/relationship"",
""cpu"": {
""self"": 25,
""server"": 35,
""unit"": ""%""
},
""disk"": {
""read"": 2000,
""write"": 2000,
""unit"": ""B/s""
},
""memory"": {
""self"": 25016,
""server_avail"": 46865636,' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.3.服务器状态'}","page_content='RESTful API Legacy

3.登录

3.3.修改Token有效期

修改Token有效期，需要传输jwt，refresh_time和expire_time三个参数，其中jwt用于校验用户身份，refresh_time和expire_time等于0时，有效期为无期限，超过refresh_time时，需要调用refresh接口获取新的Token;超过expire_time时，需要重新登录。  
- **URI**: `/update_token_time`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| Authorization | 令牌 | 字符串 |
| refresh_time | 有效时间（默认设置为0） | Int64 |
| expire_time | 有效时间（默认设置为0） | Int64 |  
- **RESPONSE**:  如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/update_token_time
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""Authorization"" : ""Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJmbWEuYWkiLCJwYXNzd29yZCI6IjczQFR1R3JhcGgiLCJ1c2VyIjoiYWRtaW4ifQ.o_yb5veSJkuy-ieBp4MqTk-tC1grcKotgVbgNJ0TyTU"",
""refresh_time"":0,
""expire_time"":0
}
```  
**Example response.**  
```
• 200: OK
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '3.登录', 'Header 3': '3.3.修改Token有效期'}"
边关联的两个点的字段，一定是点的主键吗？,"page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}","page_content='图相关DDL

Create Graph

**Syntax**
一个图至少包含一对点边，点表必须包含一个id字段作为主键，边表必须包含srcId和targetId作为主键，边表还可以有一个时间戳字段标识时间。  
```
CREATE GRAPH <graph name>
(
<graph vertex>
[ { , <graph vertex> } ... ]
, <graph edge>
[ { , <graph edge> } ... ]
) WITH （
storeType = <graph store type>
[ { , <config key> = <config value> } ... ]
);

<graph vertex>  ::=
VERTEX <vertex name>
(
<column name> <data type> ID
[ {, <column name> <data type> } ... ]
)

<graph edge>  ::=
Edge <edge name>
(
<column name> <data type> SOURCE ID
, <column name> <data type> DESTINATION ID
[ , <column name> <data type> TIMESTAMP ]
[ {, <column name> <data type> } ... ]
)

```  
**Example**
```sql
CREATE GRAPH dy_modern (
Vertex person (
id bigint ID,
name varchar,
age int
),
Vertex software (
id bigint ID,
name varchar,
lang varchar
),
Edge knows (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
),
Edge created (
srcId bigint SOURCE ID,
targetId bigint DESTINATION ID,
weight double
)
) WITH (
storeType = 'rocksdb',
shardCount = 2
);
```
这个例子创建了一张包含2个点2个边的图，存储类型为rocksdb, 分片数2个。' metadata={'Header 1': '图相关DDL', 'Header 2': 'Create Graph'}","page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}"
OutEdgeIterator 类的 Delete 方法执行什么操作？,"page_content='业务开发指南

边类型操作

删除边类型

>该操作会同步删除所有该类型的边，数据量大的时候，有时间消耗。  
如下例子，删除边类型`edge1`以及该类型的所有边数据。
```
CALL db.deleteLabel('edge', 'edge1')
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '删除边类型'}","page_content='业务开发指南

边类型操作

边类型删除字段

>该操作会同步变更所有该类型边的属性数据，数据量大的时候，有时间消耗。  
如下操作，对于边类型`edge1`，一次删除了两个字段: `field1` 和 `field2`。
```
CALL db.alterLabelDelFields('edge', 'edge1', ['field1', 'field2'])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型删除字段'}","page_content='业务开发指南

边类型操作

边类型删除索引

如下例子，对于边类型`edge1`，删除字段`field1`上的索引。
```
CALL db.deleteEdgeIndex('edge1', 'field1')
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型删除索引'}"
TuGraph-DB的日志等级如何调整？,"page_content='技术规划

2. 已完成功能

TuGraph-DB于2022年9月1日开源，TuGraph-DB在社区的反馈声中，进行日常BUG修复，自身能力得到了完善。  
| 版本号   | 功能                               | 时间         |
|-------|----------------------------------|------------|
| 3.3.0 | 开源初版                             | 2022.9.1   |
| 3.3.1 | 图分析引擎重构，多模式支持                    | 2022.10.14 |
| 3.3.2 | OGM支持，UT覆盖率提升                    | 2022.11.21 |
| 3.3.3 | 链接认证机制迭代，加入英文文档                  | 2022.12.23 |
| 3.3.4 | 支持上云，梳理LDBC SNB Audit流程          | 2023.1.28  |
| 3.4.0 | 支持OLAP Python API, 离线导入升级        | 2023.3.11  |
| 3.5.0 | 支持POG，前端升级，文档梳理                  | 2023.6.5   |
| 3.5.1 | 图学习引擎，Procedure Rust API，存储属性分离  | 2023.7.14  |
| 3.6.0 | 高可用开源，日志系统升级                     | 2023.8.11  |
| 4.0.0 | ISO GQL支持，新增11个开源图算法，支持m1 Docker | 2023.9.6   |
| 4.0.1 | 支持时序边排序，新增5个开源图算法                | 2023.9.28  |
| 4.1.0 | 支持Bolt协议，支持快速在线全量导入，支持地理空间数据类型   | 2023.12.25 |  
除此之外，TuGraph-DB搭建了较为完善的质量体系，涵盖自动化的单元测试、集成测试、性能测试等。  
更详细的描述可以在源码目录在的 ""[root]/release/CHANGELOG.md"" 文件查看。' metadata={'Header 1': '技术规划', 'Header 2': '2. 已完成功能'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

二、TuGraph-DB高可用架构与规划

4.Server架构设计—快照

前文中提到，加入 follower 时，需要同步日志。但是一个集群经过长期的服务，日志一定是非常多的，如果每加入一个 follower，都从一年之前、两年之前的日志开始同步，同步过来除了 Append，还需要应用到 Server 里面，是非常耗时的。所以需要定期对节点打快照，对数据库状态做一个保存。再去加入 follower 时，直接传输快照就可以了。  
Tugraph-DB 不管是安装快照还是打快照，都是非常快速的。因为 Tugraph-DB 底层支持 MVCC 多版本，生成快照的时候并不会去阻塞读写请求。  
增加节点  
• 新节点加入集群时，Leader发现要同步的日志不存在，则向Follower发送安装快照请求  
安装快照  
• TuGraph-DB支持MVCC，生成快照不会阻塞读写请求' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '二、TuGraph-DB高可用架构与规划', 'Header 3': '4.Server架构设计—快照'}","page_content='日志信息

1.简介

TuGraph 保留两种类型的日志：服务器日志和审计日志。服务器日志记录人为可读的服务器状态信息，而审核日志维护服务器上执行的每个操作加密后的信息。' metadata={'Header 1': '日志信息', 'Header 2': '1.简介'}"
机器性能指标中的“memory”是什么？,"page_content='功能概览

3.计算层

计算层在功能上分成三个部分，包括TP类的图事务引擎，AP类的图分析引擎和图神经网络引擎。  
- __图事务引擎__，主要用来处理并发的图操作，包括单点查询、邻居查询、路径遍历。图事务引擎侧重并发操作的ACID事务，确保操作逻辑不会互相干扰，主要性能指标为 QPS，即每秒完成的查询数量。  
- __图分析引擎__，操作类型通常为全图迭代。部分简单的分析任务（比如SPSP）可以由图事务引擎完成，复杂的分析任务均由图分析引擎完成，单个任务通常需要数秒至数小时。因此单个图分析任务要并发利用所有的硬件资源，性能指标为任务完成的总时长。  
- __图神经网络引擎__，通常也为全图迭代。图神经网络引擎除了基于图拓扑的操作，也需要集成一个机器学习的框架来处理向量操作，比如 PyTorch、MXNet、TenserFlow。  
三个引擎的操作逻辑不尽相同，独立配置资源池。事图事务引擎基于RPC操作设置了一个线程池，每接受客户端的一个操作，从线程中取一个线程来处理，并发执行的数量等于RPC线程池的容量，通常配置为服务器的核数。图分析引擎有一个分析线程池，每个图分析任务会并发执行，即用所有的线程来执行一个任务，来加速操作的性能。TuGraph图分析操作串行执行的特性会一定程度限制用户的使用体验，并发的图分析的需求可以通过高可用部署的方式，增加机器资源来处理，或者接入外部的任务调度器，将数据传到实时调度的容器来计算。图神经网络操作在图上的操作会复用图事务引擎或图分析引擎的资源，向量的操作会起单独的资源，在机器学习框架中可以使用GPU等单独的加速硬件。' metadata={'Header 1': '功能概览', 'Header 2': '3.计算层'}","page_content='性能优先

3.存储数据结构

TuGraph底层采用B+树来支持实时的增删查改事务。  
在排序树的数据结构中，B+树和LSM树为主要代表。B+树在树节点中使用拆分和合并式来更新排序数据，而 LSM 树在日志中追加更新，以进行延迟数据合并。B+ 早期用在文件系统的实现中，通过将数据保存 在自适应长度的叶子节点中，解决硬盘顺序操作和随机操作性能存在数据量级差别的问题，有较均衡的读写性能。LSM 树的主要优势使用 WAL(Write Ahead Log) 进行更新，将更新操作变成顺序操作，在键值较小时性能优势尤为突出。WAL 意味着将数据的更新合并推迟，批量更新能提升综合效率，也使得系统的调度变得复杂。如果更新合并完成前，恰好对其中的数据继续读取，LSM 树就需要读取几个层级局部合并的日志，会导致读取放大和空间放大，从而影响读效率。  
总结来说，B+ 树有较好的顺序读写性能，而 LSM 树在数据随机写方面占优。此外 LSM 树采用后台合并的方式，使得性能的波动难以预期，性能波动和上层存储和计算的关联性较弱，增加了整体设计的成本。综上考虑，TuGraph 选用 B+ 树作为读性能优先的实现。' metadata={'Header 1': '性能优先', 'Header 2': '3.存储数据结构'}","page_content='Framework原理介绍

计算引擎

容错和异常恢复

#### 集群组件容错
对于运行时的所有组件进程，比如master/driver/container,都基于context初始化和运行。在新创建进程时，首先构建进程需要的context，每个进程在初始化时将context做持久化。当进程异常重启后，首先恢复context，然后基于context重新初始化进程。  
#### 作业异常恢复
![undefined](../../static/img/framework_failover.jpeg)
* 作业分布式快照
调度器根据当前自身调度状态，确定对运行中的任务发送新的windowId，触发对新窗口的计算。当每个算子对应窗口计算结束后，如果需要对当前窗口上下文做快照，则将算子内对应状态持久化到存储中。
最终调度器收到某个窗口的所有任务执行结束的消息后，也会按需要对该调度元信息做一次快照并持久化，才标志这个窗口的处理最终成。当调度和算子恢复到这个窗口上下文时，则可以基于该窗口继续执行。  
* 快照持久化
在一个window计算完成做一次快照时，可以选择快照存储的方式。目前可选MEMORY，ROCKSDB, JDBC。  
* 状态恢复
快照存储是分布式的，每个组件，调度和算子之间各自存储并持久化。在恢复时，首先调度先从存储中恢复上一次完成执行的windowId，并调度的上下文恢复到对应windowId对应的快照。然后对所有worker发送rollback指令，每个worker恢复到指定窗口上下文。最后由调度开始继续发送执行任务，从恢复状态基础上继续执行。' metadata={'Header 1': 'Framework原理介绍', 'Header 2': '计算引擎', 'Header 3': '容错和异常恢复'}"
如果不选择清空画布数据按钮，导入的数据会如何处理？,"page_content='TuGraph-Restful-Server

7.接口

7.8 数据导入请求

用户通过此类请求导入已经上传的数据文件。导入不论成功或失败，都将删除已上传文件。数据导入请求在server中实现为一个异步任务，响应返回并不意味着导入已完成，返回的是任务id，后续可以通过此任务id查询导入进度
#### 7.8.1 URL
http://${ip}:${rpc_port}/LGraphHttpService/Query/import_data
#### 7.8.2 REQUEST
|  body参数  |          参数说明           |  参数类型  | 是否必填 |
|:--------:|:-----------------------:|:------:|:----:|
| graph |         导入目标子图          |  字符串  |  是   |
| schema |       导入schema描述        | json字符串  |  是   |
| delimiter |           分隔符           |  字符串  |  是   |
| continueOnError |     单行数据出错是否跳过错误并继续     |  boolean  |  否   |
| skipPackages |         跳过的包个数          |  字符串  |  否   |
| taskId |  任务id   |  字符串  |  否   |
| other | 其他参数 |  json字符串  |  否   |  
#### 7.8.3 RESPONSE
|    body参数     |  参数说明   |  参数类型  |  是否必填  |
|:-------------:|:-------:|:------:| :-----: |
| taskId | 任务编号 |  字符串  |  是  |' metadata={'Header 1': 'TuGraph-Restful-Server', 'Header 2': '7.接口', 'Header 3': '7.8 数据导入请求'}","page_content='可视化操作手册

2.操作指南

2.4.图项目

`图项目`提供可视化的图项目管理和图数据研发功能，它为用户提供了一系列便捷的图数据可视化操作，包括图项目的创建、修改、删除等管理操作，以及图数据的查询、点边统计等操作。此外，它也支持图模型的管理，使用户可以更加方便地进行图数据的管理和维护。  
#### 2.4.1.图项目管理  
在`图项目`界面，可以看到当前图数据库中的图项目。  
![图项目-首页](../../../images/browser/graphmanagement-homepage.png)  
##### 2.4.1.1.新建图项目  
在`图项目`界面，点击`新建图项目`按钮创建一个新的图项目。  
![图项目-新建图项目按钮](../../../images/browser/graphmanagement-creategraph.png)  
新建图项目需要通过`选择模板`和`填写配置`两个页面完成图项目的创建。  
- __选择模板__：产品提供空模板和demo模板两类模板。
- 空模板：全新的图项目，用户需要自己创建图模型和导入图数据，一般用于正式项目开发。
- demo模板：产品内置的demo数据，图项目创建成功后，系统会自动创建demo图模型并导入demo图数据，一般用于试用和学习。  
![图项目-选择模板](../../../images/browser/graphmanagement-selecttemplate.png)  
- __填写配置__：用户需要填写图项目基本信息，并点击`创建`按钮创建图项目。
- 图名称：新建图项目的名称，同时作为该图项目的唯一主键。支持中文、字母、数字以及下划线，不支持空格以及其他特殊符号。
- 图描述：新建图项目的描述，可用于详细说明该项目的背景和目标。
- 高级配置-最大存储空间：设置图项目最大可占用的存储空间，实际并不会提前占用物理存储空间，实际数据量达到最大存储空间阈值后不可再写入数据。  
![图项目-填写配置](../../../images/browser/graphmanagement-configure.png)  
创建成功后，可在`图项目`页面的图项目选项卡中查看。  
##### 2.4.1.2.编辑图项目  
在`图项目`界面，点击图项目选项卡中的`编辑`按钮（笔形图标），编辑对应图项目的基础信息。  
![图项目-编辑图项目按钮](../../../images/browser/graphmanagement-editgraph-button.png)  
编辑图项目功能可以修改`图描述`和`最大存储空间`。  
![图项目-编辑图项目](../../../images/browser/graphmanagement-editgraph.png)  
##### 2.4.1.3.删除图项目  
在`图项目`界面，点击图项目选项卡中的`删除`按钮（垃圾桶图标），删除对应的图项目。  
![图项目-删除图项目按钮](../../../images/browser/graphmanagement-deletegraph-button.png)  
_需要注意：图项目删除后无法恢复_。  
##### 2.4.1.4.点边统计  
在`图项目`界面，点击图项目选项卡中的`点边统计`按钮（刷新图标），统计对应图项目当前时间节点的点边数量。  
![图项目-点边统计按钮](../../../images/browser/graphmanagement-statistics-button.png)  
统计结果将展示在图项目选项卡上，已经统计过点边数据的图项目再次统计需要点击`刷新`按钮。  
![图项目-点边统计](../../../images/browser/graphmanagement-statistics.png)  
![图项目-刷新点边统计按钮](../../../images/browser/graphmanagement-statistics-refresh-button.png)  
##### 2.4.1.5.存储过程  
在`图项目`界面，点击图项目选项卡中的`存储过程`按钮（卡片最右侧图标），跳转到操作存储过程的图页面。  
![图项目-存储过程按钮](../../../images/browser/graphmanagement-procedure-button.png)  
在`存储过程`页面，可以新建存储过程，新建时需要填写""存储过程名称""、""存储过程类型""、""存储过程描述""，然后选择""版本""和""执行时是否修改数据库""  
![图项目-存储过程](../../../images/browser/graphmanagement-procedure.png)  
更多存储过程的相关操作可见 [存储过程](../9.olap&procedure/1.procedure/1.procedure.md)  
#### 2.4.2.图构建  
Browser的`图构建`功能主要用于图项目的模型定义和数据导入。在`图项目`页面中，点击图项目选项卡中的`图构建`按钮。  
![图构建-按钮](../../../images/browser/graphbuild-button.png)  
##### 2.4.2.1.模型定义  
Browser提供可视化的方式创建和维护图模型。  
- 也可用通过`cyphe' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.4.图项目'}","page_content='数据导入

4.离线全量导入

离线模式只能在离线状态的服务器使用。离线导入会创建一张新图，因此更适合新安装的 TuGraph 服务器上的第一次数据导入。
要在离线模式下使用`lgraph_import`工具，可以指定`lgraph_import --online false`选项。要了解可用的命令行选项，请使用`lgraph_import --online false --help`：  
```shell
$ ./lgraph_import --online false -help
Available command line options:
--log               Log file to use, empty means stderr. Default="""".
-v, --verbose       Verbose level to use, higher means more verbose.
Default=1.
...
-h, --help          Print this help message. Default=0.
```  
命令行参数：  
- **-c, --config_file** `config_file`: 导入配置文件名，其格式要求见下述。
- **--log** `log_dir`: 日志目录。默认为空字符串，此时将日志信息输出到控制台。
- **--verbose** `0/1/2`: 日志等级，等级越高输出信息越详细。默认为 1。
- **-i, --continue_on_error** `true/false`: 在碰到错误时跳过错误并继续，默认为 false，碰到错误立即退出。
- **-d, --dir** `{diretory}`: 数据库目录，导入工具会将数据写到这个目录。默认为`./db`。
- **--delimiter** `{delimiter}`: 数据文件分隔符。只在数据源是 CSV 格式时使用，默认为`"",""`。
- **-u, --username** `{user}`: 数据库用户名。需要是管理员用户才能执行离线导入。
- **-p, --password** `{password}`: 指定的数据库用户的密码
- **--overwrite** `true/false`: 是否覆盖数据。设为 true 时，如果数据目录已经存在，则覆盖数据。默认为`false`。
- **-g, --graph** `{graph_name}`: 指定需要导入的图种类。
- **-h, --help**: 输出帮助信息。' metadata={'Header 1': '数据导入', 'Header 2': '4.离线全量导入'}"
如何通过邮件提出关于TuGraph产品的建议？,"page_content='如何贡献

4. 贡献代码流程

4.1. 提交issue

不论您是修复 TuGraph 的 bug 还是新增 TuGraph 的功能，在您提交代码之前，请在 TuGraph 的 GitHub 上提交一个 issue，描述您要修复的问题或者要增加的功能。这么做有几个好处:  
- 不会与其它开发者或是他们对这个项目的计划发生冲突，产生重复工作。
- TuGraph 的维护人员会对您提的 bug 或者新增功能进行相关讨论，确定该修改是不是必要，有没有提升的空间或更好的办法。
- 在达成一致后再开发，并提交代码，减少双方沟通成本，也减少 pull request 被拒绝的情况。' metadata={'Header 1': '如何贡献', 'Header 2': '4. 贡献代码流程', 'Header 3': '4.1. 提交issue'}","page_content='什么是TuGraph

4. TuGraph企业版

企业版对商业化功能支持更加完善，包括分布式集群架构，覆盖探索、研发、服务、运维管理全生命周期的一站式图平台，在线、近线、离线的图计算引擎，支持流式、大数据类数据源，多地多中心的部署形态，以及专家支持服务等。企业版是商业化解决方案的理想选择。  
如需商业支持，请联系我们：  
- 电话：400-903-0809
- 邮件：tugraph@service.alipay.com
- 官网：https://tugraph.antgroup.com' metadata={'Header 1': '什么是TuGraph', 'Header 2': '4. TuGraph企业版'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}"
边索引支持查询加速么？,"page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属性不会存在相同的值。
由于底层存储设计，组合索引key需要保存属性的长度，因此，
组合唯一索引key的最大长度是480-2*(属性个数-1) bytes，**超过的属性不能建立唯一索引**。  
##### 1.3.2.2 非唯一索引  
和点的普通非唯一索引类似，点的非唯一索引指的是非全局唯一的索引，即若一组属性设置了非唯一索引，
在同一个图中，相同label的点的该组属性可以存在相同的值。
由于非唯一索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='QA汇总

内核引擎QA

边支持索引

Q: TuGraph 的边是否支持索引？
A: TuGraph 在引擎层支持边索引，可通过存储过程使用。Cypher的边索引功能正在开发支持中。' metadata={'Header 1': 'QA汇总', 'Header 2': '内核引擎QA', 'Header 3': '边支持索引'}","page_content='QA汇总

Cypher QA

长边条件查询

Q：是否支持不定长边的条件查询？
示例：  
```
MATCH p=(v)-[e:acted_in|:rate*1..3]-(v2) WHERE id(v) IN [3937] AND e.stars = 3 RETURN p LIMIT 100
```  
A：目前还不支持不定长边的过滤查询。目前的代替方案只能是分开写。上面的示例，就需要从 1 跳到 3 跳都写一遍。' metadata={'Header 1': 'QA汇总', 'Header 2': 'Cypher QA', 'Header 3': '长边条件查询'}"
TuGraph Monitor的主要功能是什么？,"page_content='运维监控

1.设计思路

1.2.TuGraph Monitor

TuGraph Monitor是TuGraph周边生态中的一个工具，它作为TuGraph众多用户中的一个，通过C++ RPC Client与TuGraph进行通信，通过Procedure查询接口来查询TuGraph服务所在机器的性能指标，并将TuGraph返回的结果包装成Prometheus需要的数据模型，等待Prometheus获取。用户可以通过设置查询时间间隔来保证获取监控指标对于业务查询的影响最小化。' metadata={'Header 1': '运维监控', 'Header 2': '1.设计思路', 'Header 3': '1.2.TuGraph Monitor'}","page_content='快速上手

1.简介

TuGraph 是蚂蚁集团自主研发的大规模图计算系统，提供图数据库引擎和图分析引擎。其主要特点是大数据量存储和计算，高吞吐率，以及灵活的 API，同时支持高效的在线事务处理（OLTP）和在线分析处理（OLAP）。 LightGraph、GeaGraph 是 TuGraph 的曾用名。  
主要功能特征包括：  
- 标签属性图模型
- 支持多图
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 基于 web 客户端的图可视化工具
- 支持 RESTful API 和 RPC
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程
- 适用于高效图算法开发的 Traversal API  
性能及可扩展性特征包括：  
- TB 级大容量
- 千万点/秒的高吞吐率
- 高可用性支持
- 高性能批量导入
- 在线/离线备份' metadata={'Header 1': '快速上手', 'Header 2': '1.简介'}","page_content='TuGraph-db

1. 简介

TuGraph 是支持大数据容量、低延迟查找和快速图分析功能的高效图数据库。
TuGraph的支持邮箱：tugraph@service.alipay.com  
主要功能：  
- 标签属性图模型
- 完善的 ACID 事务处理
- 内置 34 图分析算法
- 支持全文/主键/二级索引
- OpenCypher 图查询语言
- 基于 C++/Python 的存储过程  
性能和可扩展性：  
- LDBC SNB世界记录保持者 (2022/9/1)
- 支持存储多达数十TB的数据
- 每秒访问数百万个顶点
- 快速批量导入' metadata={'Header 1': 'TuGraph-db', 'Header 2': '1. 简介'}"
TuGraph HA 集群的管理工具是什么？,"page_content='TuGraph Management

简介

TuGraph Management 是一款为TuGraph开发的算法任务管理工具。采用了sofastack与brpc作为通信框架，并使用sqlite进行持久化存储。  
主要功能：  
- 算法任务状态持久化存储  
- 算法任务结果持久化存储  
- 延时触发与定时触发算法任务支持' metadata={'Header 1': 'TuGraph Management', 'Header 2': '简介'}","page_content='部署高可用模式

1.原理

TuGraph 通过多机热备份来提供高可用（HA）模式。在高可用模式下，对数据库的写操作会被同步到所有服务器（非witness）上，这样即使有部分服务器宕机也不会影响服务的可用性。  
高可用模式启动时，多个 TuGraph 服务器组成一个备份组，即高可用集群。每个备份组由三个或更多 TuGraph 服务器组成，其中某台服务器会作为`leader`，而其他复制组服务器则作为`follower`。写入请求由`leader`
提供服务，该`leader`将每个请求复制同步到`follower`，并在请求同步到服务器后才能响应客户端。这样，如果任何服务器发生故障，其他服务器仍将具有到目前为止已写入的所有数据。如果`leader`
服务器发生故障，其他服务器将自动选择出新的`leader`。  
TuGraph的高可用模式提供两种类型的节点：`replica`节点和`witness`节点。其中，`replica`节点是普通节点，有日志有数据，可对外提供服务。
而`witness`节点是一种只接收心跳和日志但不保存数据的节点。根据部署需求，`leader`节点和`follower`节点可以灵活的部署为`replica`节点或`witness`节点。
基于此，TuGraph高可用模式的部署方式有两种：一是普通部署模式，二是带witness的简约部署模式。  
对于普通部署模式，`leader`和所有`follower`均为`replica`类型的节点。写入请求由`leader`提供服务，该`leader`将每个请求复制同步到`follower`，
并在请求同步到超过半数的服务器后才能响应客户端。这样，如果少于半数的服务器发生故障，其他服务器仍将具有到目前为止已写入的所有数据。如果`leader`
服务器发生故障，其他服务器将自动选举出新的`leader`，通过这种方式保证数据的一致性和服务的可用性。  
然而，在用户服务器资源不够或者发生网络分区时，不能建立正常的HA集群。此时，由于`witness`节点没有数据，对资源占用小，可以将`witness`节点和`replica`节点部署在一台机器上。
例如，当只有2台机器的情况下，可以在一台机器上部署`replica`节点，在另一台机器上部署`replica`节点和`witness`节点，不仅节省资源，而且不需要把日志应用到状态机上，
也不需要生成和安装快照，因此响应请求的速度很快，可以在集群崩溃或网络分区时协助快速选举出新的`leader`，这就是TuGraph HA集群的简约部署模式。
尽管`witness`节点有诸多好处，但是由于没有数据，集群实际上增加了一个不能成为`leader`的节点，因此可用性会略有降低。为提高集群的可用性，
可通过指定`ha_enable_witness_to_leader`参数为`true`，允许`witness`节点临时当主。`witness`节点在把新日志同步到其他节点之后，
会将leader角色主动切换到有最新日志的节点。  
v3.6及以上版本支持此功能。' metadata={'Header 1': '部署高可用模式', 'Header 2': '1.原理'}","page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

三、TuGraph-DB高可用集群部署与应用

2.高可用集群部署

当原始数据一致的时候，可以直接指定 HA configure 参数启动集群。当初始数据不一致的时候，假如有一个节点有数据，其它节点没有数据，需要把数据同步到其它节点，但是又不能通过 SCP 传，那么就可以通过初始数据不一致的方式去启动。有数据的节点用 bootstrap 方式启动，预先生成一个快照，然后其它节点以 follower 的身份加入集群，加入集群时会安装快照，安装快照之后才会进行选举和 follower 身份的确认。  
初始数据一致:  
• 所有节点数据相同或没有数据时，可以直接指定ha_conf参数启动集群  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true \ --ha_conf 172.22.224.15:9090,172.22.224.16:9090,172.22.224.17:9090`  
初始数据不一致:  
• 有数据的节点使用bootstrap方式启动，预先生成快照  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090 --ha_bootstrap_role 1`  
• 无数据的节点直接以follower的身份加入安装快照，无需再选举  
`graph_server -c lgraph.json --rpc_port 9090 --enable_ha true --ha_conf 172.22.224.15:9090 —-ha_bootstrap_role 2`' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '三、TuGraph-DB高可用集群部署与应用', 'Header 3': '2.高可用集群部署'}"
如何通过POST方法修改Token的有效期为无限期？,"page_content='RESTful API Legacy

3.登录

3.3.修改Token有效期

修改Token有效期，需要传输jwt，refresh_time和expire_time三个参数，其中jwt用于校验用户身份，refresh_time和expire_time等于0时，有效期为无期限，超过refresh_time时，需要调用refresh接口获取新的Token;超过expire_time时，需要重新登录。  
- **URI**: `/update_token_time`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| Authorization | 令牌 | 字符串 |
| refresh_time | 有效时间（默认设置为0） | Int64 |
| expire_time | 有效时间（默认设置为0） | Int64 |  
- **RESPONSE**:  如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/update_token_time
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""Authorization"" : ""Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJmbWEuYWkiLCJwYXNzd29yZCI6IjczQFR1R3JhcGgiLCJ1c2VyIjoiYWRtaW4ifQ.o_yb5veSJkuy-ieBp4MqTk-tC1grcKotgVbgNJ0TyTU"",
""refresh_time"":0,
""expire_time"":0
}
```  
**Example response.**  
```
• 200: OK
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '3.登录', 'Header 3': '3.3.修改Token有效期'}","page_content='Token使用说明

2. Token有效期

2.4. Token有效期修改

为了方便开发者自行开发，TuGraph提供了两种方式修改有效期，均需要admin权限。  
* 通过接口调用设置。涉及有效期修改的接口`update_token_time`和有效期查询接口`get_token_time`。
具体可查询[REST接口文档](../7.client-tools/9.restful-api-legacy.md)。  
* 通过启动参数设置。server端启动时，添加参数`-unlimited_token 1` 参数可以设置为无期限。可参考[服务运行文档](../5.installation&running/7.tugraph-running.md)。' metadata={'Header 1': 'Token使用说明', 'Header 2': '2. Token有效期', 'Header 3': '2.4. Token有效期修改'}","page_content='RESTful API Legacy

3.登录

3.4.查询Token有效期

查询Token有效期，需要传输jwt，用于校验用户身份，返回，refresh_time和expire_time，其中refresh_time表示刷新时间，超过时需要调用refresh接口获取新的Token;expire_time表示过期时间，超过时需要重新登录。
- **URI**: `/get_token_time`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| Authorization | 令牌 | 字符串 |  
- **RESPONSE**:  如果成功，返回""refresh_time""和""expire_time""。  
**Example request.**  
```
• POST http://localhost:7070/get_token_time
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""Authorization"" : ""Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJmbWEuYWkiLCJwYXNzd29yZCI6IjczQFR1R3JhcGgiLCJ1c2VyIjoiYWRtaW4ifQ.o_yb5veSJkuy-ieBp4MqTk-tC1grcKotgVbgNJ0TyTU"",
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""refresh_time"":600,
""expire_time"":3600
}
```' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '3.登录', 'Header 3': '3.4.查询Token有效期'}"
TuGraph图数据库是由哪两个机构联合研发的？,"page_content='什么是TuGraph

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群，解决了图数据分析面临的大数据量、高吞吐率和低延迟等重大挑战，是蚂蚁集团金融风控能力的重要基础设施，显著提升了欺诈洗钱等金融风险的实时识别能力和审理分析效率，并面向金融、工业、政务服务等行业客户。' metadata={'Header 1': '什么是TuGraph', 'Header 2': '1. 简介'}","page_content='TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态

关于TuGraph

高性能图数据库 TuGraph（https://github.com/TuGraph-family/tugraph-db） 由蚂蚁集团和清华大学共同研发，经国际图数据库基准性能权威测试，是 LDBC-SNB 世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先水平，为用户管理和分析复杂关联数据提供了高效易用可靠的平台。  
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应用于蚂蚁内部150多个场景，助力支付宝2021年资产损失率小于亿分之0.98。关联数据爆炸性增长对图计算高效处理提出迫切需求，TuGraph 已被成熟应用于金融风控、设备管理等内外部应用，适用于金融、工业、互联网、社交、电信、政务等领域的关系数据管理和分析挖掘。  
2022年9月，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品设计，拥有完整的事务支持和丰富的系统特性，单机可部署，使用成本低，支持TB级别的数据规模。' metadata={'Header 1': 'TuGraph开源JAVA客户端工具TuGraph-OGM，无缝对接JAVA开发生态', 'Header 2': '关于TuGraph'}","page_content='地理空间数据类型使用示例

1. 简介

TuGraph图数据库由蚂蚁集团与清华大学联合研发，构建了一套包含图存储、图计算、图学习、图研发平台的完善的图技术体系，拥有业界领先规模的图集群。近年来，地理空间功能在图数据库中的应用价值显著，它不仅增强了数据的表达能力，还促进了跨领域数据的融合分析，尤其在社交网络、地图探索、城市规划等关键领域展现了强大的实用价值。TuGraph也正在逐步支持地理空间功能。' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '1. 简介'}"
TuGraph图学习模块依赖于什么系统？,"page_content='功能概览

1.2.软硬件环境

TuGraph核心是由C++开发，默认使用的编译器为GCC8.4，使用c++17标准。此外，存储过程中额外提供了Python Procedure API，该功能需要Python环境。TuGraph不需要特殊的硬件比如GPU，对RDMA、HBM等高延迟低带宽的通用硬件升级可以天然适配。  
TuGraph测试过基于X86和ARM的CPU，包括Intel、AMD、Kunpeng、Hygon、飞腾等，也同时在多个操作系统上运行，包括Ubuntu、CentOS、SUSE、银河麒麟、中标麒麟、UOS的主流版本，对操作系统和CPU没有特殊的要求。  
软硬件环境也包括依赖库的环境，由于TuGraph的存储层中默认的KV存储是LMDB，需要文件系统能够支持POSIX接口。在不同的环境下编译和参数配置会略有不同，比如在图存储的点边数据打包中，应和操作系统的页表大小匹配，默认为4KB，建议将系统的页表大小也设置为4KB。' metadata={'Header 1': '功能概览', 'Header 2': '1.2.软硬件环境'}","page_content='Learn Tutorial

1.TuGraph 图学习模块简介

图学习是一种机器学习方法，其核心思想是利用图结构中的拓扑信息，通过顶点之间的联系及规律来进行数据分析和建模。不同于传统机器学习方法，图学习利用的数据形式为图结构，其中顶点表示数据中的实体，而边则表示实体之间的关系。通过对这些顶点和边进行特征提取和模式挖掘，可以揭示出数据中深层次的关联和规律，从而用于各种实际应用中。  
这个模块是一个基于图数据库的图学习模块，主要提供了四种采样算子：Neighbor Sampling、Edge Sampling、Random Walk Sampling 和 Negative Sampling。这些算子可以用于对图中的顶点和边进行采样，从而生成训练数据。采样过程是在并行计算环境下完成的，具有高效性和可扩展性。  
在采样后，我们可以使用得到的训练数据来训练一个模型。该模型可以用于各种图学习任务，比如预测、分类等。通过训练，模型可以学习到图中的顶点和边之间的关系，从而能够对新的顶点和边进行预测和分类。在实际应用中，这个模块可以被用来处理各种大规模的图数据，比如社交网络、推荐系统、生物信息学等。' metadata={'Header 1': 'Learn Tutorial', 'Header 2': '1.TuGraph 图学习模块简介'}","page_content='快速上手

1.简介

1.1.支持的平台

TuGraph 无论是物理、虚拟还是容器化环境，均支持 X86_64 和 ARM64 架构的的平台。' metadata={'Header 1': '快速上手', 'Header 2': '1.简介', 'Header 3': '1.1.支持的平台'}"
构造FieldSpec时需要哪些参数？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.createLabel(label_type, label_name, extra, field_spec...)

Create a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| extra      | string     | for edge, it means constraints; for vertex, it means primary property |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.
for edge, `extra` should be a json array string, like this `[[""label1"",""label2""], [""label3"",""label4""]]`, if edge has no constraints, give an empty json array, like this `[]`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createLabel('vertex', 'new_label', 'id', ['id','int32',false], ['name','string', true]);
CALL db.createLabel('edge', 'new_edge', '[[""id1"",""id2""]]', ['id','int32',false], ['name', 'string', true]);
```  
**Example output:**  
```
Vertex label [new_label] successfully added.
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createLabel(label_type, label_name, extra, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createEdgeLabel( label_name, field_spec...)

Create an edge label.  
**Parameters:**  
| parameter  | parameter type | description          |
| ---------- | -------------- | ------------------------ |
| label_name | string     | name of the label    |
| edge_constraints | string | edge constraints |
| field_spec | list       | specification of a field |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`, where optional is specified as true, only for  optional fields.  
`edge_constraints` is a json array string, This parameter limits the combination of starting and ending vertex of the edge, for example: `'[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]'`, which limits the edge direction can only be from `vertex_label1` to `vertex_label2` or from `vertex_label3` to `vertex_label4`. If you don't want to have any constraints, give an empty array string, like this `'[]'`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createEdgeLabel('KNOWS', '[]', 'name', 'int32', true)
```  
**Example output:**  
```
Added type [KNOWS]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createEdgeLabel( label_name, field_spec...)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createVertexLabel(label_name, primary_field, field_spec...)

Create a vertex label.  
**Scope:** whole instance.  
**Parameters:**  
| parameter  | parameter type | description          |
| ---------- | -------------- | ------------------------ |
| label_name | string     | name of  vertex label    |
| primary_field | string  | primary field of vertex label |
| field_spec | list       | specification of a field |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, true]`, where true is specified only for optional fields.  
**Output:** If successful, it returns a success message.  
**Example input:**  
```
CALL db.createVertexLabel('Person', 'id', 'id', 'int64', false, 'name', 'string', true)
```  
**Example output:**  
```
Added label [Person]
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createVertexLabel(label_name, primary_field, field_spec...)'}"
TuGraph DB的并发性能优化最初面临的主要问题是什么？,"page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

当 TuGraph 遇见 Antlr4

ISO GQL（ISO/IEC 39075）是一种标准化的图数据库查询语言，蚂蚁集团是其主要贡献者之一。因此，Antlr4 作为一种强大的解析器生成器，成为了蚂蚁图数据库 TuGraph 生成 GQL 解释器的理想选择。Antlr4 能够帮助团队更快、更准确地构建图数据库的查询语言，从而提高产品性能和用户体验。  
然而，当我们从开发场景来到生产场景，超高的并发量带来一个严重问题：Antlr4 C++ target 的并发性能不足以支持所需的超高并发 GQL 请求。经过调研并与 Antlr 开源社区讨论，我们发现\*\*并发性能这个问题普遍存在，并且在过去 5 年中持续困扰着 C++生态的开发者。\*\*我们决定解决这个问题。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '当 TuGraph 遇见 Antlr4'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

TuGraph做了哪些工作

在调研讨论的过程中我们发现，多位开发者在论坛提出其耗时甚至多于 Java target 数倍之多。因此，我们决定从问题和开源代码出发，来定位、解决问题。  
这是一个典型的并发程序优化问题，根据以往的程序优化经验，我们分步推进该问题的解决：  
（1）识别问题  
通过对程序运行时的性能数据进行收集和分析，我们找到了程序运行瓶颈所在，通过调用分析，初步将问题定位为数据竞争导致的并发问题。  
（2）深入阅读 Antlr4 开源代码  
接下来，我们对 Antlr4 的源代码进行仔细的阅读和理解，掌握其内部的结构和核心逻辑，找出了核心的数据结构和关键的调用链路。为我们破解性能难题和分析修改的正确性做好了准备。  
（3）梳理数据竞争链路  
根据上述分析，我们判断问题的症结极大概率是数据竞争造成的。形成数据竞争至少有两个条件：一是线程之间共享内存数据，二是至少存在两个线程去读写某个共享内存。  
进一步地，我们通过分析程序中的并发访问情况，找到了可能引发数据竞争的所有代码段和共享变量（主要为 DFA、ATN 等结构），拼接出了数据竞争的完整链路。  
（4）破解数据竞争问题  
数据竞争问题是多线程程序中常见而又复杂的问题，可以考虑通过破解多种竞争条件来解决。就本文问题来说，也存在多种破解方案选择，如何制定最优的解决方案是一项极具挑战的工作，主要难点有两个：  
（i）保证修改后程序的正确性/稳定性  
（ii）保证方案的有效性（低成本）  
反复推演后，我们选择了提交给社区的优化方案，即通过改变关键数据的 ownership 接触对锁的依赖。针对上述两个难点的分析如下：  
经过源码分析并与开源社区讨论，我们确认关键数据结构的初始化构建是非常耗时的，但可以通过“只调用一次”（`call_once`）手段将成本均摊，而后续的增量构建相对开销较低，并且也可均摊。因此该优化方案的低时间成本是可以保证的。  
关于程序正确性的保证，我们通过双重验证来保证。首先在设计之初我们已经从源代码角度，推断出共享数据仍然是安全的，其次我们也设计了实验对此进行了验证，验证结果与我们的分析一致' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': 'TuGraph做了哪些工作'}","page_content='TuGraph与ARM架构

内容：

**测试介绍：**

TuGraph在测试中使用Client/Server分离的模式，来模拟真实的用户使用场景。在结果中，TuGraph在不同规模的数据集下均表现优异，在大规模100GB的数据集（2.8亿个点，18亿条边）上，TuGraph的吞吐率较上一次官方纪录提升了31%。在300GB数据集上，TuGraph测试了超过内存容量的数据吞吐量，虽然较100GB的性能有所下降，但考虑内存和硬盘的读写性能鸿沟，该结果也在预期之内。**除了性能测试，TuGraph在****系统事务性、可恢复性、正确性、稳定性等方面均达到官方标准，体现了TuGraph高并发低延迟的强大性能优势。**  
在性能测试中，我们发现并解决了一些值得注意的问题。其一是有的系统页大小默认为64KB，这个对图系统随机数据读写并不友好，调整为X86更普遍的4KB有助于提升性能。其二是在云上使用云盘，会比本地硬盘的读写带宽和稳定性差很多，如果能够在测试前进行数据预热和及时的硬盘性能监控，更有助于获得理想的结果。' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '内容：', 'Header 3': '**测试介绍：**'}"
C++客户端中实例化单节点client对象需要哪些参数？,"page_content='C++客户端

2.使用示例

2.1.实例化client对象

引入依赖并实例化  
#### 2.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
``` C++
RpcClient client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
RpcClient(const std::string& url, const std::string& user, const std::string& password);
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```  
#### 2.1.2.实例化HA集群直接连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化
``` C++
RpcClient client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
RpcClient(const std::string& url, const std::string& user, const std::string& password);
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 2.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化。
```java
std::vector<std::string> urls = {""189.33.97.23:9091"", ""189.33.97.24:9091"", ""189.33.97.25:9091""};
TuGraphDbRpcClient client = new TuGraphDbRpcClient(urls, ""admin"", ""73@TuGraph"");
```
```
RpcClient(std::vector<std::string>& urls, std::string user, std::string password)
@param urls: tugraph host list
@param user: login user name
@param password: login password
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.1.实例化client对象'}","page_content='Python客户端

3.RPC Client

3.1.实例化client对象

#### 3.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
```python
client = liblgraph_client_python.client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, url: str, user: str, password: str)
```  
#### 3.1.2.实例化HA集群直连连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化。
```python
client = liblgraph_client_python.client(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, url: str, user: str, password: str)
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 3.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化
```python
client = liblgraph_client_python.client([""189.33.97.23:9091"",""189.33.97.24:9091"", ""189.33.97.25:9091""], ""admin"", ""73@TuGraph"")
```
```
client(self: liblgraph_client_python.client, urls: list, user: str, password: str)
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.1.实例化client对象'}","page_content='Java客户端

2.使用示例

2.1.实例化client对象

添加maven依赖  
```xml
<dependency>
<groupId>com.antgroup.tugraph</groupId>
<artifactId>tugraph-db-java-rpc-client</artifactId>
<version>1.4.1</version>
</dependency>
```  
引入依赖
```java
import com.antgroup.tugraph.TuGraphDbRpcClient;
```  
#### 2.1.1.实例化单节点client对象
当以单节点模式启动server时，client按照如下格式进行实例化
```java
TuGraphDbRpcClient client = new TuGraphDbRpcClient(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(String url, String user, String pass)
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```  
#### 2.1.2.实例化HA集群直连连接client对象
当服务器上部署的HA集群可以使用ha_conf中配置的网址直接连接时，client按照如下格式进行实例化。
```java
TuGraphDbRpcClient client = new TuGraphDbRpcClient(""127.0.0.1:19099"", ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(String url, String user, String pass)
@param url: tugraph host looks like ip:port
@param user: login user name
@param password: login password
```
用户只需要传入HA集群中的任意一个节点的url即可，client会根据server端返回的查询信息自动维护连接池，在HA集群横向扩容时
也不需要手动重启client。  
#### 2.1.3.实例化HA集群间接连接client对象
当服务器上部署的HA集群不能使用ha_conf中配置的网址直接连接而必须使用间接网址（如阿里云公网网址）连接时，
client按照如下格式进行实例化
```java
List<String> urls = new ArrayList<>();
urls.add(""189.33.97.23:9091"");
urls.add(""189.33.97.24:9091"");
urls.add(""189.33.97.25:9091"");
TuGraphDbRpcClient client = new TuGraphDbRpcClient(urls, ""admin"", ""73@TuGraph"");
```
```
public TuGraphDbRpcClient(List<String> urls, String user, String password)
@param urls: tugraph host list
@param user: login user name
@param password: login password
```
因为用户连接的网址和server启动时配置的信息不同，不能通过向集群发请求的方式自动更新client连接池，所以需要在启动
client时手动传入所有集群中节点的网址，并在集群节点变更时手动重启client。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.1.实例化client对象'}"
TuGraph-DB查询引擎目前支持使用哪种查询语言，并计划在未来支持哪种查询语言？,"page_content='试用体验：TuGraph — 简单高效的图数据库

支持Cypher查询语言

TuGraph对Cypher查询语言的支持令人印象深刻。Cypher是一种直观且强大的查询语言，能够轻松地对图数据进行复杂的查询和操作。我很快就学会了使用Cypher进行查询，发现它非常适合图数据库的需求。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持Cypher查询语言'}","page_content='试用体验：TuGraph — 简单高效的图数据库

支持RESTful API

除了支持Cypher查询语言，TuGraph还提供了RESTful API接口。这使得我可以通过编程方式与图数据库进行交互，更好地将TuGraph集成到我的应用程序中。API设计合理，易于使用，为我提供了灵活性和自由度。' metadata={'Header 1': '试用体验：TuGraph — 简单高效的图数据库', 'Header 2': '支持RESTful API'}","page_content='RPC API

5.存储过程

为满足用户较为复杂的查询/更新逻辑，TuGraph支持 C 语言和 Python 语言编写的存储过程。
用户可以使用RPC请求对存储过程进行增删改查操作。' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程'}"
DeleteProcedure 函数接受什么类型的参数，并命名它们？,"page_content='Java客户端

2.使用示例

2.10.删除存储过程

```java
String result = client.deleteProcedure(""CPP"", ""sortstr"", ""default"");
log.info(""loadProcedure : "" + result);
```
```
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param graph: the graph to query.
@return: the result of procedure execution
public boolean deleteProcedure(String procedureType, String procedureName, String graph) throws Exception
```
本接口支持在单机模式和HA模式下使用。其中，由于删除存储过程是写请求，HA模式下的client只能向leader发送删除存储过程请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.10.删除存储过程'}","page_content='C++客户端

2.使用示例

2.10.删除存储过程

```C++
std::string str;
bool ret = client.DeleteProcedure(str, ""CPP"", ""test_plugin1"");
```
```
bool DeleteProcedure(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& graph = ""default"");
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  graph               (Optional) the graph to query.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，由于删除存储过程是写请求，HA模式下的client只能向leader发送删除存储过程请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.10.删除存储过程'}","page_content='RPC API

5.存储过程

5.3.删除存储过程

删除存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称  
以C++为例，用户删除存储过程的方式如下所示：
```C++
LGraphRequest req;
req.set_is_write_op(true);
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
lgraph::DelPluginRequest* dpRequest = pluginRequest->mutable_del_plugin_request();
dpRequest->set_name(procedure_name);
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
```
删除存储过程的响应不包含参数，如果删除失败则抛出BadInput异常' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.3.删除存储过程'}"
如果要在FrontierTraversal中并行执行遍历，事务的哪种模式必须被选用？,"page_content='Traversal API

2. 接口说明

2.2. Traversal

图数据库中十分常见的一大类分析是基于一个或多个点出发，逐层地拓展并访问邻居。
尽管这类分析也可以使用 Cypher 完成，但是当访问的层数较深时，其性能会受到串行解释执行的限制。
使用 C++ Core API 编写存储过程尽管避免了解释执行，但依然受限于单个线程的处理能力。
为了让用户能够方便地通过并行处理的方式加速这一类应用场景，我们基于 C++ OLAP API 封装了一个 Traversal 框架，用户可以直接使用其中的 FrontierTraversal 和 PathTraversal 类来完成这种逐层遍历的分析任务，具体的使用方法可以参考相应的 C++ API 文档（lgraph_traversal.h）。  
```c
ParallelVector<size_t> FindVertices(
GraphDB & db,
Transaction & txn,
std::function<bool(VertexIterator &)> filter,
bool parallel = false
);
```  
该方法可用于找到所有满足条件（filter 返回 true）的点，当 parallel 为 true 时则会并行该查找过程。  
```c
template <typename VertexData>
ParallelVector<VertexData> ExtractVertexData(
GraphDB & db,
Transaction & txn,
ParallelVector<size_t> & frontier,
std::function<void(VertexIterator &, VertexData &)> extract,
bool parallel = false
);
```  
该方法可用于从指定点集（frontier）中（通过 extract 方法）抽取（类型为 VertexData 的）属性，当 parallel 为 true 时会并行该抽取过程。  
FrontierTraversal 适用于只关注遍历扩展到的点集的情况；当用户在遍历过程或是结果中需要访问路径上的信息（路径上的点/边）时，则需要使用 PathTraversal。
两类 Traversal 的构造函数均有四个参数，分别为数据库句柄 db、事务句柄 txn、选项 flags 和 初始化数组容量 capacity。
选项的可选值包括以下的组合：TRAVERSAL_PARALLEL 表示遍历时使用多个线程并行；TRAVERSAL_ALLOW_REVISITS 表示遍历时允许重复地访问点（PathTraversal 隐含了该选项）。capacity 表示初始化时路径集合的容量。  
```c
void SetFrontier(size_t root_vid);
void SetFrontier(ParallelVector<size_t> & root_vids);
void SetFrontier(std::function<bool(VertexIterator &)> root_vertex_filter);
```  
两类 Traversal 设置遍历的起始点/点集有上述三种方式，前两种通过点 ID 直接指定，最后一种方式则类似于 FindVertices。  
两类 Traversal 的遍历都是从当前层的点集合出发，根据使用的扩展函数访问每条出边/入边/出边和入边，通过用户自定义的过滤函数决定扩展是否成功，若成功则将邻居点/追加了该条边的路径加入下一层的点/路径集合。  
```c
void ExpandOutEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr
);
void ExpandInEdges(
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
void ExpandEdges(
std::function<bool(OutEdgeIterator &)> out_edge_filter = nullptr,
std::function<bool(InEdgeIterator &)> in_edge_filter = nullptr,
std::function<bool(VertexIterator &)> out_neighbour_filter = nullptr,
std::function<bool(VertexIterator &)> in_neighbour_filter = nullptr
);
```  
上述为 FrontierTraversal 的三种遍历方式，即从当前的点集合出发，对集合中的每个点，依次访问每条出边/入边/出边和入边，若满足用户自定义的过滤条件（其中，edge_filter 为面向边的过滤函数，neighbour_filt' metadata={'Header 1': 'Traversal API', 'Header 2': '2. 接口说明', 'Header 3': '2.2. Traversal'}","page_content='动态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentricFunction进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph) | 首轮计算对增量图实现处理逻辑 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>temporaryGraph：临时增量图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |
| void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph) | 图遍历完成接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>mutableGraph：可变图，其中K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型。 |  
- 详细接口  
```java
public interface IncVertexCentricTraversalFunction<K, VV, EV, M, R> extends IncVertexCentricFunction<K, VV
, EV, M> {

void open(IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);

void init(ITraversalRequest<K> traversalRequest);

void evolve(K vertexId, TemporaryGraph<K, VV, EV> temporaryGraph);

void compute(K vertexId, Iterator<M> messageIterator);

void finish(K vertexId, MutableGraph<K, VV, EV> mutableGraph);

interface IncVertexCentricTraversalFuncContext<K, VV, EV, M, R> extends IncGraphContext<K, VV, EV,
M> {
/** 激活遍历起点用以下一轮迭代使用 */
void activeRequest(ITraversalRequest<K> request);
/** 收集遍历结果 */
void takeResponse(ITraversalResponse<R> response);

void broadcast(IGraphMessage<K, M> message);
/** 获取历史图数据 */
TraversalHistoricalGraph<K, VV, EV> getHistoricalGraph();
}


interface TraversalHistoricalGraph<K, VV, EV>  extends HistoricalGraph<K, VV, EV> {
/** 获取指定版本快照 */
TraversalGraphSnapShot<K, VV, EV> getSnapShot(long version);
}

interface TraversalGraphSnapShot<K, VV, EV> extends GraphSnapShot<K, VV, EV> {
/** 获取开始图遍历的点 */
TraversalVertexQuery<K, VV> vertex();
/** 获取开始图遍历的边 */
TraversalEdgeQuery<K, EV> edges();
}
}
```' metadata={'Header 1': '动态图', 'Header 2': '接口'}","page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentric function进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |  
- 详细接口  
```java
public interface VertexCentricTraversalFunction<K, VV, EV, M, R> extends VertexCentricFunction<K, VV
, EV, M> {

void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);
/** 图遍历算法初始化方法 */
void init(ITraversalRequest<K> traversalRequest);
/** 实现图遍历逻辑 */
void compute(K vertexId, Iterator<M> messageIterator);

void finish();

void close();

interface VertexCentricTraversalFuncContext<K, VV, EV, M, R> extends VertexCentricFuncContext<K,
VV, EV, M> {
/** 获取图遍历结果 */
void takeResponse(ITraversalResponse<R> response);
/** 获取开始图遍历的点 */
TraversalVertexQuery<K, VV> vertex();
/** 获取开始图遍历的边 */
TraversalEdgeQuery<K, EV> edges();

void broadcast(IGraphMessage<K, M> message);
}

interface TraversalVertexQuery<K, VV> extends VertexQuery<K, VV> {
/** 获取图遍历中点的迭代器 */
Iterator<K> loadIdIterator();
}

interface TraversalEdgeQuery<K, EV> extends EdgeQuery<K, EV> {
/** 通过指定的点id，获取对应的图遍历起点 */
TraversalEdgeQuery<K, EV> withId(K vertexId);
}
}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}"
RpcSingleClient 构造函数需要哪些参数?,"page_content='RPC API

3.登录

登录请求信息包含以下参数：
- user: 必要参数，用户名
- pass: 必要参数，密码
以C++为例，用户使用构建好的服务存根发送登录请求：
```C++
auto* req = request.mutable_acl_request();
auto* auth = req->mutable_auth_request()->mutable_login();
auth->set_user(user);
auth->set_password(pass);
// send data
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req->set_client_version(server_version);
req->set_token(token);
LGraphRPCService_Stub stub(channel.get());
LGraphResponse res;
stub.HandleRequest(cntl.get(), req, &resp, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
token = res.acl_response().auth_response().token();
```
登录响应信息包含以下参数：
- token: 必要参数，登录成功会收到带有签名的令牌，即 Json Web Token，客户端储存该令牌，并且用于以后的每次发送请求。
如果登录失败会收到“Authentication failed”错误。' metadata={'Header 1': 'RPC API', 'Header 2': '3.登录'}","page_content='RPC API

4.查询

用户可以通过Cypher查询和TuGraph进行绝大多数的交互，Cypher请求信息包含以下参数：
- query: 必要参数，Cypher查询语句
- param_names: 可选参数，参数名
- param_values: 可选参数，参数值
- result_in_json_format: 必要参数，查询结果是否以JSON格式返回
- graph: 可选参数，Cypher语句执行的子图名称
- timeout: 可选参数，Cypher语句执行的超时时间  
以C++为例，用户发送Cypher请求的方式如下所示：
```C++
LGraphResponse res;
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
LGraphRequest req;
req.set_client_version(server_version);
req.set_token(token);
lgraph::CypherRequest* cypher_req = req.mutable_cypher_request();
cypher_req->set_graph(graph);
cypher_req->set_query(query);
cypher_req->set_timeout(timeout);
cypher_req->set_result_in_json_format(true);
LGraphRPCService_Stub stub(channel.get());
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
server_version = std::max(server_version, res.server_version());
CypherResponse cypher_res = res.cypher_response();
```
Cypher请求响应为以下两个参数之一：
- json_result: JSON格式的cypher查询结果
- binary_result: CypherResult格式的cypher查询结果' metadata={'Header 1': 'RPC API', 'Header 2': '4.查询'}","page_content='RPC API

5.存储过程

5.2.调用存储过程

调用存储过程的请求包含以下参数：
- name: 必要参数，存储过程名称
- param: 必要参数，存储过程参数
- result_in_json_format: 可选参数，调用结果是否以JSON格式返回
- in_process: 可选参数，未来支持
- timeout: 可选参数，调用存储过程的超时时间  
以C++为例，用户调用存储过程的方式如下所示：
```C++
LGraphRequest req;
lgraph::PluginRequest* pluginRequest = req.mutable_plugin_request();
pluginRequest->set_graph(graph);
pluginRequest->set_type(procedure_type == ""CPP"" ? lgraph::PluginRequest::CPP
: lgraph::PluginRequest::PYTHON);
lgraph::CallPluginRequest *cpRequest = pluginRequest->mutable_call_plugin_request();
cpRequest->set_name(procedure_name);
cpRequest->set_in_process(in_process);
cpRequest->set_param(param);
cpRequest->set_timeout(procedure_time_out);
cpRequest->set_result_in_json_format(json_format);
LGraphResponse res;
cntl->Reset();
cntl->request_attachment().append(FLAGS_attachment);
req.set_client_version(server_version);
req.set_token(token);
LGraphRPCService_Stub stub(channel.get());
stub.HandleRequest(cntl.get(), &req, &res, nullptr);
if (cntl->Failed()) throw RpcConnectionException(cntl->ErrorText());
server_version = std::max(server_version, res.server_version());
if (res.error_code() != LGraphResponse::SUCCESS) throw RpcStatusException(res.error());
if (json_format) {
result = res.mutable_plugin_response()->mutable_call_plugin_response()->json_result();
} else {
result = res.mutable_plugin_response()->mutable_call_plugin_response()->reply();
}
```
调用存储过程的响应为以下两个参数之一：
- reply: ByteString格式的存储过程调用结果
- json_result: JSON格式的存储过程调用结果' metadata={'Header 1': 'RPC API', 'Header 2': '5.存储过程', 'Header 3': '5.2.调用存储过程'}"
TuGraph“中的expire_time默认设置是？,"page_content='Token使用说明

2. Token有效期

2.4. Token有效期修改

为了方便开发者自行开发，TuGraph提供了两种方式修改有效期，均需要admin权限。  
* 通过接口调用设置。涉及有效期修改的接口`update_token_time`和有效期查询接口`get_token_time`。
具体可查询[REST接口文档](../7.client-tools/9.restful-api-legacy.md)。  
* 通过启动参数设置。server端启动时，添加参数`-unlimited_token 1` 参数可以设置为无期限。可参考[服务运行文档](../5.installation&running/7.tugraph-running.md)。' metadata={'Header 1': 'Token使用说明', 'Header 2': '2. Token有效期', 'Header 3': '2.4. Token有效期修改'}","page_content='TuGraph console client

`lgraph_cli`使用

语句以分号结束，输入`exit`, `quit`或者Ctrl-C退出客户端。  
```powershell
lgraph_cli --ip 127.0.0.1 --port 7687 --graph default --user admin --password 73@TuGraph

Welcome to the TuGraph console client. Commands end with ';'.
Copyright(C) 2018-2023 Ant Group. All rights reserved.
Type 'exit', 'quit' or Ctrl-C to exit.

TuGraph> match(n) return n limit 1;
+-------------------------------------------------------------------------------------------------------------------------------------+
| n                                                                                                                                   |
+-------------------------------------------------------------------------------------------------------------------------------------+
| (:person {id:2,born:1961,poster_image:""https://image.tmdb.org/t/p/w185/mh0lZ1XsT84FayMNiT6Erh91mVu.jpg"",name:""Laurence Fishburne""}) |
+-------------------------------------------------------------------------------------------------------------------------------------+

TuGraph>
```  
语句可以中间换行，多行输入。  
```powershell
TuGraph> match(n)
-> return n
-> limit 1;
+-------------------------------------------------------------------------------------------------------------------------------------+
| n                                                                                                                                   |
+-------------------------------------------------------------------------------------------------------------------------------------+
| (:person {id:2,born:1961,poster_image:""https://image.tmdb.org/t/p/w185/mh0lZ1XsT84FayMNiT6Erh91mVu.jpg"",name:""Laurence Fishburne""}) |
+-------------------------------------------------------------------------------------------------------------------------------------+

TuGraph>
```  
非交互式
```powershell

echo ""match(n) return n limit 1;"" | lgraph_cli --ip 127.0.0.1 --port 7687 --graph default --user admin --password 73@TuGraph
+-------------------------------------------------------------------------------------------------------------------------------------+
| n                                                                                                                                   |
+---------------------------------------' metadata={'Header 1': 'TuGraph console client', 'Header 2': '`lgraph_cli`使用'}","page_content='TuGraph图模型说明

1. 数据模型

1.2. 数据类型

TuGraph支持多种可用于属性的数据类型。具体支持的数据类型如下：  
| **数据类型** | **最小值**          | **最大值**          | **描述**                            |
| ------------ | ------------------- | ------------------- | ----------------------------------- |
| BOOL         | false               | true                | 布尔值                              |
| INT8         | -128                | 127                 | 8位整型                          |
| INT16        | -32768              | 32767               | 16位整型                         |
| INT32        | - 2^31              | 2^31 - 1            | 32位整型                         |
| INT64        | - 2^63              | 2^63 - 1            | 64位整型                         |
| DATE         | 0000-00-00          | 9999-12-31          | ""YYYY-MM-DD"" 格式的日期             |
| DATETIME     | 0000-00-00 00:00:00.000000 | 9999-12-31 23:59:59.999999 | ""YYYY-MM-DD HH:mm:ss[.ffffff]"" 格式的日期时间 |
| FLOAT        |                     |                     | 32位浮点数                       |
| DOUBLE       |                     |                     | 64位浮点数                       |
| STRING       |                     |                     | 不定长度的字符串                    |
| BLOB         |                     |                     | 二进制数据（在输入输出时使用Base64编码） |
| POINT        |                     |                     | EWKB格式数据，表示点              |
| LINESTRING   |                     |                     | EWKB格式数据，表示线              |
| POLYGON      |                     |                     | EWKB格式数据，表示面(多边形)       |
| FLOAT_VECTOR |                     |                     | 包含32位浮点数的动态向量               |' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.2. 数据类型'}"
TuGraph图学习模块中包括哪四种采样算子？,"page_content='Learn Tutorial

1.TuGraph 图学习模块简介

图学习是一种机器学习方法，其核心思想是利用图结构中的拓扑信息，通过顶点之间的联系及规律来进行数据分析和建模。不同于传统机器学习方法，图学习利用的数据形式为图结构，其中顶点表示数据中的实体，而边则表示实体之间的关系。通过对这些顶点和边进行特征提取和模式挖掘，可以揭示出数据中深层次的关联和规律，从而用于各种实际应用中。  
这个模块是一个基于图数据库的图学习模块，主要提供了四种采样算子：Neighbor Sampling、Edge Sampling、Random Walk Sampling 和 Negative Sampling。这些算子可以用于对图中的顶点和边进行采样，从而生成训练数据。采样过程是在并行计算环境下完成的，具有高效性和可扩展性。  
在采样后，我们可以使用得到的训练数据来训练一个模型。该模型可以用于各种图学习任务，比如预测、分类等。通过训练，模型可以学习到图中的顶点和边之间的关系，从而能够对新的顶点和边进行预测和分类。在实际应用中，这个模块可以被用来处理各种大规模的图数据，比如社交网络、推荐系统、生物信息学等。' metadata={'Header 1': 'Learn Tutorial', 'Header 2': '1.TuGraph 图学习模块简介'}","page_content='Training

2. Mini-Batch训练

Mini-Batch训练需要使用TuGraph 图学习模块的采样算子，目前支持Neighbor Sampling、Edge Sampling、Random Walk Sampling和Negative Sampling。
TuGraph 图学习模块的采样算子进行采样后的结果以List的形式返回。
下面以Neighbor Sampling为例，介绍如何将采样后的结果，进行格式转换，送入到训练框架中进行训练。
用户需要提供一个Sample类：
```python
class TuGraphSample(object):
def __init__(self, args=None):
super(TuGraphSample, self).__init__()
self.args = args

def sample(self, g, seed_nodes):
args = self.args
# 1. 加载图数据
galaxy = PyGalaxy(args.db_path)
galaxy.SetCurrentUser(args.username, args.password)
db = galaxy.OpenGraph(args.graph_name, False)

sample_node = seed_nodes.tolist()
length = args.randomwalk_length
NodeInfo = []
EdgeInfo = []

# 2. 采样方法，结果存储在NodeInfo和EdgeInfo中
if args.sample_method == 'randomwalk':
randomwalk.Process(db, 100, sample_node, length, NodeInfo, EdgeInfo)
elif args.sample_method == 'negative':
negativesample.Process(db, 100)
else:
neighborsample(db, 100, sample_node, args.nbor_sample_num, NodeInfo, EdgeInfo)
del db
del galaxy

# 3. 对结果进行格式转换，使之符合训练格式
remap(EdgeInfo[0], EdgeInfo[1], NodeInfo[0])
g = dgl.graph((EdgeInfo[0], EdgeInfo[1]))
g.ndata['feat'] = torch.tensor(NodeInfo[1])
g.ndata['label'] = torch.tensor(NodeInfo[2])
return g
```
如代码所示，首先将图数据加载到内存中。然后使用采样算子对图数据进行采样，结果存储在NodeInfo和EdgeInfo中。NodeInfo和EdgeInfo是python list结果，其存储的信息结果如下：  
| 图数据 | 存储信息位置 |
| --- | --- |
| 边起点 | EdgeInfo[0] |
| 边终点 | EdgeInfo[1] |
| 顶点ID | NodeInfo[0] |
| 顶点特征 | NodeInfo[1] |
| 顶点标签 | NodeInfo[2] |  
最后对结果进行格式转换，使之符合训练格式。这里我们使用的是DGL训练框架，因此使用结果数据构造了DGL Graph，最终将DGL Graph返回。
我们提供TuGraphSample类之后，就可以使用它进行Mini-Batch训练了。
令DGL的数据加载部分使用TuGraphSample的实例sampler：
```python
sampler = TugraphSample(args)
fake_g = construct_graph() # just make dgl happy
dataloader = dgl.dataloading.DataLoader(fake_g,
torch.arange(train_nids),
sampler,
batch_size=batch_size,
device=device,
use_ddp=True,
num_workers=0,
drop_last=False,
)
```
使用DGL进行模型训练：
```python
def train(dataloader, model):
optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)
model.train()
s = time.time()
for graph in dataloader:
load_time = time.time()
graph = dgl.add_self_loop(graph)
logits = model(graph, graph.ndata['feat'])
loss = loss_fcn(logits, graph.ndata['label'])
optimizer.zero_grad()
loss.backward()
optimizer.step()
train_time = time.time()
print('load time', load_tim' metadata={'Header 1': 'Training', 'Header 2': '2. Mini-Batch训练'}","page_content='Sampling API

3. 图采样算子介绍

图采样算子在cython层实现，用于对输入的图进行采样处理，生成的NodeInfo用于保存feature属性、label属性等点信息，EdgeInfo用于保存边信息，这些元数据信息可以被用于特征抽取、网络嵌入等任务中。目前TuGraph图学习模块支持GetDB、NeighborSampling、EdgeSampling、RandomWalkSampling、NegativeSampling五种采样算子。' metadata={'Header 1': 'Sampling API', 'Header 2': '3. 图采样算子介绍'}"
当执行UpsertEdge操作时，根据提供的参数是否存在于现有边，返回值将是什么？,"page_content='业务开发指南

导入数据

批量upsert边数据

如果两点之间不存在某条类型的边就插入，如果存在就更新该边的属性，也就是两点之间同类型的边只能有一条。  
第四个参数是一个`list`类型，每个数组里面的元素是个`map`类型，每个`map`里面是：边的起点类型主键字段和对应的值、边的终点类型主键字段和对应的值、边类型自身的属性字段和值。每个map里面至少有两个元素。  
第二个参数和第三个参数是为第四个参数服务的。分别说明了起点和终点的类型是什么，以及第四个参数中那个字段代表起点主键字段值，那个字段代表终点主键字段值。  
注：第二个参数和第三个参数中配置的起点和终点的主键字段并不是起点和终点schema中的主键字段名，只是起一个占位和区别的作用，方便识别第四个参数中哪个字段代表起点和终点的主键字段。  
推荐使用driver里面的参数化特性，避免自己构造语句。
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据'}","page_content='业务开发指南

导入数据

批量upsert边数据-根据边的属性确定唯一

上面描述的upsert逻辑是两点之间同类型的边只能有一条，如果要求两点之间同类型的边可以有多条，并且根据边上的某个属性来确定唯一，需要在原来的基础上多加一个字段，如下：
```
CALL db.upsertEdge('edge1',{type:'node1',key:'node1_id'}, {type:'node2',key:'node2_id'}, [{node1_id:1,node2_id:2,score:10},{node1_id:3,node2_id:4,score:20}], 'score')
```
在最后多了一个字段`score`, 逻辑变成：如果两点之间不存在一条`edge1`类型的边，并且`score`值等于某个值，就插入；否则就更新改边的属性。
边上的`score`字段需要提前加上一个特殊的`pair unique`索引，如下：
```
CALL db.addEdgeIndex('edge1', 'score', false, true)
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert边数据-根据边的属性确定唯一'}","page_content='业务开发指南

导入数据

批量upsert点数据

如果不存在就插入点，如果存在就更新点的属性，根据点的主键字段值判断是否存在。  
第二个参数是一个`list`类型，每个`list`里面的元素是个`map`类型，每个`map`里面是点的字段和对应的值。  
推荐使用driver里面的参数化特性，第二个参数直接传入一个 `list`结构体，避免自己构造语句。
```
CALL db.upsertVertex('node1', [{id:1, name:'name1'},{id:2, name:'name2'}])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '导入数据', 'Header 3': '批量upsert点数据'}"
ANTLR4支持生成哪些目标语言的解析器？,"page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

关于 Antlr4

Antlr4 是一款备受欢迎的开源解析器生成器，能够根据语法规则快速生成自定义解析器。其支持 LL(\*)解析，拥有更强大的错误处理能力和更快的解析速度。不仅如此，Antlr4 还支持 Java、Python、C++、JavaScript、Go 等 10 种目标语言，广泛应用于多种开发语言生态中。简单易用的 API 和文档使得开发人员能够快速上手。无论是编程语言、数据格式、编译器还是解释器等领域，Antlr4 都发挥着重要作用。  
著名的开源项目如 Apache Spark、Eclipse IDE 和 MongoDB 等都选择了 Antlr4。 对于语言工具开发者而言，Antlr4 是不可或缺的工具，能大幅提高开发效率和代码质量。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '关于 Antlr4'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

当 TuGraph 遇见 Antlr4

ISO GQL（ISO/IEC 39075）是一种标准化的图数据库查询语言，蚂蚁集团是其主要贡献者之一。因此，Antlr4 作为一种强大的解析器生成器，成为了蚂蚁图数据库 TuGraph 生成 GQL 解释器的理想选择。Antlr4 能够帮助团队更快、更准确地构建图数据库的查询语言，从而提高产品性能和用户体验。  
然而，当我们从开发场景来到生产场景，超高的并发量带来一个严重问题：Antlr4 C++ target 的并发性能不足以支持所需的超高并发 GQL 请求。经过调研并与 Antlr 开源社区讨论，我们发现\*\*并发性能这个问题普遍存在，并且在过去 5 年中持续困扰着 C++生态的开发者。\*\*我们决定解决这个问题。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '当 TuGraph 遇见 Antlr4'}","page_content='Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！

贡献和成果

对Antlr4的优化的效果十分显著，32 线程的并发性能提升超过 18 倍 。考虑到实际生产服务器性能远高于测试机型，实际的性能提升效果将比测试结果更高， 优化后 GQL 解析能力已能完全满足企业业务的需要。' metadata={'Header 1': 'Antlr4 社区重大贡献：TuGraph 优化 C++ Target 并发性能提升 10 倍！', 'Header 2': '贡献和成果'}"
如果对DateTime对象添加超出其范围的微秒数会发生什么？,"page_content='TuGraph图模型说明

1. 数据模型

1.2. 数据类型

TuGraph支持多种可用于属性的数据类型。具体支持的数据类型如下：  
| **数据类型** | **最小值**          | **最大值**          | **描述**                            |
| ------------ | ------------------- | ------------------- | ----------------------------------- |
| BOOL         | false               | true                | 布尔值                              |
| INT8         | -128                | 127                 | 8位整型                          |
| INT16        | -32768              | 32767               | 16位整型                         |
| INT32        | - 2^31              | 2^31 - 1            | 32位整型                         |
| INT64        | - 2^63              | 2^63 - 1            | 64位整型                         |
| DATE         | 0000-00-00          | 9999-12-31          | ""YYYY-MM-DD"" 格式的日期             |
| DATETIME     | 0000-00-00 00:00:00.000000 | 9999-12-31 23:59:59.999999 | ""YYYY-MM-DD HH:mm:ss[.ffffff]"" 格式的日期时间 |
| FLOAT        |                     |                     | 32位浮点数                       |
| DOUBLE       |                     |                     | 64位浮点数                       |
| STRING       |                     |                     | 不定长度的字符串                    |
| BLOB         |                     |                     | 二进制数据（在输入输出时使用Base64编码） |
| POINT        |                     |                     | EWKB格式数据，表示点              |
| LINESTRING   |                     |                     | EWKB格式数据，表示线              |
| POLYGON      |                     |                     | EWKB格式数据，表示面(多边形)       |
| FLOAT_VECTOR |                     |                     | 包含32位浮点数的动态向量               |' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.2. 数据类型'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.alterLabelModFields(label_type, label_name, field_spec...)

Modifies the specified fields in the label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.The target field should exist.  
**Output:**  
| field_name | field_type | description               |
| ---------- | ---------- | --------------------------------- |
| affected   | integer    | number of vertexes/edges modified |  
**Example input:**  
```
CALL db.alterLabelModFields(
'vertex',
'new_label',
['birth_date', DATETIME, true],
['gender', BOOL, true])
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.alterLabelModFields(label_type, label_name, field_spec...)'}","page_content='RESTful API Legacy

6.Deprecated

6.10.在线增量导入

#### 6.10.1.指定文件内容导入  
- **URI**: `/db/{graph_name}/import/text`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| description | 文件内容描述 | 字符串 |
| data | 要导入的文件内容（建议最大在 16MB 左右，最长不超过 17MB） | 字符串 / 数组 / 对象 |
| continue_on_error | 出错后是否继续导入（可选，默认为`false`
） | 布尔值 |
| delimiter | 分隔符（可选，默认为`“,”`
） | 字符串 |  
description 的具体描述方法见《TuGraph 操作手册》中数据导入配置文件的相关内容。  
分隔符可以是单字符，也可以是字符串，但不能包含`\r`或者`\n`。  
data 可以是如下形式之一：  
- 字符串如 `""1,2\n3,4\n""`
- ASCII 码组成的数组如 `[49,44,50,10,51,44,52,10]`
- 形如上述数组的字典如 `{""0"":49,""1"":44,""2"":50,""3"":10,""4"":51,""5"":44,""6"":52,""7"":10}`  
- **RESPONSE**:  
系统**不会**自动执行新建 label、添加索引等操作。在此操作之前需要保证涉及的 label 已经存在并具有适当的索引。  
如果成功导入完毕，返回代码 200，并在 `log` 字段返回一些日志信息（可能为空）；否则，保证所有的数据均未被导入，并在 `error_message` 字段返回错误信息。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/import/text
• Accept: application/json; charset=UTF-8
• Content-Type: application/json; charset=UTF-8
Input:
{
""description"": ""{\\""files\\"":[{\\""columns\\"":[\\""SRC_ID\\"",\\""role\\"",\\""DST_ID\\""],\\""format\\"":\\""CSV\\"",\\""label\\"":\\""role\\"",\\""SRC_ID\\"":\\""actor\\"",\\""DST_ID\\"":\\""movie\\""}]}""}"",
""data"": ""1,Role1,2\n3,Role2,4\n"",
""continue_on_error"": true,
""delimiter"": "",""
}
```  
上述 description 的值是如下 json 序列化后的字符串  
```json
{
""files"": [
{
""format"": ""CSV"",
""label"": ""role"",
""SRC_ID"": ""actor"",
""DST_ID"": ""movie"",
""columns"": [""SRC_ID"", ""role"", ""DST_ID""]
}
]
}
```  
**Example response.**  
```
• 200: OK
Output:
{
""log"": ""Missing src uid 1\n""
}
```  
由于请求中指定了在出错时继续，该返回信息说明 SRC_ID 为 1 的边没有被导入，而其他信息导入成功。' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.10.在线增量导入'}"
VertexLockGuard是什么？,"page_content='运维监控

2.部署方案

2.4.第四步

+ 下载符合您机器架构以及系统版本的Grafana安装包，下载地址: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)  
+ 安装Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 启动Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 配置Grafana，首先在数据源设置中配置Prometheus的IP地址，配置完成后可以通过测试连接功能，验证是否成功连接数据源。然后，导入如下模版，并在页面中根据实际情况，修改正确的接口IP和端口。最后可以根据实际情况设置刷新时间和监控时间范围  
```json
{
""annotations"": {
""list"": [
{
""builtIn"": 1,
""datasource"": {
""type"": ""grafana""
},
""enable"": true,
""hide"": true,
""iconColor"": ""rgba(0, 211, 255, 1)"",
""name"": ""Annotations & Alerts"",
""target"": {
""limit"": 100,
""matchAny"": false,
""tags"": [],
""type"": ""dashboard""
},
""type"": ""dashboard""
}
]
},
""editable"": true,
""fiscalYearStartMonth"": 0,
""graphTooltip"": 0,
""id"": 2,
""links"": [],
""liveNow"": false,
""panels"": [
{
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
}
},
""mappings"": [],
""unit"": ""kbytes""
},
""overrides"": [
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {__name__=\""resources_report\"", instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
},
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""others""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-blue"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
}
}
]
}
]
},
""gridPos"": {
""h"": 16,
""w"": 6,
""x"": 0,
""y"": 0
},
""id"": 14,
""options"": {
""displayLabels"": [
""name"",
""value""
],
""legend"": {
""displayMode"": ""table"",
""placement"": ""bottom"",
""values"": [
""percent"",
""value""
]
},
""pieType"": ""pie"",
""reduceOptions"": {
""calcs"": [
""lastNotNull""
],
""fields"": """",
""val' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}","page_content='典型示例

PageRank动态图计算示例介绍

实例代码

```java

public class IncrGraphCompute {

private static final Logger LOGGER = LoggerFactory.getLogger(IncrGraphCompute.class);
// 计算结果路径
public static final String RESULT_FILE_PATH = ""./target/tmp/data/result/incr_graph"";
// 结果对比路径
public static final String REF_FILE_PATH = ""data/reference/incr_graph"";

public static void main(String[] args) {
// 获取执行环境
Environment environment = EnvironmentFactory.onLocalEnvironment();
// 执行作业提交
IPipelineResult result = submit(environment);
// 等待执行完成
result.get();
// 关闭执行环境
environment.shutdown();
}

public static IPipelineResult<?> submit(Environment environment) {
// 构建任务执行流
final Pipeline pipeline = PipelineFactory.buildPipeline(environment);
// 获取作业环境配置
Configuration envConfig = ((EnvironmentContext) environment.getEnvironmentContext()).getConfig();
// 指定保存计算结果的路径
envConfig.put(FileSink.OUTPUT_DIR, RESULT_FILE_PATH);

// graphview 名称
final String graphName = ""graph_view_name"";
// 创建增量图 graphview
GraphViewDesc graphViewDesc = GraphViewBuilder
.createGraphView(graphName)
// 设置 graphview 分片数, 可从配置中指定
.withShardNum(envConfig.getInteger(ExampleConfigKeys.ITERATOR_PARALLELISM))
// 设置 graphview backend 类型
.withBackend(BackendType.RocksDB)
// 指定 graphview 点边以及属性等schema信息
.withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class, Integer.class, ValueEdge.class, IntegerType.class))
.build();
// 将创建好的graphview信息添加到任务执行流
pipeline.withView(graphName, graphViewDesc);

// 提交任务并执行
pipeline.submit(new PipelineTask() {
@Override
public void execute(IPipelineTaskContext pipelineTaskCxt) {
Configuration conf = pipelineTaskCxt.getConfig();
// 1. 构建点数据输入源
PWindowSource<IVertex<Integer, Integer>> vertices =
// extract vertex from edge file
pipelineTaskCxt.buildSource(new RecoverableFileSource<>(""data/input/email_edge"",
// 指定每行数据的解析格式
line -> {
String[] fields = line.split("","");
IVertex<Integer, Integer> vertex1 = new ValueVertex<>(
Integer.valueOf(fields[0]), 1);
IVertex<Integer, Integer> vertex2 = new ValueVertex<>(
Integer.valueOf(fields[1]), 1);
return Arrays.asList(vertex1, vertex2);
}), SizeTumblingWindow.of(10000))
// 指定点数据source并发数
.withParallelism(pipelineTaskCxt.getConfig().getInteger(ExampleConfigKeys.SOURCE_PARALLELISM));

// 2. 构建边数据输入源
PWindowSource<IEdge<Integer, Integer>> edges =
pipelin' metadata={'Header 1': '典型示例', 'Header 2': 'PageRank动态图计算示例介绍', 'Header 3': '实例代码'}","page_content='静态图

接口

| API | 接口说明 | 入参说明 |
| --- | --- | --- |
| void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext) | vertexCentric function进行open操作 | vertexCentricFuncContext：K表示vertexId的类型，VV表示vertex value类型，EV表示edge value类型，M表示图遍历中定义的消息类型，R表示遍历结果类型。 |
| void init(ITraversalRequest traversalRequest) | 图遍历初始化接口 | traversalRequest：图遍历触发点，其中K表示vertex id的类型。 |
| void compute(K vertexId, Iterator messageIterator) | 图遍历接口 | vertexId：当前计算点的id，其中K表示vertex id的类型。<br>messageIterator：图遍历过程中所有发送给当前vertex的消息，其中M表示遍历迭代过程中定义的发送消息类型。 |  
- 详细接口  
```java
public interface VertexCentricTraversalFunction<K, VV, EV, M, R> extends VertexCentricFunction<K, VV
, EV, M> {

void open(VertexCentricTraversalFuncContext<K, VV, EV, M, R> vertexCentricFuncContext);
/** 图遍历算法初始化方法 */
void init(ITraversalRequest<K> traversalRequest);
/** 实现图遍历逻辑 */
void compute(K vertexId, Iterator<M> messageIterator);

void finish();

void close();

interface VertexCentricTraversalFuncContext<K, VV, EV, M, R> extends VertexCentricFuncContext<K,
VV, EV, M> {
/** 获取图遍历结果 */
void takeResponse(ITraversalResponse<R> response);
/** 获取开始图遍历的点 */
TraversalVertexQuery<K, VV> vertex();
/** 获取开始图遍历的边 */
TraversalEdgeQuery<K, EV> edges();

void broadcast(IGraphMessage<K, M> message);
}

interface TraversalVertexQuery<K, VV> extends VertexQuery<K, VV> {
/** 获取图遍历中点的迭代器 */
Iterator<K> loadIdIterator();
}

interface TraversalEdgeQuery<K, EV> extends EdgeQuery<K, EV> {
/** 通过指定的点id，获取对应的图遍历起点 */
TraversalEdgeQuery<K, EV> withId(K vertexId);
}
}
```' metadata={'Header 1': '静态图', 'Header 2': '接口'}"
value pack时的null array的具体含义是什么？,"page_content='Geaflow支持以下逻辑运算：  
操作|描述
----------------------|------
boolean1 OR boolean2 | 如果boolean1为true或boolean2为true，则返回true。
boolean1 AND boolean2 | 仅在boolean1为true和boolean2为true时才返回true。
NOT boolean | 返回给定布尔变量的NOT操作的结果。
boolean IS FALSE | 如果布尔变量为false，则返回true。如果布尔变量是UNKNOWN，则返回false。
boolean IS NOT FALSE | 如果布尔变量为true，则返回true。如果布尔变量是UNKNOWN，则返回true。
boolean IS TRUE | 如果布尔变量为true，则返回true。如果布尔变量是UNKNOWN，则返回false。
boolean IS NOT TRUE | 如果布尔变量为false，则返回true。如果布尔变量是UNKNOWN，则返回true。
value1 = value2 | 如果value1等于value2，则返回true。
value1 <> value2 | 如果value1不等于value2，则返回true。
value1 > value2 | 如果value1大于value2，则返回true。
value1 >= value2 | 如果value1大于或等于value2，则返回true。
value1 < value2 | 如果value1小于value2，则返回true。
value1 <= value2 | 如果value1小于或等于value2，则返回true。
value IS NULL | 如果value为null，则返回true。
value IS NOT NULL | 如果value不为null，则返回true。
value1 IS DISTINCT FROM value2 | 如果value1与value2不同，则返回true。如果value1和value2都为null，则它们被视为相等。
value1 IS NOT DISTINCT FROM value2 | 如果value1等于value2，则返回true。如果value1和value2都为null，则它们被视为相等。
value1 BETWEEN value2 AND value3 | 如果value1大于或等于value2且小于value3，则返回true。
value1 NOT BETWEEN value2 AND value3 | 如果value1小于value2或大于或等于value3，则返回true。
string1 LIKE string2 [ ESCAPE string3 ] | 对字符串string1进行模糊匹配，如果匹配到模式string2则返回true，如果不匹配则返回false。
string1 NOT LIKE string2 [ ESCAPE string3 ] | 对字符串string1进行模糊匹配，如果匹配到模式string2则返回false，如果不匹配则返回true。
value IN (value [, value]* ) | 如果value等于列表中的任何一个值，则返回true。
value NOT IN (value [, value]* ) | 如果value不等于列表中的任何一个值，则返回true。'","page_content='RESTful API Legacy

6.Deprecated

6.7.点操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/node/{vid}
```  
Nodes 提供节点（Vertex）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。  
#### 6.7.1.列出点数量和label数量  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| num_label | 点 label 数量 | 整数 |
| num_vertex | 点数量 | 整数 |  
_注意 num_vertex 返回的并不是准确的点数量，只是一个估计值。_  
#### 6.7.2.创建一个点  
向数据库中插入一个点。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 点属性 | 字典，其中 key 是列名，value 是相应值。value 必须是与列类型相应的类型，如列为 int32，则 value 只能是整数。 |  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新点 vid。该 ID 可用于后续的点操作中。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""property"" : {
""name"" : ""Passerby A"",
""birthyear"" : 1989
}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
21
}
```  
#### 6.7.3.批量创建点  
TuGraph 允许一次性插入多个点，以减少网络开销。  
- **URI**: `/db/{graph_name}/node`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| fields | 点属性 | 列表 |
| values | 点数据 | 列表 |  
其中 fields 是一个字符串列表，列出一系列列名；values 是一个列表，其中每个元素是一个列表，列表中每个元素是列数据。  
- **RESPONSE**: 如果成功，返回代码 200。并在 JSON 内容中返回新增加的点的 vid 列表，该列表中每一个 vid 按顺序对应请求中的每一个点。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""Person"",
""fields"" : [""name"", ""birthyear""],
""values"" : [[""alex"", 2000],
[""bob"", 1999]]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
22,
23
]
}
```  
#### 6.7.4.获取点  
- **URI**: `/db/{graph_name}/node/{vertex_id}`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | Label 名 | 字符串 |
| property | 属性 | 字典，格式为 { {列名 1}:{列值 1},...} |  
**Example request.**  
```
• GET http://localhost:7070/db/{graph_name}/node/5
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""property"": {
""birthyear' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.7.点操作'}","page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客户端端口。默认端口为 7687。                                                                                                                                                            |
| enable_ha                    | 布尔值                   | 是否启动高可用模式。默认值为 false。                                                ' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}"
"tugraph支持边属性匹配吗？，MATCH (n:chunk {id: '21604c19-0d30-11ef-b83b-0242ac110005'})-[r:kw {name:""生活补贴""}]-(m) RETURN n, r, m 类似这种cypher 为啥不能过滤边属性？","page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='功能概览

2.存储层

在图数据模型上，TuGraph支持属性图模型，按照层次可以分为子图、标签（包括点标签和边标签）、属性。从存储层看，TuGraph使用使用直观的多层的树状模型，没有跨子图的标签，也没有跨标签的属性，仅保留图模型的核心逻辑。  
在子图的存储上，TuGraph对多图做了数据的物理隔离，每个图对应一个LMDB的实例。多图的元数据描述信息，保存在meta的特殊的公共LMDB实例中。点边标签及其属性的存储，通过将图数据自适应地映射到KV键值对，最大程度发挥读性能。同时在KV层实现了多线程写，解决了LMDB写性能较低的劣势。主键索引和二级索引，对应LMDB中B+的表，支持基于比较的索引值增删查改。  
存储层还保留了一些其他非核心功能的数据，包括权限数据、预编译的插件数据、监控数据等。' metadata={'Header 1': '功能概览', 'Header 2': '2.存储层'}","page_content='TuGraph图模型说明

2. 图项目、点、边、属性命名规则和建议

2.2 使用限制

|**描述**|**最大个数**|
|-------- |--------- |
|用户数、角色数|65536|
|图项目的个数|4096|
|每个图项目的点和边类型数量之和|4096|
|每个点或边类型的属性数量|1024|  
注：
1、特殊字符和关键字说明：使用特殊字符或非保留关键字时，需要使用反单引号/backquote（``）进行引用；  
示例： ```match (`match`:match) return `match`.id limit 1```  
2、大小写敏感性：TuGraph大小写敏感；  
3、图项目、点/边、属性名称之间可以重复使用，同一点或边下的属性名称不可以重复；  
4、属性名字保留关键字：SRC_ID / DST_ID / SKIP' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '2. 图项目、点、边、属性命名规则和建议', 'Header 3': '2.2 使用限制'}"
TuGraph是如何通过语句定义点类型和边类型的？,"page_content='TuGraph图模型说明

1. 数据模型

1.1. 图模型

TuGraph是一个具备多图能力的强类型、有向属性图数据库。  
- 图项目：每个数据库服务可以承载多个图项目（多图），每个图项目可以有自己的访问控制配置，数据库管理员可以创建或删除指定图项目。
- 点：指实体，一般用于表达现实中的实体对象，如一部电影、一个演员。
- 主键：用户自定义的点数据主键，默认唯一索引，在对应的点类型中唯一。
- VID：点在存储层自动分配图项目中的唯一ID，用户不可修改。
- 上限：每个图项目存储最多2^(40)个点数据。
- 边：用于表达点与点之间的关系，如演员出演电影。
- 有向边：边为有向边。若要模拟无向边，用户可以创建两个方向相反的边。
- 多条边：两个点数据之间可以有多条边数据。当前TuGraph支持重复边，如要确保边边唯一，需要通过业务策略实现。
- 上限：两个点数据之间存储最多2^(32)条边数据。
- 属性图：点和边可以具有与其关联的属性，每个属性可以有不同的类型。
- 强类型：每个点和边有且仅有一个标签，创建标签后，修改属性数量及类型有代价。
- 指定边的起/终点类型：可限制边的起点和终点点类型，支持同类型边的起点和终点的点类型不同，如个人转账给公司、公司转账给公司；当指定边的起/终点类型后，可增加多组起/终点类型，不可删除已限制的起/终点类型。
- 无限制模式：支持不指定边的起点和终点的点类型，任意两个点类型间均可创建该类型的边数据。注：当指定边的起/终点类型后无法再采用无限制模式。' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.1. 图模型'}","page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

TuGraph 是一个具备多图能力的强模式属性图数据库。在每一张子图中，每种点和边都需要有预定义的数据格式。数据格式由 Label 决定，每种 Label 都有自己的数据格式。用户可以使用 REST API 添加，删除和查询 Label 及其对应的数据格式。  
Label 操作对应的 URI 格式为  
```
http://{host}:{port}/db/{graph_name}/label/{type}/{label_name}
```  
其中{type}可以是 node 或者 relationship。  
#### 6.6.1.创建Label  
创建 Label 的过程同时也是定义其数据类型的过程。只有创建了 Label 才能在图中插入相应类型的点或者边。  
- **URI**: `/db/{graph_name}/label`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | Label 名 | 字符串 |
| fields | 数据列定义 | 列表 |
| is_vertex | 是否是点 Label | 布尔值 |
| primary | 点的主键属性 | 字符串 |
| edge_constraints | 边的约束 | 列表 |  
`primary` 在 `is_vertex` 为 `true` 的时候设置，这个字段只有点才有, 创建点的时候必须设置。  
`edge_constraints` 在 `is_vertex` 为 `false` 的时候设置，这个字段只有边有。这个字段限制了该边的起点和终点只能是哪些点的组合，比如：`[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]`，限制了该边只能是从 `vertex_label1` 到 `vertex_label2` 和 从 `vertex_label3` 到 `vertex_label4`。如果不想有任何限制，不设置该字段即可。  
其中`fields`为一个数组，其中每个元素定义数据的一列，内容如下：  
| 域名     | 说明                                     | 类型                                                                                                |
| -------- | ---------------------------------------- | --------------------------------------------------------------------------------------------------- |
| name     | 列名                                     | 字符串                                                                                              |
| type     | 列数据类型                               | 字符串，有以下类型： int8, int16, int32, int64, float, double, string, date, datetime, binary, bool |
| optional | 数据是否可以为空（可选，缺省值为 false） | 布尔值                                                                                              |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/label
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""name"":""Actor"",
""fields"": [
{""name"":""uid"", ""type"":""int64"", ""optional"":false},
{""name"":""name"", ""type"":""string"", ""optional"":true}
],
""is_vertex"":true,
""primary"" : ""uid""
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.6.2.列出所有 Label  
- **URI**: `/db/{graph_name}/label`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| edge' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}","page_content='Heterogeneous Graph

2. 异质图创建

在TuGraph中，一个异构图由一系列边关系构成。每个关系由一个字符串三元组定义 (源节点类型, 边类型, 目标节点类型) 。异质图的创建方式与同质图类似，只是在创建图时需要指定字符串三元组定义。如下所示。  
```python
olapondb = PyOlapOnDB('Empty', db, txn, [(""node"", ""edge"", ""node"")])
```
其中，第四个参数为异质图的边关系定义，可以通过该参数，指定筛选的异质图点边类型。如果不指定该参数，则默认将全部点边类型的数据进行构图训练。' metadata={'Header 1': 'Heterogeneous Graph', 'Header 2': '2. 异质图创建'}"
想问一下，如果log_dir不设置，是不是就不会保存日志文件?,"page_content='日志信息

2.服务器日志

2.1.服务器日志配置项

服务器日志的输出位置可以通过`log_dir`配置指定。服务器日志详细程度可通过`verbose`配置项指定。  
`log_dir`配置项默认为空。若`log_dir`配置项为空，则所有日志会输出到控制台(daemon模式下若log_dir配置项为空则不会向console输出任何日志)；若手动指定`log_dir`配置项，则日志文件会生成在对应的路径下面。单个日志文件最大大小为256MB。  
`verbose`配置项控制日志的详细程度，从粗到细分为`0, 1, 2`三个等级，默认等级为`1`。等级为`2`时，日志记录最详细，服务器将打印`DEBUG`及以上等级的全部日志信息；等级为`1`时，服务器将仅打印`INFO`等级及以上的主要事件的日志；等级为`0`时，服务器将仅打印`ERROR`等级及以上的错误日志。' metadata={'Header 1': '日志信息', 'Header 2': '2.服务器日志', 'Header 3': '2.1.服务器日志配置项'}","page_content='数据库运行

4.服务配置

4.1.配置参数

具体参数及其类型描述如下：  
| **参数名**                      | **<nobr>参数类型</nobr>** | **参数说明**                                                                                                                                                                          |
|------------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| directory                    | 字符串                   | 数据文件所在目录。如果目录不存在 ，则自动创建。默认目录为 /var/lib/lgraph/data。                                                                                                                               |
| durable                      | 布尔值                   | 是否开启实时持久化。关闭持久化可以减少写入时的磁盘 IO 开销，但是在机器断电等极端情况下可能丢失数据。默认值为 `true`。                                                                                                                  |
| host                         | 字符串                   | REST 服务器监听时使用的地址，一般为服务器的 IP 地址。默认地址为 0.0.0.0。注：在HA模式下，host需要设置为对应服务器的IP地址，不能设置为0.0.0.0。                                                                                           |
| port                         | 整型                    | REST 服务器监听时使用的端口。默认端口为 7070。                                                                                                                                                      |
| enable_rpc                   | 布尔值                   | 是否使用 RPC 服务。默认值为 false。                                                                                                                                                           |
| rpc_port                     | 整型                    | RPC 及 HA 服务所用端口。默认端口为 9090。                                                                                                                                                       |
| bolt_port                    | 整型                    | Bolt 客户端端口。默认端口为 7687。                                                                                                                                                            |
| enable_ha                    | 布尔值                   | 是否启动高可用模式。默认值为 false。                                                ' metadata={'Header 1': '数据库运行', 'Header 2': '4.服务配置', 'Header 3': '4.1.配置参数'}","page_content='日志信息

2.服务器日志

2.3.存储过程日志

用户在存储过程的编写过程中可以使用日志功能将所需的调试信息输出到日志中进行查看，辅助开发。调试信息会输出到与服务器日志相同的日志文件中(如未指定`log_dir`则同样输出至console)  
#### 2.3.1.cpp存储过程
请使用2.2中提供的log宏输出调试信息，避免使用cout或者printf等输出方式。具体使用方式可参考如下示例代码（详见`procedures/demo/log_demo.cpp`）  
```
#include <stdlib.h>
#include ""lgraph/lgraph.h""
#include ""tools/lgraph_log.h""  // add log dependency
using namespace lgraph_api;

void LogExample() {
LOG_DEBUG() << ""This is a debug level log message."";
LOG_INFO() << ""This is a info level log message."";
LOG_WARN() << ""This is a warning level log message."";
LOG_ERROR() << ""This is a error level log message."";
}

extern ""C"" bool Process(GraphDB& db, const std::string& request, std::string& response) {
response = ""TuGraph log demo"";
LogExample();
return true;
}
```
将以上示例代码作为存储过程插入数据库并运行后，可以在日志文件中看到相应的日志条目。  
#### 2.3.1.python存储过程
请使用python自带的print输出调试信息，调试信息会在存储过程运行结束后合并为一条WARN等级的日志条目输出至日志文件中。' metadata={'Header 1': '日志信息', 'Header 2': '2.服务器日志', 'Header 3': '2.3.存储过程日志'}"
当调用算法 `algo.shortestPath` 实际应用中的例子是什么？,"page_content='QA汇总

Cypher QA

查询最短路径

Q：如何查询最短路径，shortestPath 函数如何使用？
A：使用示例如下（示例图谱：MovieDemo）  
```
MATCH (n1 {name:'Corin Redgrave'}),(n2 {name:'Liam Neeson'})
CALL algo.allShortestPaths(n1,n2) YIELD nodeIds,relationshipIds,cost
RETURN nodeIds,relationshipIds,cost
```  
详尽使用方案请参考官网文档https://www.tugraph.org/doc?version=V3.3.0&id=10000000000658658。' metadata={'Header 1': 'QA汇总', 'Header 2': 'Cypher QA', 'Header 3': '查询最短路径'}","page_content='Cypher API

5.附录2. 内置procedures列表

* algo.shortestPath(startNode, endNode, config)

get one of the shortest paths between two vertexes.  
**Parameters:**  
| parameter | parameter type | description                          |
| --------- | -------------- | ------------------------------------------------------------ |
| startNode | Node       | the source node of paths                     |
| endNode   | Node       | the destination node paths                   |
| config    | MAP        | the filter of shortest paths, the formate as {maxHops:3, relationshipQuery:'HAS_CHILD'} |  
**Output:**  
If successful, it will returns one group result of the shortest path.  
**Example input:**  
```
MATCH (n1 {name:'Hugo Weaving'}),(n2 {title:'The Matrix'})
CALL algo.shortestPath(n1,n2) YIELD nodeCount,totalCost RETURN nodeCount,totalCost
```  
**Example output:**  
| nodeCount | totalCost |
| --------- | --------- |
| 2     | 1     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* algo.shortestPath(startNode, endNode, config)'}","page_content='Cypher API

5.附录2. 内置procedures列表

* algo.allShortestPaths(startNode, endNode, config))

get the path of backuped files.  
**Output:**  
If successful, it returns the path of snapshot.  
**Example input:**  
```
MATCH (n1 {name:'Hugo Weaving'}),(n2 {title:'The Matrix'})
CALL algo.allShortestPaths(n1,n2) YIELD nodeIds,cost RETURN nodeIds,cost
```  
**Example output:**  
| nodeIds | cost |
| ------- | ---- |
| [2,665] | 1    |
| ...     |      |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* algo.allShortestPaths(startNode, endNode, config))'}"
方法 GetLabel() 返回什么类型的结果？,"page_content='Cypher API

5.附录2. 内置procedures列表

* db.getLabelSchema(label_type, label_name)

Get the schema definition of the label in a subgraph.  
**Scope:** subgraph, as specified in the `graph` parameter in REST or RPC request.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |  
**Output:** a list of label specifications, in which each element is a list of the following fields:  
| field_name | field_type | description           |
| ---------- | ---------- | ----------------------------- |
| name       | string     | name of the field         |
| type       | string     | type of the field         |
| optional   | boolean    | whether the field is optional |  
**Example input:**  
```
CALL db.getLabelSchema('vertex', 'Person')
```  
**Example output:**  
| name     | type   | optional |
| ------------ | ------ | -------- |
| id       | INT32  | false    |
| born     | INT32  | true     |
| name     | STRING | true     |
| poster_image | STRING | true     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.getLabelSchema(label_type, label_name)'}","page_content='RESTful API Legacy

6.Deprecated

6.9.索引

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/index/{label}/{field}
```  
提供索引操作，接受 GET/POST 请求。  
#### 6.9.1.创建索引  
该操作会启动一个创建索引的后台任务，用户可以通过列出该 Label 相关的所有索引来检查新建索引的状态。  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: POST
- **REQUEST**:  
| 域名    | 说明     | 类型                                  |
|-------|--------|-------------------------------------|
| label | Label 名 | 字符串                                 |
| field | 域名     | 字符串                                 |
| type  | 索引类型   | int类型，0表示非唯一索引，1表示全局唯一索引，2表示两点间唯一索引 |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"": ""Person"",
""field"": ""birthyear"",
""is_unique"" : false
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.9.2.列出所有索引  
- **URI**: `/db/{graph_name}/index`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""field"": ""name"",
""label"": ""City"",
""is_unique"": false
},
{
""field"": ""title"",
""label"": ""Film"",
""is_unique"": false
},
{
""field"": ""name"",
""label"": ""Person"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
#### 6.9.3.列出所有与某个 Label 相关的索引  
- **URI**: `/db/{graph_name}/index/{label}`
- **METHOD**: GET
- **RESPONSE**: 索引列表，其中每一个元素是一个索引描述，格式与[创建索引](#indexspec)时使用格式相同。  
**Example request.**  
```
• GET http://localhost:7070/db/graph1/index/Person
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
{
""label"": ""Person"",
""field"": ""name"",
""is_unique"": true
},
{
""label"": ""Person"",
""field"": ""age"",
""is_unique"": false
}
]
}
```  
#### 6.9.4.删除索引  
- **URI**: `/db/{graph_name}/index/{label}/{field}`
- **METHOD**: DELETE
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• DELETE http://localhost:7070/db/graph1/index/Person/name
• Accept: application/json; charset=UTF-8
```  
**Example response.**  
```
• 200: OK
```  
' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.9.索引'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createLabel(label_type, label_name, extra, field_spec...)

Create a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| extra      | string     | for edge, it means constraints; for vertex, it means primary property |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.
for edge, `extra` should be a json array string, like this `[[""label1"",""label2""], [""label3"",""label4""]]`, if edge has no constraints, give an empty json array, like this `[]`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createLabel('vertex', 'new_label', 'id', ['id','int32',false], ['name','string', true]);
CALL db.createLabel('edge', 'new_edge', '[[""id1"",""id2""]]', ['id','int32',false], ['name', 'string', true]);
```  
**Example output:**  
```
Vertex label [new_label] successfully added.
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createLabel(label_type, label_name, extra, field_spec...)'}"
Rust 存储过程目前支持哪个版本？,"page_content='Rust 存储过程

1. 介绍

Rust 存储过程目前仅支持v1版本，TuGraph能够支持一切编译成动态库的语言作为插件。Rust语言作为系统编程语言的新起之秀，在安全性上、可靠性以及人体工程学上相较于C++具有较大优势。  
我们提供了TuGraph的[Rust binding]库来支持在Rust中调用lgrahp api，同时提供[tugraph-plugin-util] 工具库来帮助大家更加简洁地编写Rust插件代码。  
[Rust binding]: https://crates.io/crates/tugraph
[tugraph-plugin-util]: https://crates.io/crates/tugraph-plugin-util' metadata={'Header 1': 'Rust 存储过程', 'Header 2': '1. 介绍'}","page_content='Procedure API

2.存储过程的版本支持

目前TuGraph支持两个版本的存储过程，适用于不同的场景，v3.5版本只支持v1，可通过REST或RPC接口直接调用；从v3.5版本开始支持v2，能够在图查询语言（比如Cypher）中嵌入调用，我们称之为POG（Procedure On Graph query language，APOC）。  
|                        | Procedure v1                       | Procedure v2               |
| ---------------------- | ---------------------------------- | -------------------------- |
| 适用场景                 | 极致性能，或者复杂的多事务管理情形       | 一般情况，与Cypher高度联动 |
| 事务                    | 函数内部创建，可自由控制多事务          | 外部传入函数，单一事务     |
| 签名（参数定义）          | 无                                 | 有                    |
| 输入输出参数类型          | 不需要指定                           | 需要指定参数类型        |
| Cypher Standalone Call | 支持                                | 支持                  |
| Cypher Embeded Call    | 不支持                              | 支持                  |
| 语言                    | C++/Python/Rust                    | C++                  |
| 调用模式                 | 直接传字符串，一般为JSON               | 通过Cypher语句中的变量  |  
在TuGraph中，存储过程v1和v2单独管理，支持增删查，但仍不建议重名。' metadata={'Header 1': 'Procedure API', 'Header 2': '2.存储过程的版本支持'}","page_content='Procedure API

3.存储过程语言支持

在 TuGraph 中，用户可以动态的加载，更新和删除存储过程。TuGraph 支持 C++ 语言、 Python 语言和 Rust 语言编写存储过程。在性能上 C++ 语言支持的最完整，性能最优。  
注意存储过程是在服务端编译执行的逻辑，和客户端的语言支持无关。' metadata={'Header 1': 'Procedure API', 'Header 2': '3.存储过程语言支持'}"
TuGraph单元测试使用的是什么测试框架？,"page_content='单元测试

1.简介

TuGraph单元测试采用gtest框架，可以选择一次跑全部test或者制定某些test。' metadata={'Header 1': '单元测试', 'Header 2': '1.简介'}","page_content='集成测试

2.TuGraph集成测试框架

TuGraph采用pytest框架作为自己的集成测试框架，pytest框架作为目前使用最广泛的cs端集成测试框架，以其灵活简单，容易上手，并且支持参数化的使用方式而著称，TuGraph基于pytest提供的功能，抽象出了不同的工具，通过参数来控制各个工具的处理逻辑，以方便大家进行高效的测试代码开发。  
更多pytest信息请参考官网: [https://docs.pytest.org/en/7.2.x/getting-started.html](https://docs.pytest.org/en/7.2.x/getting-started.html)' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架'}","page_content='集成测试

2.TuGraph集成测试框架

2.1.组件描述

| 组件名称            | 组件功能                       | 实现方式                                  |
|-----------------|----------------------------|---------------------------------------|
| server          | TuGraph单机服务                | 开启子进程并在子进程中启动服务                       |
| client          | TuGraph Rpc Client         | 当前进程中开启TuGraph Python Rpc Client发送请求  |
| importor        | TuGraph Importor           | 开启子进程并在子进程中处理导入请求                     |
| exportor        | TuGraph Exportor           | 开启子进程并在子进程中处理导出请求                     |
| backup_binlog   | TuGraph Backup Binlog      | 开启子进程并在子进程中处理备份binlog的请求              |
| backup_copy_dir | TuGraph Backup             | 开启子进程并在子进程中处理备份完整db的请求                |
| build_so        | 编译c++动态连接库的组件              | 开启子进程并在子进程中处理gcc编译逻辑                  |
| copy_snapshot   | TuGraph Copy Snapshot      | 当前进程中处理备份snapshot的请求                  |
| copydir         | 文件夹拷贝                      | 当前进程中处理文件夹拷贝请求                        |
| exec            | 执行c++/java可执行文件            | 开启子进程并在子进程中启动C++可执行文件                 |
| algo            | 执行算法                       | 开启子进程并在子进程中执行算法                       |
| bash            | 执行bash命令                   | 开启子进程并在子进程中执行bash命令                   |
| rest            | TuGraph Python Rest Client | 当前进程中开启TuGraph Python Rest Client发送请求 |' metadata={'Header 1': '集成测试', 'Header 2': '2.TuGraph集成测试框架', 'Header 3': '2.1.组件描述'}"
创建 Label 的请求是否需要指定该 Label 是否为点（vertex）或边（relationship）？,"page_content='RESTful API Legacy

6.Deprecated

6.6.元数据管理

TuGraph 是一个具备多图能力的强模式属性图数据库。在每一张子图中，每种点和边都需要有预定义的数据格式。数据格式由 Label 决定，每种 Label 都有自己的数据格式。用户可以使用 REST API 添加，删除和查询 Label 及其对应的数据格式。  
Label 操作对应的 URI 格式为  
```
http://{host}:{port}/db/{graph_name}/label/{type}/{label_name}
```  
其中{type}可以是 node 或者 relationship。  
#### 6.6.1.创建Label  
创建 Label 的过程同时也是定义其数据类型的过程。只有创建了 Label 才能在图中插入相应类型的点或者边。  
- **URI**: `/db/{graph_name}/label`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| name | Label 名 | 字符串 |
| fields | 数据列定义 | 列表 |
| is_vertex | 是否是点 Label | 布尔值 |
| primary | 点的主键属性 | 字符串 |
| edge_constraints | 边的约束 | 列表 |  
`primary` 在 `is_vertex` 为 `true` 的时候设置，这个字段只有点才有, 创建点的时候必须设置。  
`edge_constraints` 在 `is_vertex` 为 `false` 的时候设置，这个字段只有边有。这个字段限制了该边的起点和终点只能是哪些点的组合，比如：`[[""vertex_label1"",""vertex_label2""],[""vertex_label3"",""vertex_label4""]]`，限制了该边只能是从 `vertex_label1` 到 `vertex_label2` 和 从 `vertex_label3` 到 `vertex_label4`。如果不想有任何限制，不设置该字段即可。  
其中`fields`为一个数组，其中每个元素定义数据的一列，内容如下：  
| 域名     | 说明                                     | 类型                                                                                                |
| -------- | ---------------------------------------- | --------------------------------------------------------------------------------------------------- |
| name     | 列名                                     | 字符串                                                                                              |
| type     | 列数据类型                               | 字符串，有以下类型： int8, int16, int32, int64, float, double, string, date, datetime, binary, bool |
| optional | 数据是否可以为空（可选，缺省值为 false） | 布尔值                                                                                              |  
- **RESPONSE**: 如果成功，返回代码 200。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/label
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""name"":""Actor"",
""fields"": [
{""name"":""uid"", ""type"":""int64"", ""optional"":false},
{""name"":""name"", ""type"":""string"", ""optional"":true}
],
""is_vertex"":true,
""primary"" : ""uid""
}
```  
**Example response.**  
```
• 200: OK
```  
#### 6.6.2.列出所有 Label  
- **URI**: `/db/{graph_name}/label`
- **METHOD**: GET
- **RESPONSE**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| edge' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.6.元数据管理'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.createLabel(label_type, label_name, extra, field_spec...)

Create a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |
| extra      | string     | for edge, it means constraints; for vertex, it means primary property |
| field_spec | list       | specification of a field  |  
in which each `field_spec` is a list of string in the form of `[field_name, field_type, optional]`.
for edge, `extra` should be a json array string, like this `[[""label1"",""label2""], [""label3"",""label4""]]`, if edge has no constraints, give an empty json array, like this `[]`  
**Output:**  
If successful, it returns a success message.  
**Example input:**  
```
CALL db.createLabel('vertex', 'new_label', 'id', ['id','int32',false], ['name','string', true]);
CALL db.createLabel('edge', 'new_edge', '[[""id1"",""id2""]]', ['id','int32',false], ['name', 'string', true]);
```  
**Example output:**  
```
Vertex label [new_label] successfully added.
```' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.createLabel(label_type, label_name, extra, field_spec...)'}","page_content='RESTful API Legacy

6.Deprecated

6.8.边操作

URI 格式为  
```
http://{host}:{port}/db/{graph_name}/relationship/{euid}
```  
与 Nodes 功能类似，Relationships 提供边（edge）的 CRUD 操作，接受 GET/POST/PUT/DELETE 请求。每一条边都可以由一个唯一 ID（euid）来标识。这个 ID 可以从在插入边时获得，或者在 [列出所有边](#%E5%88%97%E5%87%BA%E6%89%80%E6%9C%89%E8%BE%B9) 操作中得到。  
#### 6.8.1.创建一条边  
- **URI**: `/db/{graph_name}/node/{src}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| destination | 目的点 ID | 整数值 |
| property | 边属性 | 字典 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid（字符串）。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/node/{src}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""destination"" : 14,
""label"" : ""BORN_IN"",
""property"" : {}
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
""1_14_1_0""
}
```  
#### 6.8.2.批量创建边  
- **URI**: `/db/{graph_name}/relationship`
- **METHOD**: POST
- **REQUEST**:
| 域名 | 说明 | 类型 |
| --- | --- | --- |
| label | 边 Label | 字符串 |
| fields | 数据列名 | 列表 |
| edge | 边数据 | 列表 |  
其中 edge 是一个数据列表，其中每个元素都是一条边，其定义如下：  
| 域名        | 说明     | 类型                                                   |
| ----------- | -------- | ------------------------------------------------------ |
| source      | 起点 id  | 整数                                                   |
| destination | 终点 id  | 整数                                                   |
| values      | 数据列表 | 列表，每列对应 fields 中的一个列，类型是该列对应的类型 |  
- **RESPONSE**: 如果成功，返回代码 200，同时返回新建立的边的 euid 列表。  
**Example request.**  
```
• POST http://localhost:7070/db/{graph_name}/relationship
• Accept: application/json; charset=UTF-8
• Content-Type: application/json
Input:
{
""label"" : ""knows"",
""fields"" : [""from_year"", ""weight""],
""edge"" : [
{""source"":0, ""destination"":1, ""values"":[2011, 0.8]},
{""source"":1, ""destination"":2, ""values"":[2008, 0.9]}
]
}
```  
**Example response.**  
```
• 200: OK
• Content-Type: application/json; charset=UTF-8
Output:
{
[
""0_1_0_0"",
""1_2_0_0""
]
}
```  
#### 6.8.3.列出所有出边（outgoing relationships）  
- **URI**: `/db/{graph_name}/node/{src}/relationship/out`
- **METHOD**: GET
- **RESPONSE**: 点 src 的所有出边 euid 列表  
**Example request.**  
```
• GET http://local' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '6.Deprecated', 'Header 3': '6.8.边操作'}"
TuGraph 中使用的两种主要图分析操作是什么？,"page_content='图分析引擎技术解析

1 TuGraph 图分析引擎概览

TuGraph 的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助 TuGraph 的 C++ 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如 BFS、PageRank、LPA、WCC 等迭代式图算法，最后根据运行结果做出相应的对策。 在 TuGraph 中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运行模式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适用于 Client/Server 部署，以及服务端直接调用，后者多用于调试。  
Standalone 模式的数据源是 TXT、二进制、ODPS 文件等外部数据源，能够独立于图数据存储直接运行分析算法。  
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六大类常用方法，可以满足多种业务场景需要，因此用户几乎不需要自己实现具体的图计算过程。  
<table><tbody><tr><td>算法类型</td><td>中文算法名</td><td>英文算法名</td><td>程序名</td></tr><tr><td rowspan=""5"">路径查询</td><td>广度优先搜索</td><td>Breadth-First Search</td><td>bfs</td></tr><tr><td>单源最短路径</td><td>Single-Source Shortest Path</td><td>sssp</td></tr><tr><td>全对最短路径</td><td>All-Pair Shortest Path</td><td>apsp</td></tr><tr><td>多源最短路径</td><td>Multiple-source Shortest Paths</td><td>mssp</td></tr><tr><td>两点间最短路径</td><td>Single-Pair Shortest Path</td><td>spsp</td></tr><tr><td rowspan=""9"">重要性分析</td><td>网页排序</td><td>Pagerank</td><td>pagerank</td></tr><tr><td>介数中心度</td><td>Betweenness Centrality</td><td>bc</td></tr><tr><td>置信度传播</td><td>Belief Propagation</td><td>bp</td></tr><tr><td>距离中心度</td><td>Closeness Centrality</td><td>clce</td></tr><tr><td>个性化网页排序</td><td>Personalized PageRank</td><td>ppr</td></tr><tr><td>带权重的网页排序</td><td>Weighted Pagerank Algorithm</td><td>wpagerank</td></tr><tr><td>信任指数排名</td><td>Trustrank</td><td>trustrank</td></tr><tr><td>sybil检测算法</td><td>Sybil Rank</td><td>sybilrank</td></tr><tr><td>超链接主题搜索</td><td>Hyperlink-Induced Topic Search</td><td>hits</td></tr><tr><td rowspan=""4"">关联性分析</td><td>平均集聚系数</td><td>Local Clustering Coefficient</td><td>lcc</td></tr><tr><td>共同邻居</td><td>Common Neighborhood</td><td>cn</td></tr><tr><td>度数关联度</td><td>Degree Correlation</td><td>dc</td></tr><tr><td>杰卡德系数</td><td>Jaccard Index</td><td>ji</td></tr><tr><td rowspan=""5"">图结构</td><td>直径估计</td><td>Dimension Estimation</td><td>de</td></tr><tr><td>K核算法</td><td>K-core</td><td>kcore</td></tr><tr><td>k阶团计数算法</td><td>Kcliques</td><td>kcliques</td></tr><tr><td>k阶桁架计数算法</td><td>Ktruss</td><td>ktruss</td></tr><tr><td>最大独立集算法</td><td>Maximal independent set</td><td>mis</td></tr><tr><td rowspan=""8"">社' metadata={'Header 1': '图分析引擎技术解析', 'Header 2': '1 TuGraph 图分析引擎概览'}","page_content='OLAP API

1. TuGraph 图分析引擎介绍

TuGraph的图分析引擎，面向的场景主要是全图/全量数据分析类的任务。借助TuGraph的 C++ / Python 图分析引擎 API ，用户可以对不同数据来源的图数据快速导出一个待处理的复杂子图，然后在该子图上运行诸如PageRank、LPA、WCC等迭代式图算法，最后根据运行结果做出相应的对策。  
在TuGraph中，导出和计算过程均可以通过在内存中并行处理的方式进行加速，从而达到近乎实时的处理分析，和传统方法相比，即避免了数据导出落盘的开销，又能使用紧凑的图数据结构获得计算的理想性能。  
TuGraph图计算系统社区版内置6个算法，商业版内置了25种算法，用户几乎不需要自己实现具体的图计算过程。其详细介绍可参考algorithms.md。  
根据数据来源及实现不同，可分为Procedure、Embed和Standalone三种运行方式，均继承于OlapBase API，OlapBase API接口文档可参考olapbase-api.md。  
其中Procedure和Embed的数据来源是图数据库中预加载的db数据，可以分别编译生成tugraph-web加载使用的.so文件和后台终端使用的embed文件，输入的图数据均通过db的加载形式，其接口文档可参考olapondb-api.md。
Standalone用于编译生成standalone文件，区别于前者，该文件的输入图数据通过txt、二进制、ODPS文件的形式加载，其接口文档可参考olapondisk-api.md。' metadata={'Header 1': 'OLAP API', 'Header 2': '1. TuGraph 图分析引擎介绍'}","page_content='OlapBase API

7. 图类OlapBase

7.4 批处理操作

TuGraph提供了两个批处理操作来并行地进行以点为中心的批处理过程。分别是：  
```c++
/*
函数名称:ReducedSum ProcessVertexInRange(std::function<ReducedSum(size_t)> work, size_t lower, size_t upper,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对Graph中节点编号介于lower和upper之间的节点执行work函数。第四个参数表示累加的基数，默认为0；
第五个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考include/lgraph/olap_base.h中具体代码

使用示例:统计数组parent数组中有出边的点个数
*/

auto vertex_num = graph.ProcessVertexInRange<size_t>(
[&](size_t i) {
if (graph.OutDegree(parent[i]) > 0) {
return 1;
}
},
0, parent.Size()
);
printf(""the number is %lu\n"",vertex_num);
```  
其中graph为图类OlapBase的实例化对象  
```C++
/*
函数名称:ReducedSum ProcessVertexActive(std::function<ReducedSum(size_t)> work, ParallelBitset &active_vertices,
ReducedSum zero = 0,std::function<ReducedSum(ReducedSum, ReducedSum)> reduce =reduce_plus<ReducedSum>)

函数用途:对active_vertices中对应为1的节点执行work函数，第三个参数表示累加的基数，默认为0；
第四个参数表示对每个work处理后的节点返回值进行迭代reduce函数操作，默认为累加操作。
具体实现请参考/include/lgraph/olap_base.h中具体代码

使用示例:输出Graph中节点1，2，3的所有出度邻居，并统计这三个节点的总出度
*/

auto active_in = graph.AllocVertexSubset();
active_in.Add(1);
active_in.Add(2);
active_in.Add(3);
auto total_outdegree = graph.ProcessVertexActive<size_t>(
[&](size_t vi) {
size_t local_outdegree = 0;
for (auto & edge : graph.OutEdges(vi)) {
size_t dst = edge.neighbour;
printf(""node %lu has neighbour %lu\n"",vi,dst);
local_outdegree += 1;
}
return local_outdegree;
},
active_in
);
printf(""total outdegree of node1,2,3 is %lu\n"",total_outdegree);
```' metadata={'Header 1': 'OlapBase API', 'Header 2': '7. 图类OlapBase', 'Header 3': '7.4 批处理操作'}"
TuGraph-DB如何在代码中增加日志输出埋点？,"page_content='蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍

二、TuGraph-DB高可用架构与规划

4.Server架构设计—快照

前文中提到，加入 follower 时，需要同步日志。但是一个集群经过长期的服务，日志一定是非常多的，如果每加入一个 follower，都从一年之前、两年之前的日志开始同步，同步过来除了 Append，还需要应用到 Server 里面，是非常耗时的。所以需要定期对节点打快照，对数据库状态做一个保存。再去加入 follower 时，直接传输快照就可以了。  
Tugraph-DB 不管是安装快照还是打快照，都是非常快速的。因为 Tugraph-DB 底层支持 MVCC 多版本，生成快照的时候并不会去阻塞读写请求。  
增加节点  
• 新节点加入集群时，Leader发现要同步的日志不存在，则向Follower发送安装快照请求  
安装快照  
• TuGraph-DB支持MVCC，生成快照不会阻塞读写请求' metadata={'Header 1': '蚂蚁关于 TuGraph-DB 图数据库高可用架构介绍', 'Header 2': '二、TuGraph-DB高可用架构与规划', 'Header 3': '4.Server架构设计—快照'}","page_content='TuGraph-db

3. 从源代码编译

建议在Linux系统中构建TuGraph，Docker环境是个不错的选择。如果您想设置一个新的环境，请参考[Dockerfile]  
以下是编译TuGraph的步骤：  
1. 如果需要web接口运行`deps/build_deps.sh`，不需要web接口则跳过此步骤
2. 根据容器系统信息执行`cmake .. -DOURSYSTEM=centos`或者`cmake .. -DOURSYSTEM=ubuntu`
3. `make`
4. `make package` 或者 `cpack --config CPackConfig.cmake`  
示例：`tugraph/tugraph-compile-centos7`Docker环境  
```bash
$ git clone --recursive https://github.com/TuGraph-family/tugraph-db.git
$ cd tugraph-db
$ deps/build_deps.sh
$ mkdir build && cd build
$ cmake .. -DOURSYSTEM=centos7
$ make
$ make package
```' metadata={'Header 1': 'TuGraph-db', 'Header 2': '3. 从源代码编译'}","page_content='技术规划

2. 已完成功能

TuGraph-DB于2022年9月1日开源，TuGraph-DB在社区的反馈声中，进行日常BUG修复，自身能力得到了完善。  
| 版本号   | 功能                               | 时间         |
|-------|----------------------------------|------------|
| 3.3.0 | 开源初版                             | 2022.9.1   |
| 3.3.1 | 图分析引擎重构，多模式支持                    | 2022.10.14 |
| 3.3.2 | OGM支持，UT覆盖率提升                    | 2022.11.21 |
| 3.3.3 | 链接认证机制迭代，加入英文文档                  | 2022.12.23 |
| 3.3.4 | 支持上云，梳理LDBC SNB Audit流程          | 2023.1.28  |
| 3.4.0 | 支持OLAP Python API, 离线导入升级        | 2023.3.11  |
| 3.5.0 | 支持POG，前端升级，文档梳理                  | 2023.6.5   |
| 3.5.1 | 图学习引擎，Procedure Rust API，存储属性分离  | 2023.7.14  |
| 3.6.0 | 高可用开源，日志系统升级                     | 2023.8.11  |
| 4.0.0 | ISO GQL支持，新增11个开源图算法，支持m1 Docker | 2023.9.6   |
| 4.0.1 | 支持时序边排序，新增5个开源图算法                | 2023.9.28  |
| 4.1.0 | 支持Bolt协议，支持快速在线全量导入，支持地理空间数据类型   | 2023.12.25 |  
除此之外，TuGraph-DB搭建了较为完善的质量体系，涵盖自动化的单元测试、集成测试、性能测试等。  
更详细的描述可以在源码目录在的 ""[root]/release/CHANGELOG.md"" 文件查看。' metadata={'Header 1': '技术规划', 'Header 2': '2. 已完成功能'}"
在删除边的全文索引时，如果边标签或字段不存在会抛出什么异常？,"page_content='业务开发指南

边类型操作

边类型删除索引

如下例子，对于边类型`edge1`，删除字段`field1`上的索引。
```
CALL db.deleteEdgeIndex('edge1', 'field1')
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型删除索引'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.deleteLabel(label_type, label_name)

Delete a vertex or edge label.  
**Parameters:**  
| parameter  | parameter type | description           |
| ---------- | -------------- | ------------------------- |
| label_type | string     | either 'vertex' or 'edge' |
| label_name | string     | name of the label     |  
**Output:**  
| field_name | field_type | description              |
| ---------- | ---------- | -------------------------------- |
| affected   | integer    | number of vertexes/edges deleted |  
**Example input:**  
```
CALL db.deleteLabel('vertex', 'Person')
```  
**Example output:**  
| affected |
| -------- |
| 1024     |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.deleteLabel(label_type, label_name)'}","page_content='业务开发指南

边类型操作

边类型删除字段

>该操作会同步变更所有该类型边的属性数据，数据量大的时候，有时间消耗。  
如下操作，对于边类型`edge1`，一次删除了两个字段: `field1` 和 `field2`。
```
CALL db.alterLabelDelFields('edge', 'edge1', ['field1', 'field2'])
```' metadata={'Header 1': '业务开发指南', 'Header 2': '边类型操作', 'Header 3': '边类型删除字段'}"
Grafana主要用于什么？,"page_content='运维监控

1.设计思路

1.4.Grafana

Grafana是一个开源的可视化和分析软件，它可以从包含Prometheus在内的多个数据源中获取数据，并且可以将时序数据库中的数据转换为精美图形和可视化效果的工具。具体信息请参考官网: [https://grafana.com/docs/grafana/v7.5/getting-started/](https://grafana.com/docs/grafana/v7.5/getting-started/)' metadata={'Header 1': '运维监控', 'Header 2': '1.设计思路', 'Header 3': '1.4.Grafana'}","page_content='运维监控

2.部署方案

2.4.第四步

+ 下载符合您机器架构以及系统版本的Grafana安装包，下载地址: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)  
+ 安装Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 启动Grafana，细节请参考: [ https://grafana.com/docs/grafana/v7.5/installation/]( https://grafana.com/docs/grafana/v7.5/installation/)  
+ 配置Grafana，首先在数据源设置中配置Prometheus的IP地址，配置完成后可以通过测试连接功能，验证是否成功连接数据源。然后，导入如下模版，并在页面中根据实际情况，修改正确的接口IP和端口。最后可以根据实际情况设置刷新时间和监控时间范围  
```json
{
""annotations"": {
""list"": [
{
""builtIn"": 1,
""datasource"": {
""type"": ""grafana""
},
""enable"": true,
""hide"": true,
""iconColor"": ""rgba(0, 211, 255, 1)"",
""name"": ""Annotations & Alerts"",
""target"": {
""limit"": 100,
""matchAny"": false,
""tags"": [],
""type"": ""dashboard""
},
""type"": ""dashboard""
}
]
},
""editable"": true,
""fiscalYearStartMonth"": 0,
""graphTooltip"": 0,
""id"": 2,
""links"": [],
""liveNow"": false,
""panels"": [
{
""datasource"": {
""type"": ""prometheus""
},
""fieldConfig"": {
""defaults"": {
""color"": {
""mode"": ""palette-classic""
},
""custom"": {
""hideFrom"": {
""legend"": false,
""tooltip"": false,
""viz"": false
}
},
""mappings"": [],
""unit"": ""kbytes""
},
""overrides"": [
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""D {__name__=\""resources_report\"", instance=\""localhost:7010\"", job=\""TuGraph\"", resouces_type=\""memory\"", type=\""available\""}""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-green"",
""mode"": ""fixed""
}
},
{
""id"": ""displayName"",
""value"": ""others""
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""others""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-blue"",
""mode"": ""fixed""
}
}
]
},
{
""matcher"": {
""id"": ""byName"",
""options"": ""graph_used""
},
""properties"": [
{
""id"": ""color"",
""value"": {
""fixedColor"": ""light-orange"",
""mode"": ""fixed""
}
}
]
}
]
},
""gridPos"": {
""h"": 16,
""w"": 6,
""x"": 0,
""y"": 0
},
""id"": 14,
""options"": {
""displayLabels"": [
""name"",
""value""
],
""legend"": {
""displayMode"": ""table"",
""placement"": ""bottom"",
""values"": [
""percent"",
""value""
]
},
""pieType"": ""pie"",
""reduceOptions"": {
""calcs"": [
""lastNotNull""
],
""fields"": """",
""val' metadata={'Header 1': '运维监控', 'Header 2': '2.部署方案', 'Header 3': '2.4.第四步'}","page_content='运维监控

1.设计思路

可视化监控并不是TuGraph自身不可或缺的一部分，因此在设计时将可视化监控作为TuGraph周边生态中的一个应用，来减少和TuGraph数据库的耦合度，以及对于TuGraph自身的影响。TuGraph可视化监控采用目前最火热的开源解决方案，TuGraph Monitor + Prometheus + Grafana来实现。其中TuGraph Monitor作为TuGraph服务的客户端，通过TCP链接向TuGraph服务发起Procedure请求，TuGraph服务在接收到请求后收集自身所在机器的cpu，memory，disk，io，以及请求数量等指标的统计结果进行响应。TuGraph Monitor在接收到TuGraph响应的指标数据后，将数据包装成prometheus需要的格式，保存在内存中，等待Prometheus服务通过http请求获取。Prometheus服务会定期通过http请求从TuGraph Monitor获取封装好的请求数据，按照获取的时间保存在自己的时序数据库中。Grafana可以根据用户的配置，从Prometheus处获取某个时间段内的统计数据，并在web界面上绘制浅显易懂的图形来展示最终结果。整个请求链路中，都采用了主动获取，即PULL的模型，好处之一是它能最大限度的避免数据生产者和数据消费者之间的耦合度，使得开发更简单，好处之二是数据生产者不需要考虑数据消费者的数据处理能力，即使某个消费者的数据处理能力较弱，也不会因为生产者生产数据过快而压垮消费者。主动拉取模型的不足之处在于数据的实时性不够，但在这个场景中，数据并没有很高的实时性要求。' metadata={'Header 1': '运维监控', 'Header 2': '1.设计思路'}"
DeleteProcedure 函数是用来执行什么操作的？,"page_content='Java客户端

2.使用示例

2.10.删除存储过程

```java
String result = client.deleteProcedure(""CPP"", ""sortstr"", ""default"");
log.info(""loadProcedure : "" + result);
```
```
@param procedureType: the procedure type, currently supported CPP and PY
@param procedureName: procedure name
@param graph: the graph to query.
@return: the result of procedure execution
public boolean deleteProcedure(String procedureType, String procedureName, String graph) throws Exception
```
本接口支持在单机模式和HA模式下使用。其中，由于删除存储过程是写请求，HA模式下的client只能向leader发送删除存储过程请求。' metadata={'Header 1': 'Java客户端', 'Header 2': '2.使用示例', 'Header 3': '2.10.删除存储过程'}","page_content='Python客户端

3.RPC Client

3.10.删除存储过程

```python
ret, res = client.deleteProcedure(""CPP"", ""sortstr"", ""default"")
```
```
deleteProcedure(self: liblgraph_client_python.client, procedure_type: str, procedure_name: str, graph: str) -> (bool, str)
```
本接口支持在单机模式和HA模式下使用。其中，由于删除存储过程是写请求，HA模式下的client只能向leader发送删除存储过程请求。' metadata={'Header 1': 'Python客户端', 'Header 2': '3.RPC Client', 'Header 3': '3.10.删除存储过程'}","page_content='C++客户端

2.使用示例

2.10.删除存储过程

```C++
std::string str;
bool ret = client.DeleteProcedure(str, ""CPP"", ""test_plugin1"");
```
```
bool DeleteProcedure(std::string& result, const std::string& procedure_type,
const std::string& procedure_name, const std::string& graph = ""default"");
@param [out] result              The result.
@param [in]  procedure_type      the procedure type, currently supported CPP and PY.
@param [in]  procedure_name      procedure name.
@param [in]  graph               (Optional) the graph to query.
@returns True if it succeeds, false if it fails.
```
本接口支持在单机模式和HA模式下使用。其中，由于删除存储过程是写请求，HA模式下的client只能向leader发送删除存储过程请求。' metadata={'Header 1': 'C++客户端', 'Header 2': '2.使用示例', 'Header 3': '2.10.删除存储过程'}"
描绘 PairUniqueIndex 的钥匙生成形式是什么？,"page_content='数据导入

3.配置文件

3.1.配置文件格式

配置文件包含两部分：schema 和 files。`schema`部分定义 label，`files`部分描述要导入的数据文件。  
#### 3.1.1.关键字  
- schema (数组形式）
- label（必选，字符串形式）
- type（必选，值只能是 VERTEX 或者 EDGE）
- properties（数组形式，对于点必选，对于边如果没有属性可以不配置）
- name（必选，字符串形式）
- type （必选，BOOL，INT8，INT16，INT32，INT64，DATE，DATETIME，FLOAT，DOUBLE，STRING，BLOB）
- optional（可选，代表该字段可以配置，也可以不配置）
- index（可选，该字段是否需要建索引）
- unique（可选，该字段是否建索引，并且是 unique 类型的，即全局唯一）
- pair_unique（可选，该字段是否建索引，并且是 pari_unique 类型的，即两点间唯一，仅用于边索引）unique与pair_unique只能设置一个，同时设置并运行将会因为输入异常而终止
- primary (仅点配置，必选，主键字段，需指定一个 property，用来唯一确定一个点)
- temproal (仅边配置，可选，指定时间戳属性用于存储层排序)
- temporal_field_order (仅边配置，可选，默认为""ASC""，表示升序，也可配置为""DESC""，表示降序)
- constraints (仅边配置，可选，数组形式，起点和终点的 label，不配置或者为空代表不限制)
- detach_property (点边都可配置，可选，默认是`false`。`true` 代表属性数据单独存放，在内存不够，属性数据比较多的场景下可以减少io读放大)
- files （数组形式）
- path（必选，字符串，可以是文件路径或者目录的路径，如果是目录会导入此目录下的所有文件，需要保证有相同的 schema）
- header（可选，数字，头信息占文件起始的几行，没有就是 0）
- format（必须选，只能是 JSON 或者 CSV）
- label（必选，字符串）
- columns（数组形式）
- SRC_ID (特殊字符串，仅边有，代表这列是起始点数据)
- DST_ID (特殊字符串，仅边有，代表这列是目的点数据)
- SKIP  (特殊字符串，代表跳过这列数据)
- [property]
- SRC_ID (仅边配置，值是起始点标签)
- DST_ID (仅边配置，值是目的点标签)  
#### 3.1.2.索引长度
因为TuGraph对key的长度有限制，唯一索引不允许建立超过限制长度的索引，而非唯一索引会对超过长度限制的属性进行截断处理，并且在通过迭代器遍历非唯一索引时，拿到的key也是经过截断的，可能和预期不一致。针对不同类型的非唯一索引，截断长度是不同的。
##### 3.1.2.1.unique索引
unique索引是全局唯一的，该索引key的最大长度是480bytes。primary作为特殊的unique索引，因此最大key的长度也是480bytes，超过无法建立索引。
##### 3.1.2.2.pair_unique索引
pair_unique索引是指两点间唯一的索引，这种类型的索引只能创建于边的schema中，这种索引在用户指定的key后面加上了源点和目标点的vid，每个vid是5bytes长度。因此最大key的长度是470bytes，超过无法建立索引。
##### 3.1.2.3.非唯一索引
非唯一索引是指既没有设置unique为1，也没有设置pair_unique为1的索引，在TuGraph的实现中，此类索引一个key可能映射到多个值，为了加速查找和写入，在用户指定的key后面加上了一组vid或euid中的最大值。其中对于创建于点中的非唯一索引，key后面跟着vid，每个vid是5bytes长度，因此最大长度是475bytes。
对于创建于边中的非唯一索引，key后面跟着euid，每个euid是24bytes长度，因此最大长度是456bytes。索引key超过对应长度则会自动截断。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件', 'Header 3': '3.1.配置文件格式'}","page_content='TuGraph图模型说明

1. 数据模型

1.3. 索引

TuGraph支持对点或边的属性创建索引，以提升查询效率。其特点如下：
- 索引包括普通索引和组合索引，普通索引基于一个点或边的一个属性创建，而组合索引基于一个点或边的多个属性创建（不超过16个），可以对同一点或边的多个（组）属性创建索引。
- 如果为点标签创建了唯一索引，在修改该标签的点时，会先执行数据完整性检查，以确保该索引的唯一性。
- BLOB类型的属性不能建立索引。  
TuGraph的点边均有多种索引类型，不同的索引类型的功能和限制不同，具体如下：  
#### 1.3.1 普通索引
##### 1.3.1.1 点索引
###### 1.3.1.1.1 unique索引  
点的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的点的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。
primary作为特殊的unique索引，因此最大key的长度也是480bytes。  
###### 1.3.1.1.2 non_unique索引  
点的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的点的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度是475bytes。
但是，不同于unique索引，超过475bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前475bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前475bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
##### 1.3.1.2 边索引  
###### 1.3.1.2.1 unique索引  
和点类似，边的unique索引指的是全局唯一的索引，即若一个属性设置了unique索引，在同一个图中，相同label的边的该属性不会存在相同的值，
unique索引key的最大长度是480bytes，**超过480bytes的属性不能建立unique索引**。  
###### 1.3.1.2.2 pair_unique索引  
pair_unique索引指的是两点间的唯一索引，即若一个属性设置了unique索引，在同一个图的同一组起点和终点之间，
相同label的边的该属性不会存在相同的值。为了保证pair_unique索引key在同一组起点和终点之间不重复，
索引在用户指定的key后面加上了起点和终点的vid，每个vid是5bytes长度。
因此最大key的长度是470bytes，**超过470bytes的属性不能建立pair_unique索引**。  
###### 1.3.1.2.3 non_unique索引  
和点类似，边的non_unique索引指的是非全局唯一的索引，即若一个属性设置了non_unique索引，
在同一个图中，相同label的边的该属性可以存在相同的值。
由于non_unique索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组eid的最大值。
每个eid是24bytes长度，因此non_unique索引key最大长度是456bytes。
但是，不同于unique索引，超过456bytes也可以建立non_unique索引。
只不过在对这样的属性建立索引时会只截取**前456bytes**作为索引key（属性本身存储的值不受影响）。
并且，在通过迭代器遍历时，也是先自动截取查询值的前456bytes再进行遍历，
所以结果可能和预期不一致，需要用户再过滤。  
#### 1.3.2 组合索引  
目前只支持对点的多个属性建立组合索引，不支持对边的属性建立组合索引。组合索引支持唯一索引和非唯一索引两种类型，建立索引的要求如下：
1. 建立组合索引的属性个数在2到16个之间（含）
2. 唯一组合索引的属性长度之和不能超过480-2*(属性个数-1)字节，非唯一组合索引的属性长度之和不能超过475-2*(属性个数-1)字节  
##### 1.3.2.1 唯一索引  
和点的普通唯一索引类似，点的组合唯一索引指的是全局唯一的索引，即若一组属性设置了unique索引，
在同一个图中，相同label的点的该组属性不会存在相同的值。
由于底层存储设计，组合索引key需要保存属性的长度，因此，
组合唯一索引key的最大长度是480-2*(属性个数-1) bytes，**超过的属性不能建立唯一索引**。  
##### 1.3.2.2 非唯一索引  
和点的普通非唯一索引类似，点的非唯一索引指的是非全局唯一的索引，即若一组属性设置了非唯一索引，
在同一个图中，相同label的点的该组属性可以存在相同的值。
由于非唯一索引一个key可能映射到多个值，为了加速查找和写入，
在用户指定的key后面加上了索引key相同的一组vid的最大值。
每个vid是5bytes长度，因此non_unique索引key最大长度' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.3. 索引'}","page_content='Cypher API

5.附录2. 内置procedures列表

* db.subgraph()

**Scope:** whole instance.  
**Parameters:**  
| parameter  | parameter type | description                                                           |
| ---------- | -------------- | --------------------------------------------------------------------- |
| vids       | list           | list of vertex id                                                     |  
**Output:**  
Get a json containing all the properties of nodes and relationships.  
**Example input:**  
```
CALL db.subgraph([3937,4126,4066,4010])
```  
**Example output**  
| subgraph |
| -------- |
| {""nodes"":[{""identity"":3937,""label"":""movie"",""properties"":{""duration"":136,""id"":1,""poster_image"":""http://image.tmdb.org/t/p/w185/gynBNzwyaHKtXqlEKKLioNkjKgN.jpg"",""rated"":""R"",""summary"":""Thomas A. Anderson is a man living two lives. By day he is an average computer programmer and by night a malevolent hacker known as Neo who finds himself targeted by the police when he is contacted by Morpheus a legendary computer hacker who reveals the shocking truth about our reality."",""tagline"":""Welcome to the Real World."",""title"":""The Matrix""}},{""identity"":4010,""label"":""user"",""properties"":{""id"":44,""login"":""Howard""}},{""identity"":4066,""label"":""user"",""properties"":{""id"":202,""login"":""Enoch""}},{""identity"":4126,""label"":""user"",""properties"":{""id"":464,""login"":""Wilburn""}}],""relationships"":[{""dst"":4126,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4010,""temporal_id"":0},{""dst"":4010,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4066,""temporal_id"":0},{""dst"":4066,""forward"":true,""identity"":0,""label"":""is_friend"",""label_id"":3,""src"":4126,""temporal_id"":0}]} |' metadata={'Header 1': 'Cypher API', 'Header 2': '5.附录2. 内置procedures列表', 'Header 3': '* db.subgraph()'}"
在上述文本中，类FieldData用于表示哪些类型的数据？,"page_content='空间数据类型在TuGraph-DB中的实现

空间数据类型的表示

空间数据类型可以用不同的坐标系来表示，EPSG<sup>[1]</sup>是一个标准化的地理空间参考系统标识符集合， 用于标识不同的地理空间参考系统，包括坐标系统、地理坐标系、投影坐标系等。通常使用EPSG编码表示数据的坐标系。行业内一般采用  
-   •WGS84坐标系（没错，就是GPS系统的坐标系），标识符为EPSG 4326  
-   •Cartesian（笛卡尔）坐标系（没错，就是你高中数学学的直角坐标系），标识符为EPSG 7203  
WGS84是全球定位系统(GPS)的基础，允许全球的GPS接收器确定精确位置。几乎所有现代GPS设备都是基于WGS84坐标系来提供位置信息。在地图制作和GIS（地图制作和地理信息系统）领域，WGS84被广泛用于定义地球上的位置。这包括各种类型的地图创建、空间数据分析和管理等。  
Cartesian（笛卡尔）坐标系，又称直角坐标系，是一种最基本、最广泛应用的坐标系统。它通过两条数轴定义一个平面，三条数轴定义一个空间，这些轴互相垂直，在数学、物理、工程、天文和许多其他领域中有着广泛的应用。' metadata={'Header 1': '空间数据类型在TuGraph-DB中的实现', 'Header 2': '空间数据类型的表示'}","page_content='TuGraph图模型说明

1. 数据模型

1.2. 数据类型

TuGraph支持多种可用于属性的数据类型。具体支持的数据类型如下：  
| **数据类型** | **最小值**          | **最大值**          | **描述**                            |
| ------------ | ------------------- | ------------------- | ----------------------------------- |
| BOOL         | false               | true                | 布尔值                              |
| INT8         | -128                | 127                 | 8位整型                          |
| INT16        | -32768              | 32767               | 16位整型                         |
| INT32        | - 2^31              | 2^31 - 1            | 32位整型                         |
| INT64        | - 2^63              | 2^63 - 1            | 64位整型                         |
| DATE         | 0000-00-00          | 9999-12-31          | ""YYYY-MM-DD"" 格式的日期             |
| DATETIME     | 0000-00-00 00:00:00.000000 | 9999-12-31 23:59:59.999999 | ""YYYY-MM-DD HH:mm:ss[.ffffff]"" 格式的日期时间 |
| FLOAT        |                     |                     | 32位浮点数                       |
| DOUBLE       |                     |                     | 64位浮点数                       |
| STRING       |                     |                     | 不定长度的字符串                    |
| BLOB         |                     |                     | 二进制数据（在输入输出时使用Base64编码） |
| POINT        |                     |                     | EWKB格式数据，表示点              |
| LINESTRING   |                     |                     | EWKB格式数据，表示线              |
| POLYGON      |                     |                     | EWKB格式数据，表示面(多边形)       |
| FLOAT_VECTOR |                     |                     | 包含32位浮点数的动态向量               |' metadata={'Header 1': 'TuGraph图模型说明', 'Header 2': '1. 数据模型', 'Header 3': '1.2. 数据类型'}","page_content='地理空间数据类型使用示例

5. 美食探索

5.2 数据模型设计

我们首先定义两种核心节点类型：  
- Food（美食）节点：每一家餐厅或小吃店都可以作为一个Food节点，其属性包括但不限于名称、地址、评分、美食类别等。特别地，我们将在每个Food节点上附加地理坐标信息，用以精确记录其地理位置。  
```
CALL db.createVertexLabel('food', 'id', 'id', int64, false, 'name', string, true,'pointTest',point,true,'mark',double,true)
```  
准备数据：  
```
CREATE (n:food {id:10001, name: 'Starbucks',pointTest:point(1.0,1.0,7203),mark:4.8}) RETURN n
CREATE (n:food {id:10002, name: 'KFC',pointTest:point(2.0,1.0,7203),mark:4.5}) RETURN n
CREATE (n:food {id:10003, name: 'Pizza Hut',pointTest:point(2.0,5.0,7203),mark:4.5}) RETURN n
CREATE (n:food {id:10004, name: 'Taco Bell',pointTest:point(3.0,4.0,7203),mark:4.7}) RETURN n
CREATE (n:food {id:10005, name: 'Pizza Fusion',pointTest:point(5.0,3.0,7203),mark:4.9}) RETURN n
CREATE (n:food {id:10006, name: 'HaiDiLao Hot Pot',pointTest:point(2.0,2.0,7203),mark:4.8}) RETURN n
CREATE (n:food {id:10007, name: 'Lao Sze Chuan',pointTest:point(4.0,3.0,7203),mark:4.7}) RETURN n
```  
- Person（人物）节点：代表应用的用户，属性包含用户名、当前位置等。用户的当前位置同样通过地理坐标表示，便于后续的地理空间查询。  
```
CALL db.createVertexLabel('person', 'id', 'id', int64, false, 'name', string, true,'pointTest',point,true)
```  
准备数据：  
```
CREATE (n:person {id:1, name: 'Tom',pointTest:point(3.0,3.0,7203)}) RETURN n
```' metadata={'Header 1': '地理空间数据类型使用示例', 'Header 2': '5. 美食探索', 'Header 3': '5.2 数据模型设计'}"
在线全量导入TuGraph时，如果发生数据包错误，默认行为是什么？,"page_content='数据导入

5.在线增量导入

在线导入模式可用于将一批文件导入已在运行中的 TuGraph 实例中。这对于处理通常以固定的时间间隔进行的增量批处理更新非常便利。`lgraph_import --online true`选项使导入工具能够在线模式工作。与`离线模式`一样，在线模式有自己的命令行选项集，可以使用`-h，--help`选项进行打印输出：  
```shell
$ lgraph_import --online true -h
Available command line options:
--online            Whether to import online.
-h, --help          Print this help message. Default=0.

Available command line options:
--log               Log file to use, empty means stderr. Default="""".
-v, --verbose       Verbose level to use, higher means more verbose.
Default=1.
-c, --config_file   Config file path.
-r, --url           DB REST API address.
-u, --username      DB username.
-p, --password      DB password.
-i, --continue_on_error
When we hit a duplicate uid or missing uid, should we
continue or abort. Default=0.
-g, --graph         The name of the graph to import into. Default=default.
--skip_packages     How many packages should we skip. Default=0.
--delimiter         Delimiter used in the CSV files
--breakpoint_continue
When the transmission process is interrupted,whether
to re-transmit from zero package next time. Default=false
-h, --help          Print this help message. Default=0.
```  
文件的相关配置在配置文件中指定，其格式与`离线模式`完全相同。但是，我们现在不是将数据导入本地数据库，而是将数据发送到正在运行的 TuGraph 实例中，该实例通常运行在与运行导入工具的客户端计算机不同的计算机上。因此，我们需要指定远程计算机的 HTTP 地址的URL、DB用户和密码。  
如果用户和密码有效，并且指定的图存在，导入工具将将数据发送到服务器，服务器随后解析数据并将其写入指定的图。数据将以大约 16MB 大小的包发送，在最近的换行符处中断。每个包都是以原子方式导入的，这意味着如果成功导入包，则成功导入所有数据，否则，任何数据都不会进入数据库。如果指定了`--continue_on_error true`，则忽略数据完整性错误，并忽略违规行。否则，导入将在第一个错误包处停止，并打印出已导入的包数。在这种情况下，用户可以修改数据以消除错误，然后使用`--skip_packages N`重做导入以跳过已导入的包。' metadata={'Header 1': '数据导入', 'Header 2': '5.在线增量导入'}","page_content='数据导入

4.离线全量导入

离线模式只能在离线状态的服务器使用。离线导入会创建一张新图，因此更适合新安装的 TuGraph 服务器上的第一次数据导入。
要在离线模式下使用`lgraph_import`工具，可以指定`lgraph_import --online false`选项。要了解可用的命令行选项，请使用`lgraph_import --online false --help`：  
```shell
$ ./lgraph_import --online false -help
Available command line options:
--log               Log file to use, empty means stderr. Default="""".
-v, --verbose       Verbose level to use, higher means more verbose.
Default=1.
...
-h, --help          Print this help message. Default=0.
```  
命令行参数：  
- **-c, --config_file** `config_file`: 导入配置文件名，其格式要求见下述。
- **--log** `log_dir`: 日志目录。默认为空字符串，此时将日志信息输出到控制台。
- **--verbose** `0/1/2`: 日志等级，等级越高输出信息越详细。默认为 1。
- **-i, --continue_on_error** `true/false`: 在碰到错误时跳过错误并继续，默认为 false，碰到错误立即退出。
- **-d, --dir** `{diretory}`: 数据库目录，导入工具会将数据写到这个目录。默认为`./db`。
- **--delimiter** `{delimiter}`: 数据文件分隔符。只在数据源是 CSV 格式时使用，默认为`"",""`。
- **-u, --username** `{user}`: 数据库用户名。需要是管理员用户才能执行离线导入。
- **-p, --password** `{password}`: 指定的数据库用户的密码
- **--overwrite** `true/false`: 是否覆盖数据。设为 true 时，如果数据目录已经存在，则覆盖数据。默认为`false`。
- **-g, --graph** `{graph_name}`: 指定需要导入的图种类。
- **-h, --help**: 输出帮助信息。' metadata={'Header 1': '数据导入', 'Header 2': '4.离线全量导入'}","page_content='数据导入

6.在线全量导入

6.2 从数据库文件导入

从原数据在线全量导入尽管操作简单、性能较高，但是对服务器资源要求较高，且耗时较长。
一种更加通用的方式是先使用离线导入在一个空db中导入子图，得到data.mdb文件，然后把该文件在线导入到
TuGraph服务中。其使用方式如下所示：  
```shell
$ ./lgraph_import --online true --online_type 2 -h
Available command line options:
--online            Whether to import online. Default=0.
--v3                Whether to use lgraph import V3. Default=1.
-h, --help          Print this help message. Default=0.

Available command line options:
--online_type       The type of import online, 0 for increment, 1 for full
import data,2 for full import file. Default=0.
-h, --help          Print this help message. Default=0.

Available command line options:
-r, --url           DB REST API address.
-u, --user          DB username.
-p, --password      DB password.
-g, --graph         The name of the graph to import into. Default=default.
--path              The path of data file.
--remote            Whether to download file from remote server. Default=0.
-h, --help          Print this help message. Default=0.
```  
除普通在线导入用到的url, user和password参数之外，从数据库文件导入的在线全量导入方式
使用graph参数指定导入的子图名称，path参数指定文件路径，remote指定文件存在在远程或者本地。
如果是本地文件，则需要保证HA集群中所有的节点在path路径下都有该文件。如果是远程文件，则会先下载再导入。
需要注意的是，由于data.mdb只有一份，需要保证HA的各个节点和离线导入生成data.mdb的机器的环境完全一致，
以保证不会出现环境问题。' metadata={'Header 1': '数据导入', 'Header 2': '6.在线全量导入', 'Header 3': '6.2 从数据库文件导入'}"
ORDER BY在GQL中有什么作用？,"page_content='内置算法

基础算法包

网页排序

网页排序程序实现了常用的Pagerank算法。该算法根据图中边和边权值计算所有点的重要性排名，PageRank值越高，表示该点在图中的重要性越高。计算时以点数量的倒数为各点初始Rank值，然后将点的Rank值按照出边平均传递到相邻点，重复该传递过程直到满足给定的收敛阈值或达到给定迭代轮数。每轮传递结束后，所有点的Rank值会有一定的的比例随机传递到任意点上。算法内容请参考 [https://en.wikipedia.org/wiki/PageRank](https://en.wikipedia.org/wiki/PageRank ""pagerank wiki"")。' metadata={'Header 1': '内置算法', 'Header 2': '基础算法包', 'Header 3': '网页排序'}","page_content='为什么使用图进行关联运算比表Join更具吸引力？

关系模型并不适合处理关系

痛点三：复杂关系查询难以描述

使用表建模的分析系统只支持SQL join一种方式进行关系分析，这在复杂场景中能力十分局限。 比如查询一个人4度以内所有好友，或者查询最短路径等，这些复杂关联关系通过SQL表的join方式很难描述。  
GeaFlow提供融合GQL和SQL样式的查询语言，这是一种图表一体的数据分析语言，继承自标准SQL+ISO/GQL，可以方便进行图表分析。  
![code_style](../../static/img/code_style.jpg)
<center>图3</center>  
**在融合DSL中，图计算的结果与表查询等价，都可以像表数据一样做关系运算处理。**这意味着图3中GQL和SQL两种描述都可以达到类似的效果，极大灵活了用户的查询表达能力。  
GeaFlow DSL引擎层还将支持SQL中的Join自动转化为GQL执行，用户可以自由混用SQL和GQL样式查询，同时做图匹配、图算法和表查询。' metadata={'Header 1': '为什么使用图进行关联运算比表Join更具吸引力？', 'Header 2': '关系模型并不适合处理关系', 'Header 3': '痛点三：复杂关系查询难以描述'}","page_content='内置算法

扩展算法包

个性化网页排序

个性化网页排序程序实现了Personalized PageRank算法。该算法根据给定的源点，基于该源点个性化计算所有点对于源点的重要性排名。Rank值越高，表示该点对于源点越重要。与PageRank不同的是，初始化时源点Rank值为1，其余点Rank值为0；并且每轮传递结束后，Rank值会有一定的比例随即传递回源点。算法内容请参考 [https://cs.stanford.edu/people/plofgren/Fast-PPR_KDD_Talk.pdf](https://cs.stanford.edu/people/plofgren/Fast-PPR_KDD_Talk.pdf)。' metadata={'Header 1': '内置算法', 'Header 2': '扩展算法包', 'Header 3': '个性化网页排序'}"
TuGraph-DB是否有http的接口？对应的接口代码在哪里？,"page_content='RESTful API Legacy

1.简介

TuGraph 提供遵从 REST 规范的 HTTP API，以供开发者通过 HTTP 请求远程调用 TuGraph 提供的服务。  
本文档描述 TuGraph 的 HTTP API 使用方式。  
**注意：除""登陆""、""查询""和""存储过程""外，其余接口自 **2023年4月30日** 起将不再提供支持，统一使用Cypher接口提供服务。**' metadata={'Header 1': 'RESTful API Legacy', 'Header 2': '1.简介'}","page_content='可视化操作手册

2.操作指南

2.1.访问

当用户完成图数据库的安装后，可以通过浏览器访问Browser。用户只需要在浏览器地址栏输入：TuGraph 所在服务器的 IP:Port。默认的端口使用的是 7070。  
- 例如：127.0.0.1:7070。
- 推荐使用Chrome。' metadata={'Header 1': '可视化操作手册', 'Header 2': '2.操作指南', 'Header 3': '2.1.访问'}","page_content='TuGraph DB BROWSER

启动TuGraph DB Browser

TuGraph DB BROWSER 是 TuGraph 图数据库的可视化平台。可以完成图谱、模型、数据等的创建和导入。同时可用使用 TuGraph Cypher 进行数据的操作。  
0. 环境准备  
- node.js >= 16  
1. 安装项目依赖  
```bash
npm install --force
```  
2. 本地研发  
```bash
npm run dev
```  
浏览器访问 http://localhost:8000  
3. 编译构建  
```bash
npm run build
```' metadata={'Header 1': 'TuGraph DB BROWSER', 'Header 2': '启动TuGraph DB Browser'}"
请问lgraph_peer工具是只有编译方式部署后才有吗？,"page_content='命令行工具

1.单命令模式

在单命令模式下，`lgraph_cypher`可用于提交单个 Cypher 查询并将结果直接打印到终端，打印结果也可以容易地重定向写入指定文件。当用户需要从服务器获取大量结果并将其保存在文件中时，这非常便利。
在此模式下，`lgraph_cypher`工具具有以下选项：' metadata={'Header 1': '命令行工具', 'Header 2': '1.单命令模式'}","page_content='数据导入

3.配置文件

`lgraph_import`工具通过指定的配置文件进行环境配置。配置文件描述输入文件的路径、它们所代表的点/边以及点/边的格式。' metadata={'Header 1': '数据导入', 'Header 2': '3.配置文件'}","page_content='Procedure API

5.Procedure v2接口

5.1.编写存储过程

用户可以通过使用 lgraph API 来编写 C++ 存储过程。一个简单的 C++ 存储过程举例如下：  
```c++
// peek_some_node_salt.cpp
#include <cstdlib>
#include ""lgraph/lgraph.h""
#include ""lgraph/lgraph_types.h""
#include ""lgraph/lgraph_result.h""

#include ""tools/json.hpp""

using json = nlohmann::json;
using namespace lgraph_api;

extern ""C"" LGAPI bool GetSignature(SigSpec &sig_spec) {
sig_spec.input_list = {
{.name = ""limit"", .index = 0, .type = LGraphType::INTEGER},
};
sig_spec.result_list = {
{.name = ""node"", .index = 0, .type = LGraphType::NODE},
{.name = ""salt"", .index = 1, .type = LGraphType::FLOAT}
};
return true;
}

extern ""C"" LGAPI bool ProcessInTxn(Transaction &txn,
const std::string &request,
Result &response) {
int64_t limit;
try {
json input = json::parse(request);
limit = input[""limit""].get<int64_t>();
} catch (std::exception &e) {
response.ResetHeader({
{""errMsg"", LGraphType::STRING}
});
response.MutableRecord()->Insert(
""errMsg"",
FieldData::String(std::string(""error parsing json: "") + e.what()));
return false;
}

response.ResetHeader({
{""node"", LGraphType::NODE},
{""salt"", LGraphType::FLOAT}
});
for (size_t i = 0; i < limit; i++) {
auto r = response.MutableRecord();
auto vit = txn.GetVertexIterator(i);
r->Insert(""node"", vit);
r->Insert(""salt"", FieldData::Float(20.23*float(i)));
}
return true;
}
```  
从代码中我们可以看到：
- 存储过程定义了一个获取签名的方法`GetSignature`。该方法返回了存储过程的签名，其中包含输入参数名称及其类型，返回参数及其类型。这使得Cypher查询语句在调用存储过程能够利用签名信息校验输入数据以及返回数据是否合理。
- 入口函数是`ProcessInTxn`函数，它的参数有三个，分别为：  
- `txn`: 存储过程所处的事务，通常来说即调用该存储过程的Cypher语句所处事务。
- `request`: 输入数据，其内容为`GetSignature`中定义的输入参数类型及其Cypher查询语句中传入的值经过json序列化后的字符串。e.g. `{num_iteration: 10}`
- `response`: 输出数据，为保证在Cypher语言中能够兼容，用户可以通过往`lgraph_api::Result` 写入存储过程处理后的数据，最后用`lgraph_api::Result::Dump`来序列化成json格式的数据。  
`ProcessInTxn`函数的返回值是一个布尔值。当它返回`true`的时候，表示该请求顺利完成，反之表示这个存储过程在执行过程中发现了错误。  
C++存储过程编写完毕后需要编译成动态链接库。TuGraph 提供了`compile.sh`脚本来帮助用户自动编译存储过程。`compile.sh`脚本只有一个参数，是该存储过程的名称，在上面的例子中就是`custom_pagerank`。编译调用命令行如下：  
```bash
g++ -fno-gnu-unique -fPIC -g --std=c++14 -I/usr/local/include/lgraph -rdynamic -O3 -fopenmp -o custom_pagerank.so custom_pagerank.cpp /usr/local/lib64/liblgraph.so -shared
```  
如果编译顺利，会生成 custom_pagerank.so，然后用户就可以将它加载到服务器中了。' metadata={'Header 1': 'Procedure API', 'Header 2': '5.Procedure v2接口', 'Header 3': '5.1.编写存储过程'}"
当前图数据库应用程序使用的CPU比率是多少？,"page_content='TuGraph与ARM架构

内容：

**背景介绍：**

在高速信息化的21世纪，计算机软硬件均经历着翻天覆地的变化，从Intel和AMD的x86 CPU架构到ARM RISC精简指令CPU，内存也演进出超高带宽内存HBM、非易失内存NVM。近年来基于ARM架构的CPU越来越普遍，在手机中ARM芯片已占90%以上份额，个人PC中苹果M1/M2均采用ARM架构，在服务器领域华为鲲鹏、飞腾等ARM架构CPU也逐步被接纳。本次测试使用的倚天710，是阿里基于ARMv9架构自研的CPU，已在阿里云服务中大规模部署，成为中国首个云上大规模应用的自研CPU。  
数据库作为底层系统软件，面对CPU的更新换代也迎来了更多的挑战和机遇。在ARM架构中，CPU通常拥有更多的核数、更低的能耗、更高的性价比。作为拥抱开源的图数据库产品，TuGraph不仅需要兼容新型硬件，更需要充分发挥出新硬件的功能和性能优势。适配和测试工作包括超多线程的支持、更加细致的负载均衡策略、并发读写性能优化等。  
**本次测试机构国际关联数据基准委员会LDBC是由高校、研究所、企业联合组成的非盈利组织，其中企业成员包括Intel、Oracle、Neo4j、蚂蚁集团等国内外知名图数据厂商，致力于推进图数据的规范标准化。**本次测试使用的图数据来自LDBC的社交网络运营场景SNB（Social Network Benchmark），LDBC SNB的图数据是一个包含14类顶点和20类边的属性图，用户可以指定scale factor生成不同规模的数据。LDBC SNB的交互式工作负载由14个复杂的只读查询、7个简单的只读查询和8个事务型更新查询组成。' metadata={'Header 1': 'TuGraph与ARM架构', 'Header 2': '内容：', 'Header 3': '**背景介绍：**'}","page_content='TuGraph产品架构

1.简介

![产品架构](../../../images/architecture.png)  
上图从功能模块的角度，以 TuGraph 为例，给出了企业级图数据库的整体架构，自下而上包括：  
- 软硬件环境。涉及图数据库的开发和使用环境。TuGraph 主要基于底层的 C++语言开发，能够兼容市面上大部分操作系统和 CPU。
- 存储层，包括 KV 存储层和图存储层。存储层需要支持计算层所需的各个功能。
- 计算层。计算层应包括图事务引擎、图分析引擎和图神经网络引擎，也包含了服务端提供的多种编程接口，包括描述式查询语言 Cypher，存储过程等。
- 客户端。客户端 SDK 应支持 Java、Python、C++ 等多种语言，也支持命令行的交互方式。Browser 和 Explorer 通过网页端交互的方式，降低了图数据库的使用门槛。
- 在生态工具方面，覆盖了企业级图数据库的开发、运维、管理等链路，提升可用性。' metadata={'Header 1': 'TuGraph产品架构', 'Header 2': '1.简介'}","page_content='性能优先

1.简介

TuGraph目前是世界上最快的图数据库，在图数据库标准评测LDBC SNB Interactive位居榜首（2023.3）。TuGraph的设计基于性能优先，致力于打造高性能的单机图数据库。该文档是TuGraph基于性能优先在存储层的核心设计。' metadata={'Header 1': '性能优先', 'Header 2': '1.简介'}"
